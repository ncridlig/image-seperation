{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE7oyG0wv6e0"
   },
   "source": [
    "# Separation of CIFAR-10 Images\n",
    "\n",
    "The model takes as input an image created by averaging two random samples from CIFAR-10 and is tasked with predicting the categories of the two components.\n",
    "\n",
    "**For sure it is a computer vision model.**\n",
    "\n",
    "The first image belongs to the first five categories (airplane, automobile, bird, cat, deer), while the second belongs to the remaining categories (dog, frog, horse, ship, truck). The model must return two labels, each within a range of five possible values.\n",
    "\n",
    "**(5->1, 5->1)**\n",
    "\n",
    "The evaluation metric for the model is as follows: calculate the classification accuracy for the two component images and then compute their average.\n",
    "\n",
    "**accuracy = acc1 + acc2 / 2**\n",
    "**where acc1 = (correct1/total) and acc2 = (correct2/total)**\n",
    "\n",
    "The metric should be evaluated on 10,000 inputs generated from test data. Repeat the calculation 10 times and measure the standard deviation, which must be reported.\n",
    "\n",
    "A data generator and some examples are provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USdmzjiO0W6D"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iHjnh5XP0Sq4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.nn import fractional_max_pool\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.saving import load_model, save_model, save_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRYiW2ipukZF",
    "outputId": "0d5c8981-51da-4c92-de73-84bcac11aa2c"
   },
   "outputs": [],
   "source": [
    "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
    "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
    "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
    "assert cifar10_y_train.shape == (50000, 1)\n",
    "assert cifar10_y_test.shape == (10000, 1)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "cifar10_x_train, cifar10_x_val, cifar10_y_train, cifar10_y_val = train_test_split(\n",
    "    cifar10_x_train, cifar10_y_train, test_size=0.1\n",
    ")\n",
    "\n",
    "# First classifier: \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\"\n",
    "# Second classifier: \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "# IDEA: extract the features with a CNN backbone and feed them to two seperate FCN classifiers. How about backpropogation?\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Normalizing to range (0,1)\n",
    "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
    "cifar10_x_val = (cifar10_x_val / 255.).astype(np.float32)\n",
    "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkiGnU4d0k4d"
   },
   "source": [
    "Let us split the images in two groups, according to their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Dpey42Vo07Yb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22513, 32, 32, 3) (22513, 1)\n",
      "(22487, 32, 32, 3) (22487, 1)\n",
      "(2487, 32, 32, 3) (2487, 1)\n",
      "(2513, 32, 32, 3) (2513, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "cond_1 = cifar10_y_train[:,0] < 5\n",
    "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
    "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
    "\n",
    "cond_2 = cifar10_y_train[:,0] >= 5\n",
    "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
    "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
    "\n",
    "cond_1_val = cifar10_y_val[:,0] < 5\n",
    "cifar10_x_val_1 = cifar10_x_val[cond_1_val]\n",
    "cifar10_y_val_1 = cifar10_y_val[cond_1_val]\n",
    "\n",
    "cond_2_val = cifar10_y_val[:,0] >= 5\n",
    "cifar10_x_val_2 = cifar10_x_val[cond_2_val]\n",
    "cifar10_y_val_2 = cifar10_y_val[cond_2_val]\n",
    "\n",
    "cond_1_test = cifar10_y_test[:,0] < 5\n",
    "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
    "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
    "\n",
    "cond_2_test = cifar10_y_test[:,0] >= 5\n",
    "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
    "cifar10_y_test_2 = cifar10_y_test[cond_2_test]\n",
    "\n",
    "print(cifar10_x_train_1.shape, cifar10_y_train_1.shape)\n",
    "print(cifar10_x_train_2.shape, cifar10_y_train_2.shape)\n",
    "print(cifar10_x_val_1.shape, cifar10_y_val_1.shape)\n",
    "print(cifar10_x_val_2.shape, cifar10_y_val_2.shape)\n",
    "print(cifar10_x_test_1.shape, cifar10_y_test_1.shape)\n",
    "print(cifar10_x_test_2.shape, cifar10_y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmLYNuR-0s0m"
   },
   "source": [
    "Now we can define the generator. The input consists of two datasets (X1,X2), their corresponding labels (Y1,Y2), and a batch size.\n",
    "\n",
    "**Model input: (B x X1\\*X2)**\n",
    "**Model output: (B x Y1 x Y2)**\n",
    "\n",
    "The generator returns (x_data,y_data), where:\n",
    "* x_data is a batch of images obtained by averaging random samples from X1 and X2.\n",
    "* y_data is a pair of batches of labels corresponding to the component images, expressed in categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "\n",
    "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
    "  size1 = X1.shape[0]\n",
    "  size2 = X2.shape[0]\n",
    "  # Convert the integer labels into one hot encoded vectors for cross entropy loss\n",
    "  # Careful: since there are two different sets of labels, I need to code two seperate outputs with seperate cross entropy losses\n",
    "  # Keras (TF) can handle this with: model = models.Model(inputs=merged_input_image, outputs=[output1, output2])\n",
    "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
    "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
    "\n",
    "  while True:\n",
    "    # Random image selections\n",
    "    num1 = np.random.randint(0, size1, batchsize)\n",
    "    num2 = np.random.randint(0, size2, batchsize)\n",
    "    # Average image production\n",
    "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
    "    # Dictionary for y_data with keys matching the model\n",
    "    y_data = {'output1': Y1_cat[num1], 'output2': Y2_cat[num2]}\n",
    "    # Convert numpy to tf tensor\n",
    "    yield tf.convert_to_tensor(x_data), y_data\n",
    "\n",
    "traingen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,batchsize)\n",
    "valgen = datagenerator(cifar10_x_val_1,cifar10_x_val_2,cifar10_y_val_1,cifar10_y_val_2,batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9lf3TuP2pdQ"
   },
   "source": [
    "\n",
    "Let us instantiate a generator on Cifar10 with batchsize=1, and let's see its behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "29TldJ6-720b"
   },
   "outputs": [],
   "source": [
    "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1DrJVzI3ysV"
   },
   "source": [
    "Let's generate an example, display the image that the model will take as input, and print the categories of the two overlapping components.\n",
    "\n",
    "You can re-run the cell to display new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "qL1sMtjG8VmG",
    "outputId": "5b9d6599-d407-4e32-dad7-f3f95890f0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: airplane, second = ship\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17e542280>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = next(datagen)\n",
    "\n",
    "print(\"first: {}, second = {}\".format(classes[np.argmax(y['output1'][0])],classes[np.argmax(y['output2'][0])+5]))\n",
    "#print(np.min(x[0]),np.max(x[0]))\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5lzBotwL5QN"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_p4UuG1QF8t"
   },
   "source": [
    "Let us define first of all the test generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQo8_6w-L4WY",
    "outputId": "a626a55c-7df8-456b-adcd-580d4166e184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
    "\n",
    "eval_samples_x, eval_samples_y = next(testgen)\n",
    "print(eval_samples_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MiLnkKROGCD"
   },
   "source": [
    "We now test a model producing random guesses. You will need to replace it with your own predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1GllTEtPN_xv"
   },
   "outputs": [],
   "source": [
    "def random_model(x):\n",
    "  #the random model ignores the input x and return a pair of random classes\n",
    "  # 10,000 examples in a 2 column array between 0 and 4 inclusive\n",
    "  return(np.random.randint(0,5,(10000,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gomFTuuDOy8A"
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "  eval_samples_x, eval_samples_y = next(testgen)\n",
    "  random_guesses = model(eval_samples_x)\n",
    "  correct_guesses_1 = random_guesses[:,0] == np.argmax(eval_samples_y['output1'],axis=1)\n",
    "  correct_guesses_2 = random_guesses[:,1] == np.argmax(eval_samples_y['output2'],axis=1)\n",
    "  return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4AL2M6yjJno",
    "outputId": "d84ecfb8-299f-4e37-85ee-c69b83a39e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20655"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(random_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7usBI88dje70"
   },
   "source": [
    "As expected, the accuracy is around 1/5 = 0.2\n",
    "\n",
    "Let us repeat the evaluation ten times, and compute the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFu8iEt9jdZA",
    "outputId": "93fa99f4-972a-4795-917b-b1db97dc7ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.199285\n",
      "standard deviation =  0.0022481158777963414\n"
     ]
    }
   ],
   "source": [
    "repeat_eval = 10\n",
    "eval_results = []\n",
    "for i in range(repeat_eval):\n",
    "  eval_results.append(eval_model(random_model))\n",
    "print(\"mean accuracy = \", np.mean(eval_results))\n",
    "print(\"standard deviation = \", np.std(eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1yTRAzn4i9g"
   },
   "source": [
    "# What to Submit\n",
    "\n",
    "As usual, you need to submit a single notebook that must be executable on Colab. The notebook should be properly commented and include a complete record of the training process, as well as the calculation of accuracy according to the guidelines provided above.\n",
    "\n",
    "# Good luck!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I googled CIFAR-10 best accuracy and I fell upon a reddit post about a person trying to train it as fast as possible, [here](https://github.com/tysam-code/hlb-CIFAR10). Since I am not interested in light speed CIFAR-10, I googled only CIFAR-10 and arrived to the main website for this [dataset](https://www.cs.toronto.edu/~kriz/cifar.html). From there, I found a non-working link to Rodrigo Benenson since github.com has been deprecated and is now github.io, changing this and selecting \"who is the best in CIFAR-10 ?\" brought me to the [world rankings](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130). Now I will read these papers in order. The first is [Fractional Max Pooling](https://arxiv.org/abs/1412.6071), with an accuracy of 96.53%. As I read this, I think, is my task the same? As a human, can I learn to distinguish the two classes? For sure, I will have to use the generator to see.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m130\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │           \u001b[38;5;34m820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m4,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m2,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │        \u001b[38;5;34m18,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,280</span> (110.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,280\u001b[0m (110.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,280</span> (110.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,280\u001b[0m (110.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define my fractional pooling model\n",
    "\n",
    "class FMP(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP, self).__init__()\n",
    "        # Input\n",
    "        #self.input_layer = layers.InputLayer(shape=(32, 32, 3))  # For CIFAR-10 images\n",
    "\n",
    "        # Four convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(10, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(20, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(30, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(40, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(50, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Three fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 3/2, 3/2, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 6/4, 6/4, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 10/7, 10/7, 1.0]\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        #self.dropout1 = layers.Dropout(0.0)  # 0% dropout in the first hidden layer\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Input\n",
    "        #x = self.input_layer(inputs)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv2(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv3(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "K.clear_session()\n",
    "model = FMP()\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n",
      "(45000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_cat_train = tf.keras.utils.to_categorical(cifar10_y_train, num_classes=10)\n",
    "Y_cat_test = tf.keras.utils.to_categorical(cifar10_y_test, num_classes=10)\n",
    "print(cifar10_x_train.shape)\n",
    "print(Y_cat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 549ms/step - accuracy: 0.1475 - loss: 2.2588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=1, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2547 - loss: 2.0465\n",
      "fmp Loss: 2.0488, Accuracy: 25.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25459998846054077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "def evaluate(model, x, y):\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    print(f\"{model.name} Loss: {loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing this, I feel like the convolutional layers would benefit from being more complex and so I use this [person's](https://github.com/WingsBrokenAngel/fractional_max_pooling_and_recurrent_convolutional_neural_network) filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,690</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m7,260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m21,690\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m43,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m18,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │        \u001b[38;5;34m54,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,820</span> (565.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m144,820\u001b[0m (565.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,820</span> (565.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,820\u001b[0m (565.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FMP1(Model):\n",
    "    def __init__(self, FILTERS):\n",
    "        super(FMP1, self).__init__()\n",
    "        # Parameters\n",
    "        self.filters = FILTERS\n",
    "\n",
    "        # Four convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(10*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(20*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(30*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(40*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(50*FILTERS, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Three fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 3/2, 3/2, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 6/4, 6/4, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 10/7, 10/7, 1.0]\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        #self.dropout1 = layers.Dropout(0.0)  # 0% dropout in the first hidden layer\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Input\n",
    "        #x = self.input_layer(inputs)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv2(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv3(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "#K.clear_session()\n",
    "model = FMP1(FILTERS=3)\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.1188 - loss: 2.5421\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=1, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2040 - loss: 2.1521\n",
      "fmp1 Loss: 2.1532, Accuracy: 20.36%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20360000431537628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decide to implement a network as similar as possible, now that I understand the architecture better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMP2(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP2, self).__init__()\n",
    "        # Input layer size 36x36\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU()) # 36x36 # comment left here to show how the first time I calculated them wrong, both by thinking the input is 36 when it is 32 and forgetting conv takes 1 \n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU()) # 25x25\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU()) # 18x18\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU()) # 13x13\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU()) # 9x9\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 6x6\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier \n",
    "        self.fc = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # CIFAR-10\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,930</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │         \u001b[38;5;34m1,930\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP2()\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.1003 - loss: 14.8851\n"
     ]
    }
   ],
   "source": [
    "Y_cat_train = tf.keras.utils.to_categorical(cifar10_y_train, num_classes=10)\n",
    "\n",
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=1, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1286 - loss: 2.3659\n",
      "fmp2 Loss: 2.3636, Accuracy: 12.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12549999356269836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without checkpoints or early stop, the model clearly overfit!\n",
    "\n",
    "Now I realize I forgot to read section 4.4 and implement that network! However, before, I try to move my network from the proxy task to the real one by adding a second classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP3(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP3, self).__init__()\n",
    "        # Input layer size 32x32\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU())\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Two Classifiers \n",
    "        self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        output1 = self.fc1(x)  # First half\n",
    "        output2 = self.fc2(x)  # Second half\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Serialize the configuration of the model\n",
    "        config = super(FMP3, self).get_config()\n",
    "        config.update({\n",
    "            'conv1': self.conv1.get_config(),\n",
    "            'conv2': self.conv2.get_config(),\n",
    "            'conv3': self.conv3.get_config(),\n",
    "            'conv4': self.conv4.get_config(),\n",
    "            'conv5': self.conv5.get_config(),\n",
    "            'conv6': self.conv6.get_config(),\n",
    "            'conv7': self.conv7.get_config(),\n",
    "            'conv8': self.conv8.get_config(),\n",
    "            'dropout': self.dropout.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "            'pooling_ratios': [\n",
    "                self.pooling_ratio1,\n",
    "                self.pooling_ratio2,\n",
    "                self.pooling_ratio3,\n",
    "                self.pooling_ratio4,\n",
    "                self.pooling_ratio5,\n",
    "                self.pooling_ratio6\n",
    "            ]\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP3()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [answer](https://stackoverflow.com/questions/55908188/this-model-has-not-yet-been-built-error-on-model-summary) with 39 upvotes explains why this summary is a bit strange (Keras subclasses Model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 3.2640 - output1_accuracy: 0.1915 - output2_accuracy: 0.1730\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.1825 - output1_accuracy: 0.3210 - output2_accuracy: 0.1944\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.2185 - output1_accuracy: 0.2629 - output2_accuracy: 0.2418\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.2213 - output1_accuracy: 0.3148 - output2_accuracy: 0.2314\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.1669 - output1_accuracy: 0.3013 - output2_accuracy: 0.2873\n"
     ]
    }
   ],
   "source": [
    "# Generate random dummy data (e.g., 100 samples, 32x32 RGB images)\n",
    "X_train = np.random.randn(100, 32, 32, 3).astype(np.float32)\n",
    "y_train1 = np.random.randint(0, 5, 100)  # Random labels for output 1\n",
    "y_train2 = np.random.randint(0, 5, 100)  # Random labels for output 2\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train1 = tf.keras.utils.to_categorical(y_train1, 5)\n",
    "y_train2 = tf.keras.utils.to_categorical(y_train2, 5)\n",
    "\n",
    "# Train the model directly using the data (no generator)\n",
    "history = model.fit(X_train, {'output1': y_train1, 'output2':y_train2}, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had a long and painful time figuring out why my generator was not working with fit. Finally I understood that the output of the generator must have a dictionary whose entries match those of the model when compiled!\n",
    "https://stackoverflow.com/questions/44036971/multiple-outputs-in-keras\n",
    "Before that I went down a rabbit hole with older versions of keras which require [fit_generator](https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/) because of a stack exchange [post](https://datascience.stackexchange.com/questions/67266/how-to-write-a-generator-for-keras-fit-generator).\n",
    "I read the keras documentation and confirmed that generators are in fact, [well supported](https://keras.io/api/models/model_training_apis/). This hinted to me that the generator would probably work for a simpler single input, single output model.\n",
    "I researched how to create [my own data generator class](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) that inherits from Keras Sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 98ms/step - loss: 3.0398 - output1_accuracy: 0.2971 - output2_accuracy: 0.3073\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(traingen, epochs=1, steps_per_epoch=len(cifar10_x_train)//batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training with [checkpoints](https://keras.io/api/callbacks/model_checkpoint/)! Its easy! Also add early stopping! I look at my history to verify the names of my scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.8955788612365723],\n",
       " 'output1_accuracy': [0.34895092248916626],\n",
       " 'output2_accuracy': [0.37237730622291565]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implement a custom model callback to save the model weights when the average accuracy improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback which does not use loss as a proxy!\n",
    "class MeanAccModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor1='output1_accuracy', monitor2='output2_accuracy', mode='max', verbose=1):\n",
    "        super(MeanAccModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor1 = monitor1\n",
    "        self.monitor2 = monitor2\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best_score = -float('inf') if mode == 'max' else float('inf')\n",
    "\n",
    "    # Called at the end of an epoch during training\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc1 = logs.get(self.monitor1)\n",
    "        acc2 = logs.get(self.monitor2)\n",
    "\n",
    "        # Compute the average accuracy\n",
    "        avg_accuracy = (acc1 + acc2) / 2 if acc1 is not None and acc2 is not None else None\n",
    "\n",
    "        if avg_accuracy is not None:\n",
    "            if (self.mode == 'max' and avg_accuracy > self.best_score) or \\\n",
    "               (self.mode == 'min' and avg_accuracy < self.best_score):\n",
    "                # Update the best score\n",
    "                self.best_score = avg_accuracy\n",
    "                \n",
    "                # Format the filepath\n",
    "                save_path = self.filepath.format(\n",
    "                    output1_accuracy=acc1,\n",
    "                    output2_accuracy=acc2,\n",
    "                    epoch=epoch + 1,  # Epoch is zero-indexed\n",
    "                    loss=logs.get('loss')\n",
    "                )\n",
    "                \n",
    "                # Save the model\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nEpoch {epoch + 1}: Average accuracy improved to {avg_accuracy:.4f}, saving model to {save_path}\")\n",
    "                self.model.save(save_path)\n",
    "            elif self.verbose:\n",
    "                print(f\"\\nEpoch {epoch + 1}: Average accuracy did not improve (current: {avg_accuracy:.4f}, best: {self.best_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to train more, but it bothers me that I am saving models based on loss, so lets write a custom callback which matches our evaluation criteria! I follow this page on [Callbacks](https://keras.io/guides/writing_your_own_callbacks/) and decide I also wish to employ the Tensorboard callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP3/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: Average accuracy improved to 0.6707, saving model to ./FMP3/0.63-0.71-epoch01-loss1.68.keras\n",
      "703/703 - 69s - 97ms/step - loss: 1.6830 - output1_accuracy: 0.6299 - output2_accuracy: 0.7209 - val_loss: 1.7101 - val_output1_accuracy: 0.6340 - val_output2_accuracy: 0.7073\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: Average accuracy did not improve (current: 0.6627, best: 0.6707)\n",
      "703/703 - 68s - 97ms/step - loss: 1.6612 - output1_accuracy: 0.6377 - output2_accuracy: 0.7221 - val_loss: 1.7644 - val_output1_accuracy: 0.6196 - val_output2_accuracy: 0.7057\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: Average accuracy improved to 0.6812, saving model to ./FMP3/0.64-0.72-epoch03-loss1.67.keras\n",
      "703/703 - 69s - 98ms/step - loss: 1.6667 - output1_accuracy: 0.6369 - output2_accuracy: 0.7217 - val_loss: 1.6689 - val_output1_accuracy: 0.6390 - val_output2_accuracy: 0.7234\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: Average accuracy did not improve (current: 0.6718, best: 0.6812)\n",
      "703/703 - 69s - 98ms/step - loss: 1.6482 - output1_accuracy: 0.6349 - output2_accuracy: 0.7263 - val_loss: 1.6992 - val_output1_accuracy: 0.6288 - val_output2_accuracy: 0.7147\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: Average accuracy did not improve (current: 0.6708, best: 0.6812)\n",
      "703/703 - 69s - 98ms/step - loss: 1.6448 - output1_accuracy: 0.6378 - output2_accuracy: 0.7281 - val_loss: 1.7147 - val_output1_accuracy: 0.6322 - val_output2_accuracy: 0.7093\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: Average accuracy did not improve (current: 0.6747, best: 0.6812)\n",
      "703/703 - 70s - 99ms/step - loss: 1.6402 - output1_accuracy: 0.6430 - output2_accuracy: 0.7297 - val_loss: 1.7124 - val_output1_accuracy: 0.6332 - val_output2_accuracy: 0.7161\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: Average accuracy did not improve (current: 0.6658, best: 0.6812)\n",
      "703/703 - 70s - 99ms/step - loss: 1.6370 - output1_accuracy: 0.6409 - output2_accuracy: 0.7293 - val_loss: 1.7561 - val_output1_accuracy: 0.6232 - val_output2_accuracy: 0.7083\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: Average accuracy did not improve (current: 0.6678, best: 0.6812)\n",
      "703/703 - 70s - 100ms/step - loss: 1.6382 - output1_accuracy: 0.6456 - output2_accuracy: 0.7277 - val_loss: 1.7547 - val_output1_accuracy: 0.6338 - val_output2_accuracy: 0.7017\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: Average accuracy did not improve (current: 0.6721, best: 0.6812)\n",
      "703/703 - 71s - 101ms/step - loss: 1.6140 - output1_accuracy: 0.6466 - output2_accuracy: 0.7352 - val_loss: 1.7365 - val_output1_accuracy: 0.6206 - val_output2_accuracy: 0.7236\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: Average accuracy improved to 0.6841, saving model to ./FMP3/0.64-0.73-epoch10-loss1.63.keras\n",
      "703/703 - 71s - 101ms/step - loss: 1.6285 - output1_accuracy: 0.6405 - output2_accuracy: 0.7333 - val_loss: 1.6441 - val_output1_accuracy: 0.6364 - val_output2_accuracy: 0.7318\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: Average accuracy did not improve (current: 0.6655, best: 0.6841)\n",
      "703/703 - 72s - 103ms/step - loss: 1.6173 - output1_accuracy: 0.6442 - output2_accuracy: 0.7348 - val_loss: 1.7695 - val_output1_accuracy: 0.6316 - val_output2_accuracy: 0.6993\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: Average accuracy did not improve (current: 0.6740, best: 0.6841)\n",
      "703/703 - 73s - 103ms/step - loss: 1.6025 - output1_accuracy: 0.6465 - output2_accuracy: 0.7356 - val_loss: 1.7141 - val_output1_accuracy: 0.6302 - val_output2_accuracy: 0.7177\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: Average accuracy did not improve (current: 0.6834, best: 0.6841)\n",
      "703/703 - 72s - 102ms/step - loss: 1.6018 - output1_accuracy: 0.6466 - output2_accuracy: 0.7390 - val_loss: 1.6382 - val_output1_accuracy: 0.6386 - val_output2_accuracy: 0.7282\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: Average accuracy did not improve (current: 0.6717, best: 0.6841)\n",
      "703/703 - 72s - 103ms/step - loss: 1.6024 - output1_accuracy: 0.6456 - output2_accuracy: 0.7373 - val_loss: 1.7254 - val_output1_accuracy: 0.6270 - val_output2_accuracy: 0.7163\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: Average accuracy did not improve (current: 0.6816, best: 0.6841)\n",
      "703/703 - 73s - 103ms/step - loss: 1.5975 - output1_accuracy: 0.6505 - output2_accuracy: 0.7369 - val_loss: 1.6747 - val_output1_accuracy: 0.6452 - val_output2_accuracy: 0.7179\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: Average accuracy did not improve (current: 0.6711, best: 0.6841)\n",
      "703/703 - 73s - 104ms/step - loss: 1.5927 - output1_accuracy: 0.6522 - output2_accuracy: 0.7364 - val_loss: 1.7076 - val_output1_accuracy: 0.6320 - val_output2_accuracy: 0.7101\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: Average accuracy did not improve (current: 0.6720, best: 0.6841)\n",
      "703/703 - 74s - 105ms/step - loss: 1.5962 - output1_accuracy: 0.6490 - output2_accuracy: 0.7367 - val_loss: 1.7189 - val_output1_accuracy: 0.6322 - val_output2_accuracy: 0.7117\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: Average accuracy did not improve (current: 0.6731, best: 0.6841)\n",
      "703/703 - 73s - 104ms/step - loss: 1.5859 - output1_accuracy: 0.6531 - output2_accuracy: 0.7384 - val_loss: 1.7184 - val_output1_accuracy: 0.6426 - val_output2_accuracy: 0.7035\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: Average accuracy improved to 0.6849, saving model to ./FMP3/0.64-0.73-epoch19-loss1.57.keras\n",
      "703/703 - 73s - 104ms/step - loss: 1.5670 - output1_accuracy: 0.6555 - output2_accuracy: 0.7427 - val_loss: 1.6410 - val_output1_accuracy: 0.6366 - val_output2_accuracy: 0.7332\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: Average accuracy improved to 0.6889, saving model to ./FMP3/0.66-0.72-epoch20-loss1.57.keras\n",
      "703/703 - 74s - 105ms/step - loss: 1.5738 - output1_accuracy: 0.6555 - output2_accuracy: 0.7431 - val_loss: 1.6384 - val_output1_accuracy: 0.6552 - val_output2_accuracy: 0.7226\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: Average accuracy did not improve (current: 0.6885, best: 0.6889)\n",
      "703/703 - 74s - 105ms/step - loss: 1.5667 - output1_accuracy: 0.6541 - output2_accuracy: 0.7469 - val_loss: 1.6245 - val_output1_accuracy: 0.6478 - val_output2_accuracy: 0.7292\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: Average accuracy did not improve (current: 0.6842, best: 0.6889)\n",
      "703/703 - 74s - 105ms/step - loss: 1.5729 - output1_accuracy: 0.6550 - output2_accuracy: 0.7421 - val_loss: 1.6747 - val_output1_accuracy: 0.6380 - val_output2_accuracy: 0.7304\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: Average accuracy improved to 0.6935, saving model to ./FMP3/0.65-0.73-epoch23-loss1.57.keras\n",
      "703/703 - 76s - 107ms/step - loss: 1.5720 - output1_accuracy: 0.6544 - output2_accuracy: 0.7421 - val_loss: 1.5966 - val_output1_accuracy: 0.6540 - val_output2_accuracy: 0.7330\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: Average accuracy did not improve (current: 0.6909, best: 0.6935)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5644 - output1_accuracy: 0.6564 - output2_accuracy: 0.7452 - val_loss: 1.6360 - val_output1_accuracy: 0.6506 - val_output2_accuracy: 0.7312\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: Average accuracy did not improve (current: 0.6726, best: 0.6935)\n",
      "703/703 - 75s - 106ms/step - loss: 1.5472 - output1_accuracy: 0.6615 - output2_accuracy: 0.7480 - val_loss: 1.7201 - val_output1_accuracy: 0.6162 - val_output2_accuracy: 0.7290\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: Average accuracy did not improve (current: 0.6833, best: 0.6935)\n",
      "703/703 - 75s - 106ms/step - loss: 1.5525 - output1_accuracy: 0.6593 - output2_accuracy: 0.7454 - val_loss: 1.6668 - val_output1_accuracy: 0.6412 - val_output2_accuracy: 0.7254\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: Average accuracy did not improve (current: 0.6833, best: 0.6935)\n",
      "703/703 - 74s - 106ms/step - loss: 1.5514 - output1_accuracy: 0.6615 - output2_accuracy: 0.7463 - val_loss: 1.6660 - val_output1_accuracy: 0.6524 - val_output2_accuracy: 0.7141\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: Average accuracy improved to 0.6938, saving model to ./FMP3/0.65-0.74-epoch28-loss1.55.keras\n",
      "703/703 - 75s - 107ms/step - loss: 1.5487 - output1_accuracy: 0.6593 - output2_accuracy: 0.7483 - val_loss: 1.6177 - val_output1_accuracy: 0.6520 - val_output2_accuracy: 0.7356\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: Average accuracy did not improve (current: 0.6841, best: 0.6938)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5344 - output1_accuracy: 0.6636 - output2_accuracy: 0.7508 - val_loss: 1.6543 - val_output1_accuracy: 0.6354 - val_output2_accuracy: 0.7328\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: Average accuracy did not improve (current: 0.6897, best: 0.6938)\n",
      "703/703 - 74s - 106ms/step - loss: 1.5347 - output1_accuracy: 0.6654 - output2_accuracy: 0.7496 - val_loss: 1.6440 - val_output1_accuracy: 0.6446 - val_output2_accuracy: 0.7348\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: Average accuracy did not improve (current: 0.6897, best: 0.6938)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5428 - output1_accuracy: 0.6616 - output2_accuracy: 0.7493 - val_loss: 1.6089 - val_output1_accuracy: 0.6500 - val_output2_accuracy: 0.7294\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: Average accuracy did not improve (current: 0.6691, best: 0.6938)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5405 - output1_accuracy: 0.6588 - output2_accuracy: 0.7496 - val_loss: 1.7155 - val_output1_accuracy: 0.6342 - val_output2_accuracy: 0.7039\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: Average accuracy improved to 0.6959, saving model to ./FMP3/0.65-0.74-epoch33-loss1.54.keras\n",
      "703/703 - 76s - 108ms/step - loss: 1.5388 - output1_accuracy: 0.6612 - output2_accuracy: 0.7473 - val_loss: 1.5881 - val_output1_accuracy: 0.6502 - val_output2_accuracy: 0.7416\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: Average accuracy did not improve (current: 0.6943, best: 0.6959)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5346 - output1_accuracy: 0.6625 - output2_accuracy: 0.7495 - val_loss: 1.5883 - val_output1_accuracy: 0.6486 - val_output2_accuracy: 0.7400\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: Average accuracy did not improve (current: 0.6872, best: 0.6959)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5196 - output1_accuracy: 0.6686 - output2_accuracy: 0.7530 - val_loss: 1.6475 - val_output1_accuracy: 0.6522 - val_output2_accuracy: 0.7222\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: Average accuracy did not improve (current: 0.6885, best: 0.6959)\n",
      "703/703 - 74s - 106ms/step - loss: 1.5341 - output1_accuracy: 0.6649 - output2_accuracy: 0.7504 - val_loss: 1.6060 - val_output1_accuracy: 0.6420 - val_output2_accuracy: 0.7350\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: Average accuracy improved to 0.7038, saving model to ./FMP3/0.67-0.74-epoch37-loss1.52.keras\n",
      "703/703 - 75s - 107ms/step - loss: 1.5244 - output1_accuracy: 0.6662 - output2_accuracy: 0.7504 - val_loss: 1.5811 - val_output1_accuracy: 0.6687 - val_output2_accuracy: 0.7390\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: Average accuracy did not improve (current: 0.6998, best: 0.7038)\n",
      "703/703 - 77s - 109ms/step - loss: 1.4968 - output1_accuracy: 0.6714 - output2_accuracy: 0.7585 - val_loss: 1.5972 - val_output1_accuracy: 0.6538 - val_output2_accuracy: 0.7458\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: Average accuracy did not improve (current: 0.6926, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5045 - output1_accuracy: 0.6665 - output2_accuracy: 0.7583 - val_loss: 1.6016 - val_output1_accuracy: 0.6458 - val_output2_accuracy: 0.7394\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: Average accuracy did not improve (current: 0.6973, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5168 - output1_accuracy: 0.6674 - output2_accuracy: 0.7553 - val_loss: 1.5993 - val_output1_accuracy: 0.6558 - val_output2_accuracy: 0.7388\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: Average accuracy did not improve (current: 0.7014, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5086 - output1_accuracy: 0.6716 - output2_accuracy: 0.7548 - val_loss: 1.6038 - val_output1_accuracy: 0.6524 - val_output2_accuracy: 0.7504\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: Average accuracy did not improve (current: 0.6831, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5004 - output1_accuracy: 0.6687 - output2_accuracy: 0.7574 - val_loss: 1.6317 - val_output1_accuracy: 0.6374 - val_output2_accuracy: 0.7288\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: Average accuracy did not improve (current: 0.7031, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5057 - output1_accuracy: 0.6697 - output2_accuracy: 0.7561 - val_loss: 1.5636 - val_output1_accuracy: 0.6671 - val_output2_accuracy: 0.7392\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: Average accuracy did not improve (current: 0.6929, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.4965 - output1_accuracy: 0.6730 - output2_accuracy: 0.7588 - val_loss: 1.5949 - val_output1_accuracy: 0.6416 - val_output2_accuracy: 0.7442\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: Average accuracy did not improve (current: 0.6975, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5084 - output1_accuracy: 0.6654 - output2_accuracy: 0.7553 - val_loss: 1.5890 - val_output1_accuracy: 0.6558 - val_output2_accuracy: 0.7392\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: Average accuracy did not improve (current: 0.6746, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.4914 - output1_accuracy: 0.6723 - output2_accuracy: 0.7610 - val_loss: 1.7206 - val_output1_accuracy: 0.6104 - val_output2_accuracy: 0.7388\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: Average accuracy did not improve (current: 0.6904, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5001 - output1_accuracy: 0.6711 - output2_accuracy: 0.7594 - val_loss: 1.6086 - val_output1_accuracy: 0.6583 - val_output2_accuracy: 0.7226\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: Average accuracy did not improve (current: 0.6899, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5059 - output1_accuracy: 0.6724 - output2_accuracy: 0.7528 - val_loss: 1.6062 - val_output1_accuracy: 0.6370 - val_output2_accuracy: 0.7428\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: Average accuracy did not improve (current: 0.6985, best: 0.7038)\n",
      "703/703 - 76s - 107ms/step - loss: 1.4825 - output1_accuracy: 0.6729 - output2_accuracy: 0.7580 - val_loss: 1.5842 - val_output1_accuracy: 0.6530 - val_output2_accuracy: 0.7440\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: Average accuracy did not improve (current: 0.6967, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5004 - output1_accuracy: 0.6722 - output2_accuracy: 0.7553 - val_loss: 1.6083 - val_output1_accuracy: 0.6673 - val_output2_accuracy: 0.7262\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: Average accuracy did not improve (current: 0.6882, best: 0.7038)\n",
      "703/703 - 78s - 111ms/step - loss: 1.4985 - output1_accuracy: 0.6737 - output2_accuracy: 0.7572 - val_loss: 1.6375 - val_output1_accuracy: 0.6494 - val_output2_accuracy: 0.7270\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: Average accuracy did not improve (current: 0.6985, best: 0.7038)\n",
      "703/703 - 78s - 110ms/step - loss: 1.4922 - output1_accuracy: 0.6717 - output2_accuracy: 0.7573 - val_loss: 1.5746 - val_output1_accuracy: 0.6633 - val_output2_accuracy: 0.7338\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: Average accuracy did not improve (current: 0.6952, best: 0.7038)\n",
      "703/703 - 81s - 115ms/step - loss: 1.4782 - output1_accuracy: 0.6758 - output2_accuracy: 0.7568 - val_loss: 1.6027 - val_output1_accuracy: 0.6575 - val_output2_accuracy: 0.7330\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get a baseline, by evaluating this model according to the project prompt! As always with **tqdm** I first imported it directly, then remembered you have the import the module with the same name as the library. My evaluated model is fresh and initialized with the best trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training, I think about data augmentation. I only have 50,000 test samples so if train 100 epochs I for sure am overfitting, need to research which augmentations are successful on CIFAR-10 to help the model generalize. My intuition says mirroring along the vertical axis should be safe. I do not think color augmentations are a good idea, since the colors are already degraded due to the random image merge. As I am thinking of this, I also realize a validation set would help me stop overfitting and allow me to test if data augmentation are helping, so I implement it (at the top of the notebook). Now I need to fit my model with validation accuracies and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6988849967718125\n",
      "standard deviation =  0.0055302394468447645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(filepath, gen, repeat=1):\n",
    "    model = load_model(filepath)\n",
    "    evaluation_results = []\n",
    "    for i in tqdm(range(repeat)):\n",
    "        loss, acc1, acc2 = model.evaluate(gen, batch_size=10000, steps=1, verbose=False)\n",
    "        evaluation_results.append(np.mean([acc1, acc2]))\n",
    "    print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "    print(\"standard deviation = \", np.std(evaluation_results))\n",
    "\n",
    "evaluate_model('./FMP3/0.67-0.74-epoch37-loss1.52.keras', testgen, repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am very happy with 70.9% accuracy, now I have to make sure saving and loading work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6927750051021576\n",
      "standard deviation =  0.006946627811636093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, acc2 = model.evaluate(testgen, batch_size=10000, steps=1, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement my idea to include dropout at 25% after conv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP4(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP4, self).__init__()\n",
    "        # Input layer size 32x32\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU())\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout1 = layers.Dropout(0.25)  # 50% dropout in the final hidden layer\n",
    "        self.dropout2 = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Two Classifiers \n",
    "        self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        x = self.dropout1(x) # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout2(x)\n",
    "        output1 = self.fc1(x)  # First half\n",
    "        output2 = self.fc2(x)  # Second half\n",
    "        print(f\"Final Output Shapes: output1={output1.shape}, output2={output2.shape}\")\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Serialize the configuration of the model\n",
    "        config = super(FMP4, self).get_config()\n",
    "        config.update({\n",
    "            'conv1': self.conv1.get_config(),\n",
    "            'conv2': self.conv2.get_config(),\n",
    "            'conv3': self.conv3.get_config(),\n",
    "            'conv4': self.conv4.get_config(),\n",
    "            'conv5': self.conv5.get_config(),\n",
    "            'conv6': self.conv6.get_config(),\n",
    "            'conv7': self.conv7.get_config(),\n",
    "            'conv8': self.conv8.get_config(),\n",
    "            'dropout1': self.dropout1.get_config(),\n",
    "            'dropout2': self.dropout2.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "            'pooling_ratios': [\n",
    "                self.pooling_ratio1,\n",
    "                self.pooling_ratio2,\n",
    "                self.pooling_ratio3,\n",
    "                self.pooling_ratio4,\n",
    "                self.pooling_ratio5,\n",
    "                self.pooling_ratio6\n",
    "            ]\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output Shapes: output1=(1, 5), output2=(1, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Final Output Shapes: output1=(None, 5), output2=(None, 5)\n",
      "Final Output Shapes: output1=(None, 5), output2=(None, 5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 23\u001b[0m\n\u001b[1;32m     10\u001b[0m val_model_checkpoint_callback \u001b[38;5;241m=\u001b[39m MeanAccModelCheckpoint(\n\u001b[1;32m     11\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FMP4/\u001b[39m\u001b[38;5;132;01m{output1_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{output2_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-loss\u001b[39m\u001b[38;5;132;01m{loss:.2f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     monitor1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output1_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     monitor2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output2_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m val_early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Track the validation loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                                patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,         \u001b[38;5;66;03m# Number of epochs to wait after the last improvement\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# Stop when the value stops decreasing (minimization)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                                restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Restore the best weights when stopping\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_model_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP4()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()\n",
    "\n",
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP4/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,           \n",
    "    epochs=100,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen, \n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6774300068616868\n",
      "standard deviation =  0.009838248775686023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model('./FMP4/0.65-0.73-epoch41-loss1.61.keras', testgen, repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more dropout made things worse! This model taken from section 4.4, still needs data augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @keras.saving.register_keras_serializable()\n",
    "# class FMP5(Model):\n",
    "#     def __init__(self):\n",
    "#         super(FMP5, self).__init__()\n",
    "#         # Input layer size 32x32\n",
    "\n",
    "#         # Twelve C2 layers, each linearly increasing the number of filters, by 160n\n",
    "#         self.conv1 = layers.Conv2D(160, (2, 2), activation=LeakyReLU(), padd)\n",
    "#         self.conv2 = layers.Conv2D(320, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv3 = layers.Conv2D(480, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv4 = layers.Conv2D(640, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv5 = layers.Conv2D(800, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv6 = layers.Conv2D(960, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv7 = layers.Conv2D(1120, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv8 = layers.Conv2D(1280, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv9 = layers.Conv2D(1440, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv10 = layers.Conv2D(1600, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv11 = layers.Conv2D(1760, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv12 = layers.Conv2D(1920, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "#         # Twelve fractional max pooling layers\n",
    "#         self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "#         self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "#         self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "#         self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "#         self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "#         self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "#         self.pooling_ratio7 = [1.0, 31/22, 31/22, 1.0]\n",
    "#         self.pooling_ratio8 = [1.0, 21/15, 21/15, 1.0]\n",
    "#         self.pooling_ratio9 = [1.0, 14/10, 14/10, 1.0]\n",
    "#         self.pooling_ratio10 = [1.0, 9/6, 9/6, 1.0]\n",
    "#         self.pooling_ratio11 = [1.0, 5/4, 5/4, 1.0]\n",
    "#         self.pooling_ratio12 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "#         # Two final convolutional layers\n",
    "#         self.conv13 = layers.Conv2D(1920, (2, 2), activation=LeakyReLU())\n",
    "#         self.conv14 = layers.Conv2D(1920, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "#         # Linearly increasing dropout up to 50% in the hidden layers\n",
    "#         self.dropout1 = layers.Dropout(0.25)\n",
    "#         self.dropout2 = layers.Dropout(0.5) \n",
    "\n",
    "#         # Two Classifiers \n",
    "#         self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "#         self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # Feature Extractor\n",
    "#         x = self.conv1(inputs) # 31x31\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 27x27\n",
    "#         x = self.conv2(x) # 26x26\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 23x23\n",
    "#         x = self.conv3(x) # 22x22\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 19x19\n",
    "#         x = self.conv4(x) # 18x18\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 16x16\n",
    "#         x = self.conv5(x) # 15x15\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 13x13\n",
    "#         x = self.conv6(x) # 12x12\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 10x10\n",
    "#         x = self.conv7(inputs) # 9x9\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 8x8\n",
    "#         x = self.conv8(x) # 7x7\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 6x6\n",
    "#         x = self.conv9(x) # 5x5\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 4x4\n",
    "#         x = self.conv10(x) # 3x3\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 2x2\n",
    "#         x = self.conv11(x) # 1x1\n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # \n",
    "#         x = self.conv12(x) # \n",
    "#         x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # \n",
    "#         x = self.conv13(x) # \n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.conv14(x) #1x1\n",
    "\n",
    "#         # Classifier\n",
    "#         x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "#         x = self.dropout2(x)\n",
    "#         output1 = self.fc1(x)  # First half\n",
    "#         output2 = self.fc2(x)  # Second half\n",
    "\n",
    "#         return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         # Serialize the configuration of the model\n",
    "#         config = super(FMP5, self).get_config()\n",
    "#         config.update({\n",
    "#             'conv1': self.conv1.get_config(),\n",
    "#             'conv2': self.conv2.get_config(),\n",
    "#             'conv3': self.conv3.get_config(),\n",
    "#             'conv4': self.conv4.get_config(),\n",
    "#             'conv5': self.conv5.get_config(),\n",
    "#             'conv6': self.conv6.get_config(),\n",
    "#             'conv7': self.conv7.get_config(),\n",
    "#             'conv8': self.conv8.get_config(),\n",
    "#             'dropout1': self.dropout1.get_config(),\n",
    "#             'dropout2': self.dropout2.get_config(),\n",
    "#             'fc1': self.fc1.get_config(),\n",
    "#             'fc2': self.fc2.get_config(),\n",
    "#             'pooling_ratios': [\n",
    "#                 self.pooling_ratio1,\n",
    "#                 self.pooling_ratio2,\n",
    "#                 self.pooling_ratio3,\n",
    "#                 self.pooling_ratio4,\n",
    "#                 self.pooling_ratio5,\n",
    "#                 self.pooling_ratio6\n",
    "#             ]\n",
    "#         })\n",
    "#         return config\n",
    "    \n",
    "#     @classmethod\n",
    "#     def from_config(cls, config):\n",
    "#         return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP5(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP5, self).__init__()\n",
    "\n",
    "        # Feature Extractor: Twelve convolutional layers with padding\n",
    "        self.convs = [\n",
    "            layers.Conv2D(160 + 160 * i, (2, 2), activation=LeakyReLU(), padding='same')\n",
    "            for i in range(12)\n",
    "        ]\n",
    "\n",
    "        # Fractional Max Pooling Ratios (1.26)\n",
    "        # self.pooling_ratios = [\n",
    "        #     [1.0, 32/25, 32/25, 1.0],  \n",
    "        #     [1.0, 25/20, 25/20, 1.0],\n",
    "        #     [1.0, 20/16, 20/16, 1.0],\n",
    "        #     [1.0, 16/13, 16/13, 1.0],\n",
    "        #     [1.0, 13/10, 13/10, 1.0],\n",
    "        #     [1.0, 10/8, 10/8, 1.0],\n",
    "        #     [1.0, 8/6, 8/6, 1.0], \n",
    "        #     [1.0, 6/5, 6/5, 1.0],\n",
    "        #     [1.0, 5/4, 5/4, 1.0],\n",
    "        #     [1.0, 4/3, 4/3, 1.0],\n",
    "        #     [1.0, 3/2, 3/2, 1.0],\n",
    "        #     [1.0, 2/1, 2/1, 1.0],\n",
    "        # ]\n",
    "\n",
    "        self.pooling_ratios = [\n",
    "            [1.0, 32/28, 32/28, 1.0],  # From 32x32 to ~28x28\n",
    "            [1.0, 28/24, 28/24, 1.0],  # From ~28x28 to ~24x24\n",
    "            [1.0, 24/20, 24/20, 1.0],  # From ~24x24 to ~20x20\n",
    "            [1.0, 20/16, 20/16, 1.0],  # From ~20x20 to ~16x16\n",
    "            [1.0, 16/13, 16/13, 1.0],  # From ~16x16 to ~13x13\n",
    "            [1.0, 13/10, 13/10, 1.0],  # From ~13x13 to ~10x10\n",
    "            [1.0, 10/8, 10/8, 1.0],    # From ~10x10 to ~8x8\n",
    "            [1.0, 8/6, 8/6, 1.0],      # From ~8x8 to ~6x6\n",
    "            [1.0, 6/5, 6/5, 1.0],      # From ~6x6 to ~5x5\n",
    "            [1.0, 5/4, 5/4, 1.0],      # From ~5x5 to ~4x4\n",
    "            [1.0, 4/3, 4/3, 1.0],      # From ~4x4 to ~3x3\n",
    "            [1.0, 3/2, 3/2, 1.0],      # From ~3x3 to ~2x2\n",
    "        ]\n",
    "\n",
    "        # Final convolutional layers with padding\n",
    "        self.conv = layers.Conv2D(1920, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Track spatial dimensions starting from input size\n",
    "        x = inputs\n",
    "\n",
    "        for i in range(12):\n",
    "            x = self.convs[i](x)  # Convolution with padding to maintain spatial size\n",
    "            x, _, _ = fractional_max_pool(x, pooling_ratio=self.pooling_ratios[i], pseudo_random=True, overlapping=True)\n",
    "            print(f\"After FMP{i + 1}: {x.shape}\")\n",
    "\n",
    "        # Final convolution and dropout\n",
    "        x = self.conv(x)\n",
    "        # print(f\"After final conv: {x.shape}\")\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Two separate classifier heads\n",
    "        x = layers.Flatten()(x)\n",
    "        output1 = self.fc1(x)\n",
    "        output2 = self.fc2(x)\n",
    "        # print(f\"Final Output Shapes: output1={output1.shape}, output2={output2.shape}\")\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(FMP5, self).get_config()\n",
    "        config.update({\n",
    "            'conv_layers': [conv.get_config() for conv in self.convs],\n",
    "            'pooling_ratios': self.pooling_ratios,\n",
    "            'conv': self.conv.get_config(),\n",
    "            'dropout': self.dropout.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After FMP1: (1, 27, 27, 160)\n",
      "After FMP2: (1, 23, 23, 320)\n",
      "After FMP3: (1, 19, 19, 480)\n",
      "After FMP4: (1, 15, 15, 640)\n",
      "After FMP5: (1, 12, 12, 800)\n",
      "After FMP6: (1, 9, 9, 960)\n",
      "After FMP7: (1, 7, 7, 1120)\n",
      "After FMP8: (1, 5, 5, 1280)\n",
      "After FMP9: (1, 4, 4, 1440)\n",
      "After FMP10: (1, 3, 3, 1600)\n",
      "After FMP11: (1, 2, 2, 1760)\n",
      "After FMP12: (1, 1, 1, 1920)\n",
      "After final conv: (1, 1, 1, 1920)\n",
      "Final Output Shapes: output1=(1, 5), output2=(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">205,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,229,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,301,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,735,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,374,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,217,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,265,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,518,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,688,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,605</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,605</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m205,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m614,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m1,229,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m2,048,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m3,072,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m4,301,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m5,735,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m7,374,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m9,217,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │    \u001b[38;5;34m11,265,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │    \u001b[38;5;34m13,518,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │     \u001b[38;5;34m3,688,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │         \u001b[38;5;34m9,605\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │         \u001b[38;5;34m9,605\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,294,730</span> (237.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,294,730\u001b[0m (237.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,294,730</span> (237.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,294,730\u001b[0m (237.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "After FMP1: (None, 27, 27, 160)\n",
      "After FMP2: (None, 23, 23, 320)\n",
      "After FMP3: (None, 19, 19, 480)\n",
      "After FMP4: (None, 15, 15, 640)\n",
      "After FMP5: (None, 12, 12, 800)\n",
      "After FMP6: (None, 9, 9, 960)\n",
      "After FMP7: (None, 7, 7, 1120)\n",
      "After FMP8: (None, 5, 5, 1280)\n",
      "After FMP9: (None, 4, 4, 1440)\n",
      "After FMP10: (None, 3, 3, 1600)\n",
      "After FMP11: (None, 2, 2, 1760)\n",
      "After FMP12: (None, 1, 1, 1920)\n",
      "After final conv: (None, 1, 1, 1920)\n",
      "Final Output Shapes: output1=(None, 5), output2=(None, 5)\n",
      "After FMP1: (None, 27, 27, 160)\n",
      "After FMP2: (None, 23, 23, 320)\n",
      "After FMP3: (None, 19, 19, 480)\n",
      "After FMP4: (None, 15, 15, 640)\n",
      "After FMP5: (None, 12, 12, 800)\n",
      "After FMP6: (None, 9, 9, 960)\n",
      "After FMP7: (None, 7, 7, 1120)\n",
      "After FMP8: (None, 5, 5, 1280)\n",
      "After FMP9: (None, 4, 4, 1440)\n",
      "After FMP10: (None, 3, 3, 1600)\n",
      "After FMP11: (None, 2, 2, 1760)\n",
      "After FMP12: (None, 1, 1, 1920)\n",
      "After final conv: (None, 1, 1, 1920)\n",
      "Final Output Shapes: output1=(None, 5), output2=(None, 5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 23\u001b[0m\n\u001b[1;32m     10\u001b[0m val_model_checkpoint_callback \u001b[38;5;241m=\u001b[39m MeanAccModelCheckpoint(\n\u001b[1;32m     11\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FMP5/\u001b[39m\u001b[38;5;132;01m{output1_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{output2_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-loss\u001b[39m\u001b[38;5;132;01m{loss:.2f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     monitor1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output1_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     monitor2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output2_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m val_early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Track the validation loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                                patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,         \u001b[38;5;66;03m# Number of epochs to wait after the last improvement\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# Stop when the value stops decreasing (minimization)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                                restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Restore the best weights when stopping\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_model_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP5()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()\n",
    "\n",
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP5/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,           \n",
    "    epochs=100,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen, \n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
