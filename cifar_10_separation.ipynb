{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE7oyG0wv6e0"
   },
   "source": [
    "# Separation of CIFAR-10 Images\n",
    "\n",
    "The model takes as input an image created by averaging two random samples from CIFAR-10 and is tasked with predicting the categories of the two components.\n",
    "\n",
    "**For sure it is a computer vision model.**\n",
    "\n",
    "The first image belongs to the first five categories (airplane, automobile, bird, cat, deer), while the second belongs to the remaining categories (dog, frog, horse, ship, truck). The model must return two labels, each within a range of five possible values.\n",
    "\n",
    "**(5->1, 5->1)**\n",
    "\n",
    "The evaluation metric for the model is as follows: calculate the classification accuracy for the two component images and then compute their average.\n",
    "\n",
    "**accuracy = acc1 + acc2 / 2**\n",
    "**where acc1 = (correct1/total) and acc2 = (correct2/total)**\n",
    "\n",
    "The metric should be evaluated on 10,000 inputs generated from test data. Repeat the calculation 10 times and measure the standard deviation, which must be reported.\n",
    "\n",
    "A data generator and some examples are provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USdmzjiO0W6D"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iHjnh5XP0Sq4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 10:01:16.761336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736359276.846650   84653 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736359276.872064   84653 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 10:01:17.085416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.nn import fractional_max_pool\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRYiW2ipukZF",
    "outputId": "0d5c8981-51da-4c92-de73-84bcac11aa2c"
   },
   "outputs": [],
   "source": [
    "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
    "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
    "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
    "assert cifar10_y_train.shape == (50000, 1)\n",
    "assert cifar10_y_test.shape == (10000, 1)\n",
    "\n",
    "# First classifier: \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\"\n",
    "# Second classifier: \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "# IDEA: extract the features with a CNN backbone and feed them to two seperate FCN classifiers. How about backpropogation?\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Normalizing to range (0,1)\n",
    "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
    "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkiGnU4d0k4d"
   },
   "source": [
    "Let us split the images in two groups, according to their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Dpey42Vo07Yb"
   },
   "outputs": [],
   "source": [
    "# No validation set!\n",
    "cond_1 = cifar10_y_train[:,0] < 5\n",
    "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
    "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
    "\n",
    "cond_2 = cifar10_y_train[:,0] >= 5\n",
    "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
    "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
    "\n",
    "cond_1_test = cifar10_y_test[:,0] < 5\n",
    "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
    "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
    "\n",
    "cond_2_test = cifar10_y_test[:,0] >= 5\n",
    "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
    "cifar10_y_test_2 = cifar10_y_test[cond_2_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmLYNuR-0s0m"
   },
   "source": [
    "Now we can define the generator. The input consists of two datasets (X1,X2), their corresponding labels (Y1,Y2), and a batch size.\n",
    "\n",
    "**Model input: (B x X1\\*X2)**\n",
    "**Model output: (B x Y1 x Y2)**\n",
    "\n",
    "The generator returns (x_data,y_data), where:\n",
    "* x_data is a batch of images obtained by averaging random samples from X1 and X2.\n",
    "* y_data is a pair of batches of labels corresponding to the component images, expressed in categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7Y5Zpv5fw2hd"
   },
   "outputs": [],
   "source": [
    "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
    "  size1 = X1.shape[0]\n",
    "  size2 = X2.shape[0]\n",
    "  # Convert the integer labels into one hot encoded vectors for cross entropy loss\n",
    "  # Careful: since there are two different sets of labels, I need to code two seperate outputs with seperate cross entropy losses\n",
    "  # Keras (TF) can handle this with: model = models.Model(inputs=merged_input_image, outputs=[output1, output2])\n",
    "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
    "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
    "\n",
    "  while True:\n",
    "    # Random image selections\n",
    "    num1 = np.random.randint(0, size1, batchsize)\n",
    "    num2 = np.random.randint(0, size2, batchsize)\n",
    "    # Average image production\n",
    "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
    "    y_data = [Y1_cat[num1],Y2_cat[num2]]\n",
    "\n",
    "    yield x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy solution!\n",
    "# In TensorFlow 2.x, tf.keras is the official Keras implementation that runs on top of TensorFlow, utilizing TensorFlow's functionalities for training, \n",
    "# backpropagation, and execution.\n",
    "\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # Model setup (with the Functional API, so previous layer is in parenthesis)\n",
    "# input_image = layers.Input(shape=(32, 32, 3))  # CIFAR-10 images\n",
    "\n",
    "# x = layers.Conv2D(32, (3, 3), activation='relu')(input_image)\n",
    "# x = layers.MaxPooling2D()(x)\n",
    "# x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "# x = layers.MaxPooling2D()(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# # Two output layers\n",
    "# output1 = layers.Dense(5, activation='softmax', name='output1')(x)  # For first 5 classes\n",
    "# output2 = layers.Dense(5, activation='softmax', name='output2')(x)  # For second 5 classes\n",
    "\n",
    "# model = models.Model(inputs=input_image, outputs=[output1, output2])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "#               metrics={'output1': 'accuracy', 'output2': 'accuracy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9lf3TuP2pdQ"
   },
   "source": [
    "\n",
    "Let us instantiate a generator on Cifar10 with batchsize=1, and let's see its behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "29TldJ6-720b"
   },
   "outputs": [],
   "source": [
    "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1DrJVzI3ysV"
   },
   "source": [
    "Let's generate an example, display the image that the model will take as input, and print the categories of the two overlapping components.\n",
    "\n",
    "You can re-run the cell to display new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "qL1sMtjG8VmG",
    "outputId": "5b9d6599-d407-4e32-dad7-f3f95890f0b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: deer, second = frog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3a58e79060>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = next(datagen)\n",
    "\n",
    "print(\"first: {}, second = {}\".format(classes[np.argmax(y[0][0])],classes[np.argmax(y[1][0])+5]))\n",
    "#print(np.min(x[0]),np.max(x[0]))\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5lzBotwL5QN"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_p4UuG1QF8t"
   },
   "source": [
    "Let us define first of all the test generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQo8_6w-L4WY",
    "outputId": "a626a55c-7df8-456b-adcd-580d4166e184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
    "\n",
    "eval_samples_x, eval_samples_y = next(testgen)\n",
    "print(eval_samples_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MiLnkKROGCD"
   },
   "source": [
    "We now test a model producing random guesses. You will need to replace it with your own predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1GllTEtPN_xv"
   },
   "outputs": [],
   "source": [
    "def random_model(x):\n",
    "  #the random model ignores the input x and return a pair of random classes\n",
    "  # 10,000 examples in a 2 column array between 0 and 4 inclusive\n",
    "  return(np.random.randint(0,5,(10000,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gomFTuuDOy8A"
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "  eval_samples_x, eval_samples_y = next(testgen)\n",
    "  random_guesses = model(eval_samples_x)\n",
    "  correct_guesses_1 = random_guesses[:,0] == np.argmax(eval_samples_y[0],axis=1)\n",
    "  correct_guesses_2 = random_guesses[:,1] == np.argmax(eval_samples_y[1],axis=1)\n",
    "  return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4AL2M6yjJno",
    "outputId": "d84ecfb8-299f-4e37-85ee-c69b83a39e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.19885)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(random_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7usBI88dje70"
   },
   "source": [
    "As expected, the accuracy is around 1/5 = 0.2\n",
    "\n",
    "Let us repeat the evaluation ten times, and compute the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFu8iEt9jdZA",
    "outputId": "93fa99f4-972a-4795-917b-b1db97dc7ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.20056000000000002\n",
      "standard deviation =  0.002620763247605547\n"
     ]
    }
   ],
   "source": [
    "repeat_eval = 10\n",
    "eval_results = []\n",
    "for i in range(repeat_eval):\n",
    "  eval_results.append(eval_model(random_model))\n",
    "print(\"mean accuracy = \", np.mean(eval_results))\n",
    "print(\"standard deviation = \", np.std(eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1yTRAzn4i9g"
   },
   "source": [
    "# What to Submit\n",
    "\n",
    "As usual, you need to submit a single notebook that must be executable on Colab. The notebook should be properly commented and include a complete record of the training process, as well as the calculation of accuracy according to the guidelines provided above.\n",
    "\n",
    "# Good luck!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I googled CIFAR-10 best accuracy and I fell upon a reddit post about a person trying to train it as fast as possible, [here](https://github.com/tysam-code/hlb-CIFAR10). Since I am not interested in light speed CIFAR-10, I googled only CIFAR-10 and arrived to the main website for this [dataset](https://www.cs.toronto.edu/~kriz/cifar.html). From there, I found a non-working link to Rodrigo Benenson since github.com has been deprecated and is now github.io, changing this and selecting \"who is the best in CIFAR-10 ?\" brought me to the [world rankings](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130). Now I will read these papers in order. The first is [Fractional Max Pooling](https://arxiv.org/abs/1412.6071), with an accuracy of 96.53%. As I read this, I think, is my task the same? As a human, can I learn to distinguish the two classes? For sure, I will have to use the generator to see.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'fmp', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │           \u001b[38;5;34m130\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │           \u001b[38;5;34m820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m40\u001b[0m)          │         \u001b[38;5;34m4,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │         \u001b[38;5;34m2,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │        \u001b[38;5;34m18,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,280</span> (110.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,280\u001b[0m (110.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,280</span> (110.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,280\u001b[0m (110.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define my fractional pooling model\n",
    "\n",
    "class FMP(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP, self).__init__()\n",
    "        # Input\n",
    "        #self.input_layer = layers.InputLayer(shape=(32, 32, 3))  # For CIFAR-10 images\n",
    "\n",
    "        # Four convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(10, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(20, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(30, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(40, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(50, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Three fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 3/2, 3/2, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 6/4, 6/4, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 10/7, 10/7, 1.0]\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        #self.dropout1 = layers.Dropout(0.0)  # 0% dropout in the first hidden layer\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Input\n",
    "        #x = self.input_layer(inputs)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv2(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv3(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "K.clear_session()\n",
    "model = FMP()\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_cat = tf.keras.utils.to_categorical(cifar10_y_train, num_classes=10)\n",
    "Y_cat_test = tf.keras.utils.to_categorical(cifar10_y_test, num_classes=10)\n",
    "print(cifar10_x_train.shape)\n",
    "print(Y_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 09:48:36.465343: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph __inference_one_step_on_data_10169[] on XLA_GPU_JIT: FractionalMaxPool (No registered 'FractionalMaxPool' OpKernel for XLA_GPU_JIT devices compatible with node {{node fmp_1/FractionalMaxPool}}){{node fmp_1/FractionalMaxPool}}\n",
      "The op is created at: \n",
      "File \"usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "File \"usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "File \"usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "File \"usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "File \"usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "File \"tmp/ipykernel_61376/2404114935.py\", line 1, in <module>\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 59, in train_step\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 908, in __call__\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n",
      "File \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n",
      "File \"tmp/ipykernel_61376/4221719843.py\", line 34, in call\n",
      "\ttf2xla conversion failed while converting __inference_one_step_on_data_10169[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node fmp_1/FractionalMaxPool defined at (most recent call last):\n<stack traces unavailable>\nDetected at node fmp_1/FractionalMaxPool defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_10169[] on XLA_GPU_JIT: FractionalMaxPool (No registered 'FractionalMaxPool' OpKernel for XLA_GPU_JIT devices compatible with node {{node fmp_1/FractionalMaxPool}}){{node fmp_1/FractionalMaxPool}}\nThe op is created at: \nFile \"usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\nFile \"tmp/ipykernel_61376/2404114935.py\", line 1, in <module>\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 59, in train_step\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"tmp/ipykernel_61376/4221719843.py\", line 34, in call\n\ttf2xla conversion failed while converting __inference_one_step_on_data_10169[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_multi_step_on_iterator_10258]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Github/image-seperation/venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node fmp_1/FractionalMaxPool defined at (most recent call last):\n<stack traces unavailable>\nDetected at node fmp_1/FractionalMaxPool defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_10169[] on XLA_GPU_JIT: FractionalMaxPool (No registered 'FractionalMaxPool' OpKernel for XLA_GPU_JIT devices compatible with node {{node fmp_1/FractionalMaxPool}}){{node fmp_1/FractionalMaxPool}}\nThe op is created at: \nFile \"usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\nFile \"usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\nFile \"tmp/ipykernel_61376/2404114935.py\", line 1, in <module>\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\", line 59, in train_step\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/layers/layer.py\", line 908, in __call__\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/ops/operation.py\", line 46, in __call__\nFile \"home/nicolas/Github/image-seperation/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\nFile \"tmp/ipykernel_61376/4221719843.py\", line 34, in call\n\ttf2xla conversion failed while converting __inference_one_step_on_data_10169[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_multi_step_on_iterator_10258]"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=cifar10_x_train, y=Y_cat, epochs=1, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0996 - loss: 2.3098\n",
      "fmp Loss: 2.3086, Accuracy: 10.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10159999877214432"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "def evaluate(model, x, y):\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    print(f\"{model.name} Loss: {loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing this, I feel like the convolutional layers would benefit from being more complex and so I use this [person's](https://github.com/WingsBrokenAngel/fractional_max_pooling_and_recurrent_convolutional_neural_network) filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'fmp1_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp1_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp1_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,690</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │         \u001b[38;5;34m7,260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m90\u001b[0m)        │        \u001b[38;5;34m21,690\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m120\u001b[0m)         │        \u001b[38;5;34m43,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m150\u001b[0m)         │        \u001b[38;5;34m18,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │        \u001b[38;5;34m54,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,820</span> (565.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m144,820\u001b[0m (565.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,820</span> (565.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,820\u001b[0m (565.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FMP1(Model):\n",
    "    def __init__(self, FILTERS):\n",
    "        super(FMP1, self).__init__()\n",
    "        # Parameters\n",
    "        self.filters = FILTERS\n",
    "\n",
    "        # Four convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(10*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(20*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(30*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(40*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(50*FILTERS, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Three fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 3/2, 3/2, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 6/4, 6/4, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 10/7, 10/7, 1.0]\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        #self.dropout1 = layers.Dropout(0.0)  # 0% dropout in the first hidden layer\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Input\n",
    "        #x = self.input_layer(inputs)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv2(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv3(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "#K.clear_session()\n",
    "model = FMP1(FILTERS=3)\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.2143 - loss: 2.1583\n",
      "Epoch 2/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.3303 - loss: 1.8607\n",
      "Epoch 3/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.3843 - loss: 1.6899\n",
      "Epoch 4/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 0.4289 - loss: 1.5799\n",
      "Epoch 5/5\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.4360 - loss: 1.5821\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=cifar10_x_train, y=Y_cat, epochs=5, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4973 - loss: 1.4186\n",
      "fmp1_2 Loss: 1.4227, Accuracy: 48.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48980000615119934"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decide to implement a network as similar as possible, now that I understand the architecture better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1736359292.802755   84653 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/nicolas/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'fmp2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,930</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m160\u001b[0m)         │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │         \u001b[38;5;34m1,930\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FMP2(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP2, self).__init__()\n",
    "        # Input layer size 36x36\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU()) # 36x36 # comment left here to show how the first time I calculated them wrong, both by thinking the input is 36 when it is 32 and forgetting conv takes 1 \n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU()) # 25x25\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU()) # 18x18\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU()) # 13x13\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU()) # 9x9\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 6x6\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier \n",
    "        self.fc = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "K.clear_session()\n",
    "model = FMP2()\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - accuracy: 0.1167 - loss: 3.4283\n",
      "Epoch 2/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.2219 - loss: 2.1018\n",
      "Epoch 3/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.2716 - loss: 1.9459\n",
      "Epoch 4/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.3036 - loss: 1.8545\n",
      "Epoch 5/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.3509 - loss: 1.7390\n",
      "Epoch 6/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.3450 - loss: 1.7441\n",
      "Epoch 7/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.3815 - loss: 1.6585\n",
      "Epoch 8/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.3970 - loss: 1.6114\n",
      "Epoch 9/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.4307 - loss: 1.5329\n",
      "Epoch 10/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.4368 - loss: 1.5154\n",
      "Epoch 11/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.4658 - loss: 1.4397\n",
      "Epoch 12/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.4584 - loss: 1.4663\n",
      "Epoch 13/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.5142 - loss: 1.3237\n",
      "Epoch 14/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.5227 - loss: 1.3127\n",
      "Epoch 15/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - accuracy: 0.5367 - loss: 1.2826\n",
      "Epoch 16/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.4932 - loss: 1.3914\n",
      "Epoch 17/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.5470 - loss: 1.2439\n",
      "Epoch 18/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.5750 - loss: 1.1864\n",
      "Epoch 19/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.5959 - loss: 1.1199\n",
      "Epoch 20/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.6249 - loss: 1.0465\n",
      "Epoch 21/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.6117 - loss: 1.0764\n",
      "Epoch 22/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.6374 - loss: 1.0033\n",
      "Epoch 23/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.6540 - loss: 0.9672\n",
      "Epoch 24/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.6687 - loss: 0.9238\n",
      "Epoch 25/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.6799 - loss: 0.9022\n",
      "Epoch 26/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.6608 - loss: 0.9513\n",
      "Epoch 27/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.6870 - loss: 0.8783\n",
      "Epoch 28/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7082 - loss: 0.8188\n",
      "Epoch 29/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.7242 - loss: 0.7795\n",
      "Epoch 30/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.6999 - loss: 0.8446\n",
      "Epoch 31/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.7226 - loss: 0.7777\n",
      "Epoch 32/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7457 - loss: 0.7253\n",
      "Epoch 33/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.7253 - loss: 0.7673\n",
      "Epoch 34/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7394 - loss: 0.7312\n",
      "Epoch 35/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.7506 - loss: 0.7051\n",
      "Epoch 36/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7417 - loss: 0.7305\n",
      "Epoch 37/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.7514 - loss: 0.7027\n",
      "Epoch 38/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.7744 - loss: 0.6391\n",
      "Epoch 39/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.7784 - loss: 0.6272\n",
      "Epoch 40/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - accuracy: 0.7816 - loss: 0.6138\n",
      "Epoch 41/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.7736 - loss: 0.6382\n",
      "Epoch 42/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.7795 - loss: 0.6292\n",
      "Epoch 43/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.7813 - loss: 0.6140\n",
      "Epoch 44/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step - accuracy: 0.7614 - loss: 0.6816\n",
      "Epoch 45/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.7829 - loss: 0.6086\n",
      "Epoch 46/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - accuracy: 0.7482 - loss: 0.7192\n",
      "Epoch 47/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8020 - loss: 0.5620\n",
      "Epoch 48/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8048 - loss: 0.5577\n",
      "Epoch 49/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8033 - loss: 0.5565\n",
      "Epoch 50/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.8063 - loss: 0.5504\n",
      "Epoch 51/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.7828 - loss: 0.6314\n",
      "Epoch 52/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.7850 - loss: 0.6101\n",
      "Epoch 53/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7935 - loss: 0.5942\n",
      "Epoch 54/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8250 - loss: 0.4992\n",
      "Epoch 55/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8072 - loss: 0.5496\n",
      "Epoch 56/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.8087 - loss: 0.5457\n",
      "Epoch 57/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - accuracy: 0.8090 - loss: 0.5441\n",
      "Epoch 58/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.7985 - loss: 0.5795\n",
      "Epoch 59/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8330 - loss: 0.4743\n",
      "Epoch 60/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8144 - loss: 0.5329\n",
      "Epoch 61/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8229 - loss: 0.5098\n",
      "Epoch 62/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.8229 - loss: 0.5053\n",
      "Epoch 63/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8201 - loss: 0.5248\n",
      "Epoch 64/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7952 - loss: 0.5985\n",
      "Epoch 65/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8251 - loss: 0.4994\n",
      "Epoch 66/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.8104 - loss: 0.5396\n",
      "Epoch 67/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8117 - loss: 0.5375\n",
      "Epoch 68/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8340 - loss: 0.4732\n",
      "Epoch 69/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8411 - loss: 0.4605\n",
      "Epoch 70/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.8028 - loss: 0.5777\n",
      "Epoch 71/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.8192 - loss: 0.5290\n",
      "Epoch 72/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.8265 - loss: 0.5038\n",
      "Epoch 73/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.7917 - loss: 0.6077\n",
      "Epoch 74/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.8124 - loss: 0.5448\n",
      "Epoch 75/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.8247 - loss: 0.5088\n",
      "Epoch 76/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.8318 - loss: 0.4821\n",
      "Epoch 77/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.8467 - loss: 0.4383\n",
      "Epoch 78/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.8195 - loss: 0.5175\n",
      "Epoch 79/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.8206 - loss: 0.5184\n",
      "Epoch 80/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.7983 - loss: 20.8670\n",
      "Epoch 81/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1016 - loss: 243714144.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.1084 - loss: 8496773.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.1348 - loss: 365390.1562\n",
      "Epoch 84/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.1343 - loss: 177663.0469\n",
      "Epoch 85/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.1350 - loss: 142320.7188\n",
      "Epoch 86/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 2s/step - accuracy: 0.1413 - loss: 93992.5625\n",
      "Epoch 87/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.1378 - loss: 84295.3359\n",
      "Epoch 88/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.1439 - loss: 59382.1914\n",
      "Epoch 89/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.1421 - loss: 58674.5898\n",
      "Epoch 90/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1558 - loss: 48927.1211\n",
      "Epoch 91/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1519 - loss: 40118.8477\n",
      "Epoch 92/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1470 - loss: 39553.6289\n",
      "Epoch 93/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1536 - loss: 36048.1211\n",
      "Epoch 94/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1443 - loss: 39613.4141\n",
      "Epoch 95/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - accuracy: 0.1424 - loss: 41324.2695\n",
      "Epoch 96/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.1647 - loss: 22415.0137\n",
      "Epoch 97/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.1597 - loss: 21365.4355\n",
      "Epoch 98/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.1558 - loss: 21489.8867\n",
      "Epoch 99/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.1515 - loss: 22919.3477\n",
      "Epoch 100/100\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.1521 - loss: 18883.2539\n"
     ]
    }
   ],
   "source": [
    "Y_cat_train = tf.keras.utils.to_categorical(cifar10_y_train, num_classes=10)\n",
    "Y_cat_test = tf.keras.utils.to_categorical(cifar10_y_test, num_classes=10)\n",
    "\n",
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=100, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without checkpoints or early stop, the model clearly overfit!\n",
    "\n",
    "Now I realize I forgot to read section 4.4 and implement that network!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
