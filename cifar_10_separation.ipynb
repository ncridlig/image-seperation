{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE7oyG0wv6e0"
   },
   "source": [
    "# Separation of CIFAR-10 Images\n",
    "\n",
    "The model takes as input an image created by averaging two random samples from CIFAR-10 and is tasked with predicting the categories of the two components.\n",
    "\n",
    "**For sure it is a computer vision model.**\n",
    "\n",
    "The first image belongs to the first five categories (airplane, automobile, bird, cat, deer), while the second belongs to the remaining categories (dog, frog, horse, ship, truck). The model must return two labels, each within a range of five possible values.\n",
    "\n",
    "**(5->1, 5->1)**\n",
    "\n",
    "The evaluation metric for the model is as follows: calculate the classification accuracy for the two component images and then compute their average.\n",
    "\n",
    "**accuracy = acc1 + acc2 / 2**\n",
    "**where acc1 = (correct1/total) and acc2 = (correct2/total)**\n",
    "\n",
    "The metric should be evaluated on 10,000 inputs generated from test data. Repeat the calculation 10 times and measure the standard deviation, which must be reported.\n",
    "\n",
    "A data generator and some examples are provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USdmzjiO0W6D"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iHjnh5XP0Sq4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 09:18:17.640690: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736615897.661267   17527 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736615897.667286   17527 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-11 09:18:17.686517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.nn import fractional_max_pool\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.saving import load_model, save_model, save_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRYiW2ipukZF",
    "outputId": "0d5c8981-51da-4c92-de73-84bcac11aa2c"
   },
   "outputs": [],
   "source": [
    "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
    "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
    "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
    "assert cifar10_y_train.shape == (50000, 1)\n",
    "assert cifar10_y_test.shape == (10000, 1)\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "cifar10_x_train, cifar10_x_val, cifar10_y_train, cifar10_y_val = train_test_split(\n",
    "    cifar10_x_train, cifar10_y_train, test_size=0.1\n",
    ")\n",
    "\n",
    "# First classifier: \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\"\n",
    "# Second classifier: \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "# IDEA: extract the features with a CNN backbone and feed them to two seperate FCN classifiers. How about backpropogation?\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Normalizing to range (0,1)\n",
    "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
    "cifar10_x_val = (cifar10_x_val / 255.).astype(np.float32)\n",
    "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkiGnU4d0k4d"
   },
   "source": [
    "Let us split the images in two groups, according to their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Dpey42Vo07Yb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22515, 32, 32, 3) (22515, 1)\n",
      "(22485, 32, 32, 3) (22485, 1)\n",
      "(2485, 32, 32, 3) (2485, 1)\n",
      "(2515, 32, 32, 3) (2515, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n",
      "(5000, 32, 32, 3) (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "cond_1 = cifar10_y_train[:,0] < 5\n",
    "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
    "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
    "\n",
    "cond_2 = cifar10_y_train[:,0] >= 5\n",
    "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
    "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
    "\n",
    "cond_1_val = cifar10_y_val[:,0] < 5\n",
    "cifar10_x_val_1 = cifar10_x_val[cond_1_val]\n",
    "cifar10_y_val_1 = cifar10_y_val[cond_1_val]\n",
    "\n",
    "cond_2_val = cifar10_y_val[:,0] >= 5\n",
    "cifar10_x_val_2 = cifar10_x_val[cond_2_val]\n",
    "cifar10_y_val_2 = cifar10_y_val[cond_2_val]\n",
    "\n",
    "cond_1_test = cifar10_y_test[:,0] < 5\n",
    "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
    "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
    "\n",
    "cond_2_test = cifar10_y_test[:,0] >= 5\n",
    "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
    "cifar10_y_test_2 = cifar10_y_test[cond_2_test]\n",
    "\n",
    "print(cifar10_x_train_1.shape, cifar10_y_train_1.shape)\n",
    "print(cifar10_x_train_2.shape, cifar10_y_train_2.shape)\n",
    "print(cifar10_x_val_1.shape, cifar10_y_val_1.shape)\n",
    "print(cifar10_x_val_2.shape, cifar10_y_val_2.shape)\n",
    "print(cifar10_x_test_1.shape, cifar10_y_test_1.shape)\n",
    "print(cifar10_x_test_2.shape, cifar10_y_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmLYNuR-0s0m"
   },
   "source": [
    "Now we can define the generator. The input consists of two datasets (X1,X2), their corresponding labels (Y1,Y2), and a batch size.\n",
    "\n",
    "**Model input: (B x X1\\*X2)**\n",
    "**Model output: (B x Y1 x Y2)**\n",
    "\n",
    "The generator returns (x_data,y_data), where:\n",
    "* x_data is a batch of images obtained by averaging random samples from X1 and X2.\n",
    "* y_data is a pair of batches of labels corresponding to the component images, expressed in categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "\n",
    "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
    "  size1 = X1.shape[0]\n",
    "  size2 = X2.shape[0]\n",
    "  # Convert the integer labels into one hot encoded vectors for cross entropy loss\n",
    "  # Careful: since there are two different sets of labels, I need to code two seperate outputs with seperate cross entropy losses\n",
    "  # Keras (TF) can handle this with: model = models.Model(inputs=merged_input_image, outputs=[output1, output2])\n",
    "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
    "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
    "\n",
    "  while True:\n",
    "    # Random image selections\n",
    "    num1 = np.random.randint(0, size1, batchsize)\n",
    "    num2 = np.random.randint(0, size2, batchsize)\n",
    "    # Average image production\n",
    "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
    "    # Dictionary for y_data with keys matching the model\n",
    "    y_data = {'output1': Y1_cat[num1], 'output2': Y2_cat[num2]}\n",
    "    # Convert numpy to tf tensor\n",
    "    yield tf.convert_to_tensor(x_data), y_data\n",
    "\n",
    "traingen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,batchsize)\n",
    "valgen = datagenerator(cifar10_x_val_1,cifar10_x_val_2,cifar10_y_val_1,cifar10_y_val_2,batchsize)\n",
    "smalltestgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9lf3TuP2pdQ"
   },
   "source": [
    "\n",
    "Let us instantiate a generator on Cifar10 with batchsize=1, and let's see its behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "29TldJ6-720b"
   },
   "outputs": [],
   "source": [
    "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1DrJVzI3ysV"
   },
   "source": [
    "Let's generate an example, display the image that the model will take as input, and print the categories of the two overlapping components.\n",
    "\n",
    "You can re-run the cell to display new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "qL1sMtjG8VmG",
    "outputId": "5b9d6599-d407-4e32-dad7-f3f95890f0b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736540896.974210    4689 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:0a:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: cat, second = horse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe5a77978e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = next(datagen)\n",
    "\n",
    "print(\"first: {}, second = {}\".format(classes[np.argmax(y['output1'][0])],classes[np.argmax(y['output2'][0])+5]))\n",
    "#print(np.min(x[0]),np.max(x[0]))\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5lzBotwL5QN"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_p4UuG1QF8t"
   },
   "source": [
    "Let us define first of all the test generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQo8_6w-L4WY",
    "outputId": "a626a55c-7df8-456b-adcd-580d4166e184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736615818.500797   16445 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13105 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:0a:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
    "\n",
    "\n",
    "eval_samples_x, eval_samples_y = next(testgen)\n",
    "print(eval_samples_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MiLnkKROGCD"
   },
   "source": [
    "We now test a model producing random guesses. You will need to replace it with your own predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1GllTEtPN_xv"
   },
   "outputs": [],
   "source": [
    "def random_model(x):\n",
    "  #the random model ignores the input x and return a pair of random classes\n",
    "  # 10,000 examples in a 2 column array between 0 and 4 inclusive\n",
    "  return(np.random.randint(0,5,(10000,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gomFTuuDOy8A"
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "  eval_samples_x, eval_samples_y = next(testgen)\n",
    "  random_guesses = model(eval_samples_x)\n",
    "  correct_guesses_1 = random_guesses[:,0] == np.argmax(eval_samples_y['output1'],axis=1)\n",
    "  correct_guesses_2 = random_guesses[:,1] == np.argmax(eval_samples_y['output2'],axis=1)\n",
    "  return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4AL2M6yjJno",
    "outputId": "d84ecfb8-299f-4e37-85ee-c69b83a39e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20655"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(random_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7usBI88dje70"
   },
   "source": [
    "As expected, the accuracy is around 1/5 = 0.2\n",
    "\n",
    "Let us repeat the evaluation ten times, and compute the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFu8iEt9jdZA",
    "outputId": "93fa99f4-972a-4795-917b-b1db97dc7ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.199285\n",
      "standard deviation =  0.0022481158777963414\n"
     ]
    }
   ],
   "source": [
    "repeat_eval = 10\n",
    "eval_results = []\n",
    "for i in range(repeat_eval):\n",
    "  eval_results.append(eval_model(random_model))\n",
    "print(\"mean accuracy = \", np.mean(eval_results))\n",
    "print(\"standard deviation = \", np.std(eval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1yTRAzn4i9g"
   },
   "source": [
    "# What to Submit\n",
    "\n",
    "As usual, you need to submit a single notebook that must be executable on Colab. The notebook should be properly commented and include a complete record of the training process, as well as the calculation of accuracy according to the guidelines provided above.\n",
    "\n",
    "# Good luck!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I googled CIFAR-10 best accuracy and I fell upon a reddit post about a person trying to train it as fast as possible, [here](https://github.com/tysam-code/hlb-CIFAR10). Since I am not interested in light speed CIFAR-10, I googled only CIFAR-10 and arrived to the main website for this [dataset](https://www.cs.toronto.edu/~kriz/cifar.html). From there, I found a non-working link to Rodrigo Benenson since github.com has been deprecated and is now github.io, changing this and selecting \"who is the best in CIFAR-10 ?\" brought me to the [world rankings](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130). Now I will read these papers in order. The first is [Fractional Max Pooling](https://arxiv.org/abs/1412.6071), with an accuracy of 96.53%. As I read this, I think, is my task the same? As a human, can I learn to distinguish the two classes? For sure, I will have to use the generator to see.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">820</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m130\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │           \u001b[38;5;34m820\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m2,430\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m4,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m2,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │        \u001b[38;5;34m18,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,280</span> (110.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,280\u001b[0m (110.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,280</span> (110.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,280\u001b[0m (110.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define my fractional pooling model\n",
    "\n",
    "class FMP(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP, self).__init__()\n",
    "        # Input\n",
    "        #self.input_layer = layers.InputLayer(shape=(32, 32, 3))  # For CIFAR-10 images\n",
    "\n",
    "        # Four convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(10, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(20, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(30, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(40, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(50, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Three fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 3/2, 3/2, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 6/4, 6/4, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 10/7, 10/7, 1.0]\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        #self.dropout1 = layers.Dropout(0.0)  # 0% dropout in the first hidden layer\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Input\n",
    "        #x = self.input_layer(inputs)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv2(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv3(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "K.clear_session()\n",
    "model = FMP()\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 32, 32, 3)\n",
      "(45000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_cat_train = tf.keras.utils.to_categorical(cifar10_y_train, num_classes=10)\n",
    "Y_cat_test = tf.keras.utils.to_categorical(cifar10_y_test, num_classes=10)\n",
    "print(cifar10_x_train.shape)\n",
    "print(Y_cat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 549ms/step - accuracy: 0.1475 - loss: 2.2588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=1, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2547 - loss: 2.0465\n",
      "fmp Loss: 2.0488, Accuracy: 25.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25459998846054077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "def evaluate(model, x, y):\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    print(f\"{model.name} Loss: {loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing this, I feel like the convolutional layers would benefit from being more complex and so I use this [person's](https://github.com/WingsBrokenAngel/fractional_max_pooling_and_recurrent_convolutional_neural_network) filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,690</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m7,260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m21,690\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m43,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m18,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │        \u001b[38;5;34m54,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,820</span> (565.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m144,820\u001b[0m (565.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,820</span> (565.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m144,820\u001b[0m (565.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FMP1(Model):\n",
    "    def __init__(self, FILTERS):\n",
    "        super(FMP1, self).__init__()\n",
    "        # Parameters\n",
    "        self.filters = FILTERS\n",
    "\n",
    "        # Four convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(10*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(20*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(30*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(40*FILTERS, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(50*FILTERS, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Three fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 3/2, 3/2, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 6/4, 6/4, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 10/7, 10/7, 1.0]\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        #self.dropout1 = layers.Dropout(0.0)  # 0% dropout in the first hidden layer\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Input\n",
    "        #x = self.input_layer(inputs)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv2(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv3(x)\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # CIFAR-10\n",
    "\n",
    "        return x\n",
    "\n",
    "#K.clear_session()\n",
    "model = FMP1(FILTERS=3)\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.1188 - loss: 2.5421\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=1, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2040 - loss: 2.1521\n",
      "fmp1 Loss: 2.1532, Accuracy: 20.36%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20360000431537628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decide to implement a network as similar as possible, now that I understand the architecture better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMP2(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP2, self).__init__()\n",
    "        # Input layer size 36x36\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU()) # 36x36 # comment left here to show how the first time I calculated them wrong, both by thinking the input is 36 when it is 32 and forgetting conv takes 1 \n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU()) # 25x25\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU()) # 18x18\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU()) # 13x13\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU()) # 9x9\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 6x6\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Classifier \n",
    "        self.fc = layers.Dense(10, activation='softmax')  # CIFAR-10 (10 classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # CIFAR-10\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,930</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │         \u001b[38;5;34m1,930\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP2()\n",
    "model.build(input_shape=(None, 32, 32, 3))  # Adjust if needed\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.1003 - loss: 14.8851\n"
     ]
    }
   ],
   "source": [
    "Y_cat_train = tf.keras.utils.to_categorical(cifar10_y_train, num_classes=10)\n",
    "\n",
    "history = model.fit(x=cifar10_x_train, y=Y_cat_train, epochs=1, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1286 - loss: 2.3659\n",
      "fmp2 Loss: 2.3636, Accuracy: 12.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12549999356269836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, x=cifar10_x_test, y=Y_cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without checkpoints or early stop, the model clearly overfit!\n",
    "\n",
    "Now I realize I forgot to read section 4.4 and implement that network! However, before, I try to move my network from the proxy task to the real one by adding a second classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP3(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP3, self).__init__()\n",
    "        # Input layer size 32x32\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU())\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Two Classifiers \n",
    "        self.fc1 = layers.Dense(5, activation='softmax', name='output1')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax', name='output2')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        output1 = self.fc1(x)  # First half\n",
    "        output2 = self.fc2(x)  # Second half\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Serialize the configuration of the model\n",
    "        config = super(FMP3, self).get_config()\n",
    "        config.update({\n",
    "            'conv1': self.conv1.get_config(),\n",
    "            'conv2': self.conv2.get_config(),\n",
    "            'conv3': self.conv3.get_config(),\n",
    "            'conv4': self.conv4.get_config(),\n",
    "            'conv5': self.conv5.get_config(),\n",
    "            'conv6': self.conv6.get_config(),\n",
    "            'conv7': self.conv7.get_config(),\n",
    "            'conv8': self.conv8.get_config(),\n",
    "            'dropout': self.dropout.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "            'pooling_ratios': [\n",
    "                self.pooling_ratio1,\n",
    "                self.pooling_ratio2,\n",
    "                self.pooling_ratio3,\n",
    "                self.pooling_ratio4,\n",
    "                self.pooling_ratio5,\n",
    "                self.pooling_ratio6\n",
    "            ]\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP3()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [answer](https://stackoverflow.com/questions/55908188/this-model-has-not-yet-been-built-error-on-model-summary) with 39 upvotes explains why this summary is a bit strange (Keras subclasses Model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 3.2640 - output1_accuracy: 0.1915 - output2_accuracy: 0.1730\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.1825 - output1_accuracy: 0.3210 - output2_accuracy: 0.1944\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.2185 - output1_accuracy: 0.2629 - output2_accuracy: 0.2418\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.2213 - output1_accuracy: 0.3148 - output2_accuracy: 0.2314\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.1669 - output1_accuracy: 0.3013 - output2_accuracy: 0.2873\n"
     ]
    }
   ],
   "source": [
    "# Generate random dummy data (e.g., 100 samples, 32x32 RGB images)\n",
    "X_train = np.random.randn(100, 32, 32, 3).astype(np.float32)\n",
    "y_train1 = np.random.randint(0, 5, 100)  # Random labels for output 1\n",
    "y_train2 = np.random.randint(0, 5, 100)  # Random labels for output 2\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train1 = tf.keras.utils.to_categorical(y_train1, 5)\n",
    "y_train2 = tf.keras.utils.to_categorical(y_train2, 5)\n",
    "\n",
    "# Train the model directly using the data (no generator)\n",
    "history = model.fit(X_train, {'output1': y_train1, 'output2':y_train2}, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had a long and painful time figuring out why my generator was not working with fit. Finally I understood that the output of the generator must have a dictionary whose entries match those of the model when compiled!\n",
    "https://stackoverflow.com/questions/44036971/multiple-outputs-in-keras\n",
    "Before that I went down a rabbit hole with older versions of keras which require [fit_generator](https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/) because of a stack exchange [post](https://datascience.stackexchange.com/questions/67266/how-to-write-a-generator-for-keras-fit-generator).\n",
    "I read the keras documentation and confirmed that generators are in fact, [well supported](https://keras.io/api/models/model_training_apis/). This hinted to me that the generator would probably work for a simpler single input, single output model.\n",
    "I researched how to create [my own data generator class](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly) that inherits from Keras Sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 98ms/step - loss: 3.0398 - output1_accuracy: 0.2971 - output2_accuracy: 0.3073\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(traingen, epochs=1, steps_per_epoch=len(cifar10_x_train)//batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training with [checkpoints](https://keras.io/api/callbacks/model_checkpoint/)! Its easy! Also add early stopping! I look at my history to verify the names of my scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.8955788612365723],\n",
       " 'output1_accuracy': [0.34895092248916626],\n",
       " 'output2_accuracy': [0.37237730622291565]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I implement a custom model callback to save the model weights when the average accuracy improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback which does not use loss as a proxy!\n",
    "class MeanAccModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor1='output1_accuracy', monitor2='output2_accuracy', mode='max', verbose=1):\n",
    "        super(MeanAccModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor1 = monitor1\n",
    "        self.monitor2 = monitor2\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best_score = -float('inf') if mode == 'max' else float('inf')\n",
    "\n",
    "    # Called at the end of an epoch during training\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc1 = logs.get(self.monitor1)\n",
    "        acc2 = logs.get(self.monitor2)\n",
    "\n",
    "        # Compute the average accuracy\n",
    "        avg_accuracy = (acc1 + acc2) / 2 if acc1 is not None and acc2 is not None else None\n",
    "\n",
    "        if avg_accuracy is not None:\n",
    "            if (self.mode == 'max' and avg_accuracy > self.best_score) or \\\n",
    "               (self.mode == 'min' and avg_accuracy < self.best_score):\n",
    "                # Update the best score\n",
    "                self.best_score = avg_accuracy\n",
    "                \n",
    "                # Format the filepath\n",
    "                save_path = self.filepath.format(\n",
    "                    output1_accuracy=acc1,\n",
    "                    output2_accuracy=acc2,\n",
    "                    epoch=epoch + 1,  # Epoch is zero-indexed\n",
    "                    loss=logs.get('loss')\n",
    "                )\n",
    "                \n",
    "                # Save the model\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nEpoch {epoch + 1}: Average accuracy improved to {avg_accuracy:.4f}, saving model to {save_path}\")\n",
    "                self.model.save(save_path)\n",
    "            elif self.verbose:\n",
    "                print(f\"\\nEpoch {epoch + 1}: Average accuracy did not improve (current: {avg_accuracy:.4f}, best: {self.best_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to train more, but it bothers me that I am saving models based on loss, so lets write a custom callback which matches our evaluation criteria! I follow this page on [Callbacks](https://keras.io/guides/writing_your_own_callbacks/) and decide I also wish to employ the Tensorboard callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP3/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: Average accuracy improved to 0.6707, saving model to ./FMP3/0.63-0.71-epoch01-loss1.68.keras\n",
      "703/703 - 69s - 97ms/step - loss: 1.6830 - output1_accuracy: 0.6299 - output2_accuracy: 0.7209 - val_loss: 1.7101 - val_output1_accuracy: 0.6340 - val_output2_accuracy: 0.7073\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: Average accuracy did not improve (current: 0.6627, best: 0.6707)\n",
      "703/703 - 68s - 97ms/step - loss: 1.6612 - output1_accuracy: 0.6377 - output2_accuracy: 0.7221 - val_loss: 1.7644 - val_output1_accuracy: 0.6196 - val_output2_accuracy: 0.7057\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: Average accuracy improved to 0.6812, saving model to ./FMP3/0.64-0.72-epoch03-loss1.67.keras\n",
      "703/703 - 69s - 98ms/step - loss: 1.6667 - output1_accuracy: 0.6369 - output2_accuracy: 0.7217 - val_loss: 1.6689 - val_output1_accuracy: 0.6390 - val_output2_accuracy: 0.7234\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: Average accuracy did not improve (current: 0.6718, best: 0.6812)\n",
      "703/703 - 69s - 98ms/step - loss: 1.6482 - output1_accuracy: 0.6349 - output2_accuracy: 0.7263 - val_loss: 1.6992 - val_output1_accuracy: 0.6288 - val_output2_accuracy: 0.7147\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: Average accuracy did not improve (current: 0.6708, best: 0.6812)\n",
      "703/703 - 69s - 98ms/step - loss: 1.6448 - output1_accuracy: 0.6378 - output2_accuracy: 0.7281 - val_loss: 1.7147 - val_output1_accuracy: 0.6322 - val_output2_accuracy: 0.7093\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: Average accuracy did not improve (current: 0.6747, best: 0.6812)\n",
      "703/703 - 70s - 99ms/step - loss: 1.6402 - output1_accuracy: 0.6430 - output2_accuracy: 0.7297 - val_loss: 1.7124 - val_output1_accuracy: 0.6332 - val_output2_accuracy: 0.7161\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: Average accuracy did not improve (current: 0.6658, best: 0.6812)\n",
      "703/703 - 70s - 99ms/step - loss: 1.6370 - output1_accuracy: 0.6409 - output2_accuracy: 0.7293 - val_loss: 1.7561 - val_output1_accuracy: 0.6232 - val_output2_accuracy: 0.7083\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: Average accuracy did not improve (current: 0.6678, best: 0.6812)\n",
      "703/703 - 70s - 100ms/step - loss: 1.6382 - output1_accuracy: 0.6456 - output2_accuracy: 0.7277 - val_loss: 1.7547 - val_output1_accuracy: 0.6338 - val_output2_accuracy: 0.7017\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: Average accuracy did not improve (current: 0.6721, best: 0.6812)\n",
      "703/703 - 71s - 101ms/step - loss: 1.6140 - output1_accuracy: 0.6466 - output2_accuracy: 0.7352 - val_loss: 1.7365 - val_output1_accuracy: 0.6206 - val_output2_accuracy: 0.7236\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: Average accuracy improved to 0.6841, saving model to ./FMP3/0.64-0.73-epoch10-loss1.63.keras\n",
      "703/703 - 71s - 101ms/step - loss: 1.6285 - output1_accuracy: 0.6405 - output2_accuracy: 0.7333 - val_loss: 1.6441 - val_output1_accuracy: 0.6364 - val_output2_accuracy: 0.7318\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: Average accuracy did not improve (current: 0.6655, best: 0.6841)\n",
      "703/703 - 72s - 103ms/step - loss: 1.6173 - output1_accuracy: 0.6442 - output2_accuracy: 0.7348 - val_loss: 1.7695 - val_output1_accuracy: 0.6316 - val_output2_accuracy: 0.6993\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: Average accuracy did not improve (current: 0.6740, best: 0.6841)\n",
      "703/703 - 73s - 103ms/step - loss: 1.6025 - output1_accuracy: 0.6465 - output2_accuracy: 0.7356 - val_loss: 1.7141 - val_output1_accuracy: 0.6302 - val_output2_accuracy: 0.7177\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: Average accuracy did not improve (current: 0.6834, best: 0.6841)\n",
      "703/703 - 72s - 102ms/step - loss: 1.6018 - output1_accuracy: 0.6466 - output2_accuracy: 0.7390 - val_loss: 1.6382 - val_output1_accuracy: 0.6386 - val_output2_accuracy: 0.7282\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: Average accuracy did not improve (current: 0.6717, best: 0.6841)\n",
      "703/703 - 72s - 103ms/step - loss: 1.6024 - output1_accuracy: 0.6456 - output2_accuracy: 0.7373 - val_loss: 1.7254 - val_output1_accuracy: 0.6270 - val_output2_accuracy: 0.7163\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: Average accuracy did not improve (current: 0.6816, best: 0.6841)\n",
      "703/703 - 73s - 103ms/step - loss: 1.5975 - output1_accuracy: 0.6505 - output2_accuracy: 0.7369 - val_loss: 1.6747 - val_output1_accuracy: 0.6452 - val_output2_accuracy: 0.7179\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: Average accuracy did not improve (current: 0.6711, best: 0.6841)\n",
      "703/703 - 73s - 104ms/step - loss: 1.5927 - output1_accuracy: 0.6522 - output2_accuracy: 0.7364 - val_loss: 1.7076 - val_output1_accuracy: 0.6320 - val_output2_accuracy: 0.7101\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: Average accuracy did not improve (current: 0.6720, best: 0.6841)\n",
      "703/703 - 74s - 105ms/step - loss: 1.5962 - output1_accuracy: 0.6490 - output2_accuracy: 0.7367 - val_loss: 1.7189 - val_output1_accuracy: 0.6322 - val_output2_accuracy: 0.7117\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: Average accuracy did not improve (current: 0.6731, best: 0.6841)\n",
      "703/703 - 73s - 104ms/step - loss: 1.5859 - output1_accuracy: 0.6531 - output2_accuracy: 0.7384 - val_loss: 1.7184 - val_output1_accuracy: 0.6426 - val_output2_accuracy: 0.7035\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: Average accuracy improved to 0.6849, saving model to ./FMP3/0.64-0.73-epoch19-loss1.57.keras\n",
      "703/703 - 73s - 104ms/step - loss: 1.5670 - output1_accuracy: 0.6555 - output2_accuracy: 0.7427 - val_loss: 1.6410 - val_output1_accuracy: 0.6366 - val_output2_accuracy: 0.7332\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: Average accuracy improved to 0.6889, saving model to ./FMP3/0.66-0.72-epoch20-loss1.57.keras\n",
      "703/703 - 74s - 105ms/step - loss: 1.5738 - output1_accuracy: 0.6555 - output2_accuracy: 0.7431 - val_loss: 1.6384 - val_output1_accuracy: 0.6552 - val_output2_accuracy: 0.7226\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: Average accuracy did not improve (current: 0.6885, best: 0.6889)\n",
      "703/703 - 74s - 105ms/step - loss: 1.5667 - output1_accuracy: 0.6541 - output2_accuracy: 0.7469 - val_loss: 1.6245 - val_output1_accuracy: 0.6478 - val_output2_accuracy: 0.7292\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: Average accuracy did not improve (current: 0.6842, best: 0.6889)\n",
      "703/703 - 74s - 105ms/step - loss: 1.5729 - output1_accuracy: 0.6550 - output2_accuracy: 0.7421 - val_loss: 1.6747 - val_output1_accuracy: 0.6380 - val_output2_accuracy: 0.7304\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: Average accuracy improved to 0.6935, saving model to ./FMP3/0.65-0.73-epoch23-loss1.57.keras\n",
      "703/703 - 76s - 107ms/step - loss: 1.5720 - output1_accuracy: 0.6544 - output2_accuracy: 0.7421 - val_loss: 1.5966 - val_output1_accuracy: 0.6540 - val_output2_accuracy: 0.7330\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: Average accuracy did not improve (current: 0.6909, best: 0.6935)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5644 - output1_accuracy: 0.6564 - output2_accuracy: 0.7452 - val_loss: 1.6360 - val_output1_accuracy: 0.6506 - val_output2_accuracy: 0.7312\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: Average accuracy did not improve (current: 0.6726, best: 0.6935)\n",
      "703/703 - 75s - 106ms/step - loss: 1.5472 - output1_accuracy: 0.6615 - output2_accuracy: 0.7480 - val_loss: 1.7201 - val_output1_accuracy: 0.6162 - val_output2_accuracy: 0.7290\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: Average accuracy did not improve (current: 0.6833, best: 0.6935)\n",
      "703/703 - 75s - 106ms/step - loss: 1.5525 - output1_accuracy: 0.6593 - output2_accuracy: 0.7454 - val_loss: 1.6668 - val_output1_accuracy: 0.6412 - val_output2_accuracy: 0.7254\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: Average accuracy did not improve (current: 0.6833, best: 0.6935)\n",
      "703/703 - 74s - 106ms/step - loss: 1.5514 - output1_accuracy: 0.6615 - output2_accuracy: 0.7463 - val_loss: 1.6660 - val_output1_accuracy: 0.6524 - val_output2_accuracy: 0.7141\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: Average accuracy improved to 0.6938, saving model to ./FMP3/0.65-0.74-epoch28-loss1.55.keras\n",
      "703/703 - 75s - 107ms/step - loss: 1.5487 - output1_accuracy: 0.6593 - output2_accuracy: 0.7483 - val_loss: 1.6177 - val_output1_accuracy: 0.6520 - val_output2_accuracy: 0.7356\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: Average accuracy did not improve (current: 0.6841, best: 0.6938)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5344 - output1_accuracy: 0.6636 - output2_accuracy: 0.7508 - val_loss: 1.6543 - val_output1_accuracy: 0.6354 - val_output2_accuracy: 0.7328\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: Average accuracy did not improve (current: 0.6897, best: 0.6938)\n",
      "703/703 - 74s - 106ms/step - loss: 1.5347 - output1_accuracy: 0.6654 - output2_accuracy: 0.7496 - val_loss: 1.6440 - val_output1_accuracy: 0.6446 - val_output2_accuracy: 0.7348\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: Average accuracy did not improve (current: 0.6897, best: 0.6938)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5428 - output1_accuracy: 0.6616 - output2_accuracy: 0.7493 - val_loss: 1.6089 - val_output1_accuracy: 0.6500 - val_output2_accuracy: 0.7294\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: Average accuracy did not improve (current: 0.6691, best: 0.6938)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5405 - output1_accuracy: 0.6588 - output2_accuracy: 0.7496 - val_loss: 1.7155 - val_output1_accuracy: 0.6342 - val_output2_accuracy: 0.7039\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: Average accuracy improved to 0.6959, saving model to ./FMP3/0.65-0.74-epoch33-loss1.54.keras\n",
      "703/703 - 76s - 108ms/step - loss: 1.5388 - output1_accuracy: 0.6612 - output2_accuracy: 0.7473 - val_loss: 1.5881 - val_output1_accuracy: 0.6502 - val_output2_accuracy: 0.7416\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: Average accuracy did not improve (current: 0.6943, best: 0.6959)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5346 - output1_accuracy: 0.6625 - output2_accuracy: 0.7495 - val_loss: 1.5883 - val_output1_accuracy: 0.6486 - val_output2_accuracy: 0.7400\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: Average accuracy did not improve (current: 0.6872, best: 0.6959)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5196 - output1_accuracy: 0.6686 - output2_accuracy: 0.7530 - val_loss: 1.6475 - val_output1_accuracy: 0.6522 - val_output2_accuracy: 0.7222\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: Average accuracy did not improve (current: 0.6885, best: 0.6959)\n",
      "703/703 - 74s - 106ms/step - loss: 1.5341 - output1_accuracy: 0.6649 - output2_accuracy: 0.7504 - val_loss: 1.6060 - val_output1_accuracy: 0.6420 - val_output2_accuracy: 0.7350\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: Average accuracy improved to 0.7038, saving model to ./FMP3/0.67-0.74-epoch37-loss1.52.keras\n",
      "703/703 - 75s - 107ms/step - loss: 1.5244 - output1_accuracy: 0.6662 - output2_accuracy: 0.7504 - val_loss: 1.5811 - val_output1_accuracy: 0.6687 - val_output2_accuracy: 0.7390\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: Average accuracy did not improve (current: 0.6998, best: 0.7038)\n",
      "703/703 - 77s - 109ms/step - loss: 1.4968 - output1_accuracy: 0.6714 - output2_accuracy: 0.7585 - val_loss: 1.5972 - val_output1_accuracy: 0.6538 - val_output2_accuracy: 0.7458\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: Average accuracy did not improve (current: 0.6926, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5045 - output1_accuracy: 0.6665 - output2_accuracy: 0.7583 - val_loss: 1.6016 - val_output1_accuracy: 0.6458 - val_output2_accuracy: 0.7394\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: Average accuracy did not improve (current: 0.6973, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5168 - output1_accuracy: 0.6674 - output2_accuracy: 0.7553 - val_loss: 1.5993 - val_output1_accuracy: 0.6558 - val_output2_accuracy: 0.7388\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: Average accuracy did not improve (current: 0.7014, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5086 - output1_accuracy: 0.6716 - output2_accuracy: 0.7548 - val_loss: 1.6038 - val_output1_accuracy: 0.6524 - val_output2_accuracy: 0.7504\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: Average accuracy did not improve (current: 0.6831, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5004 - output1_accuracy: 0.6687 - output2_accuracy: 0.7574 - val_loss: 1.6317 - val_output1_accuracy: 0.6374 - val_output2_accuracy: 0.7288\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: Average accuracy did not improve (current: 0.7031, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5057 - output1_accuracy: 0.6697 - output2_accuracy: 0.7561 - val_loss: 1.5636 - val_output1_accuracy: 0.6671 - val_output2_accuracy: 0.7392\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: Average accuracy did not improve (current: 0.6929, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.4965 - output1_accuracy: 0.6730 - output2_accuracy: 0.7588 - val_loss: 1.5949 - val_output1_accuracy: 0.6416 - val_output2_accuracy: 0.7442\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: Average accuracy did not improve (current: 0.6975, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5084 - output1_accuracy: 0.6654 - output2_accuracy: 0.7553 - val_loss: 1.5890 - val_output1_accuracy: 0.6558 - val_output2_accuracy: 0.7392\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: Average accuracy did not improve (current: 0.6746, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.4914 - output1_accuracy: 0.6723 - output2_accuracy: 0.7610 - val_loss: 1.7206 - val_output1_accuracy: 0.6104 - val_output2_accuracy: 0.7388\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: Average accuracy did not improve (current: 0.6904, best: 0.7038)\n",
      "703/703 - 75s - 107ms/step - loss: 1.5001 - output1_accuracy: 0.6711 - output2_accuracy: 0.7594 - val_loss: 1.6086 - val_output1_accuracy: 0.6583 - val_output2_accuracy: 0.7226\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: Average accuracy did not improve (current: 0.6899, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5059 - output1_accuracy: 0.6724 - output2_accuracy: 0.7528 - val_loss: 1.6062 - val_output1_accuracy: 0.6370 - val_output2_accuracy: 0.7428\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: Average accuracy did not improve (current: 0.6985, best: 0.7038)\n",
      "703/703 - 76s - 107ms/step - loss: 1.4825 - output1_accuracy: 0.6729 - output2_accuracy: 0.7580 - val_loss: 1.5842 - val_output1_accuracy: 0.6530 - val_output2_accuracy: 0.7440\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 50: Average accuracy did not improve (current: 0.6967, best: 0.7038)\n",
      "703/703 - 76s - 108ms/step - loss: 1.5004 - output1_accuracy: 0.6722 - output2_accuracy: 0.7553 - val_loss: 1.6083 - val_output1_accuracy: 0.6673 - val_output2_accuracy: 0.7262\n",
      "Epoch 51/100\n",
      "\n",
      "Epoch 51: Average accuracy did not improve (current: 0.6882, best: 0.7038)\n",
      "703/703 - 78s - 111ms/step - loss: 1.4985 - output1_accuracy: 0.6737 - output2_accuracy: 0.7572 - val_loss: 1.6375 - val_output1_accuracy: 0.6494 - val_output2_accuracy: 0.7270\n",
      "Epoch 52/100\n",
      "\n",
      "Epoch 52: Average accuracy did not improve (current: 0.6985, best: 0.7038)\n",
      "703/703 - 78s - 110ms/step - loss: 1.4922 - output1_accuracy: 0.6717 - output2_accuracy: 0.7573 - val_loss: 1.5746 - val_output1_accuracy: 0.6633 - val_output2_accuracy: 0.7338\n",
      "Epoch 53/100\n",
      "\n",
      "Epoch 53: Average accuracy did not improve (current: 0.6952, best: 0.7038)\n",
      "703/703 - 81s - 115ms/step - loss: 1.4782 - output1_accuracy: 0.6758 - output2_accuracy: 0.7568 - val_loss: 1.6027 - val_output1_accuracy: 0.6575 - val_output2_accuracy: 0.7330\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get a baseline, by evaluating this model according to the project prompt! As always with **tqdm** I first imported it directly, then remembered you have the import the module with the same name as the library. My evaluated model is fresh and initialized with the best trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training, I think about data augmentation. I only have 50,000 test samples so if train 100 epochs I for sure am overfitting, need to research which augmentations are successful on CIFAR-10 to help the model generalize. My intuition says mirroring along the vertical axis should be safe. I do not think color augmentations are a good idea, since the colors are already degraded due to the random image merge. As I am thinking of this, I also realize a validation set would help me stop overfitting and allow me to test if data augmentation are helping, so I implement it (at the top of the notebook). Now I need to fit my model with validation accuracies and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(filepath, gen, repeat=1, steps=1):\n",
    "    model = load_model(filepath)\n",
    "    evaluation_results = []\n",
    "    for i in tqdm(range(repeat)):\n",
    "        loss, acc1, acc2 = model.evaluate(gen, batch_size=10000, steps=steps, verbose=False)\n",
    "        evaluation_results.append(np.mean([acc1, acc2]))\n",
    "    print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "    print(\"standard deviation = \", np.std(evaluation_results))\n",
    "\n",
    "#evaluate_model('./FMP3/0.67-0.74-epoch37-loss1.52.keras', testgen, repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am very happy with 70.9% accuracy, now I have to make sure saving and loading work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:31<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6927750051021576\n",
      "standard deviation =  0.006946627811636093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, acc2 = model.evaluate(testgen, batch_size=10000, steps=1, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement my idea to include dropout at 25% after conv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP4(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP4, self).__init__()\n",
    "        # Input layer size 32x32\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU())\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout1 = layers.Dropout(0.25)  # 50% dropout in the final hidden layer\n",
    "        self.dropout2 = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Two Classifiers \n",
    "        self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(inputs) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        x = self.dropout1(x) # IDEA: dropout here at 25%\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout2(x)\n",
    "        output1 = self.fc1(x)  # First half\n",
    "        output2 = self.fc2(x)  # Second half\n",
    "        print(f\"Final Output Shapes: output1={output1.shape}, output2={output2.shape}\")\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Serialize the configuration of the model\n",
    "        config = super(FMP4, self).get_config()\n",
    "        config.update({\n",
    "            'conv1': self.conv1.get_config(),\n",
    "            'conv2': self.conv2.get_config(),\n",
    "            'conv3': self.conv3.get_config(),\n",
    "            'conv4': self.conv4.get_config(),\n",
    "            'conv5': self.conv5.get_config(),\n",
    "            'conv6': self.conv6.get_config(),\n",
    "            'conv7': self.conv7.get_config(),\n",
    "            'conv8': self.conv8.get_config(),\n",
    "            'dropout1': self.dropout1.get_config(),\n",
    "            'dropout2': self.dropout2.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "            'pooling_ratios': [\n",
    "                self.pooling_ratio1,\n",
    "                self.pooling_ratio2,\n",
    "                self.pooling_ratio3,\n",
    "                self.pooling_ratio4,\n",
    "                self.pooling_ratio5,\n",
    "                self.pooling_ratio6\n",
    "            ]\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output Shapes: output1=(1, 5), output2=(1, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Final Output Shapes: output1=(None, 5), output2=(None, 5)\n",
      "Final Output Shapes: output1=(None, 5), output2=(None, 5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 23\u001b[0m\n\u001b[1;32m     10\u001b[0m val_model_checkpoint_callback \u001b[38;5;241m=\u001b[39m MeanAccModelCheckpoint(\n\u001b[1;32m     11\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FMP4/\u001b[39m\u001b[38;5;132;01m{output1_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{output2_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-loss\u001b[39m\u001b[38;5;132;01m{loss:.2f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     monitor1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output1_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     monitor2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output2_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m val_early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Track the validation loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                                patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,         \u001b[38;5;66;03m# Number of epochs to wait after the last improvement\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# Stop when the value stops decreasing (minimization)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                                restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Restore the best weights when stopping\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_model_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP4()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()\n",
    "\n",
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP4/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,           \n",
    "    epochs=100,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen, \n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:30<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6774300068616868\n",
      "standard deviation =  0.009838248775686023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model('./FMP4/0.65-0.73-epoch41-loss1.61.keras', testgen, repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more dropout made things worse! This model taken from section 4.4, still needs data augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP5(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP5, self).__init__()\n",
    "\n",
    "        # Feature Extractor: Twelve convolutional layers with padding\n",
    "        self.convs = [\n",
    "            layers.Conv2D(160 + 160 * i, (2, 2), activation=LeakyReLU(), padding='same')\n",
    "            for i in range(12)\n",
    "        ]\n",
    "\n",
    "        # Fractional Max Pooling Ratios (1.26)\n",
    "        # self.pooling_ratios = [\n",
    "        #     [1.0, 32/25, 32/25, 1.0],  \n",
    "        #     [1.0, 25/20, 25/20, 1.0],\n",
    "        #     [1.0, 20/16, 20/16, 1.0],\n",
    "        #     [1.0, 16/13, 16/13, 1.0],\n",
    "        #     [1.0, 13/10, 13/10, 1.0],\n",
    "        #     [1.0, 10/8, 10/8, 1.0],\n",
    "        #     [1.0, 8/6, 8/6, 1.0], \n",
    "        #     [1.0, 6/5, 6/5, 1.0],\n",
    "        #     [1.0, 5/4, 5/4, 1.0],\n",
    "        #     [1.0, 4/3, 4/3, 1.0],\n",
    "        #     [1.0, 3/2, 3/2, 1.0],\n",
    "        #     [1.0, 2/1, 2/1, 1.0],\n",
    "        # ]\n",
    "\n",
    "        self.pooling_ratios = [\n",
    "            [1.0, 32/28, 32/28, 1.0],  # From 32x32 to ~28x28\n",
    "            [1.0, 28/24, 28/24, 1.0],  # From ~28x28 to ~24x24\n",
    "            [1.0, 24/20, 24/20, 1.0],  # From ~24x24 to ~20x20\n",
    "            [1.0, 20/16, 20/16, 1.0],  # From ~20x20 to ~16x16\n",
    "            [1.0, 16/13, 16/13, 1.0],  # From ~16x16 to ~13x13\n",
    "            [1.0, 13/10, 13/10, 1.0],  # From ~13x13 to ~10x10\n",
    "            [1.0, 10/8, 10/8, 1.0],    # From ~10x10 to ~8x8\n",
    "            [1.0, 8/6, 8/6, 1.0],      # From ~8x8 to ~6x6\n",
    "            [1.0, 6/5, 6/5, 1.0],      # From ~6x6 to ~5x5\n",
    "            [1.0, 5/4, 5/4, 1.0],      # From ~5x5 to ~4x4\n",
    "            [1.0, 4/3, 4/3, 1.0],      # From ~4x4 to ~3x3\n",
    "            [1.0, 3/2, 3/2, 1.0],      # From ~3x3 to ~2x2\n",
    "        ]\n",
    "\n",
    "        # Final convolutional layers with padding\n",
    "        self.conv = layers.Conv2D(1920, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Track spatial dimensions starting from input size\n",
    "        x = inputs\n",
    "\n",
    "        for i in range(12):\n",
    "            x = self.convs[i](x)  # Convolution with padding to maintain spatial size\n",
    "            x, _, _ = fractional_max_pool(x, pooling_ratio=self.pooling_ratios[i], pseudo_random=True, overlapping=True)\n",
    "            # print(f\"After FMP{i + 1}: {x.shape}\")\n",
    "\n",
    "        # Final convolution and dropout\n",
    "        x = self.conv(x)\n",
    "        # print(f\"After final conv: {x.shape}\")\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Two separate classifier heads\n",
    "        x = layers.Flatten()(x)\n",
    "        output1 = self.fc1(x)\n",
    "        output2 = self.fc2(x)\n",
    "        # print(f\"Final Output Shapes: output1={output1.shape}, output2={output2.shape}\")\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(FMP5, self).get_config()\n",
    "        config.update({\n",
    "            'conv_layers': [conv.get_config() for conv in self.convs],\n",
    "            'pooling_ratios': self.pooling_ratios,\n",
    "            'conv': self.conv.get_config(),\n",
    "            'dropout': self.dropout.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">205,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">614,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,229,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,072,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,301,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,735,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,374,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,217,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,265,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,518,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,688,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,605</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,605</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m205,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m614,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m1,229,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m2,048,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m3,072,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m4,301,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m5,735,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m7,374,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │     \u001b[38;5;34m9,217,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │    \u001b[38;5;34m11,265,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │    \u001b[38;5;34m13,518,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │     \u001b[38;5;34m3,688,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │         \u001b[38;5;34m9,605\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │         \u001b[38;5;34m9,605\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,294,730</span> (237.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,294,730\u001b[0m (237.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,294,730</span> (237.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,294,730\u001b[0m (237.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 23\u001b[0m\n\u001b[1;32m     10\u001b[0m val_model_checkpoint_callback \u001b[38;5;241m=\u001b[39m MeanAccModelCheckpoint(\n\u001b[1;32m     11\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FMP5/\u001b[39m\u001b[38;5;132;01m{output1_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{output2_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-loss\u001b[39m\u001b[38;5;132;01m{loss:.2f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     monitor1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output1_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     monitor2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output2_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m val_early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Track the validation loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                                patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,         \u001b[38;5;66;03m# Number of epochs to wait after the last improvement\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# Stop when the value stops decreasing (minimization)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                                restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Restore the best weights when stopping\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_model_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP5()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()\n",
    "\n",
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP5/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,           \n",
    "    epochs=100,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen, \n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem, fractional max pooling is only supported in CPU. Also, I read [this](https://stackoverflow.com/questions/39886715/fractional-max-pooling-in-tensorflow). Let's explore the second best CIFAR-10 paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class ACNN(Model):\n",
    "    def __init__(self):\n",
    "        super(ACNN, self).__init__()\n",
    "        \n",
    "        # Layer Definitions\n",
    "        self.conv1 = layers.Conv2D(320, (2, 2), strides=1, activation=LeakyReLU(), padding='valid')\n",
    "        self.act1 = layers.LeakyReLU()\n",
    "        self.conv2 = layers.Conv2D(320, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act2 = layers.LeakyReLU()\n",
    "        self.conv3 = layers.Conv2D(320, (2, 2), strides=2, activation='linear', padding='valid')\n",
    "        self.act3 = layers.LeakyReLU()\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(640, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act4 = layers.LeakyReLU()\n",
    "        self.drop4 = layers.Dropout(0.1)\n",
    "        self.conv5 = layers.Conv2D(640, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act5 = layers.LeakyReLU()\n",
    "        self.drop5 = layers.Dropout(0.1)\n",
    "        self.conv6 = layers.Conv2D(640, (2, 2), strides=2, activation='linear', padding='valid')\n",
    "        self.act6 = layers.LeakyReLU()\n",
    "        \n",
    "        self.conv7 = layers.Conv2D(960, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act7 = layers.LeakyReLU()\n",
    "        self.drop7 = layers.Dropout(0.2)\n",
    "        self.conv8 = layers.Conv2D(960, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act8 = layers.LeakyReLU()\n",
    "        self.drop8 = layers.Dropout(0.2)\n",
    "        self.conv9 = layers.Conv2D(960, (2, 2), strides=2, activation='linear', padding='valid')\n",
    "        self.act9 = layers.LeakyReLU()\n",
    "        \n",
    "        self.conv10 = layers.Conv2D(1280, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act10 = layers.LeakyReLU()\n",
    "        self.drop10 = layers.Dropout(0.3)\n",
    "        self.conv11 = layers.Conv2D(1280, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act11 = layers.LeakyReLU()\n",
    "        self.drop11 = layers.Dropout(0.3)\n",
    "        self.conv12 = layers.Conv2D(1280, (2, 2), strides=2, activation='linear', padding='valid')\n",
    "        self.act12 = layers.LeakyReLU()\n",
    "        \n",
    "        self.conv13 = layers.Conv2D(1600, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act13 = layers.LeakyReLU()\n",
    "        self.drop13 = layers.Dropout(0.4)\n",
    "        self.conv14 = layers.Conv2D(1600, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act14 = layers.LeakyReLU()\n",
    "        self.drop14 = layers.Dropout(0.4)\n",
    "        self.conv15 = layers.Conv2D(1600, (2, 2), strides=2, activation='linear', padding='valid')\n",
    "        self.act15 = layers.LeakyReLU()\n",
    "        \n",
    "        self.conv16 = layers.Conv2D(1920, (2, 2), strides=1, activation='linear', padding='valid')\n",
    "        self.act16 = layers.LeakyReLU()\n",
    "        self.drop16 = layers.Dropout(0.5)\n",
    "        self.conv17 = layers.Conv2D(1920, (1, 1), strides=1, activation='linear', padding='valid')\n",
    "        self.act17 = layers.LeakyReLU()\n",
    "        self.drop17 = layers.Dropout(0.5)\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        # Classifier\n",
    "        self.fc1 = layers.Dense(5, activation='softmax')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax')  # Second half\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Forward Pass\n",
    "        print(f\"{inputs.shape}\")\n",
    "        x = self.act1(self.conv1(inputs))\n",
    "        x = self.act2(self.conv2(x))\n",
    "        x = self.act3(self.conv3(x))\n",
    "        print(f\"{x.shape}\")\n",
    "        x = self.drop4(self.act4(self.conv4(x)))\n",
    "        x = self.drop5(self.act5(self.conv5(x)))\n",
    "        x = self.act6(self.conv6(x))\n",
    "        print(f\"{x.shape}\")\n",
    "        x = self.drop7(self.act7(self.conv7(x)))\n",
    "        x = self.drop8(self.act8(self.conv8(x)))\n",
    "        x = self.act9(self.conv9(x))\n",
    "        print(f\"{x.shape}\")\n",
    "        x = self.drop10(self.act10(self.conv10(x)))\n",
    "        x = self.drop11(self.act11(self.conv11(x)))\n",
    "        x = self.act12(self.conv12(x))\n",
    "        print(f\"{x.shape}\")\n",
    "        x = self.drop13(self.act13(self.conv13(x)))\n",
    "        x = self.drop14(self.act14(self.conv14(x)))\n",
    "        x = self.act15(self.conv15(x))\n",
    "        print(f\"{x.shape}\")\n",
    "        x = self.drop16(self.act16(self.conv16(x)))\n",
    "        x = self.drop17(self.act17(x))\n",
    "        print(f\"{x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "    \n",
    "        output1 = self.fc1(x)\n",
    "        output2 = self.fc2(x)\n",
    "        print(f\"Final Output Shapes: output1={output1.shape}, output2={output2.shape}\")\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "(1, 15, 15, 320)\n",
      "(1, 6, 6, 640)\n",
      "(1, 2, 2, 960)\n",
      "(1, 0, 0, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'acnn', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling ACNN.call().\n\n\u001b[1mComputed output size would be negative. Received `inputs shape=(1, 0, 0, 1280)`, `kernel shape=(2, 2, 1280, 1600)`, `dilation_rate=[1 1]`.\u001b[0m\n\nArguments received by ACNN.call():\n  • inputs=tf.Tensor(shape=(1, 32, 32, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mbuild(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m               loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m      6\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# val_model_checkpoint_callback = MeanAccModelCheckpoint(\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     filepath=\"./FMP5/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     monitor1='val_output1_accuracy',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#     verbose=2\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[148], line 84\u001b[0m, in \u001b[0;36mACNN.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact12(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv12(x))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop13(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact13(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv13\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     85\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop14(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact14(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv14(x)))\n\u001b[1;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact15(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv15(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling ACNN.call().\n\n\u001b[1mComputed output size would be negative. Received `inputs shape=(1, 0, 0, 1280)`, `kernel shape=(2, 2, 1280, 1600)`, `dilation_rate=[1 1]`.\u001b[0m\n\nArguments received by ACNN.call():\n  • inputs=tf.Tensor(shape=(1, 32, 32, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = ACNN()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()\n",
    "\n",
    "# val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "#     filepath=\"./FMP5/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "#     monitor1='val_output1_accuracy',\n",
    "#     monitor2='val_output2_accuracy',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "#                                patience=10,         # Number of epochs to wait after the last improvement\n",
    "#                                mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "#                                restore_best_weights=True,  # Restore the best weights when stopping\n",
    "#                                verbose=1)\n",
    "\n",
    "# history = model.fit(\n",
    "#     traingen,           \n",
    "#     epochs=100,          \n",
    "#     steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "#     validation_data=valgen, \n",
    "#     validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "#     callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "#     verbose=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will build my next, fully standard models, on the Functional API with the goal of widely easy and large data augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB/0AAAYgCAIAAAAcHMnjAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVwW5f7/8WHfhBTRTEERSVAhV9AUNRfcKhdMRdvN1GOpZZblrif1aJ00LXPJ1GORaJqZa4pL4g6kIKSAgpisIiooO/fvj/t35jtn5r5vbm7QW6bX84/zmLnmmms+jnCq98xcl4VGoxEAAAAAAAAAAIAqWJq7AAAAAAAAAAAAUGPI/QEAAAAAAAAAUA9yfwAAAAAAAAAA1IPcHwAAAAAAAAAA9SD3BwAAAAAAAABAPcj9AQAAAAAAAABQD3J/AAAAAAAAAADUg9wfAAAAAAAAAAD1IPcHAAAAAAAAAEA9yP0BAAAAAAAAAFAPa3MXAAAA1CYkJOTcuXPmrgIAgMfdmTNn3N3dzV0FAABQIXJ/AABQw7Kzs2/evGnuKgAAeNyVlZWZuwQAAKBOzPMDAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAB5HXl5eZQrz5s0zd121z/r165V3sl69euauCwAAAMDDYm3uAgAAAADdrKysZC2Wlry2IgiCYGlpaWtrK23RaDTFxcX6OivvJAAAAAAV4z+cAAAAgFomKCio8H9dvnzZ3EUBAAAAeFyQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAelibuwAAAADg4bK1tfX09NRoNCkpKWVlZdUf0Nra2sPDIz09vbi4uPqjqYCtrW39+vVdXV2trKzS09Nzc3M1Go25ixJsbW3d3d0bNmxob2+fmZmZkZFx9+7dGhnZycnJy8vr9u3bN2/erJEBAQAAgJpF7g8AAIBazNHRceXKldKWO3fuTJ8+XXto0qRJ//jHPzw9PS0tLQVBKCsrS01NjYyMXLhwYUpKis4B27VrN2PGDGnLiRMnVq9eLQiCi4vLBx98EBoa6uXlZW1tXVpaGh8fHx0dffjw4a1bt+qrUDmgIAhvvvlmUVGRsrOXl9eiRYtkjePGjbt//74gCEFBQR07dhQEwdvbW9bHxcVl6tSp2u3r16/v2rVLXz01yNvbe9y4cb169erYsaOVlZXYXlxcnJ6eHhER8f333//+++/KZwD9+/d/4403ZI2bN28+cOCAvmt99NFH7du3l7akp6d/8MEHyp4WFhYjR44cPXp0nz596tSpIz2UmJi4ffv2sLCwhIQEfRfy8PBYtmyZtCU2NnbJkiWCINjb20+ZMuXdd9/18PAQBGH58uXTpk3TNw4AAABgThoAAIAa1a1bN3P/Cw7UwMvLS/nTtWDBAlm3evXqyfpoX8EOCAjIzMzU91NaXFy8YsUKOzs75XUHDhwo67xlyxZBEAYPHnzr1i19A+7atat+/fo6/yDKATUajSyPFnXq1EnZuW7dutqjn332mb4CpPbv3y8dc8OGDco+9erVq+JfyP+wt7dfs2ZNaWlppcWkpaW98MILstO9vb2VPXfs2KHvclZWVtpvCKS++OILZc+AgICYmBjDJZWVlS1dutTe3l7ntfz9/WX9Dx48KAhC8+bNU1JSKi0AqBLZDxUAAEBNYX5/AAAAqI2vr+/hw4effPJJfR1sbW2nTp36z3/+08gBn3322fDwcH3JviAIQ4YMiY2N7d27d5VrrYXq1Kmzb9++CRMmWFtX/vWwh4fHzp07hw0bJm1MTk4+d+6crGdwcLCtra3OQQICAlxdXWWNYWFhspbhw4cfP35c9lmAkpWV1UcffXTu3DnxgUqlnnjiiUOHDnl6ehrZHwAAADAvcn8AAACoiq2tbXh4uIuLS6U9P/jgg6CgoEq7eXl57d69W9/r4aLGjRv/8ssvTz31lLGF1lpz5szp1auX8f1tbGy2bdvWs2dPaaMytXd2du7Ro4fOEQYMGCBrSU5OjoqKkrb4+/uHh4c7ODgYWZW/v//27duNeXQhCMKKFStatGhh5MgAAACA2ZH7AwAAQFXc3NyeeeYZcbeioqK8vFxnT0tLS+287YZ17drVzc3NmEvXqVNHOTt/DSotLS0qKioqKiopKZEd0mg0Rf+lPFqDGjduPHnyZGX7gwcP4uLizp8/f+PGDeVRa2vroUOHSlvCw8OVfy/KGYG0+vfvL2v58ccfZS0rV66UrjEgunv3bmpqqkbXOsN9+/adN2+ezitKderUSbkaAQAAAPA4I/cHAACAOm3cuHHIkCH169d3cXHp0aPHvn37lH3atGlj/IDp6ekbN24MDQ199dVXv/76a50B9+uvv17pPDMmmzlzpoODg4ODQ3BwsOzQ9evXHf5ryJAhD6kAQRDefPNN2Tv1xcXFkydPdnZ2fuaZZwIDA5s2bdqqVauYmBjZiQEBAdLdzMzMo0ePyvrozP1dXV0DAwNljbLcf8SIEc8995ysz8GDB1u2bFm3bt3mzZs7OztPnTq1oKBA1uf9999v0KCB8qKyAgx3AAAAAB435P4AAABQoQ0bNowdO3b37t137tx58ODBiRMnQkJCjhw5IutWr169hg0bGjPg7t273d3dx44dGx4e/v3337/77ruBgYHx8fGybpaWlsuWLauZP8NjqUOHDrKW77///quvvqqoqBBbLl++/M477yhPlE2qo5zqp0WLFr6+vrLG4OBgS8v/+c+WCxcu/Pnnn+Kug4PD559/Ljtr165dAwcOTEpK0u7ev39/5cqVffr0kX1k4OTkNHXqVMWfUreLFy/Onz9/8ODBHh4eDRo0eKjfdgAAAADVQe4PAAAAtblw4cI//vEPWWNxcfHSpUuVnX18fCodMC0t7c0335TNFZOZmdmrV6/8/HxZ565du1ax3tqkXbt2spa1a9cqu2VnZ8taHBwcGjVqJG3ZuXNncXGxrNvzzz8va6l0kp/u3bs3bdpU2lJUVDRlyhTl3D7nzp1btWqVrFHf5EIyR44c6dat24IFC3799de//vrr1q1bubm5xpwIAAAAPHrk/gAAAFCbiIiI0tJSZXtsbKyy0Zj3/SdOnHj79m1le05Ozn/+8x9Zo6Ojo4pX9/X29rb8X+fPn5f1sbOzmzt3rvJcCwsL6e7du3f37t0r66NM4WW5v0aj2bp1q7Tl6aeflp0SGRmpcxYmQRB2794ta3nmmWcqncnnwoULzz///P379w13AwAAAB4T1pV3AQAAAGqVS5cu6WzXmd1XqrCwUDlBkOjbb79VzmnTokWLjIwME671+NO5QK69vX3Lli2bNWvm7e3t5+fXv3//Jk2aGDNaWFhYSEiItCUoKKhu3bp37tzR7vr7+zdu3Fja4eTJk2lpadIWb29v2bDXrl3Tt8qCdD4iLQsLi/bt20dERBio8/vvvy8qKjLQAQAAAHiskPsDAABAbZTT7muVlZWZMNqFCxeU09GIEhISNBqN7E12b2/vyMhIE65Vi9jZ2YWEhAwYMKB9+/atWrWSzd1vpL179967d8/FxUVssba27t+/f3h4uHZ3wIABslNkk/wIut73Hz9+/Pjx440v48knnzTc4cSJE8aPBgAAAJgd8/wAAABAbfTN8WKaW7duGThaUlKifLXfy8urBgt43FhaWn7yySc3b94MCwt77bXX/P39TQv9BUEoKirauXOnrFE6xb8s9y8rK9u+fbusvzL3r6onnnjCcAfDPwMAAADA44bcHwAAAGqjcy4ak929e9dwhwcPHshaDHwfUNvZ2Njs3bt38eLF9evXN9Dt+PHjRg4YFhYmaxk4cKClpaUgCE5OTkFBQdJDhw8fzsnJkfU3ck4hA6ysrAx3MG2GKAAAAMBcmOcHAAAAMKTSRXqVuXNKSopp17K1tTXtxEdmyZIlyrl3BEHQaDQJCQnR0dFnz549fPjwrVu3cnNzlX2UJx45ciQrK0s6046bm1uXLl1OnTrVq1cv2Q1RTvIjCEJ+fr6Tk5O0JScnp0qPXpRPbmRMmyEKAAAAMBdyfwAAAMAQX19fA0fd3NwcHBxkjampqeK2zrBbth6AyNXV1fjOj16jRo3ee+89WWN6evrcuXN37NghLsYrCILhrwGkysvLw8PDp0yZIm184YUXTp06JXvAUFRU9PPPPytHuH37dqNGjaQtH3744ebNm40sAAAAAFAf5vkBAAAADGnSpImzs7O+o127dlU2St/31zlNkL4J5Zs3b171Ah+dkSNHyqbEycvL69Wr14YNG6ShvyAIzZo1U56u7wGGcqof7RT//fv3lzbu2bMnPz9febpyfYWAgADdfwAAAADg74HcHwAAAKhESEiIvkNTp06VtRQVFWVmZoq7yuluBEFwd3fXOZrOKXQeH61bt5a1HDp0KDExUdnzmWeeMX7Ys2fPXrt2TXZ6r169vL29pY06J/kRBOHkyZOyFnJ/AAAA/M2R+wMAAACVWLVqlZeXl7K9b9++vXv3ljVGR0dL5/bRuSTskCFDlI1jxowZNGiQaRVWujJtjZDOwq91/fp1nT1lr+pXSvnK/4oVK6S79+7d27dvn85zjx07JmsJDAwcM2aMzs6zZ8+++7/S09Pt7OyqVC0AAADwmGN+fwAAAKASzs7O27ZtGz16dFJSktg4fPjwH374Qdl5wYIF0t3bt2/n5ubK5rv/6KOPYmJitm/frt21tLQcNGjQxo0bTa6wfv361tbWxi8/++uvvxrfOS8vb9iwYYIg3Lx5U3aoffv2yv5vvPFGaGiost3SUu9bRz/++OPs2bOlLbIvBnbu3FlUVKTz3MjIyNTUVE9PT2njhg0brl69evbsWWlj3759582bZ239P/8RdPjw4SotAgwAAAA8/sj9AQAAgMp17Njxzz//PHLkyOXLl+vXr9+lSxedXwAcO3bs0KFD0paKior9+/e/8sor0kZLS8tt27YlJiaeO3eufv363bp1c3FxMb4YZWTv6OgYFhZ2/PjxgoKCjIyM3377zfAI3bp1M/5y2dnZ2o24uDjZob59+86fP3/t2rXaSfabNm06Y8aMcePG6RxHFrhLJSQkXLx4sW3btvo66JvkRxCE0tLSTz/99Ntvv5U22tvbR0ZGhoeHHzp06ObNm+7u7n379h0zZoxsjYGKigrZhwUAAACACpD7AwAAAEaxsrIKDg4ODg420GfmzJnKxl27dslyf62WLVu2bNlS2lJaWmphYWEgH9e6ceOGsnHEiBEjRowQBOHAgQOV5v6miY6OVjbOmzdvzpw5cXFxjRo1Uk4EJGVra2vgaFhYmL7cPzs7OyIiwsC5mzdvHj16dJ8+faSN1tbWL7/88ssvv2zgxGXLlp04ccJABwAAAKA2Yn5/AAAAwJArV67s2bPHmJ7r168/ffq0sn3nzp3KOeh1+vjjjx88eCBrlK4WoHXz5k3p0sGPTFRUlM7JiCwtLdu2bSsN/Q8dOpScnCzr1qZNGwODb926Vfkn1dq2bVt5ebmBc8vKykJCQmJiYgz0Udq3b9/cuXOrdAoAAABQK5D7AwAAAIaUl5eHhoZGRUUZ7vb1119PmDBB5yGNRvP666//+eefBk6vqKiYPXv2F198YUxJFRUVH330kb6U/KGaMmWKMtCX+eyzzwYOHBgfHy9rHzdunKOjo76z0tLSIiMjdR4yMMmP6N69e127dp01a9b9+/cr7SwIwsaNG4cMGVJaWmpMZwAAAKB2IfcHAAAAKnH//v1BgwatW7dOZ0yckJAwYMCAd99910AQn5aWFhAQsGrVqjt37iiPnjt3rnfv3osWLTK+pC1btrRv337v3r3Gn1IjCgoKOnXqtHz5cp234urVq6NGjfroo4/Ky8uPHj0qO9q/f399U/9rhYWFKRtTU1N1fkWhVFxcvHjxYh8fH8PPCaKiovr06TN27FjjVzYGAAAAahcLs7wlBAAAVCwoKOjkyZPmrgIw0cCBA/ft2ydtSUhIECeoadasWb9+/Vq0aOHu7p6Xl3fjxo2DBw9evHjR+PHt7Ox69uzZtGnTRo0a3b59OzEx8cqVKzrn6zeSs7Nzw4YNGzRo4ObmJghCYWFhRkZGQkKCyQMaydvbu1evXr6+vt7e3vfu3bt+/frvv/9+6NCh6vz3Rf369TMyMmxsbKSNixYtmj17dlWHaty4sb+/v5+fX5s2bby8vO7evZudnR0bG3vgwIGkpCSTKwRqVkpKiqenp7mrAAAAKkTuDwAAahi5P2o1w7k/HipLS8tbt27Vq1dP2ujr63vlyhVzlQQ8VOT+AADgIWGeHwAAAACPhb59+8pC/7NnzxL6AwAAAFVF7g8AAADA/Ozs7D799FNZ47p168xSDAAAAFCrWZu7AAAAAAB/U66urq+++qqNjU3jxo1HjBjh7u4uPZqXl2d4hV4AAAAAOpH7AwAAADCPhg0brlixQt/RNWvWFBYWPsp6AAAAAHVgnh8AAAAAj52CgoIvvvjC3FUAAAAAtRK5PwAAAIDHzsyZM2/dumXuKgAAAIBaidwfAAAAwGPk+vXrL7300qpVq8xdCAAAAFBbMb8/AAAA8H+io6OHDh0qbbl37565ilG9nJycRYsWOTo6WlhYZGVlpaWlXb9+PSYmhmn9AQAAgOqw0Gg05q4BAACoSlBQ0MmTJ81dBQAAj7uUlBRPT09zVwEAAFSIeX4AAAAAAAAAAFAPcn8AAAAAAAAAANSD3B8AAAAAAAAAAPUg9wcAAAAAAAAAQD3I/QEAAAAAAAAAUA9yfwAAAAAAAAAA1IPcHwAAAAAAAAAA9SD3BwAAAAAAAABAPcj9AQAAAAAAAABQD3J/AAAAAAAAAADUg9wfAAAAAAAAAAD1IPcHAAAAAAAAAEA9yP0BAAAAAAAAAFAPcn8AAAAAAAAAANSD3B8AAAAAAAAAAPUg9wcAAAAAAAAAQD3I/QEAAAAAAAAAUA9yfwAAAAAAAAAA1IPcHwAAAAAAAAAA9SD3BwAAAAAAAABAPcj9AQAAAAAAAABQD3J/AAAAAAAAAADUg9wfAAAAAAAAAAD1IPcHAAAAAAAAAEA9yP0BAAAAAAAAAFAPcn8AAAAAAAAAANSD3B8AAAAAAAAAAPUg9wcAAAAAAAAAQD3I/QEAAAAAAAAAUA9yfwAAAAAAAAAA1IPcHwAAAAAAAAAA9SD3BwAAAAAAAABAPazNXQAAAPi7sLW1tbOzM3cVAAA8XA8ePCgvLzd3FQAA4G+N3B8AADwiEyZMWLlypbmrAADg4QoKCjp58qS5qwAAAH9rzPMDAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAelibuwAAAICHqLy8/Pfff798+XJGRkZmZmZFRUXDhg0bNmzYtGnT3r17161b19wFAtWyadOm27dva7dHjBjh4eFh3nqAx0R8fPzBgwe1256eniEhIeatBwAA4BEj9wcAAOoUFxf39ddf79ix49atWzo7WFtbd+/ePTQ09K233rKysnrE5f3N/fOf/5w/f74gCPXr18/OzjZ3ObXVzz///Oabb2q3W7ZsOWXKFO12SkqKt7e3rPPevXsHDBhgYDRfX9+kpCRxd/z48d98802N1qseBQUF0dHRSUlJycnJGRkZTZs2ffrpp729vQMCAmxsbCo9XaPRHD9+/OzZs+np6Xl5eZ6enj4+Pr6+vq1atXJ0dKT4Gqm8SZMmixYt0j4Vs7KyOnPmTKdOnR5qeQAAAI8Vcn8AAKA2JSUlixYtWrJkSWlpqYFuZWVlR48ePXr06Ndff/3VV19179794ZVUXl6u3bCwsLC0fOwmWnz05Wk0moqKCkEQtP8LE+Tl5U2aNEncXbx4sbX1//27vfLGfvDBB3379pX2kamoqJCepdFoaq5Y9dBoNFu2bJkxY0ZmZqbyqLe39+LFi1966SULCwt9I6xdu3bRokU3btxQHnJ1dV28ePHbb7/9kH4Na2/xJlRet27dmTNnTp8+XRCE8vLysWPHRkdHG/NgAwAAQB0eu//sBAAAqI579+5169Zt4cKFstDf0tLSx8enW7duTzzxhOyU2NjYnj17rl+//uFV1alTJ2tra2tr61dfffXhXcVkj3l50GnatGliBurj41PpNCYJCQlr1qx5+HWpWVlZWd++fV9//XWd6bMgCMnJySNHjuzevXtBQYHO00NDQydOnKgzNxcE4fbt2xMnTuzcuXNsbGxN1v3fq9fS4k2ufOLEifXq1dNux8XFLV68uGYLAwAAeJyR+wMAAPUoKSkZNmxYVFSU2OLm5rZixYrTp0/fu3fv8uXLkZGReXl5V69e3bFjhzQn1Wg0EyZM2Lx5szmqBqrs6NGjmzZtEnenTZtm4B1t0fz58/Py8h5iWWq3YMGCI0eOVNrt5MmT48ePV7bPnTs3PDy80tOjoqJeeOGFu3fvmlKifrW3eJMrd3Jymjhxori7ePHiK1eu1GBhAAAAjzNyfwAAoB6TJk2SxkP9+vWLjY2dOnVqly5dnJyctI0WFhZeXl4hISE7duxYs2aNvb29tl2j0bz11luJiYlmqBuoolmzZonbDRo0eO2114w5Kzc3d8GCBQ+tKJU7ffr0kiVLZI3NmjULCAhwcXGRtf/444+yT4hiYmKWLl2qHNbBwUH5zObGjRuTJ0+udsn/p/YWX83KJ0+ebGtrq90uKSnh5x8AAPx9kPsDAACVSExM3Lhxo7j72WefHThw4KmnnjJwyoQJE86dO+fp6andLS8vX7Ro0UMtEqi+/fv3nz59Wtx95513xMdXlVq9ejWvPJvmvffeE1fCEAShZcuWly5dSk1NPXfuXG5u7ty5c2X9v//+e+nud999J1t0YcKECRcuXMjPz797925YWJg4I43Wli1bfvvtN4qvZuVPPfXUmDFjxN3w8PD4+PgaKQwAAOAxR+4PAABUYunSpWIy9fzzz0+fPt2YmU/8/f2/+uorcfeHH364evXqwyoRqAmyrPOtt94y/tzS0tIPPvig+jVoNJrLly8fO3Zs+/btu3fvPn36dEZGRnUGLC8vT01NTUtLM2Gp5wcPHkRHR8fHx9++fbs6NRhQVlZ24cIFacu2bdvatGmj3ba2tl6wYMHQoUOlHS5cuCCujVxWVrZt2zbp0VdfffWbb75p27atlZWVs7Pz6NGjf/nlF9lFIyIi/ubFV7NyrXHjxonbFRUV8+fPr35hAAAAjz9rcxcAAABQA27cuLFlyxbttpWV1bJly4w/9/nnn+/du7d2giDtK//fffedrM8ff/yRlJQkCIKdnd2QIUP0DXX+/PmUlBRBEFxdXfv27XvhwgXtxEF37tzRdkhLS9MmaA4ODi+++KK28eLFi9rpsN3d3b28vARBuHv37oYNG86fP5+amurm5hYQEBAQENC7d287OzvlRU2rTRAEI8szRkFBwebNm+Pj45OTk9PT0728vPz8/Nq0adO1a9fmzZsbM0Jpaem2bdsOHz58/fr10tLSjh07BgQEBAYGPv3004ZPzM/PDwsLi4uLS01NzcjIcHNza9KkiYeHR0hISNu2bXWeUs0bLnPz5s3o6OiYmJiYmJjCwsJmzZp16dJlxIgRyhWkRQUFBSUlJdptZ2dnGxubSq8iOn36tHQFizZt2ri7uxt/uiAIe/fu/e233/r161els0SXLl3SfkyTnZ0tO+Tv7x8SEjJt2jTlBCyCIOzfv1+6JsHTTz/96aefCoKwe/fuJUuWREdHa9fitre3b9GixRtvvPHuu+8a/o5h69atO3bsiI2NTU5OFp8WeHh4DB8+/K233vLz8zPtD6jT5cuXxb8yQRC6dOmi/OkaPnz4rl27xN179+5dvXrV29tbEISkpKScnBxp548//lj2YLJ79+5BQUGRkZFiS00tkFt7i69m5eJZTzzxhLjkwI4dO27evNmkSZPqlwcAAPBY0wAAANSobt266fy3jsmTJz+8i06dOlW80MSJE6t6ekxMjBhjWVtbF5xN0ZoAACAASURBVBQUyDpMmTJFe7R+/foGxnnzzTe13Tp27CirSqZJkybiWd27d9c2Tp06VaPRrF+/3tnZWXlK27Ztr1y5oryoabUZX55hZWVlq1evbtiwoc5x7O3t165dqzxLnGVbW3NERETjxo11jrBw4UJ9l75///7777+vM2LWCgwMPHTokPLEat5wUVFR0aRJk/T9wd977z3lD5KW9PHMgQMHDN9hGdnb+tOmTVP2uXbtmqyeZ599Vrrr5+dXVlYmO0v2iGXChAmyDmVlZZMnT7aystJ3w7UaNmy4Y8cOZVUrVqyQ/e2UlJS89NJL+sZp2rRpZGSkzpuQk5MzfPhwAzVYW1vPmjWruLi4SvfWgB9++EE6/pgxY5R99uzZIyvjxo0b2kP79++Xtru4uOi8iuzHqXHjxn/z4qtZuUi6irsgCKtWrap+bYbp++egUkpKysMuBgAA/D0xzw8AAFCDffv2idsff/xxVU9v3759165dtdtlZWXa9+LNYvny5W+//XZ+fr7y0MWLFzt27Lh169ZHX5UBn3zyyaRJk5SvfmsVFRVNmDDhlVdeKSoq0jfC/v37+/fvn56ervPo3Llzlat6CoJQXl4eGhq6fPnye/fu6Rv53LlzL774ouH5Rky+4cnJyc8+++zq1at1Hi0qKlqxYoW/v39ycrKBq5tgx44d0l0jX9ufMmVKixYtxN1Lly6tXbu2StctKysLDQ1dtWqVdLJ1nbKzs0eOHCl+f2PA+++//9NPP+k7mpaWNmbMGOXf74kTJ/z8/GT3QVntokWLtDFxpWUYo0+fPlES//rXv5R9zp8/L911dnYWP8W4fv269JC+p1yFhYXSXfEV9WqqvcVXs3KR7NfE8A8PAACAOjDPDwAAqPUqKirEZMrR0bFZs2YmDOLj43Py5Ent9rVr12pkkpAhQ4ZoE6jly5drc+327dtrF5nU+YL5Tz/9dPPmTUEQWrZsOWXKFD8/P1tb2+Tk5I0bNx49elQQhIKCgtdee61Tp07SWSweWXlKe/bs+fzzz7Xb/fr1mzp1qq+vr4ODQ0pKyuXLlxcvXqxdLOGHH35o3br1zJkzlSMUFBSMHDmyrKzMyspq9OjR3bp1a9GiRWJiYmRkpBi4z5w5s3379gMGDJCeOGPGjF9//VW77efnN2PGjNatW7u7u+fm5l69enXLli3bt2/XaDRFRUVDhgzJzs52dHRUXt3kG37t2rUOHTqITwv69es3aNCgtm3bZmRknDlzJiIiQrt2aEpKSv/+/c+cOdOgQQNj7melYmJiUlNTxV17e/sePXoYc6Kdnd3nn38+bNgwsWXevHljxoypW7eukZdetWqVgYxepry8fNy4cUFBQQZmeYqPjz937pzhcdLS0qZPn75u3Tqxpbi4+PXXX8/KyjKmjB07dsyZM0c7m1A1Pfnkk08++aSBDllZWbJHRNJPGUJDQ6XRs775o2QRto+Pjym1KtTe4qtZuUiW+584cSInJ6emfisBAAAeU+b+4AAAAKjNo5/nR/o6qp+fn2mDSF8qX758ueyoyXPpaLVr107brnOeCnHaGa1Ro0Yp52BZuXKl2GHYsGE1WFul5RkQFBSkPXHgwIHl5eWyo4WFhWJY/8QTT9y/f188JM7zI/6txcTEGPgjv/HGG7KjYhr4/PPPFxYWKmv74osvxNOPHTsmPVTNG67RaMRJZhwcHJQTGRUXF0tn8pk9e7asg8nz/Mienfj6+ursppznZ+fOnRqNpk+fPtLG999/X3qWgXl+8vLyXF1dZWN26NBh8eLF+/fvDwsLmzZtmvJZ0ejRo6Xjy+b50bK0tOzZs+e8efM2bdo0ZcoU5YRRsulilCG+r6/vqlWrDh8+/MMPP4wePVp21NraOikpyfg7XFX5+fnJycn/+c9/ZE84XFxcMjMzqzTU0aNHZZPmV/X3sapqb/EmVC5bK2LdunUPrzwN8/wAAIDHALk/AACoYY8+99cuyas1ePBg0waRvsusLPWR5f6+vr6lpaU6B3/rrbfEbsePH6+p2iotT5/y8vI6depoT9y8ebPOPocPHxZrjoqKEtulub+1tXVcXJzO09u3b6/t06xZM2l7WlqaePrhw4d1nltWVia+47906VLpoWre8OPHj4vtX375pc5zS0pKxGceHh4esociBQUFt/9L39V16tKli/R3qkePHjq76cv9Y2NjpbPz29jYJCYmimcZyP0//PBD2YBvvvlmUVGR9KLx8fHaRZJFFhYW58+fFzvozP1lz9ji4+Pd3NxkffLz87VHb9y4Iftuo2/fvg8ePJCO8OOPP8pOVz40qikDBw5U/okEQfD29v7jjz+qNFR+fr7y24iff/75IVWuqc3Fm1Z506ZNpZ1DQ0MfUnla5P4AAMDsmN8fAADUetKUUzqJeZV4enqK29q5X8xi7ty51ta6Z2KcP3++uG3M5OkP240bNwoKCrTbyqBZq3fv3gsXLpwzZ86cOXN0zrQjCMLUqVP1zarUs2dP7YZsXpcrV654enp6enq2a9fuueee03mulZWVOOPT7du39f0pTLjh06ZN02506tTp3Xff1XmujY3NP//5T+32jRs3pM8/BEFwcnKq91/6rq7TjRs3pLuGp0BR8vf3Hz9+vLhbWloqWyVYp9u3b69atUra4u3tvX79etl8L61bt16/fr20RaP4sENm9OjR7733nmwQ5TwtV65c0W785z//efDggdhua2u7du1aBwcHaefQ0NDQ0FBpy65duyoqKgyUYTKdw1paWk6aNOmZZ54xfpycnJzg4GDZsiLPPvvs0KFDq1uifrW3eNMql/2yyH6VAAAA1IfcHwAA1Hp5eXnidlWTUFFubq64/dRTT1W3JpNYWVm98MIL+o66u7t7eHhot2t8tVgTeHh4iLPD//vf/5ZF21oWFhZz5sxZuHDhwoULW7VqpXMc2cT9UuIE3EVFReIzBkEQ+vbtm5KSkpKS8scff0hfYJfKycnR9zRCZMINz83NjY6O1m6PGDHC0lLvv0536tRJfPAQHh5uuBJjlJeXZ2ZmSluUs+JUauHChdI5/X/99Vedf3FScXFxsmWZP/zwQ523vXfv3gEBAdIW2ZzvMtL5jkT+/v6yFnHV6MTERGl7165dZV8YaEmXMRAE4c6dOxcuXDBQRs2qqKiYNm3agAEDpI8oDLh06dKzzz575swZaaONjY24csajVHuLr7Ry2S+LGR/uAgAAPBrk/gAAoNaT5ph//fWXaYNIl0s1+aOBamrfvr3hBXXbtGmj3dCul2telpaW4nzxBQUFwcHBnTt3Xr16tfROGkP6pYWMOI+QIAiFhYXGjJaTk3P+/PmvvvrK19e3uLjYcGcTbrg0eu7QoYPh8cW3j8U31qsjMzOzvLxc2mLCUy43N7d58+ZJW6ZNmyYbVuby5cuyFtkqqVLBwcHS3aysrDt37ujrLN5eKdl0Q1Kyx11WVlZf6xIbGys7MS4uTt+Y1eHi4qJvkdtDhw4pJ0dS+vbbbwMDA2W/zpaWllu2bOnatWvNVKlH7S3etMplvyzp6ekajabmiwMAAHhsVOGzYgAAgMeTdMVRkwNx6TwV5sr9K71umzZtDhw4IAjCX3/9VVRUJFup8tFbs2ZNUlKSGLOeO3fu3LlzgiB4eHj06dNn4MCBwcHB9erVMzCCpaWlbN5tKdlKoUoPHjw4derUkSNHLl68mJqampqaauR7ylom3HBpgj9t2jTDfwXiI5CMjAzjq9JH+YayaV+3vPPOO2vWrBH/IHFxcevXr584caK+/rLc39LSskmTJvo6i19ISE+XLUugZWVl1bJlS2W7gYmPkpKSpLsRERERERH6OkuJXwzUrG3btgmC8ODBg6ioqG+++Wbr1q3So998882wYcP69u2r89z79++PHz8+LCxM1u7k5PTdd9+NHDnyYRQsVXuLN61y2fv+JSUlOTk5JnwxAwAAUFuQ+wMAgFpPGhybnPtL31L39vY2bZBqvkAq/XBBJ19fX/FCWVlZ4jQyxngYL7e6ublFRERMmTJl27Zt0nfGb9y4sWnTpk2bNllZWfXv33/69Om9evXSOULdunVtbW1NuHRZWdnKlSvnzZsnnf9Hyt3dPTc31/BXAibccOn7/sa/RS6bJ8c00vmstMR5kKrExsZm+fLlgwYNElvmzp07evRoff1lb9k3aNDAxsZGX2flI4Hk5GSdub+9vb3Ov3p9P6j5+fkmx/c1cv/1cXR07NGjR48ePfz9/WfNmiW2azSaDRs26IzOb968+eKLL/7xxx+ydm9v7507dypnOnp4am/xVa1cGfHn5eWR+wMAABVjnh8AAFDrtWvXTlzbMzU1taSkpKojlJSUHD16VLttYWGhc9JwY+Tn55t2opaTk5PhDvfv3xe3XVxcqjR4NWvTx83NLSwsLCkp6bPPPuvRo4fsZe3y8vJ9+/ZpV/fVeXqlb/TrVFJS0qNHjw8++EAa+js6OrZu3frFF1+cPXv23r17U1NT3dzcDI9jwg2/e/eu2OLq6lrfOJVeyBiNGjWStZgcZw8cOHDgwIHibk5OjrgKsZLs6YL0DigpZ/Ux7eGEkp2dnb61HCpleCKjmvLxxx/LniTpfDIUExMTGBiozM3HjBkTFRX1KEN/qdpbvJGVK39ZlL9QAAAAasL7/gAAoNaztrYOCAj4/fffBUEoKSn57rvvDExaotPWrVuzsrK02x07djR5/hzlG9lVUulqvTdu3NBuWFpaPvHEE1UavJq1Gda8efPp06dPnz79/v37kZGRR48ePXjw4MWLF8V3t+fNm/f0008beKm8SmbPnn369Gnx0u+//36/fv2efvppA6vs6mTCDZd+C/LHH38YmKSoximvJV2Muqq++OKLQ4cOlZWVaXdXrVolPjyT8fHxke4WFRXl5OToS/PFO6bvdJPZ2to2b95c+lc2a9as1157zZhz69evX82rf/XVV9LlIvr37+/n5yfrY2lpGRQUtGfPHrElMTGxtLRU+nnE3r17R40aJX2eJAiCi4vL6tWrX3755WoWqU/tLb6mKhcUvywuLi5V/b9QAACA2oXcHwAAqMGoUaO0ub8gCEuWLBk7dmyVZo/58ssvxe25c+eaXIYy9KySSueNEcdv2LBhVTPuatZmJCcnp/79+/fv3/9f//rX9evXly5d+s0332gPff/99zWS+9+5c+fzzz/Xbrdq1erIkSP63tuVBZRKJtxwaYqdlJT0KHP/evXqOTk5Sf9Qt27dMnk0X1/fd955R/zJLykp0fehjDjZkejSpUv6Jm6Kj4+X7jo4ONTgLfLx8ZHm/unp6TpXCHgYvvrqK+nSDrm5uYsXL1Z2k0XJdnZ20i9gUlJSQkNDZT+WgYGBP/74o8nfGBmj9hZfI5VryX5ZlAtRAAAAqAzz/AAAADV49dVXnZ2dtdtpaWmbNm0y/tzff/89JiZGux0QEPDiiy8q+4gTjBQUFJSWluocJz09XbbuaFWlpqbqm61eEISysrKzZ89qt7t16/aIa1M6fPjwxo0bN27ceOrUKZ0dmjVrtnr16jFjxmh3o6KiauS6cXFx4mcEH374ob7Q/9KlS7dv3zY8lAk3XBo0JyQkGB5/9+7d2lskfp1QTbKwsjrv+wuCMG/ePGNehFfm/tLnZFLp6ek//fSTtKVly5ZVfUBlgOzTgTNnzujsVlJSkvu/xM8aTCaLtsX/x5CRPfbw9/cXZ7KqqKh44403ZD9vb7/99okTJx5q6C/U5uKrX7lI9stC7g8AAFSP3B8AAKiBs7PzP/7xD3F37ty558+fN+bEvLy8cePGibv6pqEXZ4ovLi7Wl/Zu3rzZ2HL10Gg0kZGR+o5u3br1+vXr2u3nnnvuEdem9Ouvv44dO3bs2LETJkww0K1nz57ajQcPHtTI2sLS9387dOigr1tERESlQ5lwwz09PevUqaPd/vbbbw38if7444+hQ4dqb1FaWlqlxRijZnP/evXqGZjWX+Tj4yN9ziQIwu7du5W3t6Ki4pNPPpF9NDB27NjqVCjTunVr6e6ff/65bNkyZbeRI0e6STz55JPimgTz588P/V+GlyvQd+lTp05dvnxZ1mfPnj0XLlyQtrRt21bcXr16tfhNkljn2rVrjfwyyeTKa3Xx1a9cJHvf/1F+qQMAAGAWzPMDAABUYv78+Tt37tROA5KVlRUUFLRy5UrDkXRmZuaoUaPEF+G7du06YMAAnT2feuopcfv06dPKXOnEiRPGTBCk73180bhx46Kjo5988klZe2Fh4ZIlS7TbDg4Ow4cPr/HajClPKiAgQLtx6dKlxMREfTOuiHPpdOjQwbRVfGXc3d3F7ZSUFJ0ZX3x8/BdffGHMaFW94dbW1nPmzJkxY4YgCLGxsbt37x4yZIjOkWfMmKF9KlCnTp3BgwdLD2VmZorzpTRu3FjfxPpKHTp0OHTokLhb/ccJ48ePX7169aVLlwx3+/zzz5999llxV6PRDBw48LPPPnv55Zfd3NwqKioSExOnTZu2f/9+6Vne3t7Sp3HV9/LLL3/++efS5PeTTz4RBOGll17Svhh+//792bNn//LLL9KznnvuOfGzhiNHjpw4cUJ6dOXKlcZc+pVXXvn3v/8t7ubn5/fr12/Xrl3t27fX/lSHh4e/8847srNGjhwpbq9evVp2NDk5uXv37oavu2/fPu2C0iZXXquLr37lItlEZ+3btzemAAAAgFpMAwAAUKNkrwaLJk+e/LAvHRkZKYtQX3311ePHj+fm5sp63rp1a/Xq1dJJTjw8PFJSUvSNnJqaKmbWderUOX36tHiooqIiOjpaNttMx44dpaf37t1b2+7k5JSdnS0bXBafde/evaioSNohIyMjMDBQ7PD+++/XYG2VlqdPWlqanZ2d9sQBAwbk5OQo+xw7dkx8O37mzJli+4IFC7SN9evXN3AJaTgoFpaRkSE2+vv75+fny846ePCgNm0UTZ06Vdqhmje8pKREnPrG2dn5l19+kRVw584d6UoGn376qayD9FHBgQMHDNwBGdlcSXZ2doWFhcpu165dE/7Xzp079Y15+PBhQZcJEyZIu7300ks6u3l4eIhTbMls375dOsKKFSukR52cnHTWo/ySYN++feLRs2fPihNbSfn4+HTu3FlZiZ2dXWxsrHi6MqrOysoy8uZLfyREdevW7dq1a8OGDZWH3njjDfFcfRPUVEr8/67qVF6ri69O5SLZb4SVlVWV7p4J9P1zUMnAP3cAAACqg/f9AQCAenTr1u3gwYMvvviiOInEli1btmzZIghCkyZN/P39mzVrlpub+9dff0VFRUmn/H7qqaciIiI8PT31jdysWbPg4ODffvtNEISCgoJevXoFBgYGBgbevHkzIiIiOztbEAR7e/vRo0dv3LhReXqLFi2OHDkiCML9+/e7dOnSrl27Bg0arFmzRtbNwcGhsLDwxIkTrq6uPXr06NOnT926dU+dOrVv376srCxtn5YtW86aNasGazO+PBkPD49Zs2ZpvyQ4cOCAv7//lClTfH19fXx8ysrKUlJSwsPDd+zYoZ34pUWLFh9//LHhAY3UqFGjESNGbN++XRCEuLi41q1bv/fee/7+/oWFhUlJST/99JN22vcGDRq0bNny5MmTgiDs3LmzdevWjRs3fuGFF6RDmXbDbWxsVq1aFRwcLAhCfn7+0KFDhw0bFhAQ4Ofnl5OTc/HixZ07d4ovFwcHB2vfSa8RHTt2bNGixdWrV7W7xcXFZ86ckU76ZII+ffoMGTJE9o680tKlS48dO6ZcSVjfetGDBg3S96igOgIDA2fMmKFc3FU6+5PI0tJyxYoV/v7+NXLpb7/9tmvXrrI57u/cuaNzfYsGDRqIq08LgqD99TSj2lt8dSoXHTt2TLr73HPP6XxmAAAAoCrmfvAAAADUxozv+2tdvHjRwLTvSkOGDElLS6t02Lt37xp4hdPCwuLHH38UZ8OQvVOvTZ+lmjRpIh4VX4YdOXLka6+9ZqBUd3f31NTUmq2t0vIMKC4u7tSpk4GCtRwcHM6cOSM9sTrv+2s0mtzc3MaNGxu4opeXV2xsbHh4uLSxU6dONXXDNRrNrl27xJUV9OnSpYvO14pNft9fo9HIniLMmzdP2adK7/trNJrk5GTlRO2y9/01Gk18fLzh2y4aPHiw7BMKTQ2976/RaEpKSj799FNHR0fDNbi7ux85ckQ2eDXfmt+zZ4/sUxKdOnfunJCQID3R8IRjBtTU+/61uniTKxe9/vrr0p7r1q2r0q0zAe/7AwAAs2NdXwAAoDbPPPNMVFTUpk2bfHx8DHSztLTs1q3bL7/8smvXLtlyqTq5uLhoPyawtpZ/Mdm9e/czZ86EhoaWl5frPLdr164rVqyodA1MCwuLjRs3zp07V5lp2traTp8+/dKlS82aNavZ2owvT8nW1vbUqVPLli1zcnLS2cHCwmLMmDFXrlzp3LlzVQc3wNXV9ezZs0OHDlUeqlu37scffxwXF+fv7z948OB+/foZGMfkGy4IwpAhQ+Li4vQtCOHq6jp37twTJ07U+GvFo0aNku4eP368+mO2aNFi6tSplXZr3bp1QkLCRx99ZGBBgubNm4eFhe3atUucA6rG2djYzJo168qVK7JbIbKwsBgxYkRsbGyvXr0qHc34xRUEQXj++efj4+OHDx9uY2Ojs4O9vf2yZctOnjzZqlUraXtqaqrxVzFSlSoXanPxJlcukr7vb21tHRISUpViAQAAaiULjUZj7hoAAICqBAUFKd8fFwRh8uTJxi9EWVOSk5P37t0bHx+flZWVnZ1tbW3dqFGjRo0a+fn5DRkyRDbxvZGKiori4uKio6OzsrJatmzZqlWrdu3aGXNiQUHBlStX0tPTXVxc2rRpI74t3qNHD+2il6NGjdq6dasgCHl5eVu3bk1MTMzKyvL09GzdunX37t31BdA1UpuB8oyRnp5+7Nixa9euXbt27fr1666url5eXl5eXp07dza+ABOcPHkyKioqPj6+tLTU3d29Xbt2L7zwgjRxLi0tPX36dEJCgqOjY5cuXbSLD9fgDRcEITk5OSYmJiYm5sqVK25ubu7u7m3bth00aJAJz1GM5OPjk5iYqN22t7fPysoy5m3oGlRYWHj8+PETJ05kZmbeunXLzs7Ozc2tefPmwcHBbdu2rZHVm42UkZERFxd36dKl+Ph4Jycnf39/f39/Pz8/cVUJfaZNm7Z8+XJXV9fc3FwTrnv37t19+/b9+eef2dnZ9+7da968eatWrXx9fX19fSu9dDVVs3KhNhdvWuWJiYnSZ8D9+/c/cOCAKdVXhb5/DiqlpKQYmGIOAADAZOT+AACghj1WuX+toIyh8VDV9hv+5Zdfvvfee+LuqlWr3n33XTPWUxsFBwcfPny4Q4cO0dHR5q6lampv5YKZip8+ffq///1vcXfXrl3SibYeEnJ/AABgdszzAwAAANQmEyZMkH6q8s0335ixmNooOTn56NGjgiCMGTPG3LVUTe2tXDBT8YWFhdL1zNu1azd48OBHdnUAAAAzIvcHAAAAahN7e/sZM2aIuwkJCdo4FcZIT08PCQkpLy9v0qTJO++8Y+5yqqD2Vi6Yr/itW7fevn1b3J03b96jnIcKAADAjMj9AQAAgFpm0qRJbdq0EXcXLlxoxmJqkfnz53t7e8fFxdWtW3fdunX29vbmrshYtbdywXzFl5WVLV68WNwNDg7WuRg4AACAKpH7AwAAALWMra3thg0bLC3//7/MHzt2LCIiwrwl1QpHjhwpLCx87rnnYmNjBw0aZO5yqqD2Vi6Yr/jNmzcnJydrt52cnNatW/fILg0AAGB25P4AAABA7dO5c+eZM2eKu7NnzzZjMbXFa6+9dvTo0SNHjnh4eJi7lqqpvZULZiq+pKRE+h3Ml19+yfK5AADgb8Xa3AUAAAAAMMX8+fNjY2MTExMFQbhz587Zs2c7d+5s7qIea+PGjTN3CSaqvZULZip+z549jo6Ovr6+giD06NHjrbfeevQ1AAAAmBG5PwAAgJnt3LmzuLhYEAQHBwdz1/K3oJobbmVl9csvv5i7CuBxFBISEhISYu4qAAAAzIbcHwAAwMzc3NzMXcLfCzccAAAAgLoxvz8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHqQ+wMAAAAAAAAAoB7k/gAAAAAAAAAAqAe5PwAAAAAAAAAA6kHuDwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKgHuT8AAAAAAAAAAOpB7g8AAAAAAAAAgHpYm7sAAADwd1FSUnL37l1zVwEAwMNVXl5u7hIAAMDfnYVGozF3DQAAQFWCgoJOnjxp7ioAAHjcpaSkeHp6mrsKAACgQszzAwAAAAAAAACAepD7AwAAAAAAAACgHuT+AAAAAAAAAACoB7k/AAAAAAAAAADqQe4PAAAAAAAAAIB6kPsDAAAAAAAAAKAe5P4AAAAAAAAAAKiHhUajMXcNAABAVc6ePZuXl2fuKgAIgiCsWrVq37594q69vf3PP/9sxnoASPXs2dPBwcHcVQAAABWyNncBAABAbTp37mzuEgD8f7t27ZLuWllZDRgwwFzFAAAAAHg0mOcHAAAAAAAAAAD1IPcHAAAAAAAAAEA9yP0BAAAAAAAAAFAPcn8AAAAAAAAAANSD3B8AAAAAAAAAAPUg9wcAAAAAAAAAQD3I/QEAAAAAAAAAUA9ycQPnMgAAIABJREFUfwAAAAAAAAAA1IPcHwAAAAAAAAAA9SD3BwAAAAAAAABAPcj9AQAAAAAAAABQD3J/AAAAAAAAAADUg9wfAAAAAAAAAAD1IPcHAAAAAAAAAEA9yP0BAAAAAAAAAFAPcn8AAAAAAAAAANSD3B8AAAAAAAAAAPUg9wcAAAAAAAAAQD3I/QEAAAAAAAAAUA9yfwAAAAAAAAAA1IPcHwAAAAAAAAAA9SD3BwAAAAAAAABAPcj9AQAAAAAAAABQD3J/AAAAAAAAAADUg9wfAAAAAAAAAAD1IPcHAAAAAAAAAEA9yP0BAAAAAAAAAFAPcn8AAAAAAAAAANSD3B8AAAAAAAAAAPUg9wcAAAAAAAAAQD3I/QEAAAAAAP4fe3ceF1XVP3D8wsAgiCiKK6CoGKi4o7liloJmuS9gi2tpmmuWLe4+pqappbmWe+6Wj5mWSqZZLiguiLmAIiouCIoiss/vj3me+7vPvTPDMAMM3D7vP3zNPfecM18uMxznO+eeAwCAepD3BwAAAAAAAABAPcj7AwAAAAAAAACgHuT9AQAAAAAAAABQD/L+AAAAAAAAAACoB3l/AAAAAAAAAADUg7w/AAAAAAAAAADqQd4fAAAAAAAAAAD1IO8PAAAAAAAAAIB6kPcHAAAAAAAAAEA9yPsDAAAAAAAAAKAe5P0BAAAAAAAAAFAP8v4AAAAAAAAAAKgHeX8AAAAAAAAAANSDvD8AAAAAAAAAAOpB3h8AAAAAAAAAAPUg7w8AAAAAAAAAgHqQ9wcAAAAAAAAAQD3I+wMAAAAAAAAAoB7k/QEAAAAAAAAAUA/y/gAAAAAAAAAAqAd5fwAAAAAAAAAA1IO8PwAAAAAAAAAA6kHeHwAAAAAAAAAA9SDvDwAAAAAAAACAepD3BwAAAAAAAABAPcj7AwAAAAAAAACgHuT9AQAAAAAAAABQD/L+AAAAAAAAAACoh4OtAwAAAABgoZSUlKSkJBMVnjx5Ij3U6XTXr183Ud/JycnT07NgggMAAABgI3Y6nc7WMQAAAACwxJEjR1566aUC7PDdd99duXJlAXYIAAAAoOixzg8AAABQUrVr187b27sAOwwNDS3A3gAAAADYBHl/AAAAoKSyt7fv379/QfVWrVq19u3bF1RvAAAAAGyFvD8AAABQgoWFhRVgV/b2fEAAAAAASjz+Ww8AAACUYE2bNq1Xr16BdFWAXyEAAAAAsCHy/gAAAEDJ1q9fP+s7qVOnTrNmzazvBwAAAIDNkfcHAAAASrY333zTzs7Oyk4GDBhQIMEAAAAAsDny/gAAAEDJVrt2beun6hfITQMAAAAAigPy/gAAAECJZ+XS/M2aNSuoTQIAAAAA2Bx5fwAAAKDECwsL02g01jQvwGAAAAAA2BZ5fwAAAKDEq1q1alBQkGVt7e3t+/fvX7DxAAAAALAh8v4AAACAGlg8Z79du3ZeXl4FGwwAAAAAGyLvDwAAAKhBnz59nJycLGjIIj8AAACAypD3BwAAANTA3d09JCQkv60cHR379OlTGPEAAAAAsBXy/gAAAIBKWDBzPyQkpEKFCoURDAAAAABbIe8PAAAAqES3bt1cXV3z1YRFfgAAAAD1Ie8PAAAAqISLi0v37t3zVb9bt26FFw8AAAAAmyDvDwAAAKhHvubvd+/ePb/3BwAAAAAo/sj7AwAAAOoRHBzs4eFhZmUW+QEAAABUibw/AAAAoB6Ojo69e/c2p6a7u3tISEhhxwMAAACg6JH3BwAAAFTFzFn8ffv21Wq1hR0MAAAAgKJH3h8AAABQlaCgoBo1auRZjUV+AAAAALUi7w8AAACoip2dXd++fU3XqVatWlBQUNHEAwAAAKCIkfcHAAAA1CbPufxhYWH29nwWAAAAANSJ/+sDAAAAatO0adN69eqZqMAiPwAAAICKkfcHAAAAVKhfv37GTvn6+jZr1qwogwEAAABQlMj7AwAAACr05ptvGjv1xhtvFGUkAAAAAIoYeX8AAABAhWrXrh0YGGjwlIlbAQAAAACoAHl/AAAAQJ0MLuLfrFkz00v/AwAAACjpyPsDAAAA6tS/f397e/l/+ENDQ20SDAAAAIAiQ94fAAAAUCdPT8/27dtLS+zt7fv372+reAAAAAAUDfL+AAAAgGrJlvpp166dt7e3rYIBAAAAUDTI+wMAAACq1adPHycnJ/HQ4Ir/AAAAAFSGvD8AAACgWu7u7iEhIfrHjo6Offr0sW08AAAAAIoAeX8AAABAzcQ5/iEhIRUqVLBtMAAAAACKAHl/AAAAQM26devm6uoqsMgPAAAA8I9B3h8AAABQMxcXl27duun/tXUsAAAAAIqCg60DAAAAAFC4wsLCdDqdftY/AAAAANWz0+l0to4BAIqF8PDwL774wtZRAABQ8HQ6XUpKSrly5WwdCAAABS8wMHD27Nm2jgIAihfm+wPAfyQkJBw4cMDWUQAAAAAAAABWYX1/AAAAAAAAAADUg7w/AAAAAAAAAADqQd4fAAAAAAAAAAD1IO8PAAAAAAAAAIB6kPcHAAAAAAAAAEA9yPsDAAAAAAAAAKAe5P0BAAAAAAAAAFAP8v4AAAAAAAAAAKgHeX8AAAAAAAAAANSDvD8AAAAAAAAAAOpB3h8AAAAAAAAAAPUg7w8AAAAAAAAAgHqQ9wcAAAAAAAAAQD3I+wMAAAAAAAAAoB7k/QEAAAAAAAAAUA/y/gAAAAAAAAAAqAd5fwAAAAAAAAAA1IO8PwAAAAAAAAAA6kHeHwAAAAAAAAAA9SDvDwAAAAAAAACAepD3BwAAAAAAAABAPcj7AwAAAAAAAACgHuT9AQAAAAAAAABQD/L+AAAAAAAAAACoB3l/AAAAAAAAAADUg7w/AAAAAAAAAADqQd4fAAAAAAAAAAD1IO8PAAAAAAAAAIB6kPcHAAAAAAAAAEA9yPsDAAAAAAAAAKAe5P0BAAAAAAAAAFAP8v4AAAAAAAAAAKgHeX8AAAAAAAAAANSDvD8AAAAAAAAAAOpB3h8AAAAAAAAAAPUg7w8AAAAAAAAAgHqQ9wcAAAAAAAAAQD3I+wMAAAAAAAAAoB7k/QEAAAAAAAAAUA/y/gAAAAAAAAAAqAd5fwAAAAAAAAAA1IO8PwAAAAAAAAAA6uFg6wAAAAAAlHh2dnYNGjSQFcbGxj579swm8QAAAAD/ZOT9AQAAkLd9+/YFBwcbO+vj43P79m0TzWfPnj1p0iRjZ1u0aBEZGWlVfEVi4sSJc+fONadmVlZWXFzctWvXrl27dvXq1a1bt6akpBR2eIUqPT3dweF/PjvIfmuOjo7nz5+XtWrfvv3Ro0eLIr7C5OPjExQUVK1atapVq6anp1+5cuXy5ctXrlxJSkrKs+3q1asHDx5szrNkZmYmJycnJSVdunTp+PHju3fvjo+Ptzp2AAAA/EOR9wcAAEDeNBqNRqMxdrZNmzbbtm0z0bxt27YmmtvZ2VkVXFGxt7c38VNIaTQaf39/f39//eG//vWvmTNnrlixIisrqzADLETKF0BJ+a1Zo1evXuPGjWvbtq3BHzYmJmbChAk//fSTiR7Mf804Ozt7enp6eno2bNgwNDR0/vz5q1evnj179t27dy2MHgAAAP9grO8PAAAAa7Vp08bEWUdHx+bNmxdZMMWQh4fH119/HR0dHRAQYOtYYJZSpUqtWLFi165d7dq1M/YNh6+v7549e/bu3VurVq0CD0Cr1Y4aNSo2NnbgwIEF3jkAAABUj7w/AAAArNW2bVsTZ5s0aeLs7FxkwRRbderU+f7777Vara0DQd42btw4fPhwc2p27do1Ojq6cePGhRGGs7PzmjVrwsLCCqNzAAAAqBh5fwAAAFirYcOGrq6uxs6avhvgH6Vhw4bTp0+3dRTIw9ChQ/v06WN+/VKlSm3YsMHJyakwgrG3t9+wYUP37t0Lo3MAAACoFev7AwAAwBJJSUkVKlTQP9ZoNC1btjx06JDBmtK8f3Jycrly5ezt1TP7ZPPmzQ8fPpSWaLVab2/v+vXr+/j4KOt/9NFH27ZtU26BW9Ll5OTMmTNHVlgSd6bVarVffPGFsjwzM/PcuXM3b96sX7++v7+/7DXcoEGDWbNmffTRR3n2//Tp07Vr18oKPTw8AgIC/P39Dd4O4uDgsHr16t9//72k7w4NAACAIkPeHwAAAJY4efLkq6++Kh62adPGWN6/devW4uMTJ0506dKl0IMrQnPnzo2KilKW29nZ9enTZ9myZR4eHtJyjUbz0ksvqTLv/+mnn9o6igLQpUuX8uXLywqXLl364Ycfpqen6w+DgoK2bNlSrVo1aZ0PPvhgxYoV169fN91/UlLS2LFjDZ5ycHDw8/NbtmxZUFCQ7FTFihU/++wzc75XAAAAAATy/gAAALBMZGRkp06dHB0d9YfGFvOpWbNm1apVxcPjx49Lvy0wn1arrVChQvny5TUaTUJCQlJSkk6ns6CfIqPT6Xbs2JGVlfXjjz/KTtWtWzfP5tWrV69Zs2bFihXLlSuXkpKSmJh48+bNGzduWBxPgXdYeLRarY+Pj06nu3HjRnZ2tmU9VKlSxd3dPTY2NjU1NV9t33jjDVnJ9u3bx4wZI329HT16tH///n/88Ye0mr29fWBgYJ55fxOys7Ojo6M7deq0evXqt99+W3Z2zJgxc+bMefTokcX9AwAA4J+DvD8AAAAskZmZefbs2RYtWugPW7ZsqdFocnJyZNVk3wecPHkyX8/i6+s7bNiwDh06NGvWTKPRiOUZGRkJCQnh4eGbNm06evSo8jsAOzu7OXPmyObaC4IQERGxcuVK5RPNnTtXWXnbtm0HDx7MV8Ayu3fvjo2NrV27trTQRN6/evXq48aNe/XVV/38/JRnY2Ji9u3bt3jxYvPz9QXeoTEODg4bN26UFc6YMePy5cvSEhcXl6+//lpa8vjx44kTJ+pPjRw58r333vPx8dGvopOdnR0XF3fs2LGZM2eaE6Gjo+OQIUNCQ0ODgoL0Peh0uri4uFOnTn366af6jPyUKVPq1asnbfWvf/0rOjpaPJTenqK3YMEC5Qvs2LFjhw8f7tChg7SwYcOG27dvzzNO0zIzMwcOHFizZs127dpJy52cnLp167Z+/Xor+wcAAMA/gg4AoNPpdLoNGzbY+k8yABRfv/76q+zP5rRp0xYvXiwtadKkibLh8uXLxQrZ2dnu7u7Kv8DNmjVTNixVqtSKFSuysrLy/AMeHx//2muvKXsICwtTVs7MzKxTp46sZp8+fZQ1Y2JiSpcuLa320UcfKas1aNDA9KX7+eefZU3u37+vrObg4DBr1qy0tLQ8f9709PR58+YZXAi+8DpU/iJkvzWtVqvsWblejfIFcOfOHUEQmjdvfu/ePWMRZmRkLF682PTGuU2aNLlw4YKxHp49ezZixAhBEA4fPiw79fLLL4udODo65uTkSM+mpqba2dkZfMaFCxfKutqzZ4+sznfffSerY+ZXLMOGDVP+FMr+AQCCIAQHBxv7+w8A/1jq2VENAAAARcne3v748ePSEoNL/UhnT0dFRT179syczl1dXfft2zd8+HAHh7zvT/X29v7hhx969uwpK9+yZcvu3btlhY6OjgsXLpSWaLXaefPmyarl5uYOHjzYzGhNe/LkiaxE3A9ZGsOOHTsmT57s7OycZ4dOTk4fffTR7t27S5UqZaxOgXdYqPz9/Q8dOlS5cmVjFbRa7dixY2fNmmWsQpMmTX7//XcT38G4uLgsW7bM4PdDUt7e3rINexMSEnRGVpR6+vSprKRWrVqm+zffzp07MzIyZIXNmzcvqP4BAACgbuT9AQAAYKE88/5ly5YNCAgQD//66y8ze54yZYpsBRXTHB0dt2/f3r59e1n5e++9l5ycLCt87bXXgoODxcMxY8Yo07VfffWVbPV2iylvL3j8+LGsZPXq1T169MhXt126dNm0aZOxswXeYeHRarXbtm1zc3PLs+YHH3zQtm1bZXm5cuV++eWXPHuws7PbsGGDp6eniTo6ne6b/2VwVSg95Q0uN2/eNB2D+R4/fqx8BVauXDnP+zwAAAAAgfX9AQAAYLH4+Pg7d+6IiVRl3r9ly5bS2dNm5v2rVas2evRoZXlaWlpsbGx6enqVKlW8vb1lZx0cHHr06HHkyBFp4b1798aMGaNMZy9atKhRo0bZ2dkeHh6TJ0+Wnb1y5cpnn31mTqh5qlKlimw1eUEQkpKSpIctWrRQbuKql52dHR8fX716dYP3PfTu3bt9+/ayH7kwOixUHh4e0p0VcnNzdTqddC8Hkb29/Zw5c2Sr3guCMGbMmEqVKpnzXO7u7u7u7rJC6TI+N27ceP/9983pSqvVvvjii7JC2WYGVtKvgCRlZ2fn5eVlzdbBAAAA+Idgvj8AAAAsJ53y7+3tXb16delZ2TcBsvsDjBk8eLBsdZqMjIzRo0eXKVOmYcOGLVq0qF69et26dSMjI2UNDa6C8v333ytXRa9Xr957770nCML06dPLli0rPZWTkzNo0KDnz5+bE6pp9vb2K1asUK60c/bsWenh/PnzlW3/+OOPVq1alSlTpnbt2mXKlGnVqtWxY8eU1ebPn69cfb7AOywaa9eu7d69e4UKFdzc3IKCgvbt26esU79+fVmJm5vbuHHjlDVv3ry5cuXKXr16de3adfr06bGxsQUb7bRp05RfNkj3B7aewX0glN94AQAAAAbYeH8BACg22NcXAExQ7us7Y8YMQRAmTJggLQwLC5O2OnTokHjq7t27gpHdX2U7xO7atUtW4dtvv1WG1LJlS1m1tLQ0g9PYq1atmpycLKucnJzctm1b5Xa1c+fONXYRDO7r27hxY83/cnZ2rlu3blhY2MWLF5X1dTrdyJEjxT67deumrLBmzRpHR0fZs2u12vXr1ysrh4aGSqsVeId6hbevr57yV+zk5BQeHq6sKcu2f/rpp8o6J0+elK2HU65cOeUGy3qvvPKK8uc1rWXLltnZ2bJ+7t+/7+rqKqtp8b6+giB88MEHymjffPPN/EYLAKrHvr4AoMR8fwAAAFhOtnSPdIK/RqORLoRi5mR/QRAaN24sKzG4xvqDBw9kJc7OzlWqVFHWvHv37tixY2WF7u7uBw8elH1PEB0dPW3aNDPj1Dt79mz2/0pLS7t06dLmzZuVk9MFQXj27NmOHTvEQ+UqQw8fPnz//fezsrJk5ZmZmaNGjXr06JGsXNZDgXdYBM6dO6e//UIqIyNDud+yIAh+fn7SQ+WyPMnJyf369cvMzJQWPn78uHfv3vfu3bM+2o4dO/7666/KlYhmzZqVmppqff+ixMREZWGZMmUK8CkAAACgVuT9AQAAYLnIyMiMjAzxUJr3b9SokXT6s/mb+vr6+tr/r4iICFkdJyenqVOnKtsaW6Nm48aNe/fulRWWKlVKepidnT1o0CDpj1MYli5dKuZzNRpNo0aNZBW+/vrrtLQ0g21TU1OXLl0qK6xbt674gxR4h0UjPDxc+bWEIAgXLlxQFkrn+5crV65q1aqyCvPmzTO4v256errBFZDy5Z133tm3b59yD+HLly+b2AHYMi4uLspC5aL/AAAAgBJ5fwAAAFguMzNTus5+gwYNxPnIli3uLxhaiFIQhFKlSjVs2PD1118fP378d999FxsbO3DgwHyFOnz48MePH5uoMHfu3NOnT+erz/w6cODAlClTxMOaNWvKlqMRBOHHH3800cPu3btlJfb29i+88EIhdVg0Ll68aLA8OTnZdMNatWopCw1+W6C3devWfAUm5erqumnTplWrVilXTLp161bnzp0NfnVhDel2xyLy/gAAADCHgfVPAQAAAPP99ddfrVq10j/WaDStWrU6cOCAIAitW7cW62RmZp45cya/PTs5OfXq1atz585NmjSpW7euwbX7zZeQkDBu3Lh169YZPHv+/PmZM2da079pjx49+vLLLxctWiTNDvv7+ytrxsfHm+jH4Fl/f399srvAOywaxrbDzc7ONt2wdu3aysJLly4Zq3/37t3MzEzlVyN5atSo0fbt2w1+HRIfH9+pUyeDdxhYyWDe//bt2wX+RAAAAFAf5vsDAADAKrKJ/OI0f+l8/8jIyPT0dPP7tLe3/+STT+7cubN58+a33367QYMGVib99davX79v3z5leXZ29sCBAwt8vrbegwcPpk2b5uPjM3v2bNl6O8o0fUpKypMnT0z09vDhw+fPn8sKxX4KvMOicevWLcsaKuf7p6ammuhNp9NZ8FxDhw49ceKEwaR/eHh4s2bNrl69mt8+zdGwYUNZSWZmpnJbCwAAAECJ+f4AAACwisG8v7e3t7e3t7E6pjk6Ou7Zs6dz586mqx05cqR9+/b5iVQQBEG23aueg4NDlSpVzp8/n9/eBEFYvnz5/fv3ZYWPHj2Ki4uLi4u7efNmSkqKsbblypWTlZizMeyzZ8+cnZ0N9lPgHRYN/VJOFlCus5+SkmK6tzzvIZBycnL65ptvhg4dqjyl0+m++OKLzz77LCcnx/wOzVe6dGnZSlmCICQkJFh8rQAAAPCPQt4fAAAAVklISLh582aNGjX0hy+++KJGo5GlLM3f1FcQhDlz5hhM+ut0ukuXLp05c+bkyZOHDh16+PBhUlKSso6Jnt98880ePXoYPPXtt98GBASYyNEbs3z58qioqPy20lPOE69SpYqDg4OJ3HSpUqWUy7+I/RR4h8XcjRs3ZCWenp7ly5c3sTFA9erVzezc1dV1z549HTp0UJ5KSEgYOHDgoUOHzA81v1566SXlekQnTpwovGcEAACAmrDODwAAAKwlnc7v6uraqFEj6eL+Qn7y/lWqVBk3bpysMCEhYdiwYeXLlw8ICBg4cOCyZcuuXr1qZ2eXryCrVav29ddfGzvr5eW1cOHCfHVovcuXL8tKNBpNtWrVTDSR3kWh7KfAOyzmYmJilIWNGzc2Vr9SpUqyOxuMcXV1PXTokMGk/+7duxs2bFioSX9BECZNmqQs/O677wr1SQEAAKAa5P0BAABgLeVSP9L5/vHx8QkJCWZ21a9fP41GIy159OhRhw4dvvvuu8ePH0vLxTsMpEx8GbBq1Sp3d3cTTz1kyJA8FxcqWFeuXFEWmkhbC4LQqFEjE/0UeIfFXGxsrLLQxM/bsWNHc7q1s7PbsGHDiy++KCtPT08fOXJkz549lTeaFKzu3bu3a9dOVnjjxo3w8PBCfV4AAACoBnl/AAAAWEs2nb9z587SbHK+FvmpV6+erOTgwYMGl51R7npqwuDBg7t27SorVC4KtHr16rJly5rfrZVSUlLu3bsnK5wwYYKJJuPHj5eVPHny5O7du4XUYTF3+/btjIwMWeH48eMrVaqkrOzg4DBjxgxzutUn92WF8fHxbdq0Wb58uWWhmq9ly5YbNmxQlq9Zs4bF/QEAAGAm8v4AAACw1vnz558/fy4edunSRTpnP195/8qVK8tKbt68abBmSEiImX16e3svXrxYVnjhwoXp06fLCot+tZ/t27fLStq3b29weRlBEDp16iRbQEnZQ4F3WJzpdLpffvlFVujl5bV161bZXSNarXbJkiW+vr559unm5qZ8YTx+/Dg4ODgyMtK6ePPg6ur64YcfHjhwQLlfcU5Oztq1awv12QEAAKAm7OsLAAAAa2VlZZ0+fVpcmUS22I5sFSDT7ty5Iytp0qSJstqgQYNCQ0OV5fb2Bua1fPvtt8pE6tixY0+cODF48GAfHx9p+ZAhQ3bu3Ll//37zY7bGrFmzBg4cKLvJYO/evYMGDdqxY4e0sH///srMb1pa2tSpUwu1w2Luk08+ee2112RZ/g4dOpw4cWLv3r0HDhx4+vRpYGDg+++/36xZM3M6DA0NVW50/Pvvv3ft2lV5y4hMRkbGN998Y7pO+fLlld8tlS1btnbt2o0bNzZ2u8mCBQuUbw0AAADAGPL+AAAAKADHjx9XrkguCEJaWtq5c+fM7ycqKkpW0rFjx+nTp69cuVK/+Ez16tUnTZo0bNgwg80dHOT/vx0+fHhwcLCscNeuXb///rsgCB999JFyevuqVasCAgJSUlLMD9tiDx8+nDNnzty5c6WFLi4u27dv//PPP0+fPn3lyhU/P7/AwEDplgmiBQsWyNbkKfAOi7m///577dq1ytdDYGBgYGCgcuZ+nt544w1lYY8ePXr06JFn25SUlDzz/m5ubsq1lUz7448/Jk+enK8mAAAA+Icj7w8AAIACYGwxn4iIiOzsbPP7OXPmjLJw2rRpU6ZMiYqKqlKlinIhICmtVis99PHxWbBggaxOenr6xIkT9Y937Nhx9OjRoKAgaQUvL69FixYNGTLE/LCt8dVXX40aNcrb21tWLtseWen+/fvz588vgg6LuWnTpg0YMMDFxSXPmsnJyXZ2dia2d/by8jL49ZUNxcfHh4WF5etNBAAAALC+PwAAAAqAscV88rXIjyAIp0+fNriOub29faNGjaRJ/4MHD8bExMiq1a9fX3xsZ2e3Zs0aV1dXWZ0vv/wyLi5OPBw3blxubq6szuDBg1999dV8RW6x9PT0sLCwJ0+e5KvVs2fPBgwYkJqaWgQdFnMJCQndunV79uyZ6WpZWVl9+vRJSkqSlUs3y23cuLFslSrb2r9/f9OmTVnhBwAAAPlF3h8AAAAF4MGDB9evX1eW52tTX70xY8YoE/oy8+fP79KlS3R0tKx82LBh4rzvUaNGKfezvXPnzpw5c6QlZ8+eXbNmjfIpVq1aVa5cufyFbqk///yzY8eO9+7dM7N+YmJiSEjIb7/9VmQdFnPh4eHt27c/e/assQrp6enDhw8/fPiws7OziX5kmz3YUFxc3IQJE7p27ar8ogIAAADIE3l/AAAAFAyDKf78zvcXBCE1NTUwMHDRokVZWVnKs7Gxsf379//oo49ycnIOHz4sOxsSEqJf6t3X13fevHnK5h9//LFyYvjkyZOVs+M9PT0XLVqU3+AtFhERUadOnVnklm/cAAAgAElEQVSzZpmecZ+WljZv3rw6der8+eefRdxhMXfmzJnAwMDQ0NCdO3c+fPhQX/j8+fO///578eLFtWrV0t9Holzk59GjR+JjG+b9nz9/fu3atcOHD3/77bcdO3asVavWokWLpPciAAAAAOaz47+SAKC3cePGt99+29ZRAAD+n6+vb4cOHfz9/X19fZ88eXLz5s2jR48ePHhQ3f+DdXJyateuXadOnXx8fDw8PMqVK5eSkvLw4cObN28ePHjw6NGj6enptu2wRNBqtW5ubklJSdJXi1arzcjIkNWsWrWq+TdGAACKoeDg4F9//dXWUQBA8ULeHwD+g7w/AADq1qZNm2PHjklLcnNztVptTk6OrUICAFiPvD8AKDnYOgAAAAAAsNCwYcO0Wq205NGjR1u2bDFYuUePHrKS+/fvk/QHAACA+pD3BwAAAFBS9e3bNzg4WFYYFxen3FhiwIAB48ePlxXu2bOnEIMDAAAAbIR9fQEAAACUVAYT99u3bx85cqS/v7+bm1uNGjV69er15ZdfbtiwQaPRyGquWrWqSMIEAAAAihTz/QEAAACUVP/+978XLFhQqlQpaaGXl9c333yTZ9s///wzMjKy0EIDAAAAbIb5/gAAAABKqtu3b3fr1i09PT2/Da9fv963b9/CCAkAAACwOfL+AAAAAEqwgwcPduvWLS0tzfwmx44d69ix4927dwsvKgAAAMCGyPsDAAAAKNkOHjzo5eU1YcKEK1eumKiWnZ39119/9e7du127djdu3Ciy8AAAAIAixvr+AAAAAEq8R48eLVq0aNGiRc2bN69du7aXl5eXl1flypWfPXuWlJSUnJx86dKlI0eOPHnyxNaRAgAAAIWOvD8AAAAA9YiIiIiIiLB1FAAAAIAtsc4PAAAAAAAAAADqQd4fAAAAAAAAAAD1IO8PAAAAAAAAAIB6kPcHAAAAAAAAAEA9yPsDAAAAAAAAAKAe5P0BAAAAAAAAAFAP8v4AAAAAAAAAAKgHeX8AAAAAAAAAANSDvD8AAAAAAAAAAOpB3h8AAAAAAAAAAPUg7w8AAAAAAAAAgHqQ9wcAAAAAAAAAQD3I+wMAAAAAAAAAoB7k/QEAAAAAAAAAUA/y/gAAAAAAAAAAqAd5fwAAAAAAAAAA1IO8PwAAAAAAAAAA6kHeHwAAAAAAAAAA9SDvDwAAAAAAAACAepD3BwAAAAAAAABAPcj7AwAAAAAAAACgHuT9AQAAAAAAAABQD/L+AAAAAAAAAACoB3l/AAAAAAAAAADUg7w/AAAAAAAAAADqQd4fAAAAAAAAAAD1IO8PAAAAAAAAAIB6kPcHAAAAAAAAAEA9yPsDAAAAAAAAAKAe5P0BAAAAAAAAAFAP8v4AAAAAAAAAAKgHeX8AAAAAAAAAANSDvD8AAAAAAAAAAOrhYOsAAKC402q1MTExto4CAADhww8/3LZtm7I8KCho06ZNRR8PAABFydg4CABQIu8PAHnz9va2dQgAAAilS5c2WF6qVCmGKgCA6hkbBwEASqzzAwAAAAAAAACAepD3BwAAAAAAAABAPcj7AwAAAAAAAACgHuT9AQAAAAAAAABQD/L+AAAAAAAAAACoB3l/AAAAAAAAAADUg7w/AAAAAAAAAADqQd4fAAAAAAAAAAD1IO8PAAAAAAAAAIB6kPcHAAAAAAAAAEA9yPsDAAAAAAAAAKAe5P0BAAAAAAAAAFAP8v4AAAAAAAAAAKgHeX8AAAAAAAAAANSDvD8AAAAAAAAAAOpB3h8AAAAAAAAAAPUg7w8AAAAAAAAAgHqQ9wcAAAAAAAAAQD3I+wMAAAAAAAAAoB7k/QEAAAAAAAAAUA/y/gAAAAAAAAAAqAd5fwAAAAAAAAAA1IO8PwAAAAAAAAAA6kHeHwAAAAAAAAAA9SDvDwAAAAAAAACAepD3BwAAAAAAAABAPcj7AwAAAAAAAACgHuT9AQAAAAAAAABQD/L+AAAAAAAAAACoB3l/AAAAAAAAAADUg7w/AAAAAAAAAADqQd4fAAAAAAAAAAD1cLB1AAAAoDhat25dcnKy/nHfvn29vb1tGw9QTERHR//666/6xz4+Pr169bJtPLaVk5Nz9OjRy5cv37179969e7m5uZUqVapUqVL16tVffvnlcuXK2TpAwHKMg4BBjIMAUFKQ9wcA2/v77787duyof9ynT5+vvvrKtvGUaLNmzZo+fbogCBUqVHjw4IGtwympfvzxx8GDB+sfv/DCC2PGjNE/vnHjhq+vr6zyzz//3LlzZxO9+fv7X7t2TTx89913ly9fXqDxqkpqauqZM2euXbsWExNz9+7d6tWr16lTx9fXt3nz5o6Ojqbb6nS6I0eOnDx5MiEh4dGjRz4+Pn5+fv7+/nXr1nVxcSnOkZeg4D09PWfPnq3PBmo0mhMnTgQGBhZ2eMVQVFTUN998s2vXrocPHxqs4ODg0K5du9DQ0KFDh2o0miIO75+McbBAMA4WEwsXLhRfxn5+fuIvxYQHDx5s2LDh0qVLN2/edHBw8PX1rVOnTosWLVq3bl3Iwf4PCyIXbBo84yAAqJAOAKDT6XS6DRs2GPw7qdVqC/upz58/Lz7dW2+9VdhPV5Sy/ysnJ6donnHGjBn6K1mhQoWieUb1SU5OrlKlivia3Llzp3jq+vXryvdIvXr1srKyTHRYp04daf3hw4cX/g9RIuXm5q5fv1568aV8fX23b9+em5trrPmKFSuMTUctX778ihUrCu9taGXkJS74BQsWiBUaNGiQmZlZSLEpDRkyxGCcwcHBRRZDRkbG1KlTzfkuR69hw4ZHjx4t1JCKfqwxH+NgScQ4WEw8ffq0VKlS4nXr3Lmz6frZ2dmjR492cnIy+LeoS5cuUVFRxTNynU2DZxwEALVifX8AQCEKDAx0cHBwcHB46623bB0LzDVhwoR79+7pH/v5+eV5+/alS5dWrFhR+HGpXHZ2dseOHQcOHChefJmYmJh+/fq1a9cuNTVV2TY0NHTEiBG3bt0y2DY5OXnEiBEvvvjihQsXCjhu6yIXSmbwI0aMcHd31z+Oior6/PPPCzywYuvJkydt2rSZOXNmVlaWtNze3t7Pz69NmzZly5aVNblw4UL79u1Xr15deFEV57GmOMcGYxgHi4mFCxemp6ebWVmn0w0dOnTJkiUZGRkGK+zfv79x48ZbtmwpuACNylfkgk2DZxwEABUj7w8AAP7f4cOH161bJx5OmDDBzs4uz1bTp09/9OhRIYb1DzBjxozffvstz2p//vnnu+++KyucOnXqtm3b8mx7+vTp1157LSUlxcIQjbAmcqFkBl+6dOkRI0aIh59//vmVK1cKNrDiKTMzs2fPnqdPnxZLPDw8Fi9efPz48SdPnly+fPnYsWOPHj2KjY3dtWuXNFWq0+mGDx++fv16W0QN5A/jYDFx4sQJ6aTyPI0cOTLPPzI5OTnvvPNOdHS0daHlIb+RCzYNnnEQAFSMvD8AAPh/n332mfi4YsWKb7/9tjmtkpKSxJUlYIHjx4/PmTNHVlijRo3mzZu7ubnJyrds2SKdOh0ZGTlv3jxln87Ozspc1a1bt0aPHl0QIf+HNZELJTn40aNHa7Va/ePMzMx/yOt/5MiR0vRQcHDwhQsXxo4d27Jly9KlS+sL7ezsatWq1atXr127dq1YsUJc6UI/m/Xq1as2iBvID8ZBm7t69WqfPn1atWr19OlTM5t89tlnylsu/P39O3XqJE5L13v27Fn//v0LJlAFCyIXbBo84yAAqBt5fwAA8B/79+8/fvy4eDhq1Cjp6rSmLVu2jKleFhs3blxOTo54+MILL1y8eDEuLu7UqVNJSUlTp06V1d+0aZP4eM2aNbm5udKzw4cPP3fu3NOnT1NSUjZv3izLGmzcuPHAgQPFIfISHXzVqlUHDBggHm7btq2wJ5Da3NWrV9euXSsezp8//5dffqlataqJJsOHDz916pSPj4/+MCcnZ/bs2YUaJGAlxkFbiYiICAkJadGiRdWqVf38/Hbt2mV+2wcPHnz55ZfSklatWl28ePHvv/8+cODA7du3u3btKj0bHR0t3WbZStZELtg6eMZBAFA38v4AAOA/ZB/whg4dan7brKysDz74wPoYdDrd5cuXf//99x07duzZs+f48eN37961psOcnJy4uLj4+HhZftkcaWlpZ86ciY6OTk5OtiYG07Kzs8+dOyct2b59e/369fWPHRwcZsyY0aNHD2mFc+fO6XQ6fdvt27dLT7311lvLly9v1KiRRqMpU6ZMWFjYv//9b9kzhoeH2zzykh68IAjDhg0TH+fm5k6fPr1AAiu25s2bJ76JunbtOnHiRHMWP2nQoMHSpUvFw++//z42NrawQgSsxjgoUzTjoCAI9+7dO3DgQEREhLFV5k1YsWKFdFn80qVLb9y4Ufx77uLisn79etlW5AcPHrQyYJE1kQs2DZ5xEABUz8HWAQAATLl06dLFixcFQahYsWKHDh2E/34aPHHixMmTJ2NiYgICApo3b96iRYs6deoom58/f16/HLaXl1etWrUEQUhJSfnuu+8iIiLi4uI8PDyaN2/evHnzl19+2cnJSdn87Nmz+ilFTk5O3bt3NxZkRETEjRs3BEEoX758x44dBUE4d+6cfjGHx48f6+vEx8frE3zOzs6vv/56vi5Camrq+vXro6OjY2JiEhISatWqFRAQUL9+/datW9esWTPP5llZWdu3bz906NDNmzezsrKaNWtm4opJPX36dPPmzVFRUXFxcXfv3vXw8PD09PT29u7Vq1ejRo0MNrHygsvcuXPnzJkzkZGRkZGRz58/r1GjRsuWLfv27avcNlMqNTU1MzNT/7hMmTKyz4omHD9+XLpsd/369b28vMxsq/fzzz8fOHAgODg4X61EFy9e1M8gfvDggexUgwYNevXqNWHCBOVd54Ig7N+/X7oWc506df71r38JgrBnz545c+acOXNGvwFpqVKlateuPWjQoPfff9/0/M2tW7fu2rXrwoULMTExYpbE29u7d+/eQ4cODQgIsOwHNOby5cvir0wQhJYtWypfYL179969e7d4+OTJk9jYWF9f32vXriUmJkprfvzxx7JsbLt27dq2bXvs2DGxpKA2yLUmckEQSnTw+iZly5YVtxzYtWvXnTt3PD09CyS84ubWrVsbN27UP9ZoNF988YX5bbt27fryyy/rFwjST/lfs2aNtEKhjjWMgwLjIONgsR8HrST92QVBmDFjRu3ataUlFSpU2Lp1a1JSklji7+9fNLHlyYbBMw4CgPrpAAA6nU6n27Bhg8G/k1qttrCf+vz58+LTvfXWW9JT4lqZ7du31+l0Fy5cCAwMNBjnhAkTlD23a9dOf3bs2LE6nW716tVlypRRtm3UqNGVK1eUzceMGaOvUKFCBRPxDx48WF+tWbNm+pKxY8caG3c8PT3NvzLZ2dnLli2rVKmSwa5KlSq1cuVKWRPxiuljDg8Pr1atmsHmM2fONPa8z549Gz9+vMGP1notWrQ4ePCgsqGVF1yUnp4+cuRIYz/1uHHjUlNTjbWVZqZ++eUX01dYSjZL0eAr6vr167J4WrVqJT0MCAjIzs6WtZKlloYPHy6rkJ2dPXr0aI1GY+yC61WqVGnXrl3KqBYvXiz77WRmZvbp08dYP9WrVz927JjBi5CYmNi7d28TMTg4OHz22WcZGRnmX9g8ff/999KnGDBggLLO3r17ZZHcunVLp9Pt379fWujm5mbwKWQvp2rVqtk88pIevJ5061pBEJYsWVIgsZkwZMgQwZDg4OBCfV7pX/URI0bkt3lkZKT4jY6Dg4PsL1ihjjWMg4yDpq+wFOOgzkbjoE6n27Nnj+mfXRCEzp07KxsqZ9nHxcUVbGyFFLnNg2ccBADVY50fACgxwsPDW7RoIZ2JJrVw4cJJkyaZaL5o0aJ33nnH4D5j58+fb9as2datWwsm0ILzySefjBw5UjnrTS89PX348OFvvvlmenq6wQr79+8PCQlJSEgweHbq1KnKrcwEQcjJyQkNDV20aNGTJ0+MBXbq1KnXX3/d9HojFl/wmJiYVq1aLVu2zODZ9PT0xYsXN2jQICYmxsSzW0C2Iq2Z0xXHjBkjnZh28eLFlStX5ut5s7OzQ0NDlyxZIl1h1qAHDx7069dPnHRswvjx43fu3GnsbHx8/IABA5S/3z/++CMgIMD0yrzZ2dmzZ8/WfzbOMwwzvfLKK6cl5s6dq6wTEREhPSxTpox+FurNmzel5caye8+fP5ceilPzrGRN5EIJD15P9jbJ77LOJci+ffvExx9//HF+mzdp0qR169b6x9nZ2fqp8UWPcVCGcVCGcdBW46AgCK+//nqOgrjmjAknT56UHtaoUaNGjRoFGFieLI5csHXwjIMAoHqs8wMAJcO1a9e6deuWnp6u0Wh69+7dqlUrb2/v69evHz58WJwz+8UXX7Rs2bJnz57K5jt37rxz544gCC+88MKYMWMCAgK0Wm1MTMzatWsPHz4sCEJqaurbb78dGBgo3rprje7du+s/FSxatEifbmjSpIl+7y+D8/4M2rt374IFC/SPg4ODx44d6+/v7+zsfOPGjcuXL3/++ef6RaK///77evXqffrpp7Lmqamp/fr1y87O1mg0YWFhbdq0qV279tWrV48dOyYmGj799NMmTZp07txZ2nDSpEk//fST/nFAQMCkSZPq1avn5eWVlJQUGxu7cePGHTt26HS69PT07t27P3jwwMXFRRm8xRf8+vXrTZs2FbMkwcHBr776aqNGje7evXvixInw8HD9nmk3btwICQk5ceJExYoVzbyepkVGRsbFxYmHpUqVCgoKMqehk5PTggULpK+6adOmDRgwoFy5cmY+9ZIlS0zkJmRycnKGDRvWtm1bE0tbREdHnzp1ynQ/8fHxEydOXLVqlViSkZExcODA+/fvmxPGrl27pkyZol9FwXqVK1euXLmyiQr379+XZcfEWZyhoaHSj9zG1s2QfW738/OzMNb/ZU3kQgkPXk+W7/jjjz8SExML6l1ZfOTm5opf0ri4uFiWlvLz8/vzzz/1j69fv14g64Tka6xhHGQcNI1x0IbjoJ69vSWzEs+cOSM91L+c4uPjf/zxx/Pnz0dFRbm4uDRu3Lhx48YhISHGvmC2kmWRC7YOnnEQANTPtrcbAEDxUczX+dHz9PQ8f/68rPn48ePFCrJbdMXb7fX69++vvPf866+/Fiv07NlTesri9Q1EjRs3NhiYOdq2batv26VLl5ycHNnZ58+fi3mKsmXLPnv2TF8uu2IBAQGRkZEmfuRBgwbJzoofgbp27fr8+XNlYAsXLhSb//7779JTVl5wnU4n3lzv7OysXL0hIyNDunzB5MmTleFZtr6BLGHk7+9vsJpyfYMffvhBp9O98sor0sLx48dLW5lY3+DRo0fly5eX9dm0adPPP/98//79mzdvnjBhgjJHFhYWJu1ftr6Bnr29ffv27adNm7Zu3boxY8YoV8mQLRejTF74+/svWbLk0KFD33//fVhYmOysg4PDtWvXzLy8lnn69GlMTMyGDRtkyR03N7d79+6Z38/hw4dli+Zb8H7Ml4KKXFcSgpetkb1q1apCDc8m6xtI78wICAiwrBPpvPJFixZJTxXqWMM4yDiorGAQ42AxHAdls+YNrpYj3VpWEITBgwfv3r3b3d1deUHKlSu3adOmQg04X5EX2+AZBwFANcj7A8B/FP+8v4ODw6VLl5TNc3NzxVtuvby8pKekH7/9/f2zsrIMBjB06FCx2pEjR8RyG+Y7cnJyXF1d9W3Xr19vsM6hQ4fEsE+fPq0vlF2xqKgog22bNGmir1OjRg1peXx8vNj80KFDBttmZ2eLcxvnzZsnPWXlBT9y5IhY/tVXXxlsm5mZKSZ6vL29lZmg1NTU5P8yFoBSy5YtpS/7oKAgg9WM5TsuXLggXZXY0dHx6tWrYisT+Y4PP/xQ1uHgwYPT09OlTxodHa3fHFJkZ2cXEREhVjCY75AlFqOjoz08PGR1nj59qj9769Yt2XzVjh07pqWlSXvYsmWLrLkyWVaAunTpovyhBEHw9fU9e/as+f08ffpUOSf0xx9/LP6R60pI8NWrV5fWDA0NLbzwdDbKd+i35NXr1q2bZZ1IpzOPHj1aeqrI8v6Mg1KMgzKMg8VtHNSZlz3v1q2btE6eWzGHhoYqv4uySeTFM3jGQQBQE9b3B4ASY+jQoXXr1lWW29nZiWmFxMREY82nTp3q4GB4ebfp06eLj81ZNLYI3Lp1KzU1Vf9Y+Rlb7+WXX545c+aUKVOmTJlicJGBsWPHGltKon379voHsvvZr1y54uPj4+Pj07hx45deeslgW41GIy5zkZycbOxHsOCCT5gwQf8gMDDw/fffN9jW0dFx1qxZ+se3bt2SJn30Spcu7f5fxgJQunXrlvTQ9H3fSg0aNHj33XfFw6ysLNnuiAYlJycvWbJEWuLr67t69WrZei/16tVbvXq1tESnmNAqExYWNm7cOFknypvTr1y5on+wYcOGtLQ0sVyr1a5cudLZ2VlaOTQ0NDQ0VFqye/fu3NxcE2FYw2DP9vb2I0eObNiwoZmdJCYmdurUSbaWeqtWrXr06FEAIRpRIJELJSd42ZtF9lZSB+kfYek65vni4+MjPtYv/1L0GAelGAdlGAeL2zhopmfPnkkPb9++bbr+1q1bpXec2FYxDJ5xEADUhLw/AJQYY8eONXaqUaNG+gcZGRlimkBKo9G89tprxpp7eXl5e3vrHxf4LnmW8fb2FhfG/fLLL5Wf6gVBsLOzmzJlysyZM2fOnGnwGxHZgsVS4sKj6enp0ivWsWPHGzdu3Lhx4+zZs9KJe1KJiYnGUjAiCy54UlKSuMxr3759TawVGxgYKCZctm3bZjoSc+Tk5Ny7d09aolwNIE8zZ86UrmX8008/GfytSUVFRcn2ovzwww8NXvaXX365efPm0hLZmu8y0kUeRA0aNJCViFtlXr16VVreunVr2cxKPdnmGY8fPz537pyJMApcbm7uhAkTOnfuLM3OGHPx4sVWrVqdOHFCWujo6CguF16U8hW5UKKCl71ZbJXRLlSPHj0SH+c3GSpKSkoSH1etWtXamPKPcVCGcVCKcbCkjINKmZmZykKNRtOzZ88pU6YMHDhQ+Qdn6tSpxSQ3XVKCZxwEgBKKvD8AlAz29vaym8SlpPMonz9/rqzQpEkT0xsJivcj6zcJtDl7e3txqdzU1NROnTq9+OKLy5Ytk+65lyfpZZERF08QjFwxpcTExIiIiKVLl/r7+2dkZJiubMEFl37kbtq0qen+xSlX4kw9a9y7dy8nJ0daYkFqz8PDY9q0adKSCRMmyLqVuXz5sqxEtjucVKdOnaSH9+/ff/z4sbHKsvvr9Uy8g2RpPo1G840hFy5ckDWMiooy1qeV3NzcjO1ze/DgQeW6EDLffvttixYtZG9ne3v7jRs3tm7dusCiNMTKyIWSFrzszZKQkKDT6QolONuRpjLznI5qjPSvt8U3DViDcVCGcVCKcbAYjoNmUl7hMmXKnD59+ocffpg5c+a6deuio6NfffVVaYXU1FTZb8pWimHwjIMAoCbm3vYIALAtZ2dn8+9VV8ozyVK/fv1ffvlFEITbt2+np6fLduiyiRUrVly7dk38hHnq1KlTp04JguDt7f3KK6906dKlU6dOBrc+07O3t5etNyol2ylUKS0t7a+//vrtt9/Onz8fFxcXFxdn5jxlPQsuuDRzMWHCBNO/AjHvc/fuXfOjMkY5M8uyKb2jRo1asWKF+INERUWtXr16xIgRxurL8h329vaenp7GKoszQ6XNZcsx62k0mhdeeEFZbuIddO3aNelheHh4eHi4scpS4kzJArd9+3ZBENLS0k6fPr18+fKtW7dKzy5fvrxnz54dO3ZUNnz27Nm77767efNmWXnp0qXXrFnTr1+/QgpYZHHkQskMXjbPMTMzMzEx0YKZwsWZdNNRi3Pi0iWbbJL3ZxyUYRyUYhwshuOgmSpUqCArWblypbgApiAI7u7umzZt8vX1la5JpX8r2VwxDJ5xEADUhPn+AFAyGJt6YybpbE2D/P399Q90Op1sqd88FdKkHg8Pj/Dw8LCwMNkN77du3Vq3bl3//v0rVqzYtWvXw4cPG2xerlw5rVZrwfNmZ2cvXLiwcuXKnTp1mjNnzr59+y5duiRNdnh5eclWvDX47KYrKC+4dJ5jVFRUhEniRg6y9QEsI13EQ09c/yFfHB0dFy1aJC2ZOnVqSkqKsfqy2YUVK1Z0dHQ0VlmZCjG2FkepUqUM/uqNvVCfPn1qcdqiQK6/CS4uLkFBQVu2bJk9e7a0XKfTfffdd8r6d+7cadeunTJv7uvre/z48SLIm4vyG7lQYoNXpjaUb6iSTpo7tjjvL52l7uvra0EPVo41jIPmYxwUGAfNVtjjYJ5kK+G4ubmFhYXJ6ri7u7/zzjvSkqtXr2ZnZxd6cHkptsEzDgKAOpD3B4CSIc95eaaVLl3adAXpxmJubm756vzp06eWxGQGDw+PzZs3X7t2bf78+UFBQbJ5ajk5Ofv27dPvaqhsa9kVy8zMDAoK+uCDD6SLHbu4uNSrV+/111+fPHnyzz//HBcX5+HhYbofCy64NC9Qvnz5CubJ84nMUaVKFVmJxR/ju3Tp0qVLF/EwMTFR3H1RSZZVMZEZEQRBuZqBZUkZJScnJ2NrWOfJ9AIOBejjjz+WJdGUSytERka2aNHi7NmzsvIBAwacPn1auaxz0TAncqEkB698syjfUCVd48aNxSRvXFycwQWpTcvMzBRz03Z2dgbXDc+TlWMN46CZGAf1GAfNVGTjoDGy1Hm9evUMVhO/Z9LLysqS3eJgE8U/eMZBACjRWOcHAP4R8tylUNwizN7evmzZsvnqvLAn9dSsWXPixIkTJ0589uzZsWPHDh8+/Ouvv54/f16ctoCTipoAACAASURBVDZt2rQ6deooZ0hZYPLkycePHxefd/z48cHBwXXq1DGxu6BBFlxw6QTYs2fPmlicocApn0u6A2d+LVy48ODBg+JMtCVLlhibFurn5yc9TE9PT0xMNJbFUO5iJ2tuMa1WW7NmTemv7LPPPnv77bfNaau8Q98CS5cula6UHRISEhAQIKtjb2/ftm3bvXv3iiVXr17NysoSZ4b+/PPP/fv3l+bRBEFwc3NbtmzZG2+8YX2QhRe5UMKDl71Z3Nzc8vsntPhzcHBo3rz50aNHBUHIzMxcs2aNiXVLDNq6das4g75Zs2aWLaFj5VjDOGgmxkE9xsGiHAetUa1aNemhsQWalBvkWjmlpkDYNnjGQQBQPfL+APCPkOeua+KHyUqVKuX3s73yg2ghKV26dEhISEhIyNy5c2/evDlv3rzly5frT23atMn6fMfjx48XLFigf1y3bt3ffvvN2HwlWYJSyYILLv30fu3ataLMd7i7u5cuXVr6Qz18+NDi3vz9/UeNGvXVV1/pDzMzM43NDpbNXxME4eLFix06dDBYOTo6Wnro7OxcgJfIz89Pmu9ISEgwuDJyIVm6dKl0VeukpKTPP/9cWU32KdrJyUmc+Xvjxo3Q0FDZy7JFixZbtmyxbGK1mayPXCjhwQuKN4tyAW516N+/vz7vLwjCnDlzhgwZkq8FZMQ/CIIgTJ061bIYrBxrGAfNwTgoljAOFuU4aA3ZSGFsLTLZFg4ODg422WhExrbBMw4CgOqxzg8A/CPExcVJb9iXyc7OPnnypP5xmzZtxHLxpu/U1NSsrCyDbRMSEgrjXuNDhw6tXbt27dq1f/31l8EKNWrUWLZs2YABA/SHp0+ftv5Jo6KixLmTH374obFkx8WLF6W7qxlkwQWXfsC+dOmS6f737Nmjvz7irEwryT6kWTPPURCEadOmmTMBUJnvkCYHpRISEnbu3CkteeGFF/KbmDNBNmXyxIkTBqtlZmYm/a8CWWBX9rE/MjLSYDVZxqdBgwb66X65ubmDBg2Svd7eeeedP/74o1Dz5oLVkQslPHg92ZtFrfmOt956q0yZMvrH8fHx69atM7/t0aNHxcvbvHnz119/XVahaMYaxkFzMA6KGAcNViukcdAaL730knR9+atXrxrc6vnMmTPSQ19fXxNbKRQZ2wbPOAgAqkfeHwD+EXQ63bFjx4yd3bp1682bN/WPX3rpJbFcXL03IyPD2Cfw9evXF1iUEj/99NOQIUOGDBkyfPhwE9Xat2+vf5CWlmb9torSSU9NmzY1Vi08PDzPriy44D4+Pq6urvrH3377rYkf5+zZsz169NBfn/j4+DyDMUfB5jvc3d1NLGcs8vPzk+bXBEHYs2eP8vLm5uZ+8sknssmSQ4YMsSZCGdmKun///fcXX3yhrNavXz8PicqVK4trMU+fPj30f5leptnEs//111+XL1+W1dm7d++5c+ekJY0aNdI/WLZsmTgRW4xz5cqVZk7HtmHkJT14Pdk8x6KcoVyUypQp895774mHU6dOjYiIMKfho0ePhg0bJh4aXIa+aMYaxkFzMA6KGAeLchy0hoODg/jtlyAImZmZkydPltW5f//+2rVrpSWNGzcWH9sqcsHWwTMOAoD66QAAOp1Op9uwYYPBv5Narbawn/r8+fPi07311lvSUzNmzNCXV6hQwUQPq1evFnt48OCBWN6uXTux3NPT8969e8q2aWlp4v/7nZ2dExISxFNr1qwRmy9fvlzZ9ujRo9JbfZs1ayarIH4y6du3rzmXQrRx40ax2ytXrhir9v777+vrBAUF6UvMvGJff/218ort379fLPzxxx8NNrx48aL088ykSZOkZ6284PPmzROb796921jwnTp10tdxdXXVJ3qk7t69G/NfyrPGTJo0Sfqyb9OmjcFq169fl71BfvjhB4M1s7OzlavE6g0fPlysppyn6ejouHjx4sTERJ1Ol5OT8/fff0s3SNTz9fXNzMwUO1m8eLH0bOnSpQ2GpMyk7Nu3T3/q+fPnskmX9vb28+bNi42N1VdITU0dN26crPkrr7widi791evdv3/fzIuv3MzW29v7zJkzubm5+gpbt25Vzhv97bff9Gfr1q0rO9W0adM2eUlJSbF55CU9eD1PT09pBYN/KguQsUxfcHBwoT6vTqdLS0uTLr+u1WpX/B97dx4YVXX3DXwSQkA2EcGNRQQEZBFQEEQBK4soCgooS+tWXHBF0adatWi11brUpVg3qlbUilQsKnVHREShKlUwyBIQwiMCssgihJAw7x/TZ97pTBKSkGSSm8/nr5lzz7n3l0uSw3xz77lPPFH4kO+//753797RIT179sy3W5nONebBgpgH45gHkzgPFqR9+/axOxw4cGC+3RJ/n1911VW7d++ObF29enVcVJ2SkvLvf/+7IlSe3OLNgwCBJ/cH+I/A5/6hUKhXr17Z2dmxA7///vsTTjgh2uH666+P3bpq1aronbx16tT59NNPo5v27t37xRdfxK0AkJh3nHrqqZFNtWvXji1sn7KysmrUqBEZO3DgwMin3zgffvhh9MLAW265JdK4P3lH7L3VHTt23L59e9yod955p169erFf8rhx42I77OcJz8nJiX7qrlu37muvvRZXwI8//hi7fPPvfve7xC9tyJAh0Q5vv/12ISchVtwCETVq1Ni1a1dit6LnHeFw+P333w/lJzbvCIfDw4cPz7db06ZNo+uKxPn73/8eu4f9zzvC4fD8+fOjC3rEatOmTffu3RMrqVGjxsKFC6PD9zM1iP2uiKpfv37Pnj1jVwCIuuiiiyIDC7orf582bdqU3More/ERcT8R1apV2/+0qHDJzTs+/vjjuMeTnn/++bNnz47+i0Rt3Ljxscceiw2MmjZt+u233+a72zKda8yDBTEPxjEPJncezFfR0/PY23QiatWqddJJJ3Xq1Cnxi/rFL34ROza5lSe3ePMgQLDJ/QH+I9i5fzSpqVWr1sCBA++///5JkyZdfPHFhx56aHRg69atN27cGLfnAQMGRDvUrFmzd+/eN95446hRo6IfBmrWrHnxxRdHXifmHZdeeml0eIsWLYYOHRr3WbcQsctBHHbYYXfffferr76akZHx1VdfTZ8+fdSoUdGVQFq2bLlt27ZinbF8845wOHzuuedG25s2bfrHP/7x3Xfffe211x544IEePXpE2hs1ahS9K79p06ZPPvnkG2+8UVon/L333ot2SElJGTp06D333PPGG28888wz48aNi12FoH///nl5eYlfWsnyjnA4HPeMuFmzZiX2KVbeEVdMVNz3wIoVK6IraRTFGWecEXeUUsk7wuHwLbfcUsQaUlNT4y5n288P3gsXLoyGd/vUqFGj6HfOH/7whyKOilNa0XmJK6/sxUfEXgwe+u9LX8tI0vOOjz76KO4ZjxGNGzceOHDg5ZdfPnz48B49esQ99fHwww9ftmxZIbstu7nGPFgQ82Ai82AS58F8FT09X7NmTVEeqBAKherUqbNq1aqKU3lyizcPAgSb3B/gP4Kd+5933nkXXHBBIf+Vb9KkSdwHiYitW7fGrTwbKyUl5aWXXnrssccibxPzjrlz58YNady4cRFPy+7du7t27VpIzREHHHDAvHnzinvGCso7Nm3adMQRRxRyuBYtWixcuPDll1+ObezatWtpnfBwODx9+vR9fv7v0aNHQZ/rSpx3/PrXv449xO23357Yp7h5R2ZmZuJC7YmZV0ZGRuGnPWrw4MFxl46GSy/vyMnJ+d3vflerVq3Ca2jSpEniTe77nxrMmDEj7irafHXv3n3x4sXRUYUv/F2I0orOS1x5ZS8+4sILL4zt9tRTTxXr6CVQEfKOr776qpCV3xMNGTIkKyur8H2W3VxjHiyIeTCReTC582CiYqXnc+bMadSoUeGVd+jQ4ZtvvqlolSe3ePMgQIB5ri9AlZCSkvLss89OmDAh8bNcenr6jTfe+PXXXx955JGJA+vVq/fOO++cddZZcRdvhkKhXr16zZs3b+TIkXl5eQUdt2fPng8//HARH9GZWNgnn3xy33331a5dO98OKSkpo0ePXrp0affu3Uuw/3w1aNBg/vz5Z599duKm+vXr33zzzYsWLerYsePgwYNjrwDNt7aSnfBQKDRkyJBFixYNHDiwoAonTJgwZ86cfO+/3h8jRoyIfTt79uz932fLli3HjRu3z27t2rVbvHjxr371q7glRGIdddRRf/vb36ZPnx5d+KLUVa9e/dZbb126dGncqYhKSUk599xzFy5c+LOf/Wyfeyvka8nXoEGDMjIyhg0bVr169Xw71KxZ87777ps7d27smvirVq0q1lGKonwqD1Xy4iM+/PDD6Ou0tLShQ4cW6+iV1LHHHvv555//9a9/bdOmTSHdUlNTTzrppNdee2369OlxT0xNVA5zjXmwiMyDUebBRGU6D+6nk08+ecGCBWeeeWZqav4px8UXX/yvf/0r7jEG+SrnykNJLd48CBBgKeFwONk1AFQIzz//fL4XpqWnp+/evbv86ykVvXv3njNnTigUGjFixJQpU0Kh0JYtW6ZMmbJs2bL169c3b968Xbt2vXr1KuiDd6zs7OxFixZ98cUX69evb9269THHHBN9VuE+7dixY+nSpWvXrq1Xr1779u2LdTN7KBRau3bthx9+uHLlypUrV65evbpBgwYtWrRo0aJF9+7di15Dcc2dO/fzzz/PyMjYs2dPkyZNOnfufOaZZ8Z+0t6zZ8+nn366ePHiWrVq9ejRo3Xr1qFSPeGhUCgzM3PBggULFixYunRpw4YNmzRp0qlTpzPOOKNk+VFRtGnTZtmyZZHXNWvWXL9+fVEuAStFu3btmj179pw5c9atW7dx48YaNWo0bNjwqKOO6t+/f6dOnaKrbJeD77//ftGiRV9//XVGRkbt2rU7duzYsWPHDh067PN2+PHjxz/00EMNGjTYtGlTyQ69devWN99885tvvtmwYcO2bduOOuqoY445pm3btm3bti36zfglUHkrDyWp+GXLlsUG36eddtrbb79dsqMX3ZgxY+IWVYgYMGDAO++8U9ZHT5SZmfnPf/4zIyNj/fr1GzZsSEtLO+ywww477LAOHToMGTIkbu37oij1ucY8WGLmQfNgsubB/ZSVlTVt2rSVK1d+9913jRo1ipTdsWPHfa6lk/TKQ0kt3jwIEEDJvuEAoKJI4jo/ZSd68++IESOSXUuVUNlPeNxCARMnTkx2RZVPv379QqHQcccdl+xCiq3yVh5OUvE33HBD7M/L9OnTy+Gg1jcorsr+a7nSqewn3Dy4/yrvbFJ5Kw+bB82DAPmxzg8A8B+XX3557PW5jz/+eBKLqYwyMzNnzZoVCoVGjx6d7FqKp/JWHkpS8bt27Xr22Wejbzt37jx48OByOzpQRsyD+6nyziaVt/KQeRCAAsj9AYD/qFmz5k033RR9u3jx4sjHSIpi7dq1Q4cOzcvLa9y48VVXXZXscoqh8lYeSl7xU6ZM2bx5c/Tt7bffXp7rbwBlxDy4PyrvbFJ5Kw+ZBwEomNwfAPj/rrzyyvbt20ff3nnnnUksphK54447WrVqtWjRovr16z/11FM1a9ZMdkVFVXkrDyWv+Nzc3Lvvvjv6tn///vk+BBWojMyDJVN5Z5PKW3nIPAhAoeT+AMD/l56e/vTTT6em/ud/CB9++OHMmTOTW1Kl8MEHH+zateuUU05ZuHDhGWeckexyiqHyVh5KXvHPPfdcZmZm5HXt2rWfeuqpcjs0UNbMgyVTeWeTylt5yDwIQKHk/gDAf+nevfstt9wSfXvbbbclsZjK4oILLpg1a9YHH3zQtGnTZNdSPJW38lCSis/JyYm9/veRRx5p3rx5uR0dKAfmwRKovLNJ5a08ZB4EoFBpyS4AAKhw7rjjjoULFy5btiwUCv3444/z58/v3r17souq0C655JJkl1BClbfyUJKKnzFjRq1atdq2bRsKhXr37j1mzJjyrwEoa+bB4qq8s0nlrTxkHgSgUHJ/gCB79dVXd+/eHQqFDjjggGTXUiUE5oRXq1bttddeS3YVUBENHTp06NChya6CogrMr+XKIjAn3DwIBTEPAlQWcn+AIGvYsGGyS6hanHCACsWv5XLmhAMAVBDW9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjSkl0AQEWXk5PTpEmTZFcBAKEtW7bk2z579mxTFQCBV9A8CEAiuT/Avn333XfJLgEACrR7925TFQAAEGWdHwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcKQluwCAiqJr165//OMfk10FAJSm11577bPPPou+TU9PnzBhQhLrAYBS17x582SXAFDhpITD4WTXAAAAlImxY8c++eST0be1a9fesWNHEusBAADKgXV+AAAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAARHSjgcTnYNAABASbz77rsjR44spMPOnTt3794dfZuSklK/fv1C+g8bNmzSpEmlVh8AAJAMackuAAAAKKFTTjklJSVl8+bNRewfDoe3bNlSSIdBgwaVRl0AAEAyWecHAAAqq/T09GHDhpXW3urXr3/66aeX1t4AAIBkkfsDAEAlNmrUqNLa1fDhw2vUqFFaewMAAJJF7g8AAJVYnz59GjduXCq7KsU/IQAAAEkk9wcAgEosNTV1xIgR+7+fww8/vE+fPvu/HwAAIOnk/gAAULmVynX6I0eOrFat2v7vBwAASDq5PwAAVG5du3Zt3br1fu7EIj8AABAYcn8AAKj09jO1b9myZdeuXUurGAAAILnk/gAAUOntZ+4/evTolJSU0ioGAABILrk/AABUem3atDnuuONKPLxUngwMAABUEHJ/AAAIghJf8t+lS5f27duXbjEAAEASyf0BACAIRo8enZpakv/ee6IvAAAEjNwfAACC4IgjjujVq1dxR6WkpJx77rllUQ8AAJAscn8AAAiIEly5f/LJJzdv3rwMagEAAJJG7g8AAAFx7rnnpqenF2uIRX4AACB45P4AABAQDRo0GDBgQNH7p6WlDRs2rOzqAQAAkkLuDwAAwVGs6/cHDBhwyCGHlF0xAABAUsj9AQAgOIYMGVKnTp0idrbIDwAABJLcHwAAgqN27dpnnnlmUXrWqlXr7LPPLut6AACA8if3BwCAQCniVfxnnXVW0e8MAAAAKhG5PwAABMrpp59+8MEH77ObRX4AACCo5P4AABAo1atXHzp0aOF96tevP3DgwPKpBwAAKGdyfwAACJp9Xss/fPjwGjVqlE8xAABAOZP7AwBA0PTp06dx48aFdLDIDwAABJjcHwAAgiY1NXXEiBEFbT388MP79OlTnvUAAADlSe4PAAABVMgV/SNHjqxWrVp5FgMAAJQnuT8AAARQ165dW7dune8mi/wAAECwyf0BACCY8s33W7Zs2bVr1/IvBgAAKDdyfwAACKZ8c/9Ro0alpKSUfzEAAEC5kfsDAEAwtWnT5rjjjotrtMgPAAAEntwfAAACKy7l79KlS7t27ZJVDAAAUD7k/gAAEFijR49OTf3//+d3sT8AAFQFcn8AAAisI444olevXpHXKSkp5557bnLrAQAAyoHcHwAAgix6jf/JJ5/cvHnzpNYCAACUB7k/AAAE2bnnnpuenh6yyA8AAFQZcn8AAAiyBg0aDBgwIC0tbdiwYcmuBQAAKA9pyS4AAAAoW6NGjdq7d+8hhxyS7EIAAIDykBIOh5NdA0A5eeSRR1atWpXsKgCgvO3Zs2f16tWtWrVKdiEAkAS33nprw4YNk10FQLmS+wNVSI8ePebPn5/sKgAAACg/y5cv98dvoKqxvj8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCIy3ZBQAAQAVy0EEH9enTp1mzZo0aNTrwwAM3b968fv36DRs2fPPNN4sXL052dQAAAPsm9wcAgFC1atUuvPDCMWPGdO/evVq1avn2WbFixWuvvfbiiy8uWLCgnMurRJo3b967d+8jjjji8MMPz87OXrp06ZIlS5YuXbpp06Z9jp00adLFF19clKPk5ORs3rx506ZNixcv/vTTT6dPn56VlbXftQMAQECkhMPhZNcAUE569Ogxf/78ZFcBQIVzxhlnPPjgg23atClK53A4PGnSpJtvvnnLli1lXVjlMnTo0Ouuu+7kk09OSUlJ3JqZmTl+/Pg33nijkD08/fTTv/zlL0tw6JycnEmTJv3+97///vvvSzAcgGBbvnx5q1atkl0FQLmyvj8AAFXarbfeOmPGjCKG/qFQKCUl5bLLLlu6dOnJJ59cpoVVIjVr1nziiSemTZvWq1evfEP/UCjUqlWr119/fcaMGS1atCj1AtLT06+66qoVK1ZceOGFpb5zAACodOT+AABUXU8++eTvfve7gqLqQjRq1GjGjBmdOnUqi6oqneeff/7yyy8vSs9BgwZlZGR07ty5LMo44IADnnnmmVGjRpXFzgEAoBKR+wMAUEWNHTv2sssuK/HwAw888J133jnyyCNLsaTKaMyYMcOHDy96/5o1a06ePLlGjRplUUxqaurkyZOHDBlSFjsHAIDKwnN9AQCoirp37/7II4/ku2nFihWzZs365JNPPvvss4MPPrhdu3YdO3a84IILateuHdfz0EMPvffee0eOHFn29VZQ6enp9913X2J7Tk7Ol19+uXr16vbt27dt2zY19b+uN+rYseNdd931q1/9ap/73759+7PPPhvX2LBhww4dOrRt2zY9PT1xSFpa2qRJkz788MOtW7cW50sBAIAACQNUGd27d0/2L10AKopPPvkk38ni5ZdfzvdS9FatWuU7ZO/evccdd1z5119BDBkyJPGcTJw4sWbNmtE+vXv3/u677+L65OXlJS70//TTT8d1+/bbbws6dFpaWvv27WfPnp3vv2O+f40AoGpavnz5vj8uAgSLdX4AAKhy+vTpc+KJJya2P/jggyNHjty9e3fipszMzF69er399ttx7SkpKXfeeWdRDtqsWbM+ffoMHz78kksuOffcc0855ZSjjjqqBMXnKz09vXXr1kcffXRaWrne0fvzn/88rmXq1KnXXnttdnZ2tOWjjz4aMWJEXLfU1NSuXbvuz6Fzc3MzMjL69+8/efLkxK3XXnvtQQcdtD/7BwCAyss6PwAAVDk33XRTYuMHH3xwww03FDIqLy9v7NixS5cujbshoG/fvtWrV9+zZ0++o5o1a3bdddedccYZbdq0SdyamZn55ptvPvzww4Vc2F6rVq0//elPsS0//vjjjTfeGNl05ZVXXnHFFc2bN4+spZObm7tq1aqPP/74zjvvTNxnt27dxo8fH9c4c+bMv/zlLwUdfezYsX369IltycnJGTNmTG5ubigU6tmzZ1z/Bx54IBwOxzV+/PHHs2bN+tnPfhbbeOyxx06dOrWg4xZRTk7OhRdeeNRRR/Xq1Su2vUaNGoMHD37uuef2c/8AAFApJfuGA4DyY50fAEKhUN26dXNzcxOnjavsUQAAIABJREFUiUGDBhVl+NSpUxPHHn/88Yk909LS7rrrrp07d+5zhsrOzr733nvzXa0+FAoddNBBcf2/++67UCjUrVu3devWFbTP3bt3P/zww3F/oqhXr96uXbviemZkZBTy9a5YsSKu/2uvvRbZVL169by8vNhNO3bsSElJyXc/Dz74YNx+Xn/99bg+xVrnJ9Yll1ySeAYS9w9A1WSdH6AKcr0/AABVS8+ePatVqxbXuGTJkjfffLMowydOnJgYbdetWzeuJT09/eWXXz777LOLss8aNWr86le/6tix49ChQ2NXyClE27Zt33///Xr16hXUIT09fdy4cTk5ObGPz922bdvrr79+3nnnxfZs165ds2bNsrKyEnfSpk2bxFX4n3/++ciLpk2bxj2wd+3ateGEi/0jtm/fHteSuOcSe+WVVx599NG4P3J069attPYPAACVi9wfAICqJW7VmojHH3+8oMA6zpw5c+bMmbPPbpMmTSpi6B91+umnv/DCC8OHD99nz8gfFQoJ/aNuuOGG119//eOPP462vPDCC3G5fygUGjhw4FNPPZU4/Iwzzohr2bp164wZMyKvw+Hwn//859ithVye36VLl7iW1atX76v8ovrxxx/nzJnTr1+/2MZDDz00PT09JyentI4CAACVhdwfAICqJd/HyX799deleIgTTjjhggsuyHdTbm5uVlZWs2bN8n0A77Bhw/r06TN79uzC99+wYcOGDRtG3+7duzccDifexBAKhVJTU++5557Yte/ffvvtTZs2HXzwwbHdip77v/LKK9E7Er799turr7668FIj0tPTE1fbW7JkSVHGFlFk7aNYKSkpTZo0WblyZSkeBQAAKoXUfXcBAIAAiU3Mo/73f/+3FA9x//33JzbOmTPnxBNPrFu3bsuWLevWrXviiSfGXoYfO7agJfITPfvss0OGDDn44IPr1avXu3fvfJcqat++fezbPXv2JD5NN/Jo4rjGOnXq9O7dO67xhRdeKGJtsW6//fZDDjkkrrHw5woU1/r16xMbmzZtWoqHAACAykLuDwBA1dKgQYPExlLM/QcPHpwYlz/77LN9+/adN29e5GL57OzsefPm9e3bd/LkyXE9u3XrNmLEiKIc6Omnn/7lL3/5+uuv//jjjzt37pwzZ87QoUM/+OCDuG4HHXRQXOaemN3Xq1evZ8+ecY2nnnpq3KOGs7Ky9nkvQqIePXrcdNNNcY0bNmxI/PPD/tiwYUNio9wfAICqSe4PAEDVkpj7b968eefOnaW1/9tuuy2uZePGjVdfffWePXvi2nNycq666qotW7bscw+JvvzyyyuuuCKucffu3ffee29i5zZt2sS+/eSTTxJXvxk4cGBcS+IiP3/729+K+BSEqH79+r3zzjuJaxDdddddO3bsKNauCvfDDz8kNiY+bxkAAKoCuT8AAFXLAQccENeSmLyXWLVq1Tp16hTX+Kc//amgvyvs2LHj0UcfjWs85phjatasWfiBZs6cmfiHhFAotHDhwsTGxDV2XnzxxbiWxNz/9NNPj2sp7iI/l1566Ztvvpn4/OElS5Y8+eSTxdrVPtWqVSuxMXHRfwAAqArk/gAAVC0//vhjXMsRRxxRWjs/6qij4tbGCYVC//jHPwoZMn369LiW1NTU1q1bF36ggh5EvHnz5n3VGArll/t36tTpsMMOi77t0KFDs2bNYjt8+eWXRV+Rv06dOi+88MJTTz2V+NiANWvWDBw4MN8/WuyPfB/bIPcHAKBqkvsDAFC1JF7df8ABBzRq1KhUdt62bdvExqysrEKG5Ls13/3EKiiCz83NLXxgxNKlSz///PPYlpSUlNhL/hMv9n/++eeLsudQKNSpU6cvvvji5z//eeKmrKysfv36rV69uoi7KrpyeFwzAABUFnJ/AACqlnxX9Ym7tr3EEvP6rVu3btu2rZAhGzdu3LVr1z73E2fNmjUlKC9W4qI9sbl/3OL+eXl5L730UlF2O2bMmHnz5uV7v8LMmTOPP/74ZcuWFb/YfTv22GPjWnJycvJ92C8AAASe3B8AgKrlm2++SWwsrdy/fv36cS1FeXrtTz/9tM/9xCnu83UTTZkyJS8vL7alf//+kQfw1qtX76STTord9MEHH3z//feF77BGjRp/+ctf/vKXvyQ+nCAcDt97772nnXbaxo0b97PsfNWuXTuu4FAotHbt2v0/SwAAUBnJ/QEAqFo++eSTxMbEp9oWZPTo0f+boFu3bpGtiRezH3bYYWlpaYXssGbNmolr1JTRRfGx1q9f/95778W2NGjQIPKF9O/fP25d/n0+0bdOnTpvvfXWmDFjEjetXbt2wIABN998c9yfGUrRKaeckvhYhXnz5pXR4QAAoIKT+wMAULXkm/tfdNFFRbzk/8ILL2z839LT0xcsWBDZumTJkrj+1apVK/y5wU2bNk1sTNxPWUhM8yPL+sct8rNz585XX321kP3UqVPn/fff/9nPfpa4afr06ccee+z777+/38UW5qabbkpsfPrpp8v0oAAAUGHJ/QEAqFoyMjK+/fbbuMb09PRf//rX+xzbtm3bvn37xjVOnz49eiX70qVLE0d17ty5kH126tQpsTHf/ZS66dOnxy0xNHDgwJSUlLiH+k6fPr2Q1YpSUlImT57cvXv3uPbs7Owrr7zynHPO2bRpUynWnGjIkCG9evWKa/z2229nzpxZpscFAIAKS+4PAEDVEg6HH3300cT2X/7yl4lrxMdKTU3985//HFkBP9a0adOir7du3bpu3bq4DuPHjy9kt9dff31cy7Zt2/a5mH6p+Omnn6ZPnx7b0rVr1759+x5++OGxjYUv8hMJ9+Mas7KyTjrppMcff7y0Si1Ijx49Jk+enNj+zDPPWNwfAIAqS+4PAECV8/TTTydewJ6enj5r1qwrrrgi3yGHHHLIu+++e+qpp8a1b968+YMPPohtmTp1alyfPn365LsGTigU6t+/f8+ePeMaE/dQduIy/dTU1D/+8Y+xLYmPAYhVr169O+64I67xxx9/HDBgQHTtozJSp06d//mf/3n33Xfr1asXtykvL+/ZZ58t06MDAEBFVtgTxgAAIJC2bt16++23xwXcoVCoevXqjz322Kmnnjp9+vT58+dnZmbWqlWrY8eOxx133G233ZbvMv1XXnnlnj17YlvuuuuuCy+88MADD4xtnDFjxkUXXfT3v/89tnHEiBGJ8fTOnTsnTJhQ8q+tmN57773169cfeuih0ZZjjz02tsOUKVNyc3MLGj5y5MjEhxJ/+OGHgwYNGjRoUOGH3r1795///OfC+zRo0ODBBx+MazzwwANbtmzZuXPnuJMc9cADD3z33XeF7xkAAAJM7g8AQFX00EMPnX766f369UvcNHz48OHDh4dCoW3bttWpUyc1tcB7ZCdOnPjyyy/HNW7cuPGee+75wx/+ENtYq1atqVOnzp079/PPP1+6dGmbNm26du2a77JCDzzwQPks8hORl5c3ZcqUcePGFdSh8EV+fv7znyc2nn322WefffY+D71169Z95v716tVLXAepcHPmzLntttuKNQQAAAJG7g8AQFUUDocvvPDCOXPmtGjRoqA+iQvIxJo/f/6NN96Y76ZHHnnkqquuatq0aVz7SSedVPgjBNavX3///fcX0qEsvPDCCwXl/kuWLPn8888LGtikSZPEB+omV1ZW1qhRowq5QQEAAKoC6/sDAFBFrV27tmfPnv/+979LMDYrK+u8887LycnJd2t2dvaoUaO2bdtWrH3+9NNPo0ePTnzwQFmL3IKQ76YXX3yxkIGdO3dOSUkpm6JK4q233jruuOOs8AMAAHJ/AACqrvXr1/fp0+eZZ57Zu3dv0Ue98cYbXbp0ycrKKqTP3Llz+/Xrt27duiLu84cffjjttNPiHhFcbvLN98PhcOGL/DRv3rysCiqmVatWjR8/ftCgQZs2bUp2LQAAkHxyfwAAqrTt27ePGTOmU6dOr7/+etwTehN9+umngwcPHjx48ObNm/e5588+++zoo4++6667Cr+Ef+fOnffee+/RRx89d+7c4pVeevLN/efOnbtq1apCRiUx99+1a9fy5ctnzZr1l7/8pV+/fi1atHjooYfC4XCy6gEAgAolxX+OgaqjR48e8+fPT3YVAFRcdevW7devX9++fZs2bXrIIYc0atRo9+7dmzZtWrt27Zw5c2bNmrV48eIS7LZGjRq9evXq379/8+bNGzZsWL9+/a1bt27cuHH16tXvvffeRx99lJ2dXepfCwAQsXz58latWiW7CoByJfcHqhC5PwAAQFUj9weqIOv8AAAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjSkl0AQPKdc845l112WbKrAKCq27Nnz+DBg/PddPvtt/fo0aOc6wGASmTFihVXX311sqsAqCjk/gChI488cuDAgcmuAoCqLjs7u6BNXbp0MVUBQCEWLFiQ7BIAKhDr/AAAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4EhLdgEAQHL89a9/3bx5c+T1ueee27Rp0+TWAxVERkbGO++8E3ndvHnzoUOHJreeJMrLy/voo4+WLFny/fffr1u3bu/evYcccsghhxzSrFmzU089tX79+skuEPaLeRDKgmkUoIKQ+wOUuW+++aZfv36R18OHD3/kkUeSW09ld9ddd91xxx2hUOjggw/esGFDssuprP7xj39cfPHFkdetW7e+9tprI6+//fbbVq1axXX+5z//OXDgwEL21rZt2+XLl0ffXnbZZY8//nip1htMDz74YPR7uE2bNtF/kcJt2LBh8uTJixcvXr16dVpaWqtWrY4++ugTTjihZ8+eZVlsvBIUn8TKd+zY8cUXXyxfvjwzM/P7779v1qzZ0Ucf3apVq27dulWvXj2uc+PGjX//+99H0sBq1arNmzeva9euZV1hRbNo0aI///nP06ZN27hxY74d0tLSevXqNXLkyDFjxlSrVq2cy6vizIOlwjxYERR9KsnOzs7MzCziblNSUtq3b18K9RWqiMVXkMqLNQ8mCofDs2fPnj9//tq1a7ds2dK8efM2bdq0bdv2mGOOqVWrVlxn0yhARREGqDK6d++e72/C6667rkyP+9VXX0WPdf7555fpscpZ7v/Jy8srt4P+9re/jZzMgw8+uNwOGjCbN28+7LDDot+Wr7zySnTTypUrE39G2rVrt2fPnkJ2ePTRR8f2v/zyy8v+i6j0tm/fXrNmzehJGzhw4D6H5ObmXnPNNTVq1Mj3V9npp5++aNGicqg8XPzik1j53r17n3vuudhv+FitWrWaOnXq3r1740Y98MAD0T4dO3bMyckpo/Li7Nq1K986Q6HQ9OnTy6eG3bt3T5gwoSgxUMSxxx770UcflWlJSZlrisg8WEmZByuCYk0l7777bhF/KYVCodTU1IpTfNIrL9k8GOuJJ54o6G6YBg0aPPHEE4m/AJM1jX7xxRcFndvly5eXTw0AFYf1/QEoua5du6alpaWlpZ1//vnJroViGD9+/Lp16yKv27Rps8/7rxcvXvzEE0+UfV1Vy4MPPpidnV30/uFweMyYMRMnTty9e3e+Hd56663OnTu/9NJLpVRgYYpVfBIrz83N7dev34UXXhj9ho+TmZl53nnn9erVa8eOHbHtY8eOPeiggyKvFy1adPfdd5d6bRXTtm3bTjrppDvvvHPPnj2x7ampqW3atDnppJMOPPDAuCELFy7s06fPpEmTyq6qijzXVOTaKIR5sCIo1lSyatWqsqyl2IpefHIrL/E8GB0+cuTIsWPHrlmzJt/hmzdvHjt2bPfu3RcuXBjbXmWnUYAKRe4PAFXLrFmz/vrXv0bfjh8/PiUlZZ+j7rjjji1btpRhWVXMvHnzYi+FK4orr7zyueeeK7xPXl7epZdempGRsR+l7Vtxi09i5b/97W8/+OCDfXabO3fuZZddFttSu3btsWPHRt/efffdS5cuLd3aKqCcnJxzzjnn888/j7Y0bNjw4Ycf/vTTT7dt27ZkyZKPP/54y5YtK1asmDZtWmxOGg6HL7/88n3+K0MFYR6sCIo7lXz77bdlV0xxFav45FZe4nkwYsKECS+//PI+h3/++ednnnnm1q1boy1VcxoFqGjk/gBQtdx6663R140aNbrggguKMmrTpk3RlSXYH8uWLRs+fPiJJ564ffv2oo+69dZbEy81bdu2bf/+/aPX00X89NNPI0aMKIVC81OC4pNY+aeffnrPPffENR555JHdunWrV69eXPtLL70Ud8X6Nddck56eHnmdk5NTFb7/r7zyyth4aMCAAQsXLhw3blyPHj1q164daUxJSWnRosXQoUOnTZv2xBNPRJe5iNzVsWzZsiTUDcVkHkyuks2DFeR6/xIUn8TK93MeXLBgwb333pu42wMOOCDxT2Vr1qy55pprYluq4DQKUNF4ri8AVCFvvfXWp59+Gn171VVXxa5OW7jHHnvsiiuuaNOmTdmUFmSfffbZbbfdtmXLljVr1hR0o30hNmzY8Mc//jG25cQTT5w0aVLk0X87d+4877zz/vnPf0a3ZmRkLF++PG6x6RLbn+KTW/l1112Xl5cXfdu6detXX301cujc3Ny77rrrzjvvjO3/wgsvXHrppdG3hx9++OjRo6MXBb/88su33nprOTwoMlmWLVv27LPPRt/ef//9N9xwQ+EXQV9++eU9e/YcPHhwJNXKy8v7/e9/76p/KjjzYFLs5zwY+u+r5jt16nTJJZcU0jk1tTQvcNzP4pNY+X7Og88888zevXtjO1x++eVXXHFFhw4ddu7cOWPGjKuuuir2Jpjnn3/+F7/4xYABAyJvq9o0ClAByf0BoAqZMGFC7NsxY8YUfeyePXtuuOGGGTNm7GcN4XB46dKl69at++GHH2rUqNGoUaPmzZsffvjhJd5hXl7emjVrUlNTmzRpUqwPzDt37vzmm29q1qx5+OGHN2jQoMQF7NO6deuK9Vi/OE888UTsyvi1a9d+/vnnW7ZsGXlbq1at55577vDDD49dkP29994rrfR8f4pPYuW5ublffvllbMvUqVOjcUNaWtpvf/vbhQsXTp8+Pdrhyy+/DIfDsUn3JZdcEg0s9u7de8cdd/z973/f/9oqpnvvvTea7wwaNOjGG28syqiOHTs++uijZ555ZuTtiy++OGHChOg/MVRA5sFYlWUeDP33VfN9+/a9+uqr97emItvP4pNV+X7Og7m5uVOnTo0dfv755z/++OORrXXr1h01alSTJk169+4d22fmzJnR3D9UxaZRgApI7g+QZIsXL/76669DoVCjRo1+9rOfhUKhcDi8ZMmSefPmzZ8/PzMzs0OHDt26dTvhhBPyzcK++uqryGKaTZo0adGiRSgU2rp169NPP/3ZZ5+tWrWqYcOG3bp169at26mnnlqjRo24sf/+97+XL18eCoVq1KgxZMiQgir87LPPIlcqNWjQoF+/fqFQ6Msvv4ws5vDjjz9G+mRlZUU+GxxwwAFnnXVWsc7Ajh07nnvuuYyMjMzMzLVr17Zo0aJDhw7t27fv2bPnUUcdVZQ97NmzZ+rUqe+///7q1av37Nlz/PHHF3LGYm3fvv1vf/vbokWLVq1a9f333zds2LBx48ZNmzYdOnRop06d8h2yPyc8znfffffFF18sWLBgwYIFu3btOvLII3v06HHuuecmPjYz1o4dO3JyciKv69atW7169cKPEuvTTz+NXbm7ffv2TZo0KfrwUCj0z3/+89133439RFcsX3/99f333//2229v2LAhblPHjh2HDh06fvz4xBvPQ6HQW2+9FbsW89FHH/273/0uFAq9/vrr99xzzxdffBEJjmvWrNmyZcuLLrro6quvLuT6zSlTpkybNm3hwoWZmZnRoLNp06bDhg0bM2ZMhw4dSvbVlZ3Yrz0UCv32t7+Ny1UPPvjgKVOmbNq0KdrStm3b8qmtcEmsfMmSJdGflFAo1KNHj8Qf6mHDhsXmHdu2bVuxYkWrVq1iRx144IHRBYunTZv23XffNW7cuFQqrFDWrFnz/PPPR15Xq1btvvvuK/rYQYMGnXrqqZEFgiKX/D/zzDOxHcp6rjEPhsyDRWYejKh08+CuXbtiL7Rv165dEospliRWvp/z4PLly3/44YfYzjfffHPcTWC9evU6+eSTP/7442hL3NN9q840ClBBhQGqjO7du+f7m/C6664r0+N+9dVX0WOdf/75cVuji1326dMnHA4vXLiwa9eu+dY5fvz4xJ336tUrsnXcuHHhcHjSpEl169ZNHNupU6elS5fGjb322msjWw8++OBC6r/44osj3Y4//vhIy7hx4wqaVho3blz0M5Obm/vYY48dcsgh+e6qZs2aTz75ZOKo6BmLlD1z5swjjjgi3z3ceeedBR36p59+uv766/P9aB1xwgknvPfee4kD9+eER2VnZ1955ZUFfdXXXXfdjh07Chobm0y9/fbbhZ/hODfccEPssfL9jlq5cmVcSSeeeGLs2w4dOuTm5saNiouWLr/88rgOubm511xzTbVq1Qo64RGHHHLItGnTEqt6+OGH4/51cnJyhg8fXtB+mjVr9vHHHyfu54cffhg2bFghBaSlpd166627d+8u1ondp9dff73wLzwUCg0cODDfsYlLCqxatap0yyuj4pNb+Ysvvhh76NGjRyf2Sbxod82aNXF9Yp9eGwqFJk6cWKZl79q1q6CTPH369LI7buxv9bFjxxZ3+IIFC6JhUFpaWtxvsLKea8yD5sGiMw9WxnkwHA4vXrw4tucnn3xSuuWVXfFJrHw/58G33nortr1evXr5HiXuB/mII46I61DO0+gXX3xR0L/R8uXLy/TQABWQ5/oCVCAzZ8484YQTYq9Ei/Xggw/edNNNhQx/6KGHLr300nyfM/bVV18df/zxU6ZMKZ1CS8mvf/3rK6+8MvGSt4js7OzLL7/8F7/4RXZ2dkF7eOutt0477bS1a9fmu3XChAmJTzMLhUJ5eXkjR4586KGHtm3bVtCe//Wvf5111lkzZ84spP6SnfDMzMwTTzzxsccey3ef2dnZDz/8cMeOHTMzMws5dMlMmzYt9m0RL1e89tprY6/R/vrrr5988sliHTc3N3fkyJETJ06MXWQ2Xxs2bDjvvPOi1x0X4vrrr3/llVcK2pqVlTV69Oi4f985c+Z06NAh7iQklvr73/8+8tl4nzUU3VlnnZWXoIhL3M6fPz/27ZFHHnnkkUeWYm37VOLik1t53759P4/xhz/8IbHPZ599Fvu2bt26iVf+xv2YFP79U3m9+eab0dc333xzcYd36dKlZ8+ekde5ubmxi1mXM/NgHPNgHPNgZZwHQwmPxo29ar6QP5eWlv0pPomV7+c8uHr16thNBf1xMe6riF7aH1VFplGAisk6PwAVxfLlywcPHpydnV2tWrVhw4adeOKJTZs2Xbly5axZs6JX3Nx33309evQ455xzEoe/8sor3333XSgUat269bXXXtuhQ4f09PTMzMxnn3121qxZoVBox44dF1xwQdeuXWNXsSiZIUOGRD4VPPTQQ5GsoUuXLqNHjw6FQvle9JevGTNmPPDAA5HXAwYMGDduXNu2bQ844IBvv/12yZIld99994oVK0Kh0IsvvtiuXbtbbrklcQ87duw477zzcnNzq1WrNmrUqJNOOqlly5bLli37+OOPo0HDLbfc0qVLl4EDB8YOvOmmm954443I6w4dOtx0003t2rVr0qTJpk2bVqxY8fzzz//9738Ph8PZ2dlDhgzZsGFDrVq1Eo9eshO+cuXK4447LhqRDBgw4IwzzujUqdP3338/b968mTNnZmRkhEKhb7/99rTTTps3b16jRo2KeD73acGCBbEfPmvWrBm3JGtBatSo8cADD8R+191+++2jR4+uX79+EQ89ceLEQrKJOHl5eZdccsnJJ59cyOoWGRkZ//rXvwrfT1ZW1o033vjUU09F3u7evfvCCy9cv359UWqYNm3ab37zm8gSCqWlxE/qi7tyLfLtlJWV9Y9//OOrr75atGhRrVq1Onfu3Llz59NOO62gj+X7qWTFJ7fyQw899NBDDy2kw/r16+MSyXyvnI0LLObMmfPDDz+U4g9mRbB3795ovlOrVq2S/XmmTZs2c+fOjbxeuXJlqayjHkinAAAgAElEQVQTUty5xjxoHiycebCSzoOh/340bmS++M1vfvPhhx8uXbr0hx9+OPTQQ4899tguXbqMGzeuQs2DoaRWvp/z4MiRI2NnwIKW7Yr7y0HiU6+rwjQKUHEl93YDgPJUwdf5iWjcuPFXX30V1+f666+Pdoi7Szd6u33EiBEjEu89/9Of/hTtcM4550TbS7y+QVTnzp3zraooTj755MjY008/PS8vL27rrl27oiHFgQce+NNPP0U3xZ2xDh06LFiwoJAv+aKLLorbGv0UNGjQoF27diXW9uCDD0aHf/jhh7Gb9ueEh8Ph6M31BxxwQOLqDbt3745dvuC2225LrK3E6xvEZUZt27bNt1vi+gavvvpqOBzu27dvbOP1118fO6qQ9Q22bNmS+KjA44477u67737rrbf+9re/jR8/PjEmGzVqVOz+49Y3iEhNTe3Tp8/tt9/+17/+9dprr01cKCP2ZvPE8KJt27YTJ058//33X3zxxVGjRsVtTUtLK+v7weMuFSxoiYBLLrkkttvFF188ffr0gw46KPGE1K9f/4UXXijTmotVfMWsfPv27ZmZmZMnT44L1OrVq7du3bp8h8Stkf3UU0+VXXlJWecn9qLODh06lGwnsReVP/TQQ7GbynquMQ+aB4vIPBi3tbLMg+Fw+H/+53+i3Ro2bNiwYcPEsxEKherVq/foo48m/jQlsfgKWHkJ5sGCzJo1K27F/3x/E5bnNGqdH4BYcn+gCqn4uX9aWtrixYsT97B3797oXbdNmjSJ3RT78btt27Z79uzJt4YxY8ZEu82ePTvSmMS8Iy8vr06dOpGxzz33XL593n///WjNn3/+ebQ97owtWrQo3+FdunSJ9DnyyCNj27OysqLD33///XzH5ubmRq9tvPfee2M37c8Jnz17drTxkUceyXdgTk5ONOhp2rRp4ifAHTt2bP4/BR09Xz169Ij9tu/du3e+3QrKOxYuXBi7KnH16tWXLVsWHVVI3hH7iTfi4osvzs7Ojj1oRkZG5OGQUSkpKZ999lm0Q755R1y2mJGRkfhxevv27eFweM2aNXEXq/br12/nzp2xw1966aW4sYlJWekqYmQwePDg2G77fATlyJEjEzO4pBRfASs//fTT8z10q1at/v3vfxc0qlmzZnF1ll2FScn9I4/kjRg8eHDJdhJ7LfM111wTu6k8c3/zYCzzYBzzYGx7JZoHw+FwIU8ySDRkyJAyLbtYxVe0yks2D+Zr+/btibek/OMf/0jsWZ7TqNwfIJb1/QEqkDFjxhxzzDGJ7SkpKdFk4Ycffiho+IQJE9LS8l/A7Y477oi+LsqisWVtzZo1O3bsiLxO/IAdceqpp955552/+c1vfvOb3+S7wkAoFBo3blxBq0n06dMn8iLulvalS5c2b968efPmnTt3PuWUU/IdW61atehKF5s3by7oqyjuCR8/fnzkRdeuXa+++up8B1avXv2uu+6KvF6zZk1s6BNRu3btg/5PQUfP15o1a2LfFn7rd6KOHTtedtll0bd79uyJezpivjZv3jxx4sTYllatWk2aNCnubvF27dpNmjQptiWccEFrnFGjRl133XVxO0n8dL106dJQKDR58uSdO3f+P/buPD6q6v4f8GQhBAJR2URDFJFVVpVNEBSBgiuKgkCrrUvFpYoFK35dQGmrRW1rrQvWur20Fm2xuGsRF8QiCiirCiggyiIiIMgSQub3x/w6r+lMErJPcnmev+aeOffOZ24yczLvnDk32piRkfHQQw/VqVMntueIESNGjBgR2zJ9+vSCgoJiaqgaP/zwQ+zmV199VXz/qVOnxs60TaJqWHmhP9DU1NQrr7yyU6dORe0V92KJeykFQOybcOwi5qXSvHnz6O3I2i9JYRyMZRyMYxyMNtascTCUsEp+8Z5//vm//vWvlVZL6VS3yss2DibatGnTwIED467mcsIJJ5x99tmJnQM/jAJUW3J/gGpkzJgxRd3VuXPnyI09e/ZEk4JYaWlpZ5xxRlG7N2vWLDc3N3K7Mi6UV1q5ubnRVXF///vfJ36qD4VCKSkpt9xyy6RJkyZNmlTov0NCoVDcgsWxoiuH7t69O/aMDRgwYNWqVatWrfroo49iJ+7F2rRpU1EpTFRpT/jmzZujU5CGDRtWzEKxXbt2jaYtzzzzTPFllNC+ffs2bNgQ25K4GsB+TZo0KXYt4xdffLHQH1ysxYsXx12O8le/+lWhp/2UU07p1q1bbEvcirFxYtd5iOrYsWNcS+RqmcuXL49t7NWrV9y0yoi4K2ds3br1448/LqaGqpGXl5fYmJaWds4559xyyy0//elPDzvssLh7J0yYUB0+VNeUygsKCsaOHTt48ODYUCxW3IsliaF2JdmyZUv0dmmT0KjNmzdHbyf+ZKuGcTCOcTCWcTC2sWaNg6H/XSU/ol+/fnfddddjjz02duzY6G9a1NixY+MuS5ssNaLy/Y6DcZYsWXLCCSe8//77sY21atWKXrAkTuCHUYBqy3V9AaqL1NTUuC+Jx4qdSrlr167o4gBRxx57bPHXEmzfvn0kUItcJzC5UlNT+/fvP23atFAotGPHjoEDB3bv3v2nP/3paaedFvtM96uYzrGnqNAzlmjTpk2rV6+eO3fuxIkT9+zZU3zn0p7w2I/cxx13XPEH79SpU+RTX2SaXvlt2LBh3759sS1lSPcaNWo0ceLE2KtNjB07tpjYKBQKffrpp3EtcZd3izVw4MDYjGPjxo1bt24t6qqJcd+vjyjqFRSX8aWlpd1///2J3davXx/Xsnjx4v3+sCpb3A8uFArVr19/1qxZ0e8Abdmy5Sc/+ckrr7wS7bBjx46JEyc++uijVVdlYaph5dnZ2bVr1y701T1jxoxf/epXhf5ixL1Y1q1bFw6H41Y0rtFiX2X7/VpGUWLntJb5SwPlZByMYxyMZRyM3axZ4+D27dtj/7MYCoVGjx59//33R0/79ddff+qpp3700UexuzzyyCOTJk2q0kITVMPKyzYOxvrrX/96zTXXxK1Kl5qa+uSTT/bq1avQXQI/jAJUW3J/gOqiTp06pfq6epz95izt27d/7bXXQqHQV199tXv37rhLbFW9KVOmrFixYtGiRZHNDz744IMPPgiFQrm5uf379z/11FMHDhxY6CVAo1JTU+MWDI21348TO3fu/M9//vPmm28uXLhw9erVq1evLuEsp4jSnvDY5GLs2LHFn/9ogpb4CbxsEqdWlW1W71VXXTVlypToc1m8ePHDDz98+eWXF9U/Lu9ITU3NyckpqnPirLdPP/00bjnmiLS0tNatWye2F/UKWrFiRezmzJkzZ86cWVQZsSLTJJOrYcOGcS0PPfRQNDoPhUKHHHLIU0891bJly9i1OCKvpuSqhpU/++yzoVBo586d8+bNe/DBB6dOnRp774MPPnjOOecMGDAgbq+4iYp5eXmbNm0qw0zhaiv2iqNlDsRj57QmK/c3DsYxDsYyDsZu1qxxsF69elu2bNnxX/n5+XHn5NBDD73//vvjQudly5ZVbZmFqIaVl20cjPjhhx8uu+yyp59+Oq49Kyvr0UcfHT58eFEPGvhhFKDakvsDVBdxK72WVlHTwaLatm0buREOhzdu3Bj9Bv1+hcPh8hRWlEaNGs2cOfOaa6559tlnY6fgrV279vHHH3/88cfT0tIGDRp03XXX9evXr9AjHHzwwRkZGWV46Pz8/HvvvXfixImFrpgUCoWaNWu2efPmYi6wGSr9CY+d57h48eISlhq3OECZxa7jERFd/6FUatWq9cc//vG0006LtkyYMGHkyJFF9Y+bYNi4ceNatWoV1TkxClm5cmWheUdmZmahP/pCf1e3b99e5tiios5/ecQtmZKdnZ14wg855JCf//znkydPjrYsX748Pz+/PP9KLL9qW3ndunX79u3bt2/fjh073nTTTdH2cDj8yCOP7Df3D4VCW7ZsCVJgERsclzn3j53v37JlyzIcofxjjXGw5IyDIeNgyVSHcTAlJeXggw8u/vfthBNOaN++/dKlS6MtsbeTpdpWXtpxMBQKff3112eeeWbsVxMiWrZs+dxzzyUuMBUr8MMoQLVlfX+A6qKcX3fNysoqvkPsNTazs7NLfuTt27eXsab9adSo0dNPP71ixYq77rqrb9++cUnfvn37XnnllchVDQvdvWxnLC8vr2/fvuPGjYsNO+rWrXvMMceceeaZN99888svv7x69epGjRoVf5zSnvBt27ZFNxs0aNCwZPb7KCXUtGnTuJYyf5I/9dRTTz311Ojmpk2bohdgTBSXqsSehERbt24tfveyqV27djErMBQvcaWaqheXnh9zzDGFdovmaxF79+6Nm91Z9ap/5TfccENcHFNoFpn4Ykl8QdVoXbp0iV7ec/Xq1YVemKF4eXl5b731VuR2SkpKoeuG71f5xxrjYAkZByOMgyVRHcbBEoobTVauXLl3795kFVMqSay8hOPgggULunfvnhj6jxo1at68ecWH/qEDYBgFqLbM9wcIiP1epTB6tczU1NSDDjqo5EdOnCJXsY466qjrrrvuuuuu++GHH2bPnv3WW2+9/vrrCxcujM5ZmzhxYqtWrYqZTFcqN99885w5c6IP/ctf/vJHP/pRq1atirnAYKFKe8JjJ8B+9NFHxazMUBkSHy5uwdlS+cMf/jBjxoz8/PzI5p///OdoaBinTZs2sZu7d+/etGlTUSlG4gVd43Yvm4yMjKOOOir253XTTTddeOGFJdk3caWaqnf44YfHbha1MEXilVSTvnJuciu/7777YtcvHjRoUIcOHeL6pKamnnjiiS+99FK0Zfny5Xv37o2bjRv3YsnOzi7VW2j1l56e3q1bt1mzZoVCoby8vEcffbSYRUsKNXXq1I0bN0ZuH3/88WVbP6f8Y41xsISMgxHGwZLsWx3GwRKKXbIsFArVqlWrzP/tqGKVVHlFjYMvv/zy+eefH/tvvFAolJ2d/cADD/z4xz8uSSWBH0YBqi25P0BA7Pcr89EPk02aNCnVZ/vET6GVJCsra9CgQYMGDfrd7363Zs2ayZMnP/jgg5G7nnrqqQrJO7Zu3Xr33XdHbrdr1+7NN98sasJR3MebRKU94bEf3VesWFHFecchhxySlZUV+6S+/fbbMh+tbdu2V1111Z/+9KfIZl5eXlEThOOmsIVCoSVLlhS1YEXcF9vr1KlTUWepTZs2sXnHunXrCl0WuXqKmzpd1DIscUtXp6enJ2uN9ajkVn7ffffFLia+efPm22+/PbFbXPRQu3btxCWG4l4siQtwB8D5558fyf1DodAdd9xx8cUXl2r1mOi7QSgUmjBhQtlqKP9YYxwsCeNgtMU4WCFHrgLPPPNMbH593HHHJebXoVAociHoqHbt2pX2X1kVLrmVV8g4uGrVqhEjRsS9G3Tv3v3vf/97yb/adSAMowDVk9wfICBWr169Y8eOevXqFXpvfn7+3LlzI7d79+4duRGdTLRjx47EKa4R69atq4w1N954441IHNCmTZu4q5lFHHnkkQ888MC2bdsiVw+bN29ehTzu4sWLo9Mnf/WrXxUVdixZsiT2QqOFKu0Jj/2AvWzZsv79+xdz8BdeeCEyN6pt27YnnHBC8ZWUUG5ubuzVBcszzzEUCk2cOPGpp57a70ES844//elPheYd69at++c//xnb0rp164r6xN6mTZuXX345uvn+++8X2i0vLy9uNY+DDjoouUvkh0Khk08+uUmTJtGlmZcvX75+/frEOfLz58+P3WzZsmUxS0hXjeRW3qJFi9i8Y8GCBYV2i0vZOnbsmPhtg7jf80AGFhdccMENN9wQ+f3/8ssvH3/88csuu6yE+86aNSt6ert163bmmWfGdaiyscY4WBLGweimcTBR9RwH77///nfffTe6OXTo0GnTpsX12b17d9wqNIUm7FUsuZWXfxwsKCj42c9+FncVkJ///Of33Xdfqf43fCAMowDVk/X9AQIiHA7Pnj27qHunTp0anUx08sknR25El+7ds2fPsmXLCt3xiSeeqMgq/+vFF1+8+OKLL7744tGjRxfT7aSTTorc2LlzZ4VcVjH2889xxx1XVLeZM2fu91ClPeHNmzePhiN//etfi3k6H3300dlnnx05P19++eV+KymhuE9Z5cw7DjnkkGKWM45q06ZNNF+LeOGFFxJPb0FBwf/93//FTZa8+OKLy1NhrLiV5T/55JM777wzsdvw4cMbxTj00EOjCzHfeuutI/5X8Ws0V6D09PRRo0ZFN/Py8m6++ea4Phs3bnzsscdiW7p06RK9nazik1t53A/9P//5T2zeF/HSSy99/PHHsS2dO3dOPFTcRMUqnqRcNerXr3/FFVdENydMmPDhhx+WZMctW7Zceuml0c1Cl6GvsrHGOFgSxsEo42Bit+o5DkZfBRGvvvrqqlWr4vo8/PDDmzZtim3p0aNH9Hayik9u5eUfBx944IHoV8Eihg8f/tBDD5X2cuIHwjAKUE2FAQ4YsX9Gx7r22msr9XEXLlwYfawLLrgg7t7bbrstclfDhg2LOcjDDz8cPcg333wTbe/Tp0+0PScnZ8OGDYn77ty5M/qnf506ddatWxdpf/TRR6P7Pvjgg4k7zpo1K3aS1/HHHx/XIZrQDRs2rCSnIurJJ5+MHvazzz4rqtsvfvGLSJ++fftGG0t4xu69997EM/bqq69GG//1r38VuuOSJUtiP5CMHz8+9t7ynPDJkydH950+fXpRlQ8cODDSp169epGgJ9b69etX/lfivcUYP3587K997969C+32xRdfxL1AnnvuuUJ75ufnFzUlbfTo0dFu0VWko2rVqnXPPfds2rQpHA7v27fvk08+ib1AYkTLli3z8vKiB7nnnnti783Kyiq0pMQk5ZVXXgmHw7t27YqbcZmamjp58uTPP/88suOOHTuuvfbauH379+8fPXLszz1i48aNJT/5hWrfvn3sAQcPHlxUz8Qr6V111VV79uyJ3LtmzZq4tDolJeWjjz6qDsUnsfLEh87NzZ0/f35BQUGkw9SpUxPXrX7zzTcTD5WTkxPbp9B3y4qya9euUBGKedOoEDt37oxdfj0jI2PKlCnF77J+/fq+fftGd+nVq1eh3Sp7rDEOFsU4GMc4GNteg8bBGTNmxD10165dV65cGe3w6KOPxiXRLVq02L17d9KLT27l5R8H27VrF3fvcccd13t/tm3bFldJVQ6jcV8ijLVixYrKe1yA6knuDxxAAp/7h0KhPn36xH5aCIfD69ev7969e7TDL3/5y+hdq1evjn6Tt169enPmzIneVVBQMH/+/Liv/yfmHaecckrkrqysrNiq9uvLL7+sXbt2ZN/BgwdHPvrGefvtt6MTA2+88cZoe3nyjvXr10cbO3bsuH379ri9Xn/99ezs7NhnPWbMmNgO5TnheXl50U/d9evXf/755+MefevWrbHLN//mN79JfF5DhgyJdnjttdeKOQNx4taIqF279q5duxK7lTzvCIfDb7zxRqgwsXlHOBw+77zzCu2Wm5tbv379Qu/6xz/+EXuEcuYd4XB47ty5hV4lr02bNj169Egso3bt2osWLYoeObm5fzgcjk5Pjqpbt27v3r07d+6c+Lx+8pOfxO6b3OKTWHnsKzHq4IMP7tWrV5MmTRLv+tnPfpZ4kLhXRFpaWvnPXjGSmPuHw+HZs2fHXZv0ggsueOeddzZv3hzX89tvv33ggQdiA6Pc3NxVq1YVetjKHmuMg0UxDsYxDtbQcTAvLy9xLayMjIwuXbqccsop0W/txJo2bVrsEZJVfNIrL884WNS6QPsVN2RU8TAq9weIJfcHDiDBzv2jYU3dunUHDx581113PfzwwxdddNGhhx4a3bF169bffvtt7GF/9KMfRe/NzMzs27fvddddN3LkyOiHgczMzIsuuihyOzHv+PnPfx7dvUWLFkOHDo37oFuM2OUgmjZtevvttz/33HNLly5duHDh9OnTR44cGZ0AdfTRR3///felPWOF5h3hcHjYsGHR9tzc3N///vf//ve/n3/++bvvvrtnz56R9saNG0e/lZ+bm/vQQw+9+OKLFXLCY2d+paSkDB069I477njxxRcfffTRMWPGxC5BMHDgwH379iU+rzLnHeFwOO5yqW+99VZin1LlHXH1RMX9Gnz++eeFfrgtymmnnRb3KOXPO8Lh8I033ljCAlJTU+MmoyU991+7dm3ipLxC1atXb/Xq1dWn+CRWvmjRoqJWHk/UuHHjuFdrROx88ND/zn6tDMnN/cPh8KxZs+Ku8RiRk5MzePDg0aNHn3feeT179oxb7/uwww5bvnx5MYet1LHGOFgU42Ai42AJC6hu4+BXX33VuHHjEhafeJwkFp/cysszDv7ud78r4Y5x4nL/Kh5G5f4AseT+wAEk2Ln/8OHDL7zwwmL+Cm/WrFlcphYOh7dt2xa37GyslJSUv//97w888EBkMzHveO+99+J2ycnJKeFp2bNnT9euXYspOKJOnTrvv/9+Gc5YUXnH5s2bDz/88GIesUWLFosWLXrmmWdiG7t27VohJzwcDk+fPn2/H/579uxZ1Oe68uQd//d//xf7KBMnTkzsU9q8Y+XKlYnLvCbGXkuXLi3+tEedddZZcVNHwxWUd+Tl5f3mN7+pW7du8QU0a9YscbGXpOf+4XD43Xff3W920KFDh08++aS6FZ/Eyl966aW4mcuF6tGjx7Jlywo9wk9/+tPYnn/5y19KVUBpJT33D4fDCxcuLGbZ90RDhgz58ssviz9mpY41xsGiGAcTGQdr7jj41ltv7ffXJiUlZdy4cbHrI1WH4pNbeZnHweIvPVKMuNy/iodRuT9ALNf1BQiIlJSUxx57bMKECYkf5zIyMq677rolS5YceeSRcXdlZ2e//vrrZ555ZtzkzVAo1KdPn/fff3/EiBH79u0r6kF79ep1zz33lPbqXtGq/vOf/9x5551ZWVmFdkhJSRk1atRnn31W1D9syqZBgwZz5849++yzE+86+OCDb7jhhsWLF3fs2PGss86KnQRaaHllOOGhUGjIkCGLFy8ePHhwUeVNmDDh3XffLfT71+V0/vnnx26+88475T/m0UcfPWbMmP12O+aYY5YtW3b99dfHrSIS66ijjnr66aenT58eXfuiYtWqVeumm2767LPP4s5DVEpKyrBhwxYtWtSvX7/9Hq2YJ1JJTjzxxAULFpxxxhmpqYX//XbRRRd98MEHcSs4F6qKi09i5aeffvrSpUvPPffcWrVqFdohMzPzzjvvfO+99xJXMY54++23o7fT09OHDh1aqgJqok6dOs2bN+/xxx9v06ZNMd1SU1N79+79/PPPT58+Pe5yqYmqZqwxDpaQcTDKOBinOo+DJ5988ueff37DDTcU9biNGzd++eWX77777qLe8GNVZfHJrbzM4+Dq1atL9UBFOQCHUYDqIyUcDie7BoAq0rNnz7lz5ya2X3vttX/84x+rvp4K0bdv33fffTcUCp1//vlTp04NhUJbtmyZOnXq8uXLN27c2Lx582OOOaZPnz6FfvCOtXv37sWLF8+fP3/jxo2tW7du165d9FqF+7Vjx47PPvts3bp12dnZ7du3L9U32UOh0Lp1695+++0vvvjiiy++WLNmTYMGDVq0aNGiRYsePXqUvIYyeO+99+bNm7d06dK9e/c2a9asS5cuZ5xxRuwn7b17986ZM2fZsmV169bt2bNn69atQxV3wkOh0MqVKxcsWLBgwYLPPvusUaNGzZo169y582mnnVa2/KiE2rRps3z58sjtzMzMjRs3lmQWWAXatWvXO++88+67727YsOHbb7+tXbt2o0aNjjrqqIEDB3bu3Dm60HZlW79+/eLFi5csWbJ06dKsrKyOHTt27NixQ4cO+/06/NixY//4xz82aNBg8+bNVVNqoi+//HLatGlffPHF119/3bhx40jlHTt23O9yOkkvPomVb9u27ZVXXvnkk0+++eab77///qijjmrXrl3btm3btm1bzA99+fLlsdn3oEGDXnvttbIVUEK7d+8uKtOZPn16ocuJVKqVK1e+/PLLS5cu3bhx4zfffJOent60adOmTZt26NBhyJAhcWvfl0RljDXGwTIzDhoHa+I4uGHDhrlz5y5fvnzFihVbtmxp165dpPhWrVoVegGDWMktPrmVl20cLKeqH0YXLFhw/PHHF3rXihUrYi9fD3BASPYXDgCqTrLW+alU0e//nn/++cmu5YBQ00943EIBf/7zn5NdUQ0zYMCAUCh03HHHJbuQsqi5xSer8nHjxsW+XqpgpZ3qsM5PjVPT35ZrnJp+wo2D5VRzh5JwTS6+hlZe9cOodX4AYlnnBwAOIKNHj46dovvggw8msZgaZ+XKlW+99VYoFBo1alSyaym1mlt8sirftWvXY489Ft3s0qXLWWedVZUFAJXBOFgeNXcoCdXk4mto5YZRgKST+wPAASQzM3P8+PHRzWXLlkU+SbJf69atGzp06L59+3Jycq666qpkl1M6Nbf4JFY+derU7777Lro5ceLEKlt/A6g8xsEyq7lDSagmF19zKzeMAiSd3B8ADixXXnll+/bto5uTJk1KYjE1xa233tqyZcvFixcffPDBf/nLXzIzM5NdUSnU3OKTWHl+fv7tt98e3Rw4cGChF0EFaiLjYBnU3KEkVJOLr7mVG0YBqgO5PwAcWDIyMh555JHU1P//N8Dbb789c+bM5JZU/b355pu7du06+eSTFy1adNpppyW7nNKpucUnsfInnnhi5cqVkdtZWVl/+ctfqvLRgUplHCyDmjuUhGpy8TW3csMoQHUg9weAA06PHj1uvPHG6ObNN9+cxGJqhAsvvPCtt9568803c3Nzk11LqdXc4pNVeV5eXuz83z/96U/NmzevygKAymYcLK2aO5SEanLxNbRywyhANZGe7AIAgCS49dZbFy1atHz58h8zbpMAACAASURBVFAotHXr1rlz5/bo0SPZRVVfl156abJLKLuaW3yyKn/ppZfq1q3btm3bUCjUt2/fSy65JCllAJXKOFgqNXcoCdXk4mto5YZRgGpC7g9Qsz333HN79uwJhUJ16tRJdi0HhMCc8LS0tOeffz7ZVUB1NHTo0KFDhya7CkoqMG/LNUVgTrhxECqJYRSgmpD7A9RsjRo1SnYJBxYnHKBa8bZcxZxwAIAawfr+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAER3qyCwBIvn/961/Lli1LdhUAHOgKCgqKuuu222574IEHqrIYAKhZtm/fnuwSAKoRuT9AaM2aNWvWrEl2FQBQpI8++ijZJQAAADWGdX4AAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMGRnuwCAKrOWWed1b59+2RXAQBVZ+HChWvWrIlupqWlnX766UmsBwCqXnZ2drJLAKhqKeFwONk1AAAAleLyyy9/6KGHoptZWVk7duxIYj0AAEAVsM4PAAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOBIT3YBAABAGc2cOXP8+PHFdPjyyy9jN3ft2tW1a9di+p988sl33313xRQHAAAkSUo4HE52DQAAQFn88MMPhx566A8//FBRB3ziiScuvPDCijoaAACQFNb5AQCAmiorK+v000+vqKNlZmaeffbZFXU0AAAgWeT+AABQg40cObKiDnXmmWdmZ2dX1NEAAIBkkfsDAEANdtpppzVo0KBCDlWB/0IAAACSSO4PAAA1WEZGxjnnnFP+4xx00EGnnnpq+Y8DAAAkndwfAABqtgqZp3/uuedmZmaW/zgAAEDSyf0BAKBm69evX05OTjkPYpEfAAAIDLk/AADUbKmpqcOGDSvPEZo0aXLyySdXUDkAAECSyf0BAKDGK+ds/REjRqSnp1dUMQAAQHLJ/QEAoMbr3r17q1atyry7RX4AACBI5P4AABAEI0aMKNuOLVq06NGjR8UWAwAAJJHcHwAAgmDUqFFl23HkyJEpKSkVWwwAAJBEcn8AAAiCtm3bdunSpQw7lvmLAgAAQPUk9wcAgIAowzL9nTp16tChQ2UUAwAAJIvcHwAAAmLkyJGpqaX7C98VfQEAIHjk/gAAEBC5ubm9e/cuef+UlBSL/AAAQPDI/QEAIDhKNX+/V69ezZs3r7RaAACA5JD7AwBAcAwbNqxWrVol7GyRHwAACCS5PwAABEejRo0GDBhQkp7p6ennnXdeZdcDAABUPbk/AAAESgln8Q8YMODQQw+t7GIAAICqJ/cHAIBAGTp0aFZW1n67WeQHAACCSu4PAACBkpWVdfrppxffJzMz8+yzz66aegAAgCom9wcAgKDZ71z+M888Mzs7u2qKAQAAqpjcHwAAgua0005r0KBBMR0s8gMAAAEm9wcAgKDJyMg455xziro3Ozt78ODBVVkPAABQleT+AAAQQMXM6D/vvPPq1KlTlcUAAABVSe4PAAAB1K9fv5ycnELvssgPAAAEm9wfAAACKDU1ddiwYYntTZo0Ofnkk6u8HAAAoOrI/QEAIJgKndd//vnnp6enV30xAABAlZH7AwBAMHXr1u3oo4+Oa7TIDwAABJ7cHwAAgiklJWXUqFGxLS1atOjZs2ey6gEAAKqG3B8AAAIrLvcfOXJkSkpKsooBAACqhtwfAAACq23btl26dIlujhgxIonFAAAAVUPuDwAAQRZd0L9Tp04dOnRIbjEAAEAVkPsDAECQjRw5MjU1NeSKvgAAcMCQ+wMAQJDl5ub27t07JSXFIj8AAHCASE92AQAAQOUaOXJkQUFB8+bNk10IAABQFVLC4XCyawAIgg8//HDhwoXJrgIACrFjx44FCxb07ds32YUAQCGysrIsRgdQseT+ABXjhhtumDx5crKrAAAAqGFycnK++uqrZFcBECjW9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA40pNdAAAAVDv33XffBRdcUM6DHHHEEdu2bYvc3r17d3r6//zt3b179wULFpTzIQAAABLJ/QEAIF6dOnWys7PLeZCUlJTo7bS0tLS0tKLurXCpqakZGRmxLeFweM+ePeXvDAAAVH/W+QEAgKA58cQTd/2vTz/9tEI6AwAA1Z/cHwAAAAAAgkPuDwAAAAAAwWF9fwAAKJHp06cXFBSUvH9eXl7lFQMAAFAUuT8AAJTI+eefL8oHAACqP7k/AABUUxkZGQ0bNmzQoEFaWtq6des2b94cDoeTXVS8jIyMZs2aNWnSJDMzc8OGDevXr9+2bVtFHbl58+bhcHjVqlX5+fkVckwAADgQyP0BAKB6admy5aWXXtqvX7/jjz8+LS0t2r5nz55169bNnDnzqaeemjVrVuL/AE488cTjjz8+coS4u7Kzs8eMGRO5vWbNmunTp5eqc2KRKSkpw4cPHzlyZP/+/evVqxd71/Lly//xj388/fTTy5YtK+o51q1b9957741t2bp163XXXRe568orr7ziiiuaN2+empoaCoXy8/NXr149e/bsSZMmrVq1qqhjAgAA/18YgIowfvz4ZL+jA1BhHnnkkcS3+oyMjDIfcO/evXFHi2TucTIzM6dMmZLYOdGXX355xhlnxO1+1113lWTMevXVV0vbOU63bt0WLFhQ/I75+fmTJ0/OzMws9IQccsghcf2//vrryJE3bNhQ1DH37Nlzzz331K5du8w/CACqoZycnJIMSQCUXGqy39sBAIBQKBSqV6/eK6+8Mnr06PT0/X8rNzc397nnnjvnnHOqoLA455577jvvvHPssccW3y0tLe3666//4IMPDj744BIeuW3btm+88cahhx5aVIeMjIwxY8b8+te/LkW5AABw4JH7AwBAtXDLLbf069ev5P1r1ar17LPPnnTSSZVXUqKOHTs+88wzderUKXn/f/zjHyX5T0ZGRsYzzzyTnZ29357jxo078cQTS1gAAAAcgOT+AACQfIcffvjVV1+d2L5z587Fixd/+OGHa9euTbw3PT397LPPjm7u3bt39+7du3fvzsvLi+sZDod3/1fk3lJ1jrr33ntjLzkQtW3bttWrV4cLu+zwgAEDJk6cWPjTjtGoUaNOnTpFNwsKCvbt21doz9TU1DvuuGO/BwQAgAOW3B8AAEpk27Ztu0qm5CvbRF100UVxk+j37Nlz9dVX169fv1OnTt27dz/iiCPatWu3YMGCuB27desWvX3jjTfWqVOnTp06AwcOjOu2Zs2aOv81ZMiQ0naOGDZs2MknnxzX+fXXX2/duvXBBx981FFH1a9ff8yYMTt27Ijr88tf/rJx48YlPBWPPfbYkCFDGjZsmJ2d3bdv31deeSWxT/v27Ut4NAAAOADJ/QEAoEQyS6wMBz/uuOPiWp566qn77ruvoKAg2vLpp59eddVViTuWZBWd8qtTp87dd98d1zh9+vRTTz11xYoVkc0ffvjh3nvv7d+/f9xU/aysrDFjxpTkUR555JGLL774hRde2Lp1686dO999992hQ4e++eabcd0OOeSQJk2alPWpAABAwMn9AQAg+bp06RLX8tBDDyV2++abb+Ja6tSp07Rp08oqK0afPn2OOOKI2Jbdu3dfc801iWv7fPDBB3/+85/jGs8444z9PsTHH398xRVXxDXu2bNn8uTJiZ3btGmz/6IBAOCAJPcHAIDka9myZer/+vDDD+P61K5de8KECYn7pqSkVEGFrVq1imuZPXt2oVcdCIVCL7zwQlxLp06dGjRoUPxDzJw5c+/evYntixYtSmw03x8AAIpSFd8IBgAAilfoFXEzMzNbt2595JFHtmzZskOHDoMGDcrJyan62iJatmwZ1/LFF18ce+yxhXaOXZ4oIiUl5dhjj505c2YxD7FkyZJC27/77rsSlwkAAMj9AQCgZP7yl7/ELVtflLy8vDI/Su3atYcOHTp48OBjjz22Xbt2VbN2f0kkzve/7LLLLrvsspIf4dBDDy2+w9KlSwttz8/PL/mjAAAA1eVTBAAAVHNXX311eQL9/UpNTR0/fvy4ceMaNmxYeY9SZom5f2kddNBBxXcoatUgAACgVOT+AACQfLVq1XrhhRcGDx5cfLd33nnnpJNOqpqS4pR/iaG0tLTiOxS62BEAAFBacn8AAEi+O+64o9DQPxwOL1u2bP78+XPnzn3jjTe+/fbbzZs3J/apggq3b9+elZUV27Jp06Y9e/aU/Ag7d+6s6KIAAIBCyP0BACDJmjZteu2118Y1rlu3bsKECdOmTdu6dWu0MYlLAH333XdNmzaNbfnVr371xBNPJKseAACgKKnJLgAAAA50w4cPj1sDZ8uWLf369XvkkUdiQ/9QKHTkkUcm7p6SklK59YVCoVBo/fr1cS3dunWrgscFAABKS+4PAABJdswxx8S1zJgxY/ny5Yk9O3XqVCUVFeK9996La5H7AwBA9ST3BwCAJDv00EPjWtasWVNoz0GDBpXtIfZ7Td39dn777bfjWrp37z5q1KhCj3DzzTdv+1/r1q2rXbt2yWsAAADKTO4PAABJ9vXXX8e1HHvssYndfvazn40YMSKxPTV1/3/VN2zYMD29pBf3KrTz7NmzV69eHdf4yCOP9OjRI65xwIABEydOzP5fc+bMKdVFgAEAgDJzXV8AAEiyxYsXx7UMGDDg1ltvfeihhyKr6h9xxBHjx4+/9NJLC909MaPPz8+Pa6lbt+7TTz/9zjvv7NixY/369f/+979L23nv3r2/+c1v/vrXv8b2zMzMnD179jPPPDNjxoyvv/66WbNmAwYMGDVqVNwlBwoKCu65557iTwIAAFBR5P4AAJBk8+fPT2ycOHHiLbfcsnjx4qZNmyYuBBQrIyMjrmXt2rWJ3YYNGzZs2LBQKPTaa6/F5v4l7/zEE0+MHDmyf//+sT3T09N//OMf//jHPy6mwjvvvPPdd98tpgMAAFCBrPMDAABJNm/evMceeyyxPTU1tXPnzrGh/4wZM1auXBnXrX379nEtX3/99YYNG0r46CXvnJ+fP3To0AULFpTwyBGvvPLKhAkTSrULAABQHnJ/AABIvmuuuSYx0I9z1113nXrqqUuXLo1rv/TSS+vWrRvbUlBQcP3114fD4ZI8dKk6f//997169brpppt++OGHkvR/7LHHhgwZsnfv3pJ0BgAAKoTcHwAAkm/Hjh1du3b94x//WGhE/vnnn59//vnXX3/9vn373nrrrbh7Bw0alLj0/5NPPnnssce+/PLLJXn0UnXes2fP7bff3qZNm7///e/FdJs3b17//v0vvvjixOsHAAAAlSqlhPN6ACjeDTfcMHny5GRXAUCN17Jly379+rVt27Zly5bff//9mjVrZs2aNWPGjDL/3V6/fv0mTZo0bty4UaNGoVBo165d69evX7ZsWfk7h0Khww8/vGPHjh06dGjfvn2LFi22bdv2zTffLFq06LXXXluxYkXZCgbgQJOTk/PVV18luwqAQJH7A1QMuT8AAEAZyP0BKpx1fgAAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAc6ckuACDgcnJyxo4dm+wqAKC8brzxxj179iS2Dx8+vEePHlVfDwA1zjvvvPPCCy8kuwqAA4LcH6ByNW7cWO4PQADceuutheb+AwcOvPTSS6u+HgBqIrk/QNWwzg8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACA65PwAAAAAABIfcHwAAAAAAgkPuDwAAAAAAwSH3BwAAAACA4JD7AwAAAABAcMj9AQAAAAAgOOT+AAAAAAAQHHJ/AAAAAAAIDrk/AAAAAAAEh9wfAAAAAACCQ+4PAAAAAADBIfcHAAAAAIDgkPsDAAAAAEBwyP0BAAAAACA45P4AAAAAABAccn8AAAAAAAgOuT8AAAAAAASH3B8AAAAAAIJD7g8AAAAAAMEh9wcAAAAAgOCQ+wMAAAAAQHDI/QEAAAAAIDjk/gAAAAAAEBxyfwAAAAAACI70ZBcAAATQ448//t1330VuDxs2LDc3N7n1QDAsXbr09ddfj9xu3rz50KFDk1tPEu3bt2/WrFmffvrp+vXrN2zYUFBQ0KRJkyZNmhxxxBGnnHLKwQcfnOwCoVwMo1QqownAgUDuD1DjffLJJwMGDIjcPu+88/70pz8lt54a7de//vWtt94aCoUaNmz4zTffJLucmupf//rXRRddFLndunXra665JnJ71apVLVu2jOv88ssvDx48uJijtW3bdsWKFdHNyy677MEHH6zQeoPpD3/4Q/R3uE2bNtGfSKLdu3evXLmyhIdNSUlp3759BdRXrJpV/I4dO+bPn79ixYqVK1euX7/+iCOOaNWqVcuWLbt161arVq397h4Oh9955525c+euW7duy5YtzZs3b9OmTdu2bdu1a1e3bt24zjk5Ob/97W8jaWBaWtr777/ftWvXCn9G1dzixYvvv//+adOmffvtt4V2SE9P79Onz4gRIy655JK0tLQqLu8AZxitEIbRKvPJJ5/s27evDDtG/tEY11iq9/NE4XB4zpw5r7/++rp16zZu3FivXr3DDjusc+fOQ4YMOeiggyp2d6MJwAEhDEBFGD9+fKFvs126dKnsh164cGH04S644ILKfriqlP9f+/btq5pHvO222yJnsmHDhlXziMHz3XffNW3aNPo7+c9//jN61xdffJH4GjnmmGP27t1bzAFbtWoV23/06NGV/yRqvO3bt2dmZkZP2uDBg4vp/O9//7vkfzqmpqYqPqqgoOCJJ56I/YWP1bJly2effbagoKCYI0yZMqWoabwNGjSYMmVK4rvf3XffHe3TsWPHvLy8in1Sxahfv36hpT788MNVU8CePXsmTJhQkv+mRHTq1GnWrFmVWlLVj1Mll5TaDKPlZxitSkW9re3XLbfcEneoMryfx3rllVeaN29e6O61a9e++uqrd+7cWbG7J2s0+f3vf19onTk5OVVTAMCBw/r+AFRfXbt2TU9PT09Pv+CCC5JdCyU1duzYDRs2RG63adNmv98cX7Zs2ZQpUyq/rgPLH/7wh927d5ew8+rVqyuzllKrKcXn5+cPGDDgpz/9afQXPs7KlSuHDx/ep0+fHTt2FLr7iBEjLr/88rVr1xa6+3fffXf55Zf36NFj0aJFse2XX375IYccErm9ePHi22+/vXzPo8b4/vvve/fuPWnSpL1798a2p6amtmnTpnfv3okTWhctWnTSSSc9/PDDlVdVdR6nqnNtFMMwWpXy8/Mr5CBlez+P+u1vf3vaaacVNaLt2bPnz3/+c9euXaNLP1XI7gfsaAJw4JD7AwAV5q233nr88cejm2PHjk1JSdnvXrfeeuuWLVsqsawDzPvvvx87iW+/Vq1aVXnFlFYNKv622257880399vtvffeu+yyyxLbJ0yY8Mwzz+x393nz5p1xxhnbtm2LtmRlZV1++eXRzdtvv/2zzz4rWck1WF5e3jnnnDNv3rxoS6NGje655545c+Z8//33n3766ezZs7ds2fL5559PmzYtNicNh8OjR49+4oknklE1lJphtIpVSO5f5vfziBdffPGWW27Z7+7Lli378Y9/XFBQUFG7H5ijCcABRe4PAFSYm266KXq7cePGF154YUn22rx5c3RpCMpj+fLl55133gknnLB9+/aS71VN5vvXrOLnzJlzxx13xDUeeeSR3bp1y87Ojmv/+9//HjflfMGCBZMnT048bJ06dRIzvrVr11599dWxLVdffXVGRkbkdl5e3oHw8rnyyitj/8vyox/9aNGiRWPGjOnZs2dWVlakMSUlpUWLFkOHDp02bdqUKVOiq0WFw+FLLrlk+fLlSagbSskwWsXKn/uX8/08FApdd9114XA4tiUlJaVDhw716tWL6/naa6/NmDGjAnc/AEcTgAOK6/oCABXj1VdfnTNnTnTzqquuil2lvXgPPPDAFVdc0aZNm8opLcg+/PDDm2++ecuWLWvXri1qwZnixU6Z79y586WXXlpM59TUipw1UnOLv/baa2MvBdm6devnnnsuctHg/Pz8X//615MmTYrt/9RTT/385z+Pbj766KNxczZHjx59xRVXdOjQYefOnS+99NJVV10VO3v3ySef/MlPfvKjH/0osnnYYYeNGjUqOin4mWeeuemmm6rgesvJsnz58sceeyy6edddd40bN674SdCjR4/u1avXWWedFfnP0L59+37729+a9U81ZxitYuFw+KyzzipJz1WrVsUu0ZOdnT1s2LDI7XK+n8+bNy/uv5KjRo266667Dj/88Ly8vBdeeGHEiBGxw83f/va3QYMGRTfLufuBNpoAHGjk/gBAxZgwYULs5iWXXFLyfffu3Ttu3LiXXnqpnDWEw+HPPvtsw4YNmzZtql27duPGjZs3b37YYYeV+YD79u1bu3Ztampqs2bNSpsa79y585NPPsnMzDzssMMaNGhQ5hqKt2HDhlJd2zZR7JT5/v37/+IXvyhvTSVWQ4vPz8//+OOPY1ueffbZaFCSnp5+2223LVq0aPr06dEOH3/8cTgcjkTV+fn5zz77bOzuF1xwwYMPPhi5t379+iNHjmzWrFnfvn1j+8ycOTOaE4VCoUsvvTSa1BQUFNx6663/+Mc/KvA5ViuTJ0+Oxmqnn376ddddV5K9OnbseN99951xxhmRzb/97W8TJkw4+uijK6tKKDfDaJzKHkZTUlJi36iLsmnTpm7dukU309LS/vnPf3bs2DFUEe/nf/vb32Lvys3NnTJlSuRqwxkZGeedd964cePuvPPOaIfp06fv2rWrTp06FbJ76AAbTQAONHJ/gCBbtmzZkiVLQqFQ48aN+/XrFwqFwuHwp59++v7778+dO3flypUdOnTo1q1b9+7dW7Vqlbj7woULI4uQNmvWrEWLFqFQaNu2bY888siHH364evXqRo0adevWrVu3bqecckrt2rUTd//oo49WrFgRCoVq1649ZMiQoor88MMPIzN2GzRoDcBs6wAAIABJREFUMGDAgFAo9PHHH0fmLm3dujXS58svv4x8rKpTp86ZZ55Z8jOwY8eOJ554YunSpStXrly3bl2LFi06dOjQvn37Xr16HXXUUSU5wt69e5999tk33nhjzZo1e/fuPf7444s5Y7G2b9/+9NNPL168ePXq1evXr2/UqFFOTk5ubu7QoUM7d+5c6C7lPOFxvv766/nz5y9YsGDBggW7du068sgje/bsOWzYsMRLX0bt2LEjLy8vcrt+/fq1atXa76NEzZkzJ3bp7fbt2zdr1qzku4dCoZdffvnf//53bLJZKkuWLLnrrrtee+21b775Ju6ujh07Dh06dOzYsYkLsIRCoVdffTV2MeVWrVr95je/CYVCL7zwwh133DF//vzIRUQzMzOPPvron/3sZ7/4xS+Kn4A5derUadOmLVq0aOXKldGwMjc399xzz73kkks6dOhQtidYSXbt2hU70f6YY45JYjGllaziP/300+grJRQK9ezZM/FFfe6558bGSd9///3nn3/esmXLUCi0YsWKTZs2xXa+4YYb4mav9+nT58QTT5w9e3a0Je5qkD179jzooIOi60RPmzbt66+/zsnJKdcTq5bWrl375JNPRm6npaXFBlj7dfrpp59yyimRBYIiU/4fffTR2A6VPU4lZRitwDE0dAAPo2UYQ0OG0VAoFLhhNHJxkTVr1kRbJk2aNHDgwMjtcr6f79u3b+rUqbGdx4wZE0ntYw8Y+763ffv2F198cfjw4eXfPeLAGU0ADkRhACrC+PHjC32b7dKlS2U/9MKFC6MPd8EFF8TeFV2m86STTgqHw4sWLeratWuhdY4dOzbxyH369IncO2bMmHA4/PDDD8d9lojo3LnzZ599lrj7NddcE+nQsGHDYuq/6KKLIt2OP/74SMuYMWOKGrZycnJKeFry8/MfeOCBJk2aFHqczMzMhx56KHGv6BmL1Dxz5szDDz+80CNMmjSpqIf+4YcffvnLXxb62Tiie/fuM2bMSNyxnCc8avfu3VdeeWVRT/zaa6/dsWNHoTvG5kqvvfZa8Wc4zrhx42IfqNDfqC+++CKunhNOOCF2s0OHDvn5+XF7xWVDo0f/P/buO0Cq6mwc/91lWao0sSCgKBaqggU7NhAwCpZIM5ao0bwxsUWjsaG+eZNoLERsEXt8jSZq0NgSwd5QRCmr0oSAUqUoSFkX5vvH/DK/+96ZHbbM7uze/Xz+mrn3nDPPvbt7z5xnzz33/EiBsrKyX/ziF40aNSrvhCdtv/32Tz/9dHpUY8eOjfx0SktLf/jDH5bXzs477/z2229nPAkrVqw45ZRTssRQVFR09dVXb9q0qVLnNrvnnnsu+4EHQTB48ODyqn/66afhku+++24OY4tr8JH5laNHj04vkz7rdtGiRcldL730Unh7q1atMn5K5K94p512ihQIP702CIJx48bl9jDTZbwiBUEwfvz4mvvQcI/w05/+tLLVp06dmsrBFRUVRa5+Nd1P5aUbzUkfmmjA3WiV+9CEbvQ/P5361Y1mF37ybRAExx577JYtW1J7q3k9f+eddyIH+Oqrr6ZX32WXXcJlRo4cmZPqKbXcm9x6660Zf7iVukABUBGe6wvQUEyaNKlfv37hqWRht912W3n/uki6/fbbf/KTn2R83ua0adP222+/yISjvPv1r3/9s5/9LH3OWtLGjRvPP//8H/3oRxs3biyvhZdeemnQoEGLFy/OuPe6665Lf6pnEASbN28eOXLk7bff/u2335bX8gcffHDCCSdMmjQpS/xVPuFz5849+OCD77777ox7N27cOHbs2N69e8+dOzfLp1fB008/HX5bwfmGF154YXjZjZkzZ/7pT3+q1OeWlZWNHDly3Lhx4eVrM1q+fPnw4cNTE4ezuOSSS5566qny9i5cuHD06NHpP9+33nqrV69ekfOQHu3//M//JNPEWw2jgk444YTNaSq+OG/kubjhKfMbNmzIVZDlqafBH3PMMVNCfv/736eX+fDDD8Nvt9lmm9TU3fC80SAIysuKRg4hNRkzJfJXlv13r/568cUXU6+vvPLKylbv27fvIYccknxdVlYWfiBELdONRtTNbjRffWigG81fN5rFpEmT7r333tTb1q1bP/roo+Hp/NW8ni9cuDBSsk+fPunVIxsXLVqUk+opDaQ3AWiArPMD0CDMmTNn6NChGzdubNSo0SmnnHLwwQd37tz5iy++eO2111IzlW6++eaDDjropJNOSq/+1FNPffXVV0EQ7LnnnhdeeGGvXr2Ki4vnzp370EMPvfbaa0EQrFu37owzzth///2Tq1hU07Bhw5IJsttvvz2ZL+jbt+/o0aODIChvtmnE888/f8sttyRfH3vssRdddFG3bt2aNWs2f/78zz///Le//e28efOCIPjf//3fHj16XHXVVektrFu3bvjw4WVlZY0aNRo1atShhx7atWvX2bNnv/3226lMwVVXXdW3b9/BgweHK15xxRX/+Mc/kq979ep1xRVX9OjRo1OnTitXrpw3b96f//znv/3tb4lEYuPGjcOGDVu+fHnz5s3TP73KJ/yLL77Yd999U2mOY4899rjjjttnn32WLFny/vvvT5o0qaSkJAiC+fPnDxo06P33399uu+0qcj63aurUqeEMbNOmTSNL2ZanSZMmt9xyS/i3bsyYMaNHj27Tpk0FP3rcuHFZkgsRmzdvPvfccw877LAsy1OUlJR88MEH2dtZuHDhZZdddt9996W2bNq06cwzz1y2bFlFwnj66aevvfba5DIIOVGdx9WG06DJhMW11177+uuvz5o1a8WKFTvssMPee+/dt2/fiy66qLx0RjXVx+B32GGHHXbYIUuBZcuWRVKK4amvI0eODCdZyltvJPKfg/THdUYyNW+99daKFSty9UddR2zZsiWVVmvevHlk1moF7bXXXqlZsV988UVOFgmpbD9Vm91o9fvQoKF2o/nqQwPdaL670YzWr18ffh57EATXXntt5OJfzet55Hi33Xbbtm3bplePPJgk9d+4alZPaQi9CUADld/bDQBio46v85PUsWPHadOmRapfcsklqQKR1SpS98snjRgxIv3m8TvuuCNV4KSTTgrvqvL6CSmpCUoZl9HI4rDDDktWHDJkyObNmyN7N2zYkMoytG7d+rvvvkvtipyxXr16TZ06Ncshn3XWWZG9qQHhD37wgw0bNqTHdtttt6Wqv/766+Fd1TzhiUQidXd8s2bN0ldg2LRpU3gJgmuuuSZSoMoLFESSPt26dctYLH2BgmeeeSaRSBxzzDHhjZdcckm4VpYFClavXp3+oL999933t7/97UsvvfT4449feuml6XmuUaNGhduPLFCQVFhYeMQRR4wZM+bhhx++8MIL01e6iCy6kp596Nat27hx4yZOnPi///u/o0aNiuwtKiqaM2dOxc9wZUWmzGdZKufyyy9PFWvfvn379u3Tz0YQBK1atbrzzjvT/5oEH7Z27dq5c+c++uijkYxYq1atli5dWqmmXnvttcgK0Rkvg5E1su+7774cHUpmtb/OT3guba9evarWSHhS+e233x7eVdP9VH670Sr3oYmG2o1Wsw9N6EZD6ns3mkgkLr744vAn7rHHHlVbXyjL9Tzyc99ll10ytnDttdeGi6VWE6pm9bDa7E2s8wNQa+T9AXKj7uf9i4qKPv300/TqW7ZsSa0+0alTp/Cu8Pi5W7du33//fcYAzjnnnFSxN954I7U9X3n/zZs3t2zZMlnxkUceyVhm4sSJqZinTJmS2h45YzNmzMhYvW/fvhmHWOEbridOnJixbllZWWpy4k033RTeVc0T/sYbb6S2//GPf8xYt7S0NJWs6dy5cySbs27dulX/Ud6nZ3TQQQeFf+379++fsVh5CYvp06eHlxVu3Ljx7NmzU7WyJCzCad+kH//4xxs3bgx/aElJSfLpjikFBQUffvhhqkDGhEUkOVhSUpKeU167dm1y76JFiyITTgcMGLB+/fpwC3/5y18i1dOzXTlU8dR5liWY0w0bNqzmYq7vwQ8ZMiTj5+6+++4ff/xxpZpau3Zt+lzav//97+kld95553CZ9FWbc6v28/7JR/ImDR06tGqNhOcy/+IXvwjvqs28f+13o1XO+zfMbrT6fWhCNxpS37vRyZMnR25He/bZZ6vQTvbrefhXMQiCnj17ZmwkfTW55M+omtXDarM3kfcHqDXW9wdoKM4555zu3bunby8oKEilBlasWFFe9euuu66oKPPqcNdff33qdUVWfa1pixYtWrduXfJ1+gg56eijj77xxhuvvfbaa6+9NuMSAUEQXHTRReUtB3HEEUckX0TusJ41a1aXLl26dOnSp0+fI488MmPdRo0apZaqWLVqVXlHUYUTfumllyZf7L///j//+c8z1m3cuPF///d/J18vWrQonLgJgqBFixZt/6O8T88oslZs9iVQ0vXu3fu8885Lvf3+++8jjzfMaNWqVePGjQtv2X333cePHx+5y75Hjx7jx48Pb0mkzUiNGDVqVGSWX48ePdJTzLNmzUq+ePTRR9evX5/aXlxc/Kc//alZs2bhwiNHjhw5cmR4y4QJE7Zs2ZIljNoRWSI/u2efffb++++vsVgqrU4Fn/GnWVhY+LOf/WzvvfeueDsrVqwYOHBgZBn6gw8++MQTT0wvHPlbS1+1ub4LX8MjS1VUXJcuXVKvk2u/5IVuNKwOdqPV70MD3eh/xKAb/fWvfx1ufMCAAUOHDq1sI1u9nkeW3GnRokXGdtK3JytWs3pY7HsTgIZJ3h+gobjooovK27XPPvskX2zatCk11A9r1KjR8ccfX171Tp06de7cOfm6Jp50V1mdO3dOLWt76623pg/LgyAoKCi49tprb7zxxhtvvDHjv0OCIIisOByWWvN048aN4TM2YMCA+fPnz58//+OPPw7PvAtbsWJFeWmUlCqc8JUrV3700UfJ16eeemqWNdP333//VMbkySefzB5JRWzevHnp0qXhLem382/VjTfeGF6M+B//+EfGH1zYjBkzIs+TvPzyyzOe9qOPPvqAAw4Ib4mstBsRXqghpXfv3pEtqWHz7Nmzw9sPOeSQyNTIpMjDM9asWfPJJ59kCaN2pD/m9KijjvrDH/7w0EMPXXrppanftJRLL7008hjDPKr7wW/ZsuXSSy8dPHhwOKWVxcyZMw8++OD3338/vLFx48apldYjIn9reUxq15DVq1enXlc2E5qycuXK1OsOHTpUN6Yq0Y1G1LVuNI99aKAbrXvd6Ouvvx6+2ahRo0bh1aUqqCLX8/AlLgiCyL86smxPVqxm9bDY9yYADZPn+gI0CIWFhZG7vMPCcyE3bNiQurs/pW/fvtkfBtizZ8/kzKDkg/7yq7Cw8Jhjjnn66aeDIFi3bt3AgQP79et35plnHnfcceEj3aoshcOnKOMZS7dixYoFCxZMnjx5zJgxmzZtyl64Cic8PGbed999s7e/9957J7Ofqal21bF06dLNmzeHt1QhPde+ffsxY8aEnzZx6aWXZsn7BEHw+eefR7ZEHkwXNnDgwHCSYtmyZWvWrCnvsYeRdWaSsvwFRfJ0jRo1uuuuu9KLLVmyJLJlxowZW/1h1ai1a9eGU6JBEJx//vl33XVX6rT/6le/GjJkyMcffxyu8sADD9x44421GmgmdS34Vq1aNWnSJONf9yuvvHL55Zdn/K0Iu//++y+88MINGzaENxYWFv75z38+5JBDMlaJ/K0tXrw4kUhEFpKu18J/pF9++WXVGgnfF1LlmwaqSTcaUde60Tz2oYFutO51o9dcc0347dlnn53+T4vsKng9jzyGN1I+y/ZkxWpWD4t9bwLQMMn7AzQIzZo1q9T95hFbTZT07Nnz5ZdfDoLgyy+/3LhxY+ThYLXv3nvvnTNnzvTp05NvP/jggw8++CAIgs6dOx9zzDFDhgwZOHBg+pgnrLCwMLLUadhWB0Lr169/9913X3311WnTpi1YsGDBggUVnO2bVIUTHs4+XHrppdl/BKksWPoQugrSJ4VVbVruBRdccO+996YOZMaMGePHj//pT39aXvlIwqKwsLBjx47lFU6f+v35559H1lNOatSo0Z577pm+Pctf0Jw5c8JvJ02aNGnSpPIKh6XfaF/LWrZsuXr16nX/UVZWFjknO+yww1133RVJOn/66ae1G2ZmdS34v/71r0EQrF+/fsqUKffcc88TTzwR3nvPPfecdNJJAwYMyFj3u+++O++88x5//PHI9hYtWjz44IPDhw8v70MjMzRLS0tXrFhRhZnCdVb4iaNVToiH7wvJV95fNxpR17rRPPahgW60jnWjEydOfOedd8JbfvGLX1S8eqWu55EfdMabbpNtRrYkr/PVrJ5lS/x6E4CGSd4foEGILNVaWeXN50rp1q1b8kUikVi2bFnqFviKSCQSVY+sHO3bt580adKFF17417/+NTyHbtGiRQ8//PDDDz/cqFGjQYMGXXbZZUcddVTGFtq0aVNcXFyFjy4rK7vjjjvGjBlT3uirU6dOK1euLG9OVurTs39K+gkPz1WcMWNGBaON3OBfNel3i6cWcKiUxo0b33777ccdd1xqy3XXXTdq1KjyykemB2633XaNGzcur3B6LmPu3LkZExZNmzbN+KMv7xd17dq1Vc475OT8V0dBQUGbNm2y/74dfPDBPXv2LCkpSW0Jv86juhl88+bN+/fv379//969e1999dWp7YlE4oEHHsiY9//qq69OOOGE8H0JSbvvvvszzzyTfZJpelJm9erVccrUhBPHVc77h+f777777lVoofr9lG604vLSjeaxDw10o3WsG7333nvDb/v161fxyf6VvZ5HLtcVTNy3bt06+cW+mtWzRBLErjcBaJis7w/QIFTzRt3yHhSWEh5RtGrVqlKNr127tioxbU379u0ff/zxOXPm/OEPf+jfv39kltnmzZtffPHF5GMJM1av2hkrLS3t37//L3/5y/DQq3nz5j169DjhhBOuueaaF154YcGCBe3bt8/eThVO+DfffJPa0q5du20rZqsfVBE77rhjZEuVx+FDhgwZMmRI6u2KFStST1BMF0mLhM9AujVr1mSvXmVNmjTJsopCdpGFHeqsVIIsae7cud9//32+gqmsfAV/5ZVXRjKPGZOJU6dO7devX3qSaPTo0VOmTNlqsin9by3977Fe69OnT2pl6gULFpSWlla2hdLS0tdeey35uqCgIOOi4VtV/X5KN1pB+epG89iHBrrRutSNfv311//4xz/CW84666wK1q3C9TySWP/2228zthz5G0/Vqmb1sNj3JgANk/n+AGzdVh8zmFwkNwiCwsLC1q1bV6rx9GluObTrrrtedtlll1122Xfffff222+/9tpr//znP6dNm5aadDZmzJg99tgjy2y4Srnmmmvee++91Edfcsklxx577B577JHlCYEZVeGEhyexfvzxx1lWV8i59M+KrLpeKbfddtsrr7xSVlaWfDtu3LjynlO31157hd9u3LhxxYoV5aUhUmesvOpVVlxcvOuuu4Z/ZFdfffUZZ5xRkbrbbrttTmKoaeG1VoIgaNy4cZVzNLWvJoK/8847w8uLDxo0qFevXpEyhYWFhx122PPPP5/aMnv27O+//z48nfaFF14YMWJEZCZmq1at7r777tNOO60ikUT+1lq1alXZK3AdV1RUdMABB7z55ptBEJSWlj744INZFi3J6Iknnli2bFny9X777Ve19XOq30/pRisoX91oHvvQQDdal7rRxx57LPL/xSwPiA6r2vU8slDPmjVrli1blr7KU+RJEqnEfTWrh8W+NwFomOT9Adi6rd7znhoNbr/99pUdnKePJGtCixYtBg0aNGjQoN///vf//ve/b7rppnvuuSe567HHHstJwmLNmjW33HJL8nX37t1fffXV8qZKpS+0GlGFEx4efs+ZM6c2cxZt27Zt0aJF+KC+/vrrKrfWrVu3Cy644I9//GPybWlpaXkzfCPzuIMgmDlzZnkrTkRWd2nWrFkOT9Fee+0VTlgsXrw449LGddCTTz4Zzl/vu+++6fnrIAiST7BM6d69e2X/zGtCHoO/8847w2mUlStX/va3v00vFkmaNGnSJDxjev78+SNHjoxcDfr16/eXv/yl4nPSI39r6Qtwx8CIESOSef8gCH73u9+dffbZlVo9JnUxCYLguuuuq1oM1e+ndKMVkcduNI99aKAbrUvd6GOPPRZ+27t374pcV6t8PU8/h5988smgQYMiG1NP2khKrQNWzephDaE3AWiA8j9mA6DuW7BgQXlrhgZBUFZWNnny5OTrQw89NLU9Nal23bp15S2ssXjx4sjD3Kpv4sSJDz300EMPPfTuu+9mLLDLLrvcfffdo0ePTr6dMmVKTj53xowZqfmPl19+eXnZipkzZ65atSp7U1U44eER8lafXPrcc88lT1FqWmU1RcaH1ZmoGATBmDFjKjKDLz1hEU7whS1evPipp54Kb9lzzz1zmLmOzHl8//33MxYrLS1d+X+l5mPmy1133XVmyJgxY9LLbNy4MbJqQcb0eu3LY/CRPM7UqVMzFoukyXr37p1a+WTLli1nnXVW5M/8Jz/5yVtvvVWphWgif2uxzNScfvrp22yzTfL1woULH3744YrXffPNN1M/nQMOOOCEE06IFKi1fko3WhF57Ebz24cGutG60Y2uXr060mWEH5ZQnupczw866KAOHTqEt6T/NS1fvjzy5OeTTjopJ9XDGkJvAtAAyfsDsHWJROLtt98ub+8TTzyRmlF75JFHpranlt/dtGlTeaPoRx55JGdR/sc//vGPs88+++yzzz7//POzFDviiCOSL9avX5+ThyKG5//uu+++5RWbNGnSVpuqwgnv0qVLy5Ytk6/vv//+LEf08ccfn3jiiclTtHDhwq0GUxG5TVi0bds2y3rEKXvttVc4QRYEwXPPPZd+erds2fLrX/86Mtvx7LPPrk6EET169Ai//eyzz26++eb0YsOHD28fssMOO6QWU77++utH/l/Z11nOldRfQdJLL700f/78SJnx48evWLEivOXAAw9Mvc5X5EFeg4/8xN99993PP/88Uub555//5JNPwlv22Wef1Ou77747NYc9afjw4X/6058q+xzUyAzNWp6kXDu22Wab//qv/0q9ve666z788MOKVFy9evW5556beptxGfpa66d0oxWRx240v31ooButXjeaq57orbfe2rJlS3hL//79t1qrOtfzwsLCkSNHhrfccccdkX9rRa5drVq1Si09VM3qYQ2hNwFoiBIA5MIVV1yR8TLbp0+fmv7oadOmpT7u9NNPD++64YYbktu33XbbLC2MHz8+1cLy5ctT2w8//PDU9o4dOy5dujS97vr161OjtWbNmi1evDi168EHH0xVv+eee9Lrvvnmm+FVL/bbb79IgT59+iR3nXrqqRU5FUl//vOfU23OmjWrvGI///nPk2X69++f2ljBM3bHHXekn7GXXnoptfHvf/97xoozZ84MD6WuuOKK8N5qnvCbbropVX3ChAnlBT9w4MBkmZYtWyaTNSlLliyZ+x+RXdlFfv8PPfTQjMW++OKLyB/IM888k7FkWVlZefOyzz///FSx9LmWjRs3Hjt27IoVKxKJxObNmz/77LPwEw6Tdt9999LS0lQjY8eODe9t0aJFxpDSUyEvvvhicteGDRsisyYLCwtvuummefPmJQusW7fu4osvjlQ/5phjUo2Hf/RJy5Ytq/j5T9ezZ89wa4MHD85Y7JVXXol87v777z937txUgQcffDCSudhtt902btxYc5HXi+DTH9vYuXPnjz76aMuWLckCTzzxRPpk21dffTXVQvfu3SN7991330O35ptvvolE0rFjx3AjGa+0OZSadx8xfvz4Gv3c9evXh5dfLy4uvvfee7NXWbJkSThhd8ghh2QsVtP9VH670ar1oYmG2o1Wvw9N6EaDIMhHN5qrnujSSy+tQjvVvJ6nz9AfPnz4l19+mUgkNm3a9MQTT0Tuq/jxj38c/vRqVk+pzd7k1ltvDTLp2LFjzX0oQMMk7w+QG7HP+wdBcPjhh4dTZolEYsmSJf369UsVuOSSS8J7FyxYkFrUomXLlu+9915q15YtWz766KPILfzp+ZSjjz46uatFixbhwLJbuHBhkyZNkhUHDx6cHLtGvP7666mZfVdddVVqe3USFkuWLElt7N2799q1ayO1/vnPf7Zq1Sp8yBdddFG4QDVPeGlpaWrYvM022zz77LORANasWRNegvk3v/lNpMCwYcNSe19++eUsZyAiMuxs0qTJhg0b0otVPGGRSCQmTpwYZBJOWCQSiR/+8IcZi3Xu3Lm8HOXf/va3cAvVT1gkEonJkydnfFrsXnvtdeCBB6ZH0qRJk+nTp6eq5yvvX1paesghh0Q+uri4uE+fPkcffXRqrnHY008/HW4hj3n//AYf/ktMadOmzSGHHJLxkYlnnXVWqm556wJt1cqVK8MxRP6gGjVqVP2Tn12+8v6JROLtt9+OPJv09NNPf+ONNyLnJJFIfP3113fffXf4/y6dO3eeP39+xmZrup/KbzdatT400VC70er3oQndaBAE+ehGc9UTHXbYYeFGdt55561Wycn1PP0JyQUFBfvss0/ktz1p4sSJkRiqWT1R672JvD9ArfFcXwC2rlmzZhs2bHjrrbfatWvXv3//Y445pk2bNu++++6LL764bNmyZJk999zz6quvDtfaZZddBg4c+K9//SsIgnXr1h111FH9+vXr16/fV199NWnSpOXLlwdB0LRp01GjRj300EMZP7dr166vvvpqEATffffdQQcd1KdPn+222+7ee+/NHm3nzp2vvvrq5PMbX3755d69e1944YXdunXba6+9ysrK5s+f/+STTz799NPJO9a7du165ZVXVvcEBUEQBDvuuOOpp576t7/9LQjUh6byAAAgAElEQVSCGTNm9OjR4+KLL+7du/eGDRvmzJnz1FNPJder3W677fbcc8933nknCIJnnnmmR48eO+20U+Se66qd8MaNG48bNy45FXHt2rUnnnjiSSeddMABB/Tq1WvFihXTpk175plnUk8yHDhw4K9//eucHHgQBPvtt1/Xrl3nzZuXfLtp06b3338/vFpFFRxzzDHDhg179tlnsxe76aabXn/99fRHIJb3oMvjjjuuvBxHdfTr1++KK65If7hreNmKlMLCwrFjx/bu3TvnYVRW48aN//rXv/bt2ze8GE5paWlkgZqUwYMHn3zyybUV3VbkN/j777//kEMOiSzovGbNmozroW+33Xapp5UGQZC8Klbf66+/Hn575JFHZvyXQzwceuih//znP0844YTU8h1//vOfk9PSO3bs2Lt371122WXlypVffvnllClTwkt+d+jQYdKkSV26dMnYbK31U3npRqvWhwYNtRvNYx8a6EbrRjf65Zdfht/uvffeW62Sk+v57bff/oMf/CARWl0q8X+n9aQMHTo09f+8XFUPGlhvAtCw5PffDgCxEe/5/sOHDz/jjDOy9CadOnVasGBBesvffPNNZOnYsIKCgr/85S9333138m36PMrkqD6sglOBNm3atP/++2cJOKlZs2bvv/9+Fc5YxomKiURi5cqVO+20U5ZP3G233aZPn/7kk0+GN+6///65OuGJRGLChAkZZzqHHXTQQRlnclV5omIikYhkQMaMGZNeplITFROJxNy5c9OXx41MVEwkEiUlJdlPe8rQoUMjcz8TOZqomEgkSktLf/Ob3zRv3jx7DJ06dQqv95KUr/n+Sa+99tpWf2cKCgp++ctfhhd2qKHI61Hwzz//fMbZlBEHHnjgp59+Gq6Yfc30LCJz288888zw3vvuu6/iwVdNHuf7J02bNi3Lsu/phg0btnDhwuxt1mg/ld9utMp9aKIBd6PV6UMTutEgCPLRjeakJ9qyZUvkXJ1zzjlbrZWr6/kf/vCH1M095enbt++aNWsyhlHN6rXcm5jvD1BrPNcXgK0rKCh46KGHrrvuuvTBWHFx8WWXXTZz5sxddtklvWKrVq2SMzTDCxAnHX744e+///7IkSM3b95c3ucecsghY8eOreyDLpNRvfvuuzfffHOLFi0yFigoKBg9evSsWbPCD/msvnbt2k2ePPnEE09M39WmTZsrr7xyxowZvXv3Hjp06LHHHpulnSqf8CAIhg0bNmPGjMGDB5cX4XXXXffWW2/lfCbXiBEjwm/feOON6rfZtWvXiy66aKvFevTo8emnn/7qV7+KLAMStuuuuz7++OMTJkxILV6Rc40bN7766qtnzZoVORUpBQUFp5566vTp04866qittpblWHLuyCOPnDdv3pVXXlneh2633XYvvPDCLbfc0rhx4622VpuRB3kN/gc/+EFJSckpp5xSXstNmza9+eab33nnncjqzwsWLKj4p2QRnqFZVFRUd27FqDl77733lClTHn744fR1LcIKCwsPPfTQZ599dsKECZHHpaarnX4qL91olfvQoAF3o/nqQwPdaE670Sr0RCtWrIg8u7giP+VcXc8vu+yySZMmRR5ykNKiRYtf/epX77//fuvWrWuiegPsTQAaiIJE6HYwAKrsyiuvDD8RLqVPnz7pT4CsL/r37//WW28FQTBixIgnnngiCILVq1c/8cQTs2fPXrZsWZcuXXr06HH44YeXl4AO27hx44wZMz766KNly5btueee3bt3Tz1vcKvWrVs3a9asxYsXt2rVqmfPnludiBe2ePHi119//Ysvvvjiiy/+/e9/t2vXbrfddtttt90OPPDAigdQBe+8886UKVNKSkq+//77Tp069enT5/jjjw8Plb///vv33nvv008/bd68+UEHHbTnnnsGOT3hQRDMnTt36tSpU6dOnTVrVvv27Tt16rTPPvscd9xxVcsBVcRee+01e/bs5OumTZsuW7asIrOhc2jDhg1vvPHGW2+9tXTp0q+//rpJkybt27ffddddBw4cuM8++2x1KlwOLVmyZMaMGTNnziwpKWnRokXv3r179+7dq1ev1HLY5bn00ktvv/32du3arVy5snZCDVu6dOnkyZNnz549Z86c1atXd+/ePRn5HnvskXHZ5bD8Rh7kNfhvvvnmxRdf/Oyzz5YvX/7tt9/uuuuu3bt379atW7du3bb6E6+y2bNnh3PfgwYNevnll2vos1JatWq1du3a9O3jx48/99xza/rTI+bOnfvCCy+UlJQsW7Zs+fLlRUVFO+6444477tirV69hw4ZFFr6viJrop+pCN1qdPjRowN1o7fehgW40pGrdaN57our75JNP/vWvf3311VfLly9v2bLljjvumPzF2+ptEFWuXvu9yW233fbLX/4yfXvHjh0jSy0BUF35vuEAICbyuM5PzUndNz1ixIh8x9Ig1PcTHrnTf9y4cfmOqP4ZMGBAEAT77rtvvgOptPobeaJ+Bh9JmkyYMKEWPjTv6/zUO/X9ql7v1PcTrhutpvp4Mc+72u9NrPMDUGus8wMA5Mb5558fnmN7zz335DGY+mju3LmvvfZaEASjR4/OdyyVU38jD+pn8Bs2bAg/x7VPnz5Dhw7NYzxATuhGq6M+XszzTm8CEG/y/gBAbjRt2jR848unn36aHIFTEYsXLz755JM3b97csWPHCy64IN/hVEL9jTyot8E/8cQTq1atSr0dM2ZMba6/AdQQ3WiV1dOLed7pTQDiTd4fAMiZn/3sZz179ky9vfHGG/MYTD1y/fXX77777jNmzGjTps19993XtGnTfEdUUfU38qDeBl9WVvbb3/429XbgwIEZH4IK1Ee60SqopxfzvNObAMSevD8AkDPFxcUPPPBAYeH/9wXj9ddfnzRpUn5DqhdeffXVDRs2HHnkkdOnTz/uuOPyHU4l1N/Ig3ob/COPPDJ37tzk6xYtWtx33335jQfIId1oFdTTi3ne6U0AYk/eHwDIpQMPPPCqq65Kvb3mmmvyGEx9ccYZZ7z22muvvvpq586d8x1L5dTfyIP6GXxpaWl4/u8f//jHLl265C8cIPd0o5VVHy/meac3AWgIivIdAAAQN9dff/306dNnz54dBMGaNWsmT5584IEH5juoOu3cc8/NdwhVVH8jD+pn8M8//3zz5s27desWBEH//v3POeecfEcE5J5utFLq48U87/QmAA2BvD8A5XrmmWc2bdoUBEGzZs3yHUuDEJsT3qhRo2effTbfUUAMnXzyySeffHK+o6CiYnNVry9ic8J1o9Q0vQlAQyDvD0C52rdvn+8QGhYnHCBOXNVrmRMOAJBifX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIgPeX8AAAAAAIiPonwHABBzX3311SWXXJLvKACgujZt2pRx+5NPPllSUlLLwQBQH02dOjXfIQA0FPL+ADVrxYoVY8eOzXcUAFBTJk6cOHHixHxHAQAA/P+s8wMAAAAAAPEh7w8AAAAAAPEh7w8AAAAAAPEh7w8AAAAAAPEh7w8AAAAAAPEh7w8AAAAAAPFRlO8AAGJi5513PvDAA/MdBdR1a9eu/frrr8NbOnbsWFxcnK94ACDnvv3225UrV4a3dOrUqXHjxvmKB+q+7bffPt8hAMRNQSKRyHcMAEBD8cADD5x77rnhLTNnzuzZs2e+4gGAnLvrrrt+/vOfh7fMnTu3a9eu+YoHAGiArPMDAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxIe8PAAAAAADxUZTvAACA+Fi+fPm1116bpcDnn38e2XLDDTe0bdu2vPItW7a89dZbcxMcAOTC4sWLb7jhhiwFSkpKIluuueaaVq1alVe+bdu2v//973MTHABAEARBUJBIJPIdAwAQH3vttdfs2bNz1drpp5/+6KOP5qo1AKi+RCKx2267LViwIFcNnnvuuePHj89VawAAgXV+AIDcGjFiRJ1tDQCqr6CgYPjw4TlscOTIkTlsDQAgMN8fAMitzz77rEePHjlpqn379osXL27cuHFOWgOAXPnkk0/69u2bk6Z22mmnhQsXNmrUKCetAQAkme8PAORS9+7dc5UKOfXUUyX9AaiD+vTp07Nnz5w0NWLECEl/ACDn5P0BgBwbNWpUTtqx7gEAdVauVqLT2QEANcE6PwBAji1atKhLly5btmypTiOdO3desGBBYaE5CgDURfPmzdtjjz2qOaDu2rXrnDlzCgoKchUVAECSsTQAkGOdO3c+9NBDq9nIqFGjJP0BqLO6du16wAEHVLOR0047TdIfAKgJhtMAQO5Vf6mfXC0WBAA1pPpdVa4WCwIAiLDODwCQe6tWrerQoUNpaWnVqnfr1u2zzz7LbUgAkFtLly7t1KnT5s2bq1a9b9++U6dOzW1IAABJ5vsDALnXrl27AQMGVLn66NGjcxgMANSEHXfc8cgjj6xydXe2AQA1R94fAKgR1UlnjBw5MoeRAEANqXJnV1BQMHz48NwGAwCQYp0fAKBGfPfddzvssMN3331X2Yr9+vWbPHlyTYQEALm1Zs2aHXfccdOmTZWt2L9//zfeeKMmQgIACMz3BwBqSIsWLY4//vgqVLTuAQD1RZs2bQYPHlyFijo7AKBGyfsDADWlCkmNwsLCU089tSaCAYCaUIXOrqio6OSTT66JYAAAkuT9AYCaMmTIkHbt2lWqylFHHdWxY8caigcAcm7YsGGtWrWqVJVBgwZtv/32NRQPAEAg7w8A1Jzi4uLKzme07gEA9UvTpk2HDh1aqSo6OwCgpsn7AwA1qFKpjeLi4pNOOqnmggGAmlCpzq558+bDhg2ruWAAAAJ5fwCgRh155JEVX7fnuOOOq+y6QACQd8cee2zF1+0ZOnRoy5YtazQeAAB5fwCgBhUWFg4fPryCha17AEB9VFRUdMopp1SwsM4OAKgFBYlEIt8xAABx9uGHH/br12+rxVq0aLFs2bIWLVrUQkgAkFtvvfVW//79t1qsbdu2S5YsadKkSS2EBAA0ZOb7AwA164ADDthzzz23Wuzkk0+W9AegnjrssMO6dOmy1WKnnHKKpD8AUAvk/QGAGjdixIiclAGAuqmgoKAi69qNHDmyFoIBALDODwBQ4z7//PPu3btnKdC+ffvFixc3bty41kICgNz65JNP+vbtm6VAhw4dFi1a1KhRo1oLCQBosMz3BwBqXLdu3fr06ZOlwKmnnirpD0C91qdPn549e2YpMHLkSEl/AKB2yPsDALVh1KhRVd4LAPVC9jXrdHYAQK2xzg8AUBsWLVrUpUuXLVu2pO/q3LnzggULCgtNRwCgfps3b94ee+yRcZTdtWvXOXPmFBQU1H5UAEADZIANANSGzp07H3rooRl3jRo1StIfgBjo2rXr/vvvn3HXaaedJukPANQaY2wAoJaUt76BdQ8AiI3yOrXsSwABAOSWdX4AgFqyatWqDh06lJaWhjd269bts88+y1dIAJBbS5Ys6dy58+bNm8Mb+/btO3Xq1HyFBAA0QOb7AwC1pF27dgMGDIhsNNkfgDjp0KHDEUccEdk4cuTIvAQDADRY8v4AQO1Jz/LL+wMQM5GuraCgwCI/AEAts84PAFB7vvvuux122OG7775Lvu3Xr9/kyZPzGxIA5NaaNWt23HHHTZs2Jd/279//jTfeyG9IAEBDY74/AFB7WrRocfzxx6femuwPQPy0adNm8ODBqbc6OwCg9sn7AwC1KpX+KCwsPPXUU/MbDADUhFRnV1RUdPLJJ+c3GACgAZL3BwBq1ZAhQ9q1axcEwVFHHdWxY8d8hwMAuXfCCSe0bNkyCIJBgwZtv/32+Q4HAGhw5P0BgFpVXFycnPlo3QMA4qp58+bDhg0LdHYAQJ7I+wMAtW3UqFHFxcUnnXRSvgMBgJoyatSoVPYfAKCWFWXZt2bNms8++6zWQgEAGogmTZqccMIJs2bNyncgUG9069atbdu2+Y4iCIJgw4YNn3zySb6jgHqgdevWP/jBD2bMmJHvQACAeNptt9122GGHcncnyvfSSy/VYpwAAEBmEyZMyPK9vTbNnDkz3ycDAAAI7rzzzizf263zAwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8SHvDwAAAAAA8VGU7wAA6rrx48f/+Mc/rkjJ0tLSVatWrVy58tNPP33vvfcmTJiwcOHCmg4PAACofYYJANRpifK99NJL+Y4OIP8eeOCBLJfKLDZt2nTnnXd26NAh30cAQL03YcKEqnVGOTdz5sx8nwyAOsEwAYD8uvPOO7N0N9b5AagpxcXFF1xwwbx5884888x8xwIAANQJhgkA1AJ5f4Ca1axZswcffHDUqFH5DgQAAKgrDBMAqFHy/gA1rrCw8NFHHx02bFi+AwEAAOoKwwQAao7n+gJU2tq1ax966KHIxvbt2/fq1atbt27FxcXpVYqKisaPH//6669/8803tRIjAABQqwwTAKhDsqz977m+AEGmB3bNnz+/vMJFRUU9e/Z84403Ml5Xb7755tqMHIDY8FxfgLrGMAGA/Mr+XF/z/QFyqaysrKSkZODAgePHjz/jjDMiey+88MLf/e53q1evzt5IcXFxp06dtt9++6ZNmy5dunTJkiW5mv5TXFzcpUuX5JikrKysCi0UFhZ26tRp9913Lyws/PLLL7/88st169ZVOZgaOkwAAKhTqj9MMEYAoHKy/E/AfH+AoJITecLefPPN9EvrmWeeWV75goKCESNGTJgwYe3atZFas2bN+s1vftOjR48sH9e8efP7/69bbrklteuyyy6bN2/e5s2bkw1+//33c+bMeeihh3bdddeKHEubNm1uvfXWkpKSjRs3RmJbs2bNU089dfTRRxcUFFSkqWoeJkDDZL4/QF1TO8MEYwRjBIDyZJ/vL+8PsBVV/kJ/7rnnpl9an3vuuYyFDzjggKlTp2a5JicSibKysptuuqlp06YZW2jbtm2k/FdffZVseenSpeW1uWnTprFjxzZp0qS8o2jUqNHPfvazr7/+OntsiUTi888/P/roo7Ofk+ofJkDDJO8PUNfUwjDBGKGChwnQMMn7A1RLlb/Qt2nTJn3my5IlS9JLnnLKKevXr8/+TTdl+vTpbdq0SW8k43f6bt26ffPNN1ttM8uKoo888kgFA0skEmvXrt1vv/3KayonhwnQMMn7A9Q1NT1MMEao+GECNEzy/gDVUuUv9EEQvPLKK5G6W7ZsKS4uDpfp3bt3WVlZBb/pJr3yyitFRdEHtKR/p1+xYsW0adMq0uDmzZsPO+yw9PjPOuusSgWWSCSWLVu22267pTeVq8MEaJjk/QHqmhodJhgjlMcYASAle96/MN/hAcRZ8i7asIKCgk6dOoW33HHHHY0aNUqv+8033yxYsCCRSKTvGjBgwJgxY7b66e3bt997771Tb7ds2bJ58+aMJQsLC3/3u99FNnbp0uWuu+6KbFy0aNHYsWMvv/zyq6666uGHH06fl7T99tv/13/9V/pH1NxhAgBA/bLVYYIxgjECQHVl+Z+A+f4AQfUm8tx0003pV9cjjjgiVeDUU09NL/Dyyy/vscceyQItWrS48MIL0x9vtW7duu222y78WelzeVIefPDBoUOHtmnTpnnz5ocffvgLL7yQXmbVqlWR4H/yk59EykycOLFx48aRD33xxRcjxaZNmxZpKoeHCdAwme8PUNfU3DDBGKGyhwnQMFnnB6BaqvOF/pe//GX61fVHP/pRcm+zZs3+/e9/R/b+/e9/LygoiLTTr1+/9Btgf/Ob34TLlPed/v7774+01qRJk0mTJqWX3H777cPFxo8fHylw1llnpR/jPvvsEym2ZcuWHXbYIVUgt4cJ0DDJ+wPUNTU0TDBGqMJhAjRM1vkByJsVK1akb9xmm22SLw4//PCdd945vGvjxo0XXnhhIu2G1g8++GDcuHGRjccff/xWA/jkk0/S76jdtGnTTTfdlF54r732Cr/t06dPpMCwYcPS78OdNm3aDTfccGvIbbfdtu2226YK1MJhAgBAPZJlmGCMEGnKGAGgajwLBaAGNW/ePH1jajXP1B2sKW+//faiRYsyNvXcc89dfPHF4S177713u3bt0u+9DZs0adL333+fvn369OnpGyNzeZYvXx4pcOKJJ86cOfPJJ598+eWXp0yZUlZWltx+/fXXZ4mhFg4TAADqkSzDBGOEdMYIAFUg7w9Qg9q3b5++MZX333333SO7vvjii759+2ZsasuWLZEtBQUFffv2nTRpUpYAyluNoSJfkUtKSo477rjIxm7duo0ZM2bMmDHr1q1777333n333bfffvuNN97IOHJIqoXDBACAeiTLMMEYIZ0xAkAVyPsD1KCMX+i//PLL5Iv0SS7nnXfeeeedV/H2w0tkZlRSUpJxe2oaThaPP/74xRdfHHlIV0rLli0HDhw4cODAIAhWr17997///a9//eu//vWv9Dtza+EwAQCgHskyTDBGqCBjBIDsrO8PUIP23nvvyJbS0tLUvbHpX3Yrq3Xr1tkLlHerbEV88sknN9xwQ0VKtm3b9uyzz3755ZcnTpzYpUuXyN5aOEwAAKhHsgwTjBEqyBgBIDt5f4Ca0qJFi0MPPTSycfHixanZLh07dqzmR6Q/QSsifWZNpfzP//zPyJEjlyxZUsHyRx999IwZM4455pjwxlo4TAAAqC+yDxOMESrIGAEgO+v8ANSUI488sri4OLLx/fffT71eu3ZtixYtwntXrFixadOmin/E+vXrqxNhRTz55JMvvfTSj3/84x/+8IeHHHJIYeFW/mHcsmXLRx55pHfv3qtXr05uqReHCQAAtSP7MKFefHk2RgCoBxLle+mll/IdHUD+PfDAA5HL4/z58ytS8c0330y/tA4YMCBVoKSkJLL3zDPPrHKcbdu2Tf+48la9LCwsTC98yimnZP+IDh06/PSnP33yySeXLl2apftIJBK33nprDR0mQMM0YcKE7BfeWlPe0yABGpoaGiYYIwBQQXfeeWeWq651fgBqxLBhww4//PDIxvnz50+aNCn1Nv3e2AMOOKDGI6uGJUuW3HvvvSNGjNhxxx179ep1ySWXvPrqqxkf/3XwwQeHa0X21vHDBACAGrLVYUK9+/JsjABQN1nnByD3DjrooEcffTR9+4MPPpgILab5zjvvRJa5rDtfdgcPHjxw4MDwlvnz5995552ptyUlJSUlJWPHju3cufOzzz7bt2/fcOHwk8rq8mECAECtqcgwoS5/eTZGAKhPstwLYJ0fgKCSN/C2bNny8ssv//bbb9MvqmVlZZGnVx111FHpxUaPHp2x5Wuuueab/2vx4sVNmjRJFcjtPbynnXZaZO+qVavKW7jzxBNPjBRetGhRDR0mQMNknR+AuqaGhgnGCFU4TICGKfs6P+b7A1Rau3btbrvttsjG1q1bd+3atU+fPq1bt85Y65Zbbvnqq6/CW95+++0FCxZ06dIlvPGBBx6YN2/e5MmTwxsHDBgwZsyYoqL/c9GeOHFipZ58VSkfffRRZEvbtm3PO++8e5JgkAMAACAASURBVO+9N71wp06dIlumTJmSel2XDxMAAHIlJ8OEuvzl2RgBoD7J8j8B8/0BgkwTeargzTffjHxVTTrnnHPSC3///fePPfbYmWeeOWDAgLPOOuuxxx7bsmVLpMzmzZsjC4Pmdi5PYWHh6tWr08v87W9/O/LII7t06VJUVNShQ4chQ4bccMMNGzZsiBS76qqraugwARom8/0B6pqaGyYYIxgjAFRE9vn+8v4AW1H9L/T//ve/Iyv8pBQVFU2cOLEKbf7ud7+LNJXb7/RBEPzoRz/KEkD69++UpUuXdujQoYYOE6BhkvcHqGtqbphgjFDZwwRomOT9Aaqlml/oX3zxxW233TZL+61atfroo48q1eYLL7zQuHHjSDs5/05ftWMvKys76qijau4wARomeX+AuqZGhwnGCJU6TICGSd4foFqq/IV+/vz5l1xySUFBwVY/okmTJlddddW6desq0uyDDz6YccmgmvhO37x58yeeeCLLtJ2IdevW/fSnP63RwwRomOT9Aeqamh4mGCNU/DABGiZ5f4BqqfgX+vXr18+ePfvVV18dP378McccU5GMf1jHjh0ff/zxLO1/+OGHRx99dHnVa+I7fVKfPn2ef/757Me+bt26m266qX379jV9mAANk7w/QF1TO8MEY4SKHCZAw5Q971+QSCTKq/nyyy8PGTKkNmMFYKeddurdu3evXr169uy52267ffPNN8uXL58+ffrLL788Z86cPAbWq1evHj167PIfbdu2Xbx48cL/ePvtt7/++uuKt1ZnDxOgbpowYcKwYcPyHUUQBEFJSUmvXr3yHQVAw1JnvzwbIwDk0Z133nnBBReUuzvL/wTM9wcAgLrAfH8AACAs+3z/wnyHBwAAAAAA5Iy8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxIe8PwAAAAAAxEdR1aqdfvrpjRs3zm0oAOTF5s2bH3nkkYy7BgwYsPPOO9dyPAANVpYLcr1w8sknt2nTJt9RAJAbjz/++MaNG9O3H3zwwd27d6/9eAAarPIuyNlVMe8/bty41q1bV60uAHXKxo0by0sz/fznPx82bFgtxwPQYGW5INcLN954Y8+ePfMdBQC58dxzz2VMM5122mkXXHBB7ccD0GCVd0HOzjo/AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAAAAAQH/L+AAAA/L/27jwgivr/H/ibGwTRFLwARTxQgTDzQM0jE69SyzzQPlZqhWVqktnhgfFJy/TzyfKiLI/s49EnDCNvFG/lo2JyKYeCkiiigooCyzG/P+bb/N7N7A67M8vOzuzz8dfu7Lxn37zZfb3m9Z6dGQAAAADQDsz7AwAAAAAAAAAAAABoB+b9AQAAAAAAAAAAAAC0A/P+AAAAAAAAAAAAAADagXl/AAAAAAAAAAAAAADtwLw/AAAAAAAAAAAAAIB2YN4fAAAAAAAAAAAAAEA7MO8PAAAAAAAAAAAAAKAdmPcHAAAAAAAAAAAAANAOzPsDAAAAAAAAAAAAAGiHo9IdAFCTTZs23bt3j308btw4Pz8/ZfsDWpKRkbF//372sb+//5gxY5Ttj4JqamqOHTt2+fLlmzdv3rp1q7a2tlmzZs2aNWvduvWgQYMaN26sdAcBZEEqsX4IyABgEgR2qD9ISRzUCKBtSCXWT40B2Urn/S9dujR48GD28dixY7/++mtl+6Nq//znPxcvXkwIadq06e3bt5Xujor9+uuvU6ZMYR937Nhx1qxZhJC8vLz27dvz1ty9e/ewYcNENtWpU6ecnBzu6VtvvbVu3Tpz91fFLl26VFNTI6Ehu+dHL2EY5ujRo8nJyYWFhSUlJf7+/oGBgZ06dercuXODBg3q3CDDMKdPn96/f39hYWFRUZGHh0fLli1DQ0NHjx7dqFEj8zb38fFZsmQJm+kdHBzOnDnTvXt3U/56LUhLS1uzZk1cXNydO3f0ruDo6NivX7+IiIhp06Y5ODhYuHs2DtnELPSmEoJsUm8qKipyc3ONXNnOzi4oKIggIFsx1AhmhKhuLqgRLMaMNQKRVyagRrAw1AjWDNnELFAjWJgN1QiMYXv37jXUqrS0VKShfBcvXuTea/LkyfX6XhZW/ZeamhrLvOOnn37KjmTTpk0t846adO/evRYtWnAfy19++YVdfvXqVeEXpEuXLlVVVSJb69ChA71+ZGSkRf4I1WjYsKG0gLZw4UJ6O7GxsYYOkjdp0iQ2Nlb8a7hnzx5/f3+9zV1cXGbOnPn48WPzNl+xYgW3TkhIiE6nkzyGJikvLzc0pPHx8ZbpQ2Vl5aJFi5ycnIz8Xz/55JPHjh2r1y5ZPlwbT5G+IZvIZyiVMMgm9ebAgQNGRhVCiL29PdfQlgNyndLT0w11Mj09vV7fGjWCGSGqmwVqBEsyV43AyCsTbKdGYBjGy8tLb1dXr15tmQ6gRjAJagSVQo1geaqrERipARnX97e07t27Ozo6Ojo6Tp48Wem+gAmioqJu3brFPg4MDBQ/nSczMzM2NtYi/dKm6upq+VuIiIiYPn16QUGB3hXu3bs3ffr0Xr16paam6l1hyZIlI0aMyM/P1/tqZWXlqlWrunfvzp2IZ5bm06dPf+KJJ9jHaWlpS5cu1dtcex48eNC3b9+YmJiqqip6ub29fWBgYN++fYU/fUpNTR0wYMD69evrr1fWHK6tuW8gwqRUQpBNzMFQHK6TzQZkUAoCu0qhRrAk+TUCkV0moEawJNQIprLmvoEI1AiWZzs1Aub9AeqWlJS0adMm7mlUVJSdnZ14k8WLF5eUlNRvt7RL/j79okWLduzYUedq586de+GFF+7fv89bnpCQsHDhwjqbZ2ZmvvLKK7W1teZq7u7uPn36dO7p0qVLs7Ky6tyO2ul0updeeuncuXPcEi8vr5UrV54+ffrBgweXL18+ceJESUnJlStX4uLi6H0ghmEiIyM3b96sRK8BTCYhlRBkE9ny8vKkNbTNgAwAJkGNYGFmmfeXUyagRrAk1AhgI1AjKMJ2agTM+wPUbf78+dxjb2/vV199tc4md+/e5c53A1PJ3KdPSUlZtmyZcLmbm5swgxYUFMycOZO3cO7cuQzD0Evs7OyCg4M9PDx4a+7bt+/gwYNmbD5z5kxnZ2f2sU6ns4VP0TvvvHP48GHu6ZAhQ1JTU2fPnh0WFubu7s4utLOzCwgIGDNmTFxcXGxsrKurK7ucYZhp06ZlZ2cr0G8AE0lIJQTZRDbJv+UhNhmQAcAkqBEsTP68v8wyATWCJaFGABuBGkERtlMjWOl9fQGsx969e0+fPs09nTFjBrc/IW7t2rVvv/12YGBgvXVNmxiGGTVqlDFr5uXl0affenp6jhs3jhCyYcMG3u9rIiMj33777eDg4MePH//+++8zZsygj41v2bLlH//4x5AhQ9in586d4+0jTpo0afny5a1atdLpdL/99ltERAR9S7H//Oc/Q4cO5Z7KbN6yZctJkyZxB/x37Ngxf/589h4ympSdnb1x40bu6fLly99//33xHzhERkb26dNn1KhRbKquqalZsmQJftEDVk5yKiHIJvLQv+UJDQ194403RFa2t//bD2JsLSADgElQI1iY/BqByCsTUCNYEmoEsBGoEZRiQzWCyLX/cV/f+tC1a1f275o0aZJl3hF3WZGJd3vugoIC+lW9d1nhPP/883q3adJdVmpray9dupSUlPTzzz/v2rXr1KlThYWFcv6i6urqvLy8a9euSbjbz6NHj86dO5eenn737l05fZDv9u3bbdq04cbQwcHhwIEDDMNUVVV5e3vTwzt58uTa2lq67bFjx3j/qXnz5nGvvvfee/RLfn5+Dx48oJvPmzePXqFhw4b03bdkNmcY5sSJE/QKY8eONeO46aXgbSSnTp1a5/dFr99//53+7+fm5pq9b5YP18ZTpG/IJnKIpxLGxrKJJVMJfZO0qKgoU5vbVEA2Hu7rWx9QI6gOagSa9dcIjOwywQZrBEa5+/qiRpAGNYLqoEbgsVg2UV2NwEgNyOr7vX9mZiZbbHh7ez/77LOEEIZhLl++fObMmeTk5Nzc3ODg4B49evTs2ZP3QWddvHiRvUifr69vQEAAIeT+/fs//PDD2bNn8/Pzvby8evTo0aNHj0GDBrm4uAibX7hwIScnhxDi4uIyevRoQ508e/Yse+yoSZMmgwcPJoT88ccf7OH90tJSdp3r16///PPPhBA3N7eRI0eaNAhlZWWbN2/OyMjIzc0tLCwMCAgIDg4OCgrq06dP27Zt62xeVVX1888/JyYmXrt2raqq6umnnxYZMdrDhw+3bt2alpaWn59/8+ZNLy8vHx8fPz+/MWPGhIaG6m0ic8B5bty4cf78+ZSUlJSUlPLy8jZt2oSFhY0bN054Px9aWVmZTqdjHzds2NDJyanON+KcPn2avqRgUFCQr6+v8c1379594MAB7ofkpkpPT1++fPm+fftu377NeykkJGTMmDFRUVGenp7Chnv37qWvENehQ4fPPvuMEPLbb799/vnn58+fZ++M5Orq2q5du9dff/3dd98VP6q8ffv2uLi41NTU3Nxc7jcyfn5+L7/88rRp04KDg6X9gZKxV3u8du0atyQmJiY8PJwQkpOTU1xcTK/80Ucf8X4b0q9fv2eeeYaO1NxvgmpqarZv306vPHv27IYNG/I2+OWXX3JPHz58mJCQMH78ePnNWWFhYY0aNeIuJxoXF3fjxg0fHx+Dw6FaBQUFW7ZsYR87ODjQw1Kn559/ftCgQezJv+zPeTZs2ECvUN/hWk5w00YqIarNJqpLJUQr2cTyqaS8vJy7SRohpEuXLqZuwXYCsgagRiCoEdQT2LUR1YmqagQir0xAjWBJNlsjSO6eVaUSotpsorpUQpBNpLKtGkHkmIB1/t6fO5Y4YMAAhmFSU1N5x8c4eo/Y9OvXj3119uzZDMOsX7+el25ZoaGhWVlZwuazZs1iVxA/kjllyhR2taeffppdMnv2bEOD6ePjY/zIVFdXr127tlmzZno35erq+u233/Ka8I6+Hjp0qFWrVnqbx8TEGHrfR48ezZkzR+8XntWzZ8+DBw8KG8occE5FRcU777xj6K9+7733ysrKDLWl8+W+ffvER5jn/fffp99L+KESHn3t3bs3/TQ4OLi6uprXqs6jr9XV1TNnznRwcDA04KxmzZrFxcUJu71y5Uref0en040dO9bQdlq3bn3ixAm9I1BcXPzyyy+L9MHR0XH+/PmVlZUmDaxM9H1UCCFDhgzhfqrDC1yenp56t8D7OLVq1YpdfvLkSd4fePjwYWFz+mdEhJCIiAizNOfQd6YihKxatUraQBlJqZ+X0oFx+vTppjZPSUnhSjVHR0deEKjvcC0nuKkxlTCayCZWm0oYrWcTpVJJZmYm/S6nTp2SsBEbCcgmsc7f+6NGQI0g/KtRI/DYco3AyCsTbLNGYBT6vb/N1giSu4caQfKAs6w2lTDIJvWTTdRYIzBSA7K65/0TExPFDxnR1+5g0UHh3//+t0hbDw+Pbdu28Zorvk//wQcfiPSZ9corr5SXlwtHrGnTpnv27HF0FDvJY+nSpcI3ra6uNuYQsaura2JionkHnJWTk/PUU0+Jv3vbtm1zcnL0NpcTiP39/el3ETYXRuFt27a1a9eOXrJmzRpeK/EoXFVVJRIxeRwcHH788Ufe9oVReMaMGeLbad269f3793nbOXbsWPPmzY3pxssvv8w7Sbb+JCYm0m/dqFGjW7duca/GxsbSr3bq1EnvRrgvKcvd3Z1dvm3bNt6fdu/ePWFz3o8v+vbta5bmhv6KgQMHShgo4yk1zUR/EfLz8yVsoW/fvtwW0tLS6JcsuU9vanBTYyph1J9NrDmVMJrOJgqmkj179tDbp3dfeRdPEGEjAdkk1j/vjxpBL9QIPKgRbKpGYOSVCbZZIzAKzfvbbI0guXuoEQhqhL9DNhGnxhqBscF5/1atWjVo0IAQ4uDgMH78+K+++uqXX3758ssvhw8fTnd1586ddHMuKHDnX3Ts2HH16tVHjhw5derUjz/+yJ4XzHJycuJ9tyUnicOHDy9fvpy9bw/70lNPPcUuiY2NNXJYEhISuAPXQ4YM2b1795UrVwoLC0+ePPnDDz/Q3/wlS5YIR8zFxcXDw4MdsX/84x/r1q07cODA6tWrIyIi6BHbu3cv733pg5DBwcFbtmw5f/58UVFRZmYme+4h1yt3d/dHjx6ZccAZhrly5Qp9wHbIkCErV65MSkraunXrrFmz6FtnBAQE3L59WzhukgPx+fPn6ZFxdXUVhgBhFN65c+evv/5KL/Hy8iopKaFbiUdh8XQl5OzsfPXqVXoLvCjs7u5uzHbefPNNeiMVFRVGnsfHmj9/vvFjK9mjR494vVqxYgW9Qmlp6VXKjRs39G6Hd6ZYt27d2OW8oTP0TY+KiqJX69Chg1mac3ifKwcHB72fbXNRZJqppqbG2dmZfZcGDRpI2wh96c9du3bRL9V3uJYT3NSYShiVZxMrTyWMdrOJsqlkzZo13JZbtWpVWlq6YMGCZ555hr2+c/PmzcPDw+fNm2coU7BsISCbysrn/VEjoEawhsCu1ajOKB3YDamzRmDklQm2WSMwSsz723KNILl7qBEkD7iVpxIG2YRixmyixhqBscF5f5aPj8/Fixd5zefMmcOtwLufCRcUWBMmTBCeEfPNN99wK7z00kv0S5KTBEfOjVaeeeYZtu3w4cOF98coLy8fNmwYu0KjRo24aMgbseDg4JSUFJE/+fXXX+e9yh1/e/7553mHdll01Dhy5Aj9kswBZxiGO+XHzc1NeFpZZWUlHWcXLFgg7J7kQPzJJ5/Qndf7kxC9UZhhmOeee45eOGfOHLqVSBQuKSlp0qQJb5vdunVbunTp3r17t27dGhUVJTxzbeLEifT2eVGYZW9vP2DAgOjo6E2bNs2aNUt4+h53rRsWe4E23gisWrUqMTHxP//5z8SJE3mvOjo6GjoGbka8O2J16NBBwglfSUlJvEt5ct9H3j+9TZs2erewcOFCejXuNGGZzWm8Hyp+9913pv6ZxlNkmom+9GpwcLC0jXz++efcRr766iv6pfoO13KCmxpTCaPybGLlqYTRbjZRNpXQP1vz8vIytK/s6em5evVqkTuPaT4gm8rK5/1ZqBE4qBEIaoS/oEaok6EywTZrBEaJeX9brhHkdw81AmoEFrKJODXWCIxtzvs7OjpmZmYKm9fW1nJ3w/D19aVfooNCp06dqqqq9HZg2rRp3GpHjx7lliu4T19TU8MeOyWEbN68We869LmN586dYxfyRox3mhuHO7OJtxdy/fp1rrnwpCpWdXU1+7sqQsiyZcvol2QO+NGjR7nlX3/9td62Op2Oy0B+fn7C72RZWdm9vxjqgF5hYWH0x75///7CdQxF4dTUVPpaaU5OTtnZ2VwrkSgsPLduypQpFRUV9JtmZGSwt6zh2NnZnT17lltBbxTm7fFkZGQIo8bDhw/ZVwsKCrj/KWvw4MG848/C81WFKdy8kpOT7e3t6Xfk/XzDGA8fPhQeVf7111/ZV+mPIiEkKChI70a++OIL3hbY/5HM5rTWrVvTKwiv72lGikwzsbfbYo0aNUraRn755RduIzNnzqRfsuQ+vanBTY2phFFzNrH+VMJoNJsonkqMP4WZEDJ69GhD29F8QDaV9c/7o0bgQY2AGoGFGkGcSJlgmzUCo8S8vy3XCPK7hxoBNQIL2UScGmsERmpAttfbRi2mTZvWuXNn4XI7Ozsu3hUXFxtqvmjRIkOXHlu8eDH3mLuVvLIKCgrKysrYx8JvPmvQoEExMTELFy5cuHAh7yvEmj17tqEbYQ8YMIB9UFRURC/Pysry9/f39/fv2rXrwIED9bZ1cHDg7kF07949Q3+ChAHnTnXs3r37u+++q7etk5PTP//5T/ZxQUEB78KOhBB3d/cn/iJ+sTmegoIC+qmR1x1jhYSEvPXWW9zTqqoq3j1b9Lp3796qVavoJe3bt1+/fj3v1vNdunRZv349vYQRHGbnmThxIu9XMF26dBEGu6ysLPbBjz/++PjxY265s7Pzt99+6+bmRq8cERHBO2UvPj6eu/d6ffj444/p7Q8ePHjUqFEmbaG4uDg8PDwvL49e2Lt37xdffJF9zLuRvaET1oTL2YYym9N4nzfep1ED6DjGu0Ch8ehLIt64cUNmlyRTUTYxSyohassm6k0lROXZRPFUkp+fb/zKu3bt+v777/W+pPmArD2oEXhQI1hPYFd1VCdWENj1kl8jkLrKBNQIFoMaQRGoEdSVSgiyiTw2VSOoe95f5O4loaGh7IPKykouftEcHBxeeOEFQ819fX39/PzYx7m5ufK6aR5+fn6NGzdmH//rX/8ShhtCiJ2d3cKFC2NiYmJiYvRWO9yBSiH2OlaEkIqKCnrEBg8enJeXl5eXd+HCBUM3+y4uLjaUGzgSBvzu3bvcJc/GjRvH+xEHrXv37lwa2LFjh3hPjFRTU3Pr1i16iaH72hsSExPD/csIIQkJCXr/a7S0tLSKigp6yQcffKB32AcNGtSjRw96ydmzZ0W2zLtJFCskJIS3hNuzzM7Oppf36dOHd7yX9dJLL9FPS0tL//jjD5FuyHHkyBH61x8ODg6mXpYuPT29d+/eZ86coRc6OTmtWLGCe1pSUkK/yks8IsvZhjKb03ifNwV3WOsJ/SebupfDuXv3Lve4ZcuWcvskibqyiVlSCVFVNlF7KiFqziaKpxLe9A0h5Nlnn12+fPnGjRujoqK4jwonKiqKvrwAR/MBWXtQI/CgRiDWFNjVG9WJFQR2Ifk1AjGiTECNYDGoERSBGkF1qYQgm8hgUzWCCQejrI29vT3v1BUafYC3vLycO2WJ89RTTwkvWUULCgpij9VcuXJFVkfNxN7e/rnnnouLiyOElJWVhYeH9+zZ87XXXhsxYgTvJuAiRNakh0jviAkVFxfn5+cnJydHR0dXVlaKryxhwOlA0K1bN/HtP/nkk+z3kDt+KNOtW7dqamroJabudnh5eUVHR9NXko2KihJJZoSQy5cv85YMGTLE0Mrh4eF05C0qKiotLaXjPo2+Iw1H5BvE2/lwcHCg73zCuXnzJm9JWlpanf8saRYsWEA/nTp1qjCLiPj+++9nzZrFu36Cvb39li1b+vTpwy154okn6BUMXW9BuJxtKLM5jfd5KywsZBiGd71RVaM/q3/++ae0jdAH6iX/IEgmdWUTs6QSoqpsovZUQtScTZRNJQ8fPqTLfkJIZGTkmjVruHGbN2/e8OHDL1y4QDf54YcfYmJieJvSfEDWGNQIqBFoVhjY1RvVidKBXS+ZNQIxrkxAjWAxqBEUgRpBfONWmEoIsolUtlYjqHje383NzaSTaHjqjP5BQUH79u0jhPz5558VFRW82zUoIjY2NicnJzU1lX36v//973//+x8hxM/P77nnnhs+fHh4eLhwz4Bjb2/Pu/gUrc6P5uPHj0+dOnX48OGLFy/m5+fn5+fTZ+XUScKA0yE1KipK/F/ApXZhXJBGeKROQiCeMWNGbGws94ekpaWtX79++vTphtbnRWF7e3vurvRCwoOQly9f5l0kjuXg4NCxY0fhcpFvUE5ODv300KFDhw4dMrQyTXguqlkkJiaePHmSXjJz5kwj2z569Oitt97aunUrb7m7u/uGDRvGjx9PL+T9l/X+EpDdJm8Je6RXZnORJTqdrri4WMKvAKwWfTchyTu79IF6pfbpVZdNZKYSorZsooFUQlSbTZRNJR4eHiUlJWV/qa6u5v1RzZs3X7NmDX3olxCSmZkp3JTmA7LGoEZAjUCzzsCu0qhOlA7sQnJqBGJKmYAawWJQIygFNYJIW+tMJQTZRBJbqxFUPO/Pu/6UqQwdpOJ06tSJfcAwTFFREXdejzEYhpHeM8O8vLwOHTo0a9asn3/+mT42WFBQsGnTpk2bNjk4OAwdOnTu3LnPPvussHnjxo2dnZ0lvG91dfU333wTHR1taAfF19f37t27IneiI5IGnD4Am5aWZmRveWctSSY8p5I7Mc14Tk5OX3311YgRI7glixYtEt6XnMM75unt7e3k5GRoZWGAzs3N1RuFXV1d9f7rDX1QHz58KDmYmmv8eWJjY+mnPXv2NPKHPDdu3Bg5ciR9qJbVvn37nTt3CjfCi9FG7pQ3atSIjUgym4v0hBBSUlJibSlEDnqnUPI+Pf1bnvbt20vYgvxwXX/ZxDpTCVFbNtFAKiHqzCaKpxI7O7vGjRuLf2B69+4dFBSUfwir8AAAGIFJREFUkZHBLaEfczQfkDUGNQK3HDUCzaoCuxqjOrGCwC4kuUYgJpYJqBEsBjWCMeojm6BGMIZVpRKCbCKJrdUIKp73l3nqhKF76XDopOvp6WnSxh8+fCilT0bw8vLaunXrkiVL4uLiEhISTp06VV1dzb1aU1OzZ8+ePXv2fPrpp4sWLeK1lTZiOp1u4MCBp0+fphc2aNDA39+/Xbt2oaGhvXv3Hjp0aNu2bcVvYSFhwO/fv88tadKkiZH9r/ONjNSiRQveEmnxZfjw4cOHD9+7dy/7tLi4mLstjBAv1tMjIFRaWireXDIXFxcHBwfeeWdGktZK3J07dxISEuglr7/+ujENU1JSRo4cWVhYyFs+adKktWvXNmrUSNiEF6MfPHigd8u87zjXSmZzmvDzJvxMqlrXrl3d3NzYvbf8/HydTmfqbqJOp0tKSmIf29nZ6b0gYJ3kh+v6yybWmUqI2rKJNlIJUWE2sbZUYkinTp3o/fjc3NyqqipeCaT5gKwxqBFQI0h7IyOhRrCewC65RiCmlwmoESwGNYIx6imboEaok7WlEoJsUm80UyOoeN5fpjrvncLFFHt7e73zgyKEx+7Mq23btnPnzp07d+6jR49OnDiRlJS0f//+ixcvcgfToqOjO3ToIHKUz3gLFizgQnDbtm3nzJkzZMiQDh06iNz2RC8JA04fmb9w4YLIKWP1Qfh2vEuAGe/f//73wYMHuZS5atUqQ7dyCgwMpJ9WVFQUFxcbiq3CtMdrLpmzs3Pbtm3pf9n8+fNfffVVY9o2bdrULH2g/fTTTzqdjl4icscezu7duydMmMD71Yynp+fatWtfeeUVQ614p9eVlpYWFRUJz7njXdeP2ymX2ZzG+7x5enqaGoisnKOjY48ePY4dO0YI0el0GzZsEDkhUa/t27cXFRWxj59++mlp58bKD9f1l020lEqIctlEM6mEqC2bWFsqMYS+ngAhxMnJSXhRVM0HZKChRjASagQOagRj2lpPjUAklQmoESwGNYIx6jWboEawAFuuEYj1ZRO9NFMj2O68f50n8nAf8WbNmpkaccSPQ5qRu7v70KFDhw4d+sUXX1y7dm3ZsmXr1q1jX/rpp5/kB+LS0tIVK1awjzt37nz48GFDB6+E1yLkkTDgdEzJycmxcCB+4okn3N3d6b/rzp070jbVqVOnGTNmfP311+xTnU7H20Ol1+QtSU9PN3QaHe88Izc3NzMOUWBgIB2FCwsL9V6vzTJ++ukn+mlISIjwSnM8eXl5ERERvI9lz549t23bJv6LD+EY/vHHH0OHDuUt5K57yOLOypTZnMb7vNX5J6vRhAkT2H16Qsjnn38+depUk37Ow32nCCF6f3JiDPnhuv6yiWZSCVE0m2gmlRAVZhNlU8mOHTvoW8B169YtODhYuBp7lzZO586dhd9TWwjIwEGNYAzUCKgRWKqrEYjUMgE1giWhRqiTZbIJaoT6Y+M1AlE0m9hajWBacNGS/Px8Q9cOI4RUV1cnJyezj/v27cst5w7vlJWVVVVV6W1bWFjIu0OFWSQmJm7cuHHjxo2nTp3Su0KbNm3Wrl07adIk9um5c+fkv2laWhp3UPeDDz4wFILT09Pv3bsnvikJA05/7fXeQ4P222+/sePDO0FMDt6XVs4B2OjoaGMOSwqjML3XQissLPzll1/oJR07djR1d0EE70DumTNn9K6m0+nu/h19JqBZlJSU8C67SV+9Tq/a2trXX3+d93l78803jx8/XudpnmFhYS1btqSXCL9Kt2/f5t2H56WXXjJLcxrv82adKUSmyZMnN2zYkH18/fr1TZs2Gd/22LFjKSkp7OMePXqMHDmSt4LFwrWE4GZrqYQomk20lEqI2rKJsqlkzZo1r1Gio6OF61RUVPBSjN79flsIyMBBjWAM1Aj0U9QIQtZZIxAZZQJqBEuy2RrBkt3jQY0gvnErTyUE2cQUtlYj2O68P8MwJ06cMPTq9u3buWM7AwcO5JZ7eXmxDyorKw2Fhs2bN5utl5SEhISpU6dOnTo1MjJSZLUBAwawDx4/fiz/Zi/0mYbdunUztJox992WMOD+/v4eHh7s4++//17kz7lw4cKLL77Ijs/169fr7IyRzBiIn3jiCZGLrHECAwPprE8I+e2334TDW1tb+/HHH/MO4U6dOlVy94S6dOlCP7106dKXX34pXG38+PFelObNm3NXiFu8eHHE34lfPM6Q48eP19bW0kv69+8v3mTt2rXcL0S4fn777bfG/E7E3t4+IiKCXvLNN9/wdjJiYmLop56entw5xTKb03iHji38AwTLaNiw4dtvv809XbRo0dmzZ41pWFJS8sYbb3BPeUPKsli4lhDcbC2VEEWziZZSCVFbNlE2lXAfY9bevXvz8vJ466xfv764uJhe0qtXL+GmbCEgAwc1gjFQI9BPUSMIV7POGoHIKBNQI1iSzdYIluweD2oEVacSYnvZBDWCCRjDuPtCCJWWloo0lO/ixYvce02ePJl+6dNPP2WXN23aVGQL69ev57Zw+/Ztbnm/fv245T4+Prdu3RK2ffz4MfcRdHNzKyws5F7asGED13zdunXCtseOHXN0/P9XT3r66ad5K3Tt2pV9ady4ccYMBWfLli3cZrOysgyt9u6777Lr9O/fn11i5Ih98803whGjPwO//vqr3obp6en0h/vDDz+kX5U54MuWLeOax8fHG+p8eHg4u46HhwebgWg3b97M/YvwVREffvgh/bHv27evcJ2rV6/yvh07d+7Uu7Xq6mq9RwgJIZGRkdxqwgPITk5OK1euLC4uZhimpqbm0qVLw4cP563Tvn17nU7HbWTlypX0q+7u7nq7JIzve/bsYV8qLy/nHQq2t7dftmzZlStX2BXKysree+89XvPnnnuO2zj9r2cVFRUZP/icqKgoU7fTuXNnXpNu3br1rcv9+/fZ5sIfL4wfP/7PP/9kGKaysnL79u28o9xTpkyh311mc46Pjw+9mt6AYy7sjbP0EvnemcXjx4/pSys6OzvHxsaKN7l58yZd1/Xp00fvavUdruUENzWmEkbN2cT6Uwmj0WyibCo5ePAgr2337t1zc3O5FTZs2MCb6AkICKioqBBuykYCsvHS09MNdTI9Pb1e3xo1ghBqBOsM7JqM6ozSgZ0moUZg5JUJNlgjMAzDTUPzrF69ul7f1zZrBPndQ42AGoHoo71sYoM1AiM1INv0vD8hpF+/frx/3s2bN3v27MmtMGfOHPrV/Px87jbfHh4ep0+f5l6qra09f/4877wkYZIYNGgQ+5K7uzvdsTpdv37dxcWFbTts2DD2O8lz5MgR7ojlJ598wi6UE4Vv3rzJLQwJCXn48CGv1f79+3m3np89eza9gswB1+l0XCxo2LDhrl27eB0oLS2lryv32WefCf+00aNHcyvs27dPZBB4eDtnLi4u5eXlvHWMj8IMwyQmJhJ96CjMMMzYsWP1rubn58ed8Mjz3//+l96C/CjMMExycrLwviWEkMDAwF69egl74uLikpqayjU31z79M888Q2+kdevW4utz53Wa6u7du9xGhPersbOzCw0N5X3aWYmJibw+yGzOCD5XDg4O0kbPSMpOM504cYJ336HJkycfPXqU/o+w7ty5s3btWvoERj8/v7y8PL2bre9wLSe4qTGVMGrOJtafShjtZhMFU4lOp+vTpw+vubOzc9euXQcNGqR3vzkuLq7Of422A7KRND/vT1AjUKwwqjNqCOxajeqMamsExhxlgq3VCIxy8/6MTdYI8ruHGgE1AtFHe9nEBmsEBvP+PHXu03MppEGDBsOGDVu+fPn69eunTJnSvHlzrmHHjh3v3LnD2/KQIUO4FVxdXfv37z937tyJEyc2a9aMWzhlyhT2sTBJvPnmm1zzgICAMWPG8L6BIujz1Fq0aLF06dKdO3dmZGRcvHgxPj5+4sSJ3CGpdu3aPXjwwKQR0xuFGYYZN24ct9zPz+9f//rXgQMHdu3atWLFirCwMHa5t7c3d66Qn5/ft99+m5CQYK4Bp4/F2dnZjRkz5vPPP09ISNiwYcPs2bPpc6PCw8NramqEf5rkQMwwTLt27QglKSmJt4JJUZjXGQ7vM3DlyhVD32e9RowYwXsXs0RhhmE++eQTI/tgb2/PO7Zprn16f39/eiMvvPCC+PpffPGF8UNHo/cg9+zZw+1viRs1alRtbS2vDzKbM3//oQf5+4+k6oPi00zHjh3Te+N7Hx+fYcOGRUZGjh07NiwsjP5tCyGkZcuW2dnZIput13AtM7ipLpUwKs8mVp5KGE1nEwVTyZ9//unt7W3kuw8bNkzvRmwtIBtD2/P+qBF4rDOqM1Yf2DUc1Rl11giMOcoEW6sRGEXn/RmbrBFkdg81gqkDbuWphEE2+Qsvm9hgjcBg3p+nzn368ePHv/rqqyL/Wl9f3/z8fOGW79+/z7seFs3Ozm7btm1r165lnwqTxMmTJ3lNfHx8jByWysrK7t27i/SZ5ebmdubMGVNHzFAUvnv3bqtWrUTeLiAgIDU1dceOHfTC7t27m2vAGYaJj4+vMyqFhYUZ+p7LCcQff/wx/S7R0dG8FUyNwrm5ucLLRwqTcUZGhviwc0aNGiU84chcUVin03322WcNGjQQ74Ovr+/hw4d5GzfLPn1tbS1vuKZNmybeRPyKhCJ4vxxZvnx5nfvlTz31lKFgKLP5a6+9Rq/53XffmTp0JrGGaaaLFy+KXNJRaPTo0devXxffZr2Ga5nBTXWphFF/NrHmVMJoOpsom0qSkpLq/L/b2dm9//779MnLNBsMyHXS9rw/agQeq43qjHUHdg1HdUbpwM5IqhEYM5UJNlUjMErP+zO2VyPI7B5qBJHtoEagqT2b2GCNwEgNyLZ7X187O7uNGzcuWrRI+AlzdnaeO3duenp6mzZthA09PT33798/cuRI3lFlQki/fv3OnDkTERFRU1Nj6H379OmzcuVKY+4vKuTs7Hzq1Kkvv/zS3d1d7wp2dnaTJk3KysrSe8cJaZo0aZKcnPziiy8KX2rcuPFHH32UlpYWEhIyatQo+ri03r5JG3BCyOjRo9PS0oYNG2aoh4sWLTp+/Dh3ANyMJkyYQD89evSozA22a9du9uzZda7WpUuXzMzMefPm8c5tpLVt23br1q3x8fHcGXlm5+TkNH/+/KysLN44cOzs7MaNG5eamvrss8/WuTWRv8WQ4uJi3s1k6vwv5+fnm/oues2dO/fQoUPC+92z3N3d582bd+bMGb2/QJHf/MiRI9xjR0fHMWPGmNZ7FXryySfPnTu3adMm4RnQNHt7+759++7atSs+Pp53KyQhy4RracHN1lIJsYJsoqVUQlSVTZRNJQMHDrxy5cpHH31kqKG3t/fu3btXrFjh5OSkdwUbDMg2DjWCkRSP6kRbgV1FUZ0oHdiJpBqBmKlMQI1gYbZWI8jsnupSCbGCbKKlVEJsOJugRjDEjjF80+p9+/YJb+bAKi0tNZSKrFz//v2PHz9OCJkwYcL27dsJISUlJdu3b8/Ozi4qKvL39+/SpUu/fv0M7VzSKioq0tLSzp8/X1RU1LFjx86dO3M3UalTWVlZVlZWYWGhp6dnUFCQSafYEEIKCwuPHDly9erVq1evXrt2rUmTJgEBAQEBAb169TK+D6Y6efLkuXPnMjIyqqqqfH19u3bt+sILL9Df/6qqqtOnT2dmZjZo0CAsLKxjx47ErANOCMnNzU1JSUlJScnKyvLy8vL19Q0NDR0xYoS0xGakwMDA7Oxs9rGrq2tRUZHeKzDWk/Ly8qNHjx4/fvzWrVt37txxcXHx8vJq27ZteHh4aGiokSeKmsXNmzfT0tLS09MzMjLc3d1DQkJCQkKCg4O5a/wZEhUV9dVXXzVp0kTmHeqV8scffxw4cODGjRu3b9/28PBo0aIF+6mr86C05ObZ2dn0fu3QoUP37dtnhr/EsIqKCkPZLj4+Xu+pgvUqNzd39+7dGRkZRUVFt2/fdnR0bNGiRYsWLYKDg0ePHs27qKUx6iNcmyu42VoqIVaQTWwwlRCrySYKppJbt24lJydnZ2fn5OSUlJR07tyZffcOHTrovbQoCwFZr4yMDEM3jktPTw8KCrJwf8wCNYJkikd1YpOB3UqiOkGNoOkagRDi7e19584d4fLVq1fPmDGjvt+dx6ZqBDndU2MqIVaQTWwwlRD1ZxPbqRGI5IAsci6Agtf5qT/cySATJkxQui82QQMDzjuDadWqVUr3SGUGDx5MCOnWrZvSHVGN999/n/7IWeDCDqq4rIS10UBwUxe1DzhSiUxKpRIEZL0UvM5P/VF7kFEdDQw4ArtMqBFMZfmUxFjBdX5URwPBTV3UPuBIJTLZTo3A4Do/APUkMjKS/u3AunXrFOyM6uTm5iYlJRFCJk2apHRf1KG8vHzjxo3c065du44aNUrB/gCAWSCVyKFUKkFABgARCOxyoEYwFVISgCYhlciBGsEYmPcHqIOrq+uHH37IPc3MzGQjC9SpsLBwzJgxNTU1Pj4+lj8PVKW2b99+79497ml0dLQlz60DgHqCVCKZgqkEARkARCCwS4YaQQKkJABNQiqRDDWCkTDvD1C3d955h75YbUxMjIKdUYvFixe3b98+LS2tcePG3333naurq9I9UoHq6uqlS5dyT8PDw/Xe4AgA1AipRAIFUwkCMgDUCYFdAtQIEiAlAWgYUokEqBGMh3l/gLo5Ozv/8MMP9vb/9305cuTIoUOHlO2S9Tt8+HB5efnAgQNTU1NHjBihdHfUYfPmzbm5uexjd3f37777Ttn+AIAZIZVIoGAqQUAGgDohsEuAGkECpCQADUMqkQA1gvEw7w9glF69en3yySfc0wULFijYGVV49dVXk5KSDh8+7Ofnp3Rf1EGn09HH9r/++mt/f3/lugMA5odUYiqlUgkCMgAYCYHdVKgRTIWUBKB5SCWmQo1gPEelOwCgGosXL05NTc3OziaElJaWJicn9+rVS+lOWa833nhD6S6ozO+//96gQYNOnToRQvr37z9t2jSlewQA5odUYhKlUgkCMgAYD4HdJKgRTIWUBGALkEpMghrBeHYMwxh6bd++fcOHD9f7UmlpaaNGjeqtV/Xozp07lZWVhBA3N7cmTZoo3R3tw4ADWL+Kigo3Nze9L8XHx48ePdrC/VEFBDcLw4CDjVBFQM7IyAgODtb7Unp6On2NWhVBkLEwDDiAKnh7e9+5c0e4fPXq1bgns14IbhaGAQfbIS0g29zv/b28vJTugm3BgAOAJiG4WRgGHADqFYKMhWHAAUCTENwsDAMOIA7X9wcAAAAAAAAAAAAA0A7M+wMAAAAAAAAAAAAAaAfm/QEAAAAAAAAAAAAAtAPz/gAAAAAAAAAAAAAA2oF5fwAAAAAAAAAAAAAA7cC8PwAAAAAAAAAAAACAdmDeHwAAAAAAAAAAAABAOzDvDwAAAAAAAAAAAACgHZj3BwAAAAAAAAAAAADQDsz7AwAAAAAAAAAAAABoB+b9AQAAAAAAAAAAAAC0A/P+AAAAAAAAAAAAAADagXl/AAAAAAAAAAAAAADtwLw/AAAAAAAAAAAAAIB2YN4fAAAAAAAAAAAAAEA7MO8PAAAAAAAAAAAAAKAdmPcHAAAAAAAAAAAAANAOzPsDAAAAAAAAAAAAAGgH5v0BAAAAAAAAAAAAALQD8/4AAAAAAAAAAAAAANqBeX8AAAAAAAAAAAAAAO3AvD8AAAAAAAAAAAAAgHZg3h8AAAAAAAAAAAAAQDsw7w8AAAAAAAAAAAAAoB2Y9wcAAAAAAAAAAAAA0A7M+wMAAAAAAAAAAAAAaIejtGY//vijm5ubebsCAACKqK6uNvTSwYMHi4uLLdkZAABbJhKQVSEuLu706dNK9wIAAMyjoqJC7/JTp065uLhYuDMAALbMUECuA2PY3r17zd1JAAAAAAAwWXx8vMh+uyWlp6crPRgAAAAAAEBWr14tst+O6/wAAAAAAAAAAAAAAGgH5v0BAAAAAAAAAAAAALQD8/4AAAAAAAAAAAAAANqBeX8AAAAAAAAAAAAAAO3AvD8AAAAAAAAAAAAAgHZg3h8AAAAAAAAAAAAAQDscxV5zdGzYsKHFugIAAAAAAHo5OTkp3YX/4+DggBoBAAAAAEBxzs7OIq/aMQxjsa4AAAAAAAAAAAAAAEC9wnV+AAAAAAAAAAAAAAC0A/P+AAAAAAAAAAAAAADagXl/AAAAAAAAAAAAAADtwLw/AAAAAAAAAAAAAIB2YN4fAAAAAAAAAAAAAEA7MO8PAAAAAAAAAAAAAKAdmPcHAAAAAAAAAAAAANAOzPsDAAAAAAAAAAAAAGgH5v0BAAAAAAAAAAAAALQD8/4AAAAAAAAAAAAAANrx/wAa+QINNjyLVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "inputs = keras.Input(shape=(32,32,3))\n",
    "pool = layers.MaxPool2D(pool_size=(2,2))(inputs) # 16x16\n",
    "conv = layers.Conv2D(32, (2, 2), activation=LeakyReLU())(pool) # 15x15\n",
    "x = layers.Flatten()(conv)\n",
    "output1 = layers.Dense(5, name='output1')(x)\n",
    "output2 = layers.Dense(5, name='output2')(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs,\n",
    "    outputs={'output1':output1, 'output2':output2}, name='Toy',\n",
    "    )\n",
    "keras.utils.plot_model(model, \"toy.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Toy\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Toy\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7200</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,005</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,005</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │        \u001b[38;5;34m416\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7200\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │     \u001b[38;5;34m36,005\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │     \u001b[38;5;34m36,005\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,426</span> (282.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,426\u001b[0m (282.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,426</span> (282.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,426\u001b[0m (282.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "703/703 - 3s - 5ms/step - loss: 2.5423 - output1_accuracy: 0.4601 - output2_accuracy: 0.5068 - val_loss: 2.5641 - val_output1_accuracy: 0.4545 - val_output2_accuracy: 0.5084\n",
      "Epoch 2/2\n",
      "703/703 - 2s - 4ms/step - loss: 2.4828 - output1_accuracy: 0.4726 - output2_accuracy: 0.5258 - val_loss: 2.5371 - val_output1_accuracy: 0.4399 - val_output2_accuracy: 0.5168\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam', \n",
    "    loss={'output1':keras.losses.CategoricalCrossentropy(from_logits=True), 'output2':keras.losses.CategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={'output1':'accuracy', 'output2':'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,           \n",
    "    epochs=2,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen, \n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "    # callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important, I have to add a dictionary entry for my custom layer Leaky ReLU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toy.keras')\n",
    "toy = load_model('toy.keras',custom_objects={\"LeakyReLU\": LeakyReLU})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"These include adding horizontally flipped examples of all images as well as randomly translated\n",
    "versions (with a maximum translation of 5 pixels in each dimension). In all experiments images\n",
    "were whitened and contrast normalized following Goodfellow et al. (2013)\" from STRIVING FOR SIMPLICITY:\n",
    "THE ALL CONVOLUTIONAL NET\n",
    "\n",
    "((22500)*2)*(6^4) = 58 million examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "def FMP6():\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Data Augmentation\n",
    "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # Feature Extractor\n",
    "    pool = layers.MaxPool2D(pool_size=(2,2))(x) # 16x16\n",
    "    conv = layers.Conv2D(32, (2, 2), activation=LeakyReLU())(pool) # 15x15\n",
    "    x = layers.Flatten()(conv)\n",
    "    # Classifiers\n",
    "    output1 = layers.Dense(5, name='output1')(x)\n",
    "    output2 = layers.Dense(5, name='output2')(x)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='Toy',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "model = FMP6()\n",
    "keras.utils.plot_model(model, \"toy.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "703/703 - 4s - 6ms/step - loss: 2.8701 - output1_accuracy: 0.3740 - output2_accuracy: 0.3994 - val_loss: 2.6709 - val_output1_accuracy: 0.4441 - val_output2_accuracy: 0.4679\n",
      "Epoch 2/2\n",
      "703/703 - 3s - 5ms/step - loss: 2.7494 - output1_accuracy: 0.4098 - output2_accuracy: 0.4410 - val_loss: 2.6554 - val_output1_accuracy: 0.4277 - val_output2_accuracy: 0.4798\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='Adam', \n",
    "    loss={'output1':keras.losses.CategoricalCrossentropy(from_logits=True), 'output2':keras.losses.CategoricalCrossentropy(from_logits=True)},\n",
    "    metrics={'output1':'accuracy', 'output2':'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,           \n",
    "    epochs=2,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen, \n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  \n",
    "    # callbacks=[val_early_stopping, val_model_checkpoint_callback],  \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP3S(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP3S, self).__init__()\n",
    "        # Input layer size 32x32\n",
    "        # Data Augmentation\n",
    "        self.rf = layers.RandomFlip(\"horizontal\")\n",
    "        # self.rt = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU())\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Two Classifiers \n",
    "        self.fc1 = layers.Dense(5, activation='softmax', name='output1')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax', name='output2')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Data Augmentation\n",
    "        x = self.rf(inputs)\n",
    "        # x = self.rt(x)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(x) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        # Idea, make the classifier heads deeper or convolutionnally based\n",
    "        output1 = self.fc1(x)  # First half\n",
    "        output2 = self.fc2(x)  # Second half\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Serialize the configuration of the model\n",
    "        config = super(FMP3S, self).get_config()\n",
    "        config.update({\n",
    "            'rf': self.rf.get_config(),\n",
    "            # 'rt': self.rt.get_config(),\n",
    "            'conv1': self.conv1.get_config(),\n",
    "            'conv2': self.conv2.get_config(),\n",
    "            'conv3': self.conv3.get_config(),\n",
    "            'conv4': self.conv4.get_config(),\n",
    "            'conv5': self.conv5.get_config(),\n",
    "            'conv6': self.conv6.get_config(),\n",
    "            'conv7': self.conv7.get_config(),\n",
    "            'conv8': self.conv8.get_config(),\n",
    "            'dropout': self.dropout.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "            'pooling_ratios': [\n",
    "                self.pooling_ratio1,\n",
    "                self.pooling_ratio2,\n",
    "                self.pooling_ratio3,\n",
    "                self.pooling_ratio4,\n",
    "                self.pooling_ratio5,\n",
    "                self.pooling_ratio6\n",
    "            ]\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp3s\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp3s\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ random_flip (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ random_flip (\u001b[38;5;33mRandomFlip\u001b[0m)        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = FMP3S()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: Average accuracy improved to 0.4156, saving model to ./FMP3S/0.40-0.43-epoch01-loss2.88.keras\n",
      "703/703 - 70s - 99ms/step - loss: 2.8800 - output1_accuracy: 0.3663 - output2_accuracy: 0.3780 - val_loss: 2.7374 - val_output1_accuracy: 0.4018 - val_output2_accuracy: 0.4293\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: Average accuracy improved to 0.4442, saving model to ./FMP3S/0.43-0.46-epoch02-loss2.60.keras\n",
      "703/703 - 71s - 100ms/step - loss: 2.6002 - output1_accuracy: 0.4315 - output2_accuracy: 0.4856 - val_loss: 2.6324 - val_output1_accuracy: 0.4285 - val_output2_accuracy: 0.4599\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: Average accuracy improved to 0.5194, saving model to ./FMP3S/0.47-0.57-epoch03-loss2.42.keras\n",
      "703/703 - 73s - 104ms/step - loss: 2.4240 - output1_accuracy: 0.4658 - output2_accuracy: 0.5475 - val_loss: 2.3655 - val_output1_accuracy: 0.4730 - val_output2_accuracy: 0.5659\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: Average accuracy improved to 0.5306, saving model to ./FMP3S/0.47-0.59-epoch04-loss2.33.keras\n",
      "703/703 - 73s - 104ms/step - loss: 2.3292 - output1_accuracy: 0.4853 - output2_accuracy: 0.5775 - val_loss: 2.3236 - val_output1_accuracy: 0.4690 - val_output2_accuracy: 0.5923\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: Average accuracy improved to 0.5689, saving model to ./FMP3S/0.54-0.60-epoch05-loss2.25.keras\n",
      "703/703 - 73s - 104ms/step - loss: 2.2479 - output1_accuracy: 0.5064 - output2_accuracy: 0.5952 - val_loss: 2.1713 - val_output1_accuracy: 0.5361 - val_output2_accuracy: 0.6018\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: Average accuracy did not improve (current: 0.5489, best: 0.5689)\n",
      "703/703 - 74s - 105ms/step - loss: 2.1761 - output1_accuracy: 0.5213 - output2_accuracy: 0.6156 - val_loss: 2.2197 - val_output1_accuracy: 0.5058 - val_output2_accuracy: 0.5919\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: Average accuracy improved to 0.5849, saving model to ./FMP3S/0.53-0.64-epoch07-loss2.14.keras\n",
      "703/703 - 74s - 105ms/step - loss: 2.1366 - output1_accuracy: 0.5320 - output2_accuracy: 0.6230 - val_loss: 2.0919 - val_output1_accuracy: 0.5335 - val_output2_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: Average accuracy improved to 0.5853, saving model to ./FMP3S/0.54-0.63-epoch08-loss2.09.keras\n",
      "703/703 - 73s - 104ms/step - loss: 2.0929 - output1_accuracy: 0.5415 - output2_accuracy: 0.6324 - val_loss: 2.0747 - val_output1_accuracy: 0.5359 - val_output2_accuracy: 0.6348\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: Average accuracy improved to 0.5963, saving model to ./FMP3S/0.55-0.65-epoch09-loss2.06.keras\n",
      "703/703 - 74s - 105ms/step - loss: 2.0574 - output1_accuracy: 0.5538 - output2_accuracy: 0.6392 - val_loss: 2.0340 - val_output1_accuracy: 0.5459 - val_output2_accuracy: 0.6466\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: Average accuracy improved to 0.6045, saving model to ./FMP3S/0.55-0.66-epoch10-loss2.03.keras\n",
      "703/703 - 74s - 105ms/step - loss: 2.0276 - output1_accuracy: 0.5569 - output2_accuracy: 0.6460 - val_loss: 2.0127 - val_output1_accuracy: 0.5493 - val_output2_accuracy: 0.6597\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: Average accuracy improved to 0.6183, saving model to ./FMP3S/0.58-0.66-epoch11-loss2.00.keras\n",
      "703/703 - 74s - 106ms/step - loss: 1.9967 - output1_accuracy: 0.5635 - output2_accuracy: 0.6606 - val_loss: 1.9517 - val_output1_accuracy: 0.5785 - val_output2_accuracy: 0.6581\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: Average accuracy did not improve (current: 0.6122, best: 0.6183)\n",
      "703/703 - 74s - 105ms/step - loss: 1.9894 - output1_accuracy: 0.5661 - output2_accuracy: 0.6563 - val_loss: 1.9753 - val_output1_accuracy: 0.5591 - val_output2_accuracy: 0.6653\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: Average accuracy improved to 0.6252, saving model to ./FMP3S/0.58-0.67-epoch13-loss1.96.keras\n",
      "703/703 - 74s - 105ms/step - loss: 1.9626 - output1_accuracy: 0.5703 - output2_accuracy: 0.6649 - val_loss: 1.9396 - val_output1_accuracy: 0.5775 - val_output2_accuracy: 0.6729\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: Average accuracy did not improve (current: 0.6167, best: 0.6252)\n",
      "703/703 - 74s - 105ms/step - loss: 1.9451 - output1_accuracy: 0.5786 - output2_accuracy: 0.6682 - val_loss: 1.9674 - val_output1_accuracy: 0.5649 - val_output2_accuracy: 0.6685\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: Average accuracy did not improve (current: 0.6132, best: 0.6252)\n",
      "703/703 - 74s - 106ms/step - loss: 1.9276 - output1_accuracy: 0.5775 - output2_accuracy: 0.6715 - val_loss: 1.9937 - val_output1_accuracy: 0.5747 - val_output2_accuracy: 0.6516\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: Average accuracy improved to 0.6368, saving model to ./FMP3S/0.59-0.68-epoch16-loss1.91.keras\n",
      "703/703 - 74s - 106ms/step - loss: 1.9126 - output1_accuracy: 0.5771 - output2_accuracy: 0.6798 - val_loss: 1.8628 - val_output1_accuracy: 0.5899 - val_output2_accuracy: 0.6837\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: Average accuracy did not improve (current: 0.6329, best: 0.6368)\n",
      "703/703 - 74s - 106ms/step - loss: 1.8950 - output1_accuracy: 0.5860 - output2_accuracy: 0.6780 - val_loss: 1.8992 - val_output1_accuracy: 0.5933 - val_output2_accuracy: 0.6725\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: Average accuracy did not improve (current: 0.6293, best: 0.6368)\n",
      "703/703 - 75s - 106ms/step - loss: 1.8808 - output1_accuracy: 0.5887 - output2_accuracy: 0.6851 - val_loss: 1.9127 - val_output1_accuracy: 0.5988 - val_output2_accuracy: 0.6599\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: Average accuracy did not improve (current: 0.6353, best: 0.6368)\n",
      "703/703 - 75s - 106ms/step - loss: 1.8628 - output1_accuracy: 0.5929 - output2_accuracy: 0.6872 - val_loss: 1.8685 - val_output1_accuracy: 0.5986 - val_output2_accuracy: 0.6721\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: Average accuracy improved to 0.6445, saving model to ./FMP3S/0.60-0.69-epoch20-loss1.85.keras\n",
      "703/703 - 74s - 106ms/step - loss: 1.8542 - output1_accuracy: 0.5964 - output2_accuracy: 0.6865 - val_loss: 1.8365 - val_output1_accuracy: 0.5968 - val_output2_accuracy: 0.6923\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: Average accuracy did not improve (current: 0.6353, best: 0.6445)\n",
      "703/703 - 74s - 106ms/step - loss: 1.8571 - output1_accuracy: 0.5949 - output2_accuracy: 0.6858 - val_loss: 1.8927 - val_output1_accuracy: 0.5913 - val_output2_accuracy: 0.6793\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: Average accuracy improved to 0.6517, saving model to ./FMP3S/0.59-0.71-epoch22-loss1.82.keras\n",
      "703/703 - 75s - 106ms/step - loss: 1.8236 - output1_accuracy: 0.6048 - output2_accuracy: 0.6913 - val_loss: 1.8051 - val_output1_accuracy: 0.5946 - val_output2_accuracy: 0.7089\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: Average accuracy improved to 0.6542, saving model to ./FMP3S/0.62-0.69-epoch23-loss1.83.keras\n",
      "703/703 - 74s - 106ms/step - loss: 1.8259 - output1_accuracy: 0.6006 - output2_accuracy: 0.6943 - val_loss: 1.8238 - val_output1_accuracy: 0.6180 - val_output2_accuracy: 0.6905\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: Average accuracy did not improve (current: 0.6429, best: 0.6542)\n",
      "703/703 - 74s - 105ms/step - loss: 1.8069 - output1_accuracy: 0.6074 - output2_accuracy: 0.6981 - val_loss: 1.8520 - val_output1_accuracy: 0.6010 - val_output2_accuracy: 0.6849\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: Average accuracy improved to 0.6548, saving model to ./FMP3S/0.61-0.70-epoch25-loss1.81.keras\n",
      "703/703 - 74s - 105ms/step - loss: 1.8072 - output1_accuracy: 0.6045 - output2_accuracy: 0.6990 - val_loss: 1.7987 - val_output1_accuracy: 0.6142 - val_output2_accuracy: 0.6955\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: Average accuracy did not improve (current: 0.6432, best: 0.6548)\n",
      "703/703 - 74s - 105ms/step - loss: 1.7947 - output1_accuracy: 0.6061 - output2_accuracy: 0.7042 - val_loss: 1.8579 - val_output1_accuracy: 0.5988 - val_output2_accuracy: 0.6877\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: Average accuracy did not improve (current: 0.6495, best: 0.6548)\n",
      "703/703 - 74s - 105ms/step - loss: 1.7867 - output1_accuracy: 0.6098 - output2_accuracy: 0.7041 - val_loss: 1.8269 - val_output1_accuracy: 0.6018 - val_output2_accuracy: 0.6973\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: Average accuracy did not improve (current: 0.6502, best: 0.6548)\n",
      "703/703 - 74s - 105ms/step - loss: 1.7899 - output1_accuracy: 0.6060 - output2_accuracy: 0.7021 - val_loss: 1.8182 - val_output1_accuracy: 0.6108 - val_output2_accuracy: 0.6897\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: Average accuracy did not improve (current: 0.6401, best: 0.6548)\n",
      "703/703 - 74s - 106ms/step - loss: 1.7830 - output1_accuracy: 0.6095 - output2_accuracy: 0.7028 - val_loss: 1.8324 - val_output1_accuracy: 0.5962 - val_output2_accuracy: 0.6841\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: Average accuracy did not improve (current: 0.6491, best: 0.6548)\n",
      "703/703 - 74s - 106ms/step - loss: 1.7685 - output1_accuracy: 0.6122 - output2_accuracy: 0.7085 - val_loss: 1.8512 - val_output1_accuracy: 0.6076 - val_output2_accuracy: 0.6907\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: Average accuracy improved to 0.6604, saving model to ./FMP3S/0.63-0.69-epoch31-loss1.76.keras\n",
      "703/703 - 76s - 108ms/step - loss: 1.7625 - output1_accuracy: 0.6154 - output2_accuracy: 0.7085 - val_loss: 1.7517 - val_output1_accuracy: 0.6266 - val_output2_accuracy: 0.6941\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: Average accuracy did not improve (current: 0.6595, best: 0.6604)\n",
      "703/703 - 76s - 108ms/step - loss: 1.7547 - output1_accuracy: 0.6156 - output2_accuracy: 0.7123 - val_loss: 1.7489 - val_output1_accuracy: 0.6074 - val_output2_accuracy: 0.7115\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: Average accuracy improved to 0.6671, saving model to ./FMP3S/0.63-0.70-epoch33-loss1.74.keras\n",
      "703/703 - 77s - 109ms/step - loss: 1.7376 - output1_accuracy: 0.6221 - output2_accuracy: 0.7133 - val_loss: 1.7544 - val_output1_accuracy: 0.6294 - val_output2_accuracy: 0.7047\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: Average accuracy did not improve (current: 0.6658, best: 0.6671)\n",
      "703/703 - 76s - 108ms/step - loss: 1.7395 - output1_accuracy: 0.6192 - output2_accuracy: 0.7151 - val_loss: 1.7682 - val_output1_accuracy: 0.6178 - val_output2_accuracy: 0.7137\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: Average accuracy did not improve (current: 0.6616, best: 0.6671)\n",
      "703/703 - 77s - 110ms/step - loss: 1.7542 - output1_accuracy: 0.6168 - output2_accuracy: 0.7109 - val_loss: 1.7856 - val_output1_accuracy: 0.6178 - val_output2_accuracy: 0.7053\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: Average accuracy did not improve (current: 0.6650, best: 0.6671)\n",
      "703/703 - 77s - 110ms/step - loss: 1.7358 - output1_accuracy: 0.6272 - output2_accuracy: 0.7133 - val_loss: 1.7692 - val_output1_accuracy: 0.6238 - val_output2_accuracy: 0.7061\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: Average accuracy did not improve (current: 0.6566, best: 0.6671)\n",
      "703/703 - 77s - 110ms/step - loss: 1.7358 - output1_accuracy: 0.6207 - output2_accuracy: 0.7157 - val_loss: 1.7723 - val_output1_accuracy: 0.6126 - val_output2_accuracy: 0.7005\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: Average accuracy did not improve (current: 0.6614, best: 0.6671)\n",
      "703/703 - 78s - 111ms/step - loss: 1.7323 - output1_accuracy: 0.6206 - output2_accuracy: 0.7178 - val_loss: 1.7648 - val_output1_accuracy: 0.6212 - val_output2_accuracy: 0.7015\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: Average accuracy improved to 0.6811, saving model to ./FMP3S/0.64-0.72-epoch39-loss1.73.keras\n",
      "703/703 - 79s - 112ms/step - loss: 1.7347 - output1_accuracy: 0.6220 - output2_accuracy: 0.7129 - val_loss: 1.6883 - val_output1_accuracy: 0.6376 - val_output2_accuracy: 0.7246\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: Average accuracy did not improve (current: 0.6619, best: 0.6811)\n",
      "703/703 - 79s - 112ms/step - loss: 1.7098 - output1_accuracy: 0.6297 - output2_accuracy: 0.7160 - val_loss: 1.7600 - val_output1_accuracy: 0.6174 - val_output2_accuracy: 0.7063\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: Average accuracy did not improve (current: 0.6645, best: 0.6811)\n",
      "703/703 - 81s - 115ms/step - loss: 1.7110 - output1_accuracy: 0.6290 - output2_accuracy: 0.7184 - val_loss: 1.7397 - val_output1_accuracy: 0.6178 - val_output2_accuracy: 0.7111\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: Average accuracy did not improve (current: 0.6561, best: 0.6811)\n",
      "703/703 - 80s - 114ms/step - loss: 1.7044 - output1_accuracy: 0.6314 - output2_accuracy: 0.7195 - val_loss: 1.7814 - val_output1_accuracy: 0.6152 - val_output2_accuracy: 0.6971\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: Average accuracy did not improve (current: 0.6666, best: 0.6811)\n",
      "703/703 - 84s - 119ms/step - loss: 1.7090 - output1_accuracy: 0.6270 - output2_accuracy: 0.7186 - val_loss: 1.7509 - val_output1_accuracy: 0.6286 - val_output2_accuracy: 0.7045\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: Average accuracy did not improve (current: 0.6564, best: 0.6811)\n",
      "703/703 - 84s - 119ms/step - loss: 1.7055 - output1_accuracy: 0.6273 - output2_accuracy: 0.7234 - val_loss: 1.7905 - val_output1_accuracy: 0.6062 - val_output2_accuracy: 0.7065\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: Average accuracy did not improve (current: 0.6665, best: 0.6811)\n",
      "703/703 - 82s - 116ms/step - loss: 1.6985 - output1_accuracy: 0.6287 - output2_accuracy: 0.7235 - val_loss: 1.7341 - val_output1_accuracy: 0.6186 - val_output2_accuracy: 0.7143\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: Average accuracy did not improve (current: 0.6774, best: 0.6811)\n",
      "703/703 - 85s - 120ms/step - loss: 1.6956 - output1_accuracy: 0.6299 - output2_accuracy: 0.7236 - val_loss: 1.7101 - val_output1_accuracy: 0.6358 - val_output2_accuracy: 0.7190\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: Average accuracy did not improve (current: 0.6695, best: 0.6811)\n",
      "703/703 - 80s - 114ms/step - loss: 1.6849 - output1_accuracy: 0.6353 - output2_accuracy: 0.7217 - val_loss: 1.7142 - val_output1_accuracy: 0.6298 - val_output2_accuracy: 0.7091\n",
      "Epoch 48/100\n",
      "\n",
      "Epoch 48: Average accuracy did not improve (current: 0.6722, best: 0.6811)\n",
      "703/703 - 79s - 112ms/step - loss: 1.6856 - output1_accuracy: 0.6374 - output2_accuracy: 0.7232 - val_loss: 1.7061 - val_output1_accuracy: 0.6242 - val_output2_accuracy: 0.7202\n",
      "Epoch 49/100\n",
      "\n",
      "Epoch 49: Average accuracy did not improve (current: 0.6768, best: 0.6811)\n",
      "703/703 - 82s - 117ms/step - loss: 1.7019 - output1_accuracy: 0.6289 - output2_accuracy: 0.7260 - val_loss: 1.6930 - val_output1_accuracy: 0.6370 - val_output2_accuracy: 0.7165\n",
      "Epoch 49: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n"
     ]
    }
   ],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP3S/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6712249994277955\n",
      "standard deviation =  0.008714215770584259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, acc2 = model.evaluate(testgen, batch_size=10000, steps=1, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'fmp3m', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fmp3m\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fmp3m\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ random_flip (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_translation              │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomTranslation</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ random_flip (\u001b[38;5;33mRandomFlip\u001b[0m)        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_translation              │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomTranslation\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m24,672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m82,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m123,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │       \u001b[38;5;34m147,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m37,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │           \u001b[38;5;34m965\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">474,410</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m474,410\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: Average accuracy improved to 0.4087, saving model to ./FMP3M/0.41-0.41-epoch01-loss2.93.keras\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[250], line 121\u001b[0m\n\u001b[1;32m    108\u001b[0m val_model_checkpoint_callback \u001b[38;5;241m=\u001b[39m MeanAccModelCheckpoint(\n\u001b[1;32m    109\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./FMP3M/\u001b[39m\u001b[38;5;132;01m{output1_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{output2_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-loss\u001b[39m\u001b[38;5;132;01m{loss:.2f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m     monitor1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output1_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    111\u001b[0m     monitor2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output2_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    112\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    115\u001b[0m val_early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Track the validation loss\u001b[39;00m\n\u001b[1;32m    116\u001b[0m                                patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,         \u001b[38;5;66;03m# Number of epochs to wait after the last improvement\u001b[39;00m\n\u001b[1;32m    117\u001b[0m                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# Stop when the value stops decreasing (minimization)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m                                restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Restore the best weights when stopping\u001b[39;00m\n\u001b[1;32m    119\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Training data generator\u001b[39;49;00m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Number of epochs to train\u001b[39;49;00m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data generator\u001b[39;49;00m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Steps per validation epoch (if using a generator)\u001b[39;49;00m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_model_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Early stopping callback\u001b[39;49;00m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m    129\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[107], line 37\u001b[0m, in \u001b[0;36mMeanAccModelCheckpoint.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Average accuracy improved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, saving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Average accuracy did not improve (current: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, best: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[250], line 69\u001b[0m, in \u001b[0;36mFMP3M.get_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Serialize the configuration of the model\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFMP3S\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_config()\n\u001b[1;32m     70\u001b[0m     config\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrf\u001b[38;5;241m.\u001b[39mget_config(),\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrt\u001b[38;5;241m.\u001b[39mget_config(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m         ]\n\u001b[1;32m     92\u001b[0m     })\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class FMP3M(Model):\n",
    "    def __init__(self):\n",
    "        super(FMP3M, self).__init__()\n",
    "        # Input layer size 32x32\n",
    "        # Data Augmentation\n",
    "        self.rf = layers.RandomFlip(\"horizontal\")\n",
    "        self.rt = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')\n",
    "\n",
    "        # Six convolutional layers (C2 layers). Each convolutional layer should have an increasing number of filters, starting from 10n filters.\n",
    "        self.conv1 = layers.Conv2D(32, (2, 2), activation=LeakyReLU())\n",
    "        self.conv2 = layers.Conv2D(64, (2, 2), activation=LeakyReLU())\n",
    "        self.conv3 = layers.Conv2D(96, (2, 2), activation=LeakyReLU())\n",
    "        self.conv4 = layers.Conv2D(128, (2, 2), activation=LeakyReLU())\n",
    "        self.conv5 = layers.Conv2D(160, (2, 2), activation=LeakyReLU())\n",
    "        self.conv6 = layers.Conv2D(192, (2, 2), activation=LeakyReLU())\n",
    "\n",
    "        # Six fractional max pooling layers\n",
    "        self.pooling_ratio1 = [1.0, 31/22, 31/22, 1.0]\n",
    "        self.pooling_ratio2 = [1.0, 21/15, 21/15, 1.0]\n",
    "        self.pooling_ratio3 = [1.0, 14/10, 14/10, 1.0]\n",
    "        self.pooling_ratio4 = [1.0, 9/6, 9/6, 1.0]\n",
    "        self.pooling_ratio5 = [1.0, 5/4, 5/4, 1.0]\n",
    "        self.pooling_ratio6 = [1.0, 3/2, 3/2, 1.0]\n",
    "\n",
    "        # Two final convolutional layers\n",
    "        self.conv7 = layers.Conv2D(192, (2, 2), activation=LeakyReLU()) # 4x4\n",
    "        self.conv8 = layers.Conv2D(192, (1, 1), activation=LeakyReLU())\n",
    "\n",
    "        # Linearly increasing dropout in the hidden layers\n",
    "        self.dropout = layers.Dropout(0.5)  # 50% dropout in the final hidden layer\n",
    "\n",
    "        # Two Classifiers \n",
    "        self.fc1 = layers.Dense(5, activation='softmax', name='output1')  # First half\n",
    "        self.fc2 = layers.Dense(5, activation='softmax', name='output2')  # Second half\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Data Augmentation\n",
    "        x = self.rf(inputs)\n",
    "        x = self.rt(x)\n",
    "\n",
    "        # Feature Extractor\n",
    "        x = self.conv1(x) # 31x31\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio1, pseudo_random=True, overlapping=True) # 22x22\n",
    "        x = self.conv2(x) # 21x21\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio2, pseudo_random=True, overlapping=True) # 15x15\n",
    "        x = self.conv3(x) # 14x14\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio3, pseudo_random=True, overlapping=True) # 10x10\n",
    "        x = self.conv4(x) # 9x9\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio4, pseudo_random=True, overlapping=True) # 6x6\n",
    "        x = self.conv5(x) #5x5\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio5, pseudo_random=True, overlapping=True) # 4x4\n",
    "        x = self.conv6(x) # 3x3\n",
    "        x, _, _ = fractional_max_pool(x, self.pooling_ratio6, pseudo_random=True, overlapping=True) # 2x2\n",
    "        x = self.conv7(x) # 1x1\n",
    "        x = self.conv8(x) #1x1\n",
    "\n",
    "        # Classifier\n",
    "        x = layers.Flatten()(x) # future improvement might be to use global average pooling to lower the FCN parameter count\n",
    "        x = self.dropout(x)\n",
    "        # Idea, make the classifier heads deeper or convolutionnally based\n",
    "        output1 = self.fc1(x)  # First half\n",
    "        output2 = self.fc2(x)  # Second half\n",
    "\n",
    "        return {'output1': output1, 'output2': output2}\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Serialize the configuration of the model\n",
    "        config = super(FMP3S, self).get_config()\n",
    "        config.update({\n",
    "            'rf': self.rf.get_config(),\n",
    "            'rt': self.rt.get_config(),\n",
    "            'conv1': self.conv1.get_config(),\n",
    "            'conv2': self.conv2.get_config(),\n",
    "            'conv3': self.conv3.get_config(),\n",
    "            'conv4': self.conv4.get_config(),\n",
    "            'conv5': self.conv5.get_config(),\n",
    "            'conv6': self.conv6.get_config(),\n",
    "            'conv7': self.conv7.get_config(),\n",
    "            'conv8': self.conv8.get_config(),\n",
    "            'dropout': self.dropout.get_config(),\n",
    "            'fc1': self.fc1.get_config(),\n",
    "            'fc2': self.fc2.get_config(),\n",
    "            'pooling_ratios': [\n",
    "                self.pooling_ratio1,\n",
    "                self.pooling_ratio2,\n",
    "                self.pooling_ratio3,\n",
    "                self.pooling_ratio4,\n",
    "                self.pooling_ratio5,\n",
    "                self.pooling_ratio6\n",
    "            ]\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()\n",
    "    \n",
    "    K.clear_session()\n",
    "model = FMP3M()\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model(tf.random.normal((1, 32, 32, 3)))\n",
    "model.summary()\n",
    "\n",
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./FMP3M/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, acc2 = model.evaluate(testgen, batch_size=10000, steps=1, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ''\n",
    "evaluate_model(filepath, testgen, repeat=10)\n",
    "\n",
    "K.clear_session()\n",
    "def FMP6():\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Data Augmentation\n",
    "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # Feature Extractor\n",
    "    pool = layers.MaxPool2D(pool_size=(2,2))(x) # 16x16\n",
    "    conv = layers.Conv2D(32, (2, 2), activation=LeakyReLU())(pool) # 15x15\n",
    "    x = layers.Flatten()(conv)\n",
    "    # Classifiers\n",
    "    output1 = layers.Dense(5, name='output1')(x)\n",
    "    output2 = layers.Dense(5, name='output2')(x)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='Toy',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "model = FMP6()\n",
    "keras.utils.plot_model(model, \"toy.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, 4, 192)\n",
      "(None, 2, 2, 192)\n",
      "(None, 1, 1, 5)\n",
      "(None, 5)\n",
      "(None, 5)\n"
     ]
    }
   ],
   "source": [
    "def ACCN():\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Data Augmentation\n",
    "    # x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    # x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # x = layers.Normalization()(x)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    print(x.shape)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    # Classifers\n",
    "    x1 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    print(x1.shape)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    print(x1.shape)\n",
    "    output1 = layers.Activation('softmax', name='output1')(x1)\n",
    "    print(output1.shape)\n",
    "    x2 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    output2 = layers.Activation('softmax', name='output2')(x2)\n",
    "\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "model = ACCN()\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: Average accuracy improved to 0.1929, saving model to ./ACNN/0.19-0.20-epoch01-loss3.22.keras\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ACNN/0.19-0.20-epoch01-loss3.22.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[272], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m val_model_checkpoint_callback \u001b[38;5;241m=\u001b[39m MeanAccModelCheckpoint(\n\u001b[1;32m      2\u001b[0m     filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ACNN/\u001b[39m\u001b[38;5;132;01m{output1_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{output2_accuracy:.2f}\u001b[39;00m\u001b[38;5;124m-epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m-loss\u001b[39m\u001b[38;5;132;01m{loss:.2f}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     monitor1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output1_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     monitor2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_output2_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#                                patience=10,         # Number of epochs to wait after the last improvement\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#                                mode='min',         # Stop when the value stops decreasing (minimization)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#                                restore_best_weights=True,  # Restore the best weights when stopping\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#                                verbose=1)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Training data generator\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Number of epochs to train\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data generator\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcifar10_x_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Steps per validation epoch (if using a generator)\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_early_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_model_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Early stopping callback\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[107], line 37\u001b[0m, in \u001b[0;36mMeanAccModelCheckpoint.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Average accuracy improved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, saving model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Average accuracy did not improve (current: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, best: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ACNN/0.19-0.20-epoch01-loss3.22.keras'"
     ]
    }
   ],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./ACNN/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "#                                patience=10,         # Number of epochs to wait after the last improvement\n",
    "#                                mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "#                                restore_best_weights=True,  # Restore the best weights when stopping\n",
    "#                                verbose=1)\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, 4, 192)\n",
      "(None, 2, 2, 192)\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "def ACCN():\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Data Augmentation\n",
    "    # x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    # x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # x = layers.Normalization()(x)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    print(x.shape)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    print(x.shape)\n",
    "    # Classifers\n",
    "    x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "\n",
    "    # # Feature Extractor\n",
    "    # x = layers.Conv2D(96, (3,3), activation='relu')(inputs\n",
    "\n",
    "    # x1 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # print(x1.shape)\n",
    "    # x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    # print(x1.shape)\n",
    "    # output1 = layers.Activation('softmax', name='output1')(x1)\n",
    "    # print(output1.shape)\n",
    "    # x2 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    # output2 = layers.Activation('softmax', name='output2')(x2)\n",
    "\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "model = ACCN()\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,126,496</span> (15.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,126,496\u001b[0m (15.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,750,998</span> (10.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,750,998\u001b[0m (10.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4482 - output1_accuracy: 0.6692 - output1_loss: 0.8353 - output2_accuracy: 0.7706 - output2_loss: 0.6130\n",
      "Epoch 1: Average accuracy improved to 0.6767, saving model to ./ACNN/0.63-0.73-epoch01-loss1.45.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4482 - output1_accuracy: 0.6692 - output1_loss: 0.8353 - output2_accuracy: 0.7707 - output2_loss: 0.6129 - val_loss: 1.6807 - val_output1_accuracy: 0.6282 - val_output1_loss: 0.9497 - val_output2_accuracy: 0.7252 - val_output2_loss: 0.7310\n",
      "Epoch 2/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4377 - output1_accuracy: 0.6717 - output1_loss: 0.8302 - output2_accuracy: 0.7725 - output2_loss: 0.6075\n",
      "Epoch 2: Average accuracy improved to 0.6821, saving model to ./ACNN/0.63-0.73-epoch02-loss1.44.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4377 - output1_accuracy: 0.6717 - output1_loss: 0.8302 - output2_accuracy: 0.7725 - output2_loss: 0.6075 - val_loss: 1.6682 - val_output1_accuracy: 0.6340 - val_output1_loss: 0.9343 - val_output2_accuracy: 0.7302 - val_output2_loss: 0.7339\n",
      "Epoch 3/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4458 - output1_accuracy: 0.6706 - output1_loss: 0.8383 - output2_accuracy: 0.7765 - output2_loss: 0.6074\n",
      "Epoch 3: Average accuracy did not improve (current: 0.6791, best: 0.6821)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4458 - output1_accuracy: 0.6706 - output1_loss: 0.8383 - output2_accuracy: 0.7765 - output2_loss: 0.6074 - val_loss: 1.6945 - val_output1_accuracy: 0.6200 - val_output1_loss: 0.9842 - val_output2_accuracy: 0.7382 - val_output2_loss: 0.7104\n",
      "Epoch 4/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4188 - output1_accuracy: 0.6794 - output1_loss: 0.8218 - output2_accuracy: 0.7787 - output2_loss: 0.5970\n",
      "Epoch 4: Average accuracy did not improve (current: 0.6727, best: 0.6821)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4189 - output1_accuracy: 0.6794 - output1_loss: 0.8218 - output2_accuracy: 0.7787 - output2_loss: 0.5971 - val_loss: 1.7271 - val_output1_accuracy: 0.6324 - val_output1_loss: 0.9422 - val_output2_accuracy: 0.7129 - val_output2_loss: 0.7849\n",
      "Epoch 5/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4337 - output1_accuracy: 0.6711 - output1_loss: 0.8330 - output2_accuracy: 0.7748 - output2_loss: 0.6007\n",
      "Epoch 5: Average accuracy did not improve (current: 0.6713, best: 0.6821)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4336 - output1_accuracy: 0.6712 - output1_loss: 0.8330 - output2_accuracy: 0.7748 - output2_loss: 0.6007 - val_loss: 1.7247 - val_output1_accuracy: 0.6278 - val_output1_loss: 0.9563 - val_output2_accuracy: 0.7147 - val_output2_loss: 0.7684\n",
      "Epoch 6/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4511 - output1_accuracy: 0.6703 - output1_loss: 0.8389 - output2_accuracy: 0.7743 - output2_loss: 0.6122\n",
      "Epoch 6: Average accuracy improved to 0.6911, saving model to ./ACNN/0.64-0.74-epoch06-loss1.44.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4511 - output1_accuracy: 0.6703 - output1_loss: 0.8389 - output2_accuracy: 0.7743 - output2_loss: 0.6122 - val_loss: 1.6634 - val_output1_accuracy: 0.6428 - val_output1_loss: 0.9344 - val_output2_accuracy: 0.7394 - val_output2_loss: 0.7290\n",
      "Epoch 7/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4072 - output1_accuracy: 0.6793 - output1_loss: 0.8241 - output2_accuracy: 0.7860 - output2_loss: 0.5831\n",
      "Epoch 7: Average accuracy did not improve (current: 0.6829, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4073 - output1_accuracy: 0.6793 - output1_loss: 0.8241 - output2_accuracy: 0.7859 - output2_loss: 0.5832 - val_loss: 1.6917 - val_output1_accuracy: 0.6282 - val_output1_loss: 0.9546 - val_output2_accuracy: 0.7376 - val_output2_loss: 0.7370\n",
      "Epoch 8/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4250 - output1_accuracy: 0.6720 - output1_loss: 0.8288 - output2_accuracy: 0.7787 - output2_loss: 0.5962\n",
      "Epoch 8: Average accuracy did not improve (current: 0.6881, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4251 - output1_accuracy: 0.6721 - output1_loss: 0.8288 - output2_accuracy: 0.7787 - output2_loss: 0.5962 - val_loss: 1.6766 - val_output1_accuracy: 0.6364 - val_output1_loss: 0.9476 - val_output2_accuracy: 0.7398 - val_output2_loss: 0.7290\n",
      "Epoch 9/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4256 - output1_accuracy: 0.6769 - output1_loss: 0.8285 - output2_accuracy: 0.7789 - output2_loss: 0.5971\n",
      "Epoch 9: Average accuracy did not improve (current: 0.6795, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4256 - output1_accuracy: 0.6769 - output1_loss: 0.8285 - output2_accuracy: 0.7789 - output2_loss: 0.5971 - val_loss: 1.7006 - val_output1_accuracy: 0.6250 - val_output1_loss: 0.9713 - val_output2_accuracy: 0.7340 - val_output2_loss: 0.7294\n",
      "Epoch 10/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4178 - output1_accuracy: 0.6798 - output1_loss: 0.8198 - output2_accuracy: 0.7829 - output2_loss: 0.5981\n",
      "Epoch 10: Average accuracy did not improve (current: 0.6829, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4178 - output1_accuracy: 0.6798 - output1_loss: 0.8197 - output2_accuracy: 0.7829 - output2_loss: 0.5981 - val_loss: 1.6878 - val_output1_accuracy: 0.6230 - val_output1_loss: 0.9825 - val_output2_accuracy: 0.7428 - val_output2_loss: 0.7053\n",
      "Epoch 11/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4270 - output1_accuracy: 0.6721 - output1_loss: 0.8284 - output2_accuracy: 0.7758 - output2_loss: 0.5986\n",
      "Epoch 11: Average accuracy did not improve (current: 0.6672, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4270 - output1_accuracy: 0.6722 - output1_loss: 0.8284 - output2_accuracy: 0.7758 - output2_loss: 0.5986 - val_loss: 1.7161 - val_output1_accuracy: 0.6218 - val_output1_loss: 0.9451 - val_output2_accuracy: 0.7125 - val_output2_loss: 0.7709\n",
      "Epoch 12/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4155 - output1_accuracy: 0.6794 - output1_loss: 0.8199 - output2_accuracy: 0.7796 - output2_loss: 0.5957\n",
      "Epoch 12: Average accuracy did not improve (current: 0.6817, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4155 - output1_accuracy: 0.6794 - output1_loss: 0.8198 - output2_accuracy: 0.7796 - output2_loss: 0.5957 - val_loss: 1.6874 - val_output1_accuracy: 0.6266 - val_output1_loss: 0.9667 - val_output2_accuracy: 0.7368 - val_output2_loss: 0.7207\n",
      "Epoch 13/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3999 - output1_accuracy: 0.6779 - output1_loss: 0.8125 - output2_accuracy: 0.7847 - output2_loss: 0.5874\n",
      "Epoch 13: Average accuracy did not improve (current: 0.6875, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.3999 - output1_accuracy: 0.6779 - output1_loss: 0.8125 - output2_accuracy: 0.7847 - output2_loss: 0.5873 - val_loss: 1.6775 - val_output1_accuracy: 0.6474 - val_output1_loss: 0.9327 - val_output2_accuracy: 0.7276 - val_output2_loss: 0.7448\n",
      "Epoch 14/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4042 - output1_accuracy: 0.6797 - output1_loss: 0.8172 - output2_accuracy: 0.7818 - output2_loss: 0.5870\n",
      "Epoch 14: Average accuracy did not improve (current: 0.6764, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4043 - output1_accuracy: 0.6797 - output1_loss: 0.8173 - output2_accuracy: 0.7817 - output2_loss: 0.5870 - val_loss: 1.6719 - val_output1_accuracy: 0.6314 - val_output1_loss: 0.9370 - val_output2_accuracy: 0.7214 - val_output2_loss: 0.7348\n",
      "Epoch 15/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4103 - output1_accuracy: 0.6835 - output1_loss: 0.8120 - output2_accuracy: 0.7768 - output2_loss: 0.5983\n",
      "Epoch 15: Average accuracy did not improve (current: 0.6774, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4103 - output1_accuracy: 0.6835 - output1_loss: 0.8120 - output2_accuracy: 0.7768 - output2_loss: 0.5983 - val_loss: 1.7088 - val_output1_accuracy: 0.6214 - val_output1_loss: 0.9764 - val_output2_accuracy: 0.7334 - val_output2_loss: 0.7324\n",
      "Epoch 16/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4043 - output1_accuracy: 0.6794 - output1_loss: 0.8183 - output2_accuracy: 0.7819 - output2_loss: 0.5861\n",
      "Epoch 16: Average accuracy did not improve (current: 0.6813, best: 0.6911)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4043 - output1_accuracy: 0.6794 - output1_loss: 0.8183 - output2_accuracy: 0.7819 - output2_loss: 0.5861 - val_loss: 1.6904 - val_output1_accuracy: 0.6414 - val_output1_loss: 0.9322 - val_output2_accuracy: 0.7212 - val_output2_loss: 0.7582\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./ACNN/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testgensmall = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7936863243579865\n",
      "standard deviation =  0.003479763093993383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = model.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7924940764904023\n",
      "standard deviation =  0.0025116521517537503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = model.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a small problem with my save checkpoint which does not save the best one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7925562739372254\n",
      "standard deviation =  0.0033339649525372422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(filepath, gen, repeat=1, steps=1):\n",
    "    model = load_model(filepath)\n",
    "    evaluation_results = []\n",
    "    for i in tqdm(range(repeat)):\n",
    "        loss, acc1, loss1, acc2, loss2 = model.evaluate(gen, batch_size=10000, steps=steps, verbose=False)\n",
    "        evaluation_results.append(np.mean([acc1, acc2]))\n",
    "    print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "    print(\"standard deviation = \", np.std(evaluation_results))\n",
    "\n",
    "evaluate_model('test2.keras', testgensmall, repeat=10, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "def ACCN1(): # Adds dropout\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    x = layers.Dropout(0.2)\n",
    "    # Data Augmentation\n",
    "    # x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    # x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # x = layers.Normalization()(x)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    # Classifers\n",
    "    x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "\n",
    "    # # Feature Extractor\n",
    "    # x = layers.Conv2D(96, (3,3), activation='relu')(inputs\n",
    "\n",
    "    # x1 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # print(x1.shape)\n",
    "    # x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    # print(x1.shape)\n",
    "    # output1 = layers.Activation('softmax', name='output1')(x1)\n",
    "    # print(output1.shape)\n",
    "    # x2 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    # output2 = layers.Activation('softmax', name='output2')(x2)\n",
    "\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN1',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "model = ACCN1()\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0758 - output1_accuracy: 0.2917 - output1_loss: 1.5433 - output2_accuracy: 0.2959 - output2_loss: 1.5325\n",
      "Epoch 1: Average accuracy improved to 0.3775, saving model to ./ACNN1/0.37-0.39-epoch01-loss2.99.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 3.0753 - output1_accuracy: 0.2919 - output1_loss: 1.5430 - output2_accuracy: 0.2961 - output2_loss: 1.5323 - val_loss: 2.8521 - val_output1_accuracy: 0.3700 - val_output1_loss: 1.4207 - val_output2_accuracy: 0.3850 - val_output2_loss: 1.4315\n",
      "Epoch 2/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.8123 - output1_accuracy: 0.3900 - output1_loss: 1.4029 - output2_accuracy: 0.3926 - output2_loss: 1.4094\n",
      "Epoch 2: Average accuracy improved to 0.4268, saving model to ./ACNN1/0.41-0.44-epoch02-loss2.76.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.8121 - output1_accuracy: 0.3900 - output1_loss: 1.4028 - output2_accuracy: 0.3926 - output2_loss: 1.4093 - val_loss: 2.6928 - val_output1_accuracy: 0.4103 - val_output1_loss: 1.3497 - val_output2_accuracy: 0.4433 - val_output2_loss: 1.3431\n",
      "Epoch 3/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.6788 - output1_accuracy: 0.4255 - output1_loss: 1.3476 - output2_accuracy: 0.4386 - output2_loss: 1.3313\n",
      "Epoch 3: Average accuracy improved to 0.4547, saving model to ./ACNN1/0.44-0.47-epoch03-loss2.65.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6787 - output1_accuracy: 0.4256 - output1_loss: 1.3475 - output2_accuracy: 0.4386 - output2_loss: 1.3312 - val_loss: 2.5789 - val_output1_accuracy: 0.4375 - val_output1_loss: 1.3089 - val_output2_accuracy: 0.4720 - val_output2_loss: 1.2700\n",
      "Epoch 4/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.6152 - output1_accuracy: 0.4366 - output1_loss: 1.3186 - output2_accuracy: 0.4635 - output2_loss: 1.2966\n",
      "Epoch 4: Average accuracy improved to 0.4767, saving model to ./ACNN1/0.44-0.51-epoch04-loss2.59.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6152 - output1_accuracy: 0.4366 - output1_loss: 1.3186 - output2_accuracy: 0.4635 - output2_loss: 1.2966 - val_loss: 2.5060 - val_output1_accuracy: 0.4439 - val_output1_loss: 1.2908 - val_output2_accuracy: 0.5094 - val_output2_loss: 1.2152\n",
      "Epoch 5/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.5481 - output1_accuracy: 0.4475 - output1_loss: 1.3020 - output2_accuracy: 0.4891 - output2_loss: 1.2461\n",
      "Epoch 5: Average accuracy improved to 0.4971, saving model to ./ACNN1/0.46-0.53-epoch05-loss2.54.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5481 - output1_accuracy: 0.4475 - output1_loss: 1.3020 - output2_accuracy: 0.4892 - output2_loss: 1.2461 - val_loss: 2.4477 - val_output1_accuracy: 0.4617 - val_output1_loss: 1.2682 - val_output2_accuracy: 0.5325 - val_output2_loss: 1.1795\n",
      "Epoch 6/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.4960 - output1_accuracy: 0.4554 - output1_loss: 1.2850 - output2_accuracy: 0.5091 - output2_loss: 1.2109\n",
      "Epoch 6: Average accuracy did not improve (current: 0.4901, best: 0.4971)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4960 - output1_accuracy: 0.4554 - output1_loss: 1.2850 - output2_accuracy: 0.5091 - output2_loss: 1.2109 - val_loss: 2.4432 - val_output1_accuracy: 0.4499 - val_output1_loss: 1.2752 - val_output2_accuracy: 0.5302 - val_output2_loss: 1.1680\n",
      "Epoch 7/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.4722 - output1_accuracy: 0.4601 - output1_loss: 1.2853 - output2_accuracy: 0.5174 - output2_loss: 1.1869\n",
      "Epoch 7: Average accuracy improved to 0.5014, saving model to ./ACNN1/0.46-0.54-epoch07-loss2.46.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4722 - output1_accuracy: 0.4601 - output1_loss: 1.2853 - output2_accuracy: 0.5174 - output2_loss: 1.1868 - val_loss: 2.3893 - val_output1_accuracy: 0.4587 - val_output1_loss: 1.2527 - val_output2_accuracy: 0.5441 - val_output2_loss: 1.1366\n",
      "Epoch 8/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.4165 - output1_accuracy: 0.4726 - output1_loss: 1.2599 - output2_accuracy: 0.5353 - output2_loss: 1.1566\n",
      "Epoch 8: Average accuracy improved to 0.5145, saving model to ./ACNN1/0.49-0.54-epoch08-loss2.42.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4165 - output1_accuracy: 0.4726 - output1_loss: 1.2599 - output2_accuracy: 0.5353 - output2_loss: 1.1567 - val_loss: 2.3448 - val_output1_accuracy: 0.4878 - val_output1_loss: 1.2174 - val_output2_accuracy: 0.5413 - val_output2_loss: 1.1274\n",
      "Epoch 9/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3959 - output1_accuracy: 0.4710 - output1_loss: 1.2631 - output2_accuracy: 0.5501 - output2_loss: 1.1328\n",
      "Epoch 9: Average accuracy improved to 0.5291, saving model to ./ACNN1/0.49-0.57-epoch09-loss2.39.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3959 - output1_accuracy: 0.4710 - output1_loss: 1.2631 - output2_accuracy: 0.5501 - output2_loss: 1.1328 - val_loss: 2.3204 - val_output1_accuracy: 0.4856 - val_output1_loss: 1.2177 - val_output2_accuracy: 0.5727 - val_output2_loss: 1.1027\n",
      "Epoch 10/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3645 - output1_accuracy: 0.4815 - output1_loss: 1.2450 - output2_accuracy: 0.5534 - output2_loss: 1.1195\n",
      "Epoch 10: Average accuracy improved to 0.5388, saving model to ./ACNN1/0.50-0.57-epoch10-loss2.36.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3645 - output1_accuracy: 0.4815 - output1_loss: 1.2450 - output2_accuracy: 0.5534 - output2_loss: 1.1195 - val_loss: 2.2621 - val_output1_accuracy: 0.5026 - val_output1_loss: 1.1937 - val_output2_accuracy: 0.5749 - val_output2_loss: 1.0684\n",
      "Epoch 11/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3476 - output1_accuracy: 0.4754 - output1_loss: 1.2500 - output2_accuracy: 0.5638 - output2_loss: 1.0976\n",
      "Epoch 11: Average accuracy did not improve (current: 0.5311, best: 0.5388)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3476 - output1_accuracy: 0.4754 - output1_loss: 1.2500 - output2_accuracy: 0.5638 - output2_loss: 1.0976 - val_loss: 2.2938 - val_output1_accuracy: 0.4890 - val_output1_loss: 1.2229 - val_output2_accuracy: 0.5733 - val_output2_loss: 1.0709\n",
      "Epoch 12/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3414 - output1_accuracy: 0.4793 - output1_loss: 1.2417 - output2_accuracy: 0.5663 - output2_loss: 1.0998\n",
      "Epoch 12: Average accuracy improved to 0.5410, saving model to ./ACNN1/0.49-0.59-epoch12-loss2.33.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3414 - output1_accuracy: 0.4793 - output1_loss: 1.2416 - output2_accuracy: 0.5663 - output2_loss: 1.0997 - val_loss: 2.2525 - val_output1_accuracy: 0.4944 - val_output1_loss: 1.1985 - val_output2_accuracy: 0.5875 - val_output2_loss: 1.0540\n",
      "Epoch 13/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3193 - output1_accuracy: 0.4882 - output1_loss: 1.2304 - output2_accuracy: 0.5717 - output2_loss: 1.0889\n",
      "Epoch 13: Average accuracy improved to 0.5420, saving model to ./ACNN1/0.50-0.58-epoch13-loss2.32.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3193 - output1_accuracy: 0.4882 - output1_loss: 1.2304 - output2_accuracy: 0.5717 - output2_loss: 1.0889 - val_loss: 2.2675 - val_output1_accuracy: 0.4992 - val_output1_loss: 1.1963 - val_output2_accuracy: 0.5847 - val_output2_loss: 1.0712\n",
      "Epoch 14/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3089 - output1_accuracy: 0.4868 - output1_loss: 1.2349 - output2_accuracy: 0.5771 - output2_loss: 1.0741\n",
      "Epoch 14: Average accuracy improved to 0.5486, saving model to ./ACNN1/0.50-0.59-epoch14-loss2.30.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3089 - output1_accuracy: 0.4868 - output1_loss: 1.2348 - output2_accuracy: 0.5771 - output2_loss: 1.0741 - val_loss: 2.2520 - val_output1_accuracy: 0.5046 - val_output1_loss: 1.1983 - val_output2_accuracy: 0.5925 - val_output2_loss: 1.0538\n",
      "Epoch 15/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2840 - output1_accuracy: 0.4895 - output1_loss: 1.2144 - output2_accuracy: 0.5813 - output2_loss: 1.0696\n",
      "Epoch 15: Average accuracy did not improve (current: 0.5386, best: 0.5486)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2840 - output1_accuracy: 0.4895 - output1_loss: 1.2144 - output2_accuracy: 0.5813 - output2_loss: 1.0696 - val_loss: 2.2455 - val_output1_accuracy: 0.4950 - val_output1_loss: 1.1884 - val_output2_accuracy: 0.5821 - val_output2_loss: 1.0571\n",
      "Epoch 16/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2663 - output1_accuracy: 0.4960 - output1_loss: 1.2110 - output2_accuracy: 0.5884 - output2_loss: 1.0553\n",
      "Epoch 16: Average accuracy improved to 0.5509, saving model to ./ACNN1/0.51-0.60-epoch16-loss2.26.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2663 - output1_accuracy: 0.4960 - output1_loss: 1.2109 - output2_accuracy: 0.5884 - output2_loss: 1.0553 - val_loss: 2.2248 - val_output1_accuracy: 0.5060 - val_output1_loss: 1.1819 - val_output2_accuracy: 0.5958 - val_output2_loss: 1.0429\n",
      "Epoch 17/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2465 - output1_accuracy: 0.5012 - output1_loss: 1.2003 - output2_accuracy: 0.5906 - output2_loss: 1.0462\n",
      "Epoch 17: Average accuracy improved to 0.5525, saving model to ./ACNN1/0.51-0.59-epoch17-loss2.25.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2465 - output1_accuracy: 0.5012 - output1_loss: 1.2003 - output2_accuracy: 0.5906 - output2_loss: 1.0462 - val_loss: 2.2026 - val_output1_accuracy: 0.5130 - val_output1_loss: 1.1641 - val_output2_accuracy: 0.5919 - val_output2_loss: 1.0384\n",
      "Epoch 18/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2507 - output1_accuracy: 0.4969 - output1_loss: 1.2116 - output2_accuracy: 0.5924 - output2_loss: 1.0391\n",
      "Epoch 18: Average accuracy improved to 0.5571, saving model to ./ACNN1/0.52-0.60-epoch18-loss2.24.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2507 - output1_accuracy: 0.4969 - output1_loss: 1.2116 - output2_accuracy: 0.5924 - output2_loss: 1.0391 - val_loss: 2.1789 - val_output1_accuracy: 0.5152 - val_output1_loss: 1.1573 - val_output2_accuracy: 0.5990 - val_output2_loss: 1.0216\n",
      "Epoch 19/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2136 - output1_accuracy: 0.5068 - output1_loss: 1.1939 - output2_accuracy: 0.6042 - output2_loss: 1.0196\n",
      "Epoch 19: Average accuracy improved to 0.5613, saving model to ./ACNN1/0.51-0.61-epoch19-loss2.22.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2136 - output1_accuracy: 0.5068 - output1_loss: 1.1939 - output2_accuracy: 0.6041 - output2_loss: 1.0197 - val_loss: 2.1844 - val_output1_accuracy: 0.5132 - val_output1_loss: 1.1686 - val_output2_accuracy: 0.6094 - val_output2_loss: 1.0158\n",
      "Epoch 20/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2286 - output1_accuracy: 0.4991 - output1_loss: 1.2025 - output2_accuracy: 0.5994 - output2_loss: 1.0262\n",
      "Epoch 20: Average accuracy did not improve (current: 0.5578, best: 0.5613)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2286 - output1_accuracy: 0.4991 - output1_loss: 1.2025 - output2_accuracy: 0.5994 - output2_loss: 1.0261 - val_loss: 2.2101 - val_output1_accuracy: 0.5242 - val_output1_loss: 1.1576 - val_output2_accuracy: 0.5913 - val_output2_loss: 1.0524\n",
      "Epoch 21/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2016 - output1_accuracy: 0.5115 - output1_loss: 1.1804 - output2_accuracy: 0.6018 - output2_loss: 1.0212\n",
      "Epoch 21: Average accuracy improved to 0.5714, saving model to ./ACNN1/0.53-0.62-epoch21-loss2.20.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2016 - output1_accuracy: 0.5115 - output1_loss: 1.1804 - output2_accuracy: 0.6018 - output2_loss: 1.0212 - val_loss: 2.1455 - val_output1_accuracy: 0.5270 - val_output1_loss: 1.1496 - val_output2_accuracy: 0.6158 - val_output2_loss: 0.9959\n",
      "Epoch 22/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1904 - output1_accuracy: 0.5117 - output1_loss: 1.1884 - output2_accuracy: 0.6123 - output2_loss: 1.0020\n",
      "Epoch 22: Average accuracy improved to 0.5800, saving model to ./ACNN1/0.52-0.64-epoch22-loss2.19.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1904 - output1_accuracy: 0.5117 - output1_loss: 1.1883 - output2_accuracy: 0.6123 - output2_loss: 1.0020 - val_loss: 2.0966 - val_output1_accuracy: 0.5224 - val_output1_loss: 1.1388 - val_output2_accuracy: 0.6376 - val_output2_loss: 0.9578\n",
      "Epoch 23/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1993 - output1_accuracy: 0.5094 - output1_loss: 1.1856 - output2_accuracy: 0.6017 - output2_loss: 1.0137\n",
      "Epoch 23: Average accuracy did not improve (current: 0.5551, best: 0.5800)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1992 - output1_accuracy: 0.5094 - output1_loss: 1.1856 - output2_accuracy: 0.6018 - output2_loss: 1.0136 - val_loss: 2.2179 - val_output1_accuracy: 0.5244 - val_output1_loss: 1.1480 - val_output2_accuracy: 0.5857 - val_output2_loss: 1.0700\n",
      "Epoch 24/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1848 - output1_accuracy: 0.5088 - output1_loss: 1.1850 - output2_accuracy: 0.6125 - output2_loss: 0.9999\n",
      "Epoch 24: Average accuracy did not improve (current: 0.5742, best: 0.5800)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1848 - output1_accuracy: 0.5088 - output1_loss: 1.1849 - output2_accuracy: 0.6125 - output2_loss: 0.9999 - val_loss: 2.1312 - val_output1_accuracy: 0.5250 - val_output1_loss: 1.1404 - val_output2_accuracy: 0.6234 - val_output2_loss: 0.9907\n",
      "Epoch 25/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1591 - output1_accuracy: 0.5165 - output1_loss: 1.1693 - output2_accuracy: 0.6138 - output2_loss: 0.9898\n",
      "Epoch 25: Average accuracy did not improve (current: 0.5726, best: 0.5800)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1591 - output1_accuracy: 0.5165 - output1_loss: 1.1693 - output2_accuracy: 0.6138 - output2_loss: 0.9898 - val_loss: 2.1145 - val_output1_accuracy: 0.5240 - val_output1_loss: 1.1411 - val_output2_accuracy: 0.6212 - val_output2_loss: 0.9733\n",
      "Epoch 26/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1575 - output1_accuracy: 0.5122 - output1_loss: 1.1738 - output2_accuracy: 0.6173 - output2_loss: 0.9837\n",
      "Epoch 26: Average accuracy improved to 0.5852, saving model to ./ACNN1/0.54-0.63-epoch26-loss2.16.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1575 - output1_accuracy: 0.5122 - output1_loss: 1.1738 - output2_accuracy: 0.6173 - output2_loss: 0.9837 - val_loss: 2.0747 - val_output1_accuracy: 0.5387 - val_output1_loss: 1.1136 - val_output2_accuracy: 0.6318 - val_output2_loss: 0.9611\n",
      "Epoch 27/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1421 - output1_accuracy: 0.5262 - output1_loss: 1.1620 - output2_accuracy: 0.6215 - output2_loss: 0.9801\n",
      "Epoch 27: Average accuracy improved to 0.5864, saving model to ./ACNN1/0.53-0.64-epoch27-loss2.14.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1421 - output1_accuracy: 0.5262 - output1_loss: 1.1620 - output2_accuracy: 0.6215 - output2_loss: 0.9801 - val_loss: 2.0609 - val_output1_accuracy: 0.5347 - val_output1_loss: 1.1262 - val_output2_accuracy: 0.6382 - val_output2_loss: 0.9347\n",
      "Epoch 28/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1510 - output1_accuracy: 0.5175 - output1_loss: 1.1772 - output2_accuracy: 0.6221 - output2_loss: 0.9738\n",
      "Epoch 28: Average accuracy did not improve (current: 0.5830, best: 0.5864)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1509 - output1_accuracy: 0.5175 - output1_loss: 1.1772 - output2_accuracy: 0.6221 - output2_loss: 0.9738 - val_loss: 2.0937 - val_output1_accuracy: 0.5317 - val_output1_loss: 1.1463 - val_output2_accuracy: 0.6344 - val_output2_loss: 0.9474\n",
      "Epoch 29/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1340 - output1_accuracy: 0.5219 - output1_loss: 1.1645 - output2_accuracy: 0.6256 - output2_loss: 0.9694\n",
      "Epoch 29: Average accuracy did not improve (current: 0.5845, best: 0.5864)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1340 - output1_accuracy: 0.5219 - output1_loss: 1.1646 - output2_accuracy: 0.6256 - output2_loss: 0.9694 - val_loss: 2.0777 - val_output1_accuracy: 0.5343 - val_output1_loss: 1.1323 - val_output2_accuracy: 0.6348 - val_output2_loss: 0.9454\n",
      "Epoch 30/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1327 - output1_accuracy: 0.5205 - output1_loss: 1.1643 - output2_accuracy: 0.6239 - output2_loss: 0.9683\n",
      "Epoch 30: Average accuracy did not improve (current: 0.5828, best: 0.5864)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1327 - output1_accuracy: 0.5205 - output1_loss: 1.1643 - output2_accuracy: 0.6239 - output2_loss: 0.9683 - val_loss: 2.0743 - val_output1_accuracy: 0.5327 - val_output1_loss: 1.1306 - val_output2_accuracy: 0.6330 - val_output2_loss: 0.9437\n",
      "Epoch 31/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1200 - output1_accuracy: 0.5179 - output1_loss: 1.1579 - output2_accuracy: 0.6280 - output2_loss: 0.9621\n",
      "Epoch 31: Average accuracy improved to 0.5889, saving model to ./ACNN1/0.55-0.63-epoch31-loss2.12.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1200 - output1_accuracy: 0.5179 - output1_loss: 1.1579 - output2_accuracy: 0.6280 - output2_loss: 0.9621 - val_loss: 2.0722 - val_output1_accuracy: 0.5483 - val_output1_loss: 1.1138 - val_output2_accuracy: 0.6296 - val_output2_loss: 0.9584\n",
      "Epoch 32/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1117 - output1_accuracy: 0.5270 - output1_loss: 1.1574 - output2_accuracy: 0.6310 - output2_loss: 0.9542\n",
      "Epoch 32: Average accuracy improved to 0.5947, saving model to ./ACNN1/0.54-0.65-epoch32-loss2.11.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1117 - output1_accuracy: 0.5270 - output1_loss: 1.1574 - output2_accuracy: 0.6310 - output2_loss: 0.9542 - val_loss: 2.0303 - val_output1_accuracy: 0.5407 - val_output1_loss: 1.1148 - val_output2_accuracy: 0.6486 - val_output2_loss: 0.9155\n",
      "Epoch 33/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1012 - output1_accuracy: 0.5308 - output1_loss: 1.1491 - output2_accuracy: 0.6313 - output2_loss: 0.9522\n",
      "Epoch 33: Average accuracy did not improve (current: 0.5772, best: 0.5947)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1012 - output1_accuracy: 0.5308 - output1_loss: 1.1491 - output2_accuracy: 0.6313 - output2_loss: 0.9521 - val_loss: 2.1004 - val_output1_accuracy: 0.5240 - val_output1_loss: 1.1389 - val_output2_accuracy: 0.6304 - val_output2_loss: 0.9615\n",
      "Epoch 34/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1075 - output1_accuracy: 0.5246 - output1_loss: 1.1558 - output2_accuracy: 0.6320 - output2_loss: 0.9517\n",
      "Epoch 34: Average accuracy did not improve (current: 0.5914, best: 0.5947)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1074 - output1_accuracy: 0.5246 - output1_loss: 1.1558 - output2_accuracy: 0.6320 - output2_loss: 0.9517 - val_loss: 2.0463 - val_output1_accuracy: 0.5256 - val_output1_loss: 1.1409 - val_output2_accuracy: 0.6573 - val_output2_loss: 0.9054\n",
      "Epoch 35/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0926 - output1_accuracy: 0.5325 - output1_loss: 1.1468 - output2_accuracy: 0.6363 - output2_loss: 0.9457\n",
      "Epoch 35: Average accuracy improved to 0.5978, saving model to ./ACNN1/0.56-0.64-epoch35-loss2.10.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0926 - output1_accuracy: 0.5325 - output1_loss: 1.1468 - output2_accuracy: 0.6363 - output2_loss: 0.9457 - val_loss: 2.0189 - val_output1_accuracy: 0.5571 - val_output1_loss: 1.0897 - val_output2_accuracy: 0.6384 - val_output2_loss: 0.9292\n",
      "Epoch 36/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0817 - output1_accuracy: 0.5360 - output1_loss: 1.1399 - output2_accuracy: 0.6364 - output2_loss: 0.9417\n",
      "Epoch 36: Average accuracy improved to 0.5996, saving model to ./ACNN1/0.55-0.64-epoch36-loss2.08.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0817 - output1_accuracy: 0.5360 - output1_loss: 1.1399 - output2_accuracy: 0.6364 - output2_loss: 0.9417 - val_loss: 1.9971 - val_output1_accuracy: 0.5543 - val_output1_loss: 1.0927 - val_output2_accuracy: 0.6448 - val_output2_loss: 0.9045\n",
      "Epoch 37/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0919 - output1_accuracy: 0.5313 - output1_loss: 1.1488 - output2_accuracy: 0.6380 - output2_loss: 0.9430\n",
      "Epoch 37: Average accuracy did not improve (current: 0.5988, best: 0.5996)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0919 - output1_accuracy: 0.5313 - output1_loss: 1.1488 - output2_accuracy: 0.6380 - output2_loss: 0.9430 - val_loss: 2.0224 - val_output1_accuracy: 0.5541 - val_output1_loss: 1.0991 - val_output2_accuracy: 0.6434 - val_output2_loss: 0.9233\n",
      "Epoch 38/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0753 - output1_accuracy: 0.5398 - output1_loss: 1.1310 - output2_accuracy: 0.6351 - output2_loss: 0.9443\n",
      "Epoch 38: Average accuracy improved to 0.6119, saving model to ./ACNN1/0.57-0.66-epoch38-loss2.06.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.0752 - output1_accuracy: 0.5398 - output1_loss: 1.1310 - output2_accuracy: 0.6351 - output2_loss: 0.9442 - val_loss: 1.9678 - val_output1_accuracy: 0.5675 - val_output1_loss: 1.0782 - val_output2_accuracy: 0.6562 - val_output2_loss: 0.8896\n",
      "Epoch 39/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0854 - output1_accuracy: 0.5335 - output1_loss: 1.1458 - output2_accuracy: 0.6343 - output2_loss: 0.9396\n",
      "Epoch 39: Average accuracy did not improve (current: 0.5895, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0854 - output1_accuracy: 0.5335 - output1_loss: 1.1458 - output2_accuracy: 0.6343 - output2_loss: 0.9396 - val_loss: 2.0357 - val_output1_accuracy: 0.5419 - val_output1_loss: 1.1085 - val_output2_accuracy: 0.6372 - val_output2_loss: 0.9272\n",
      "Epoch 40/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0547 - output1_accuracy: 0.5364 - output1_loss: 1.1298 - output2_accuracy: 0.6437 - output2_loss: 0.9249\n",
      "Epoch 40: Average accuracy did not improve (current: 0.6002, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.0547 - output1_accuracy: 0.5365 - output1_loss: 1.1297 - output2_accuracy: 0.6437 - output2_loss: 0.9249 - val_loss: 2.0096 - val_output1_accuracy: 0.5413 - val_output1_loss: 1.1292 - val_output2_accuracy: 0.6591 - val_output2_loss: 0.8804\n",
      "Epoch 41/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0638 - output1_accuracy: 0.5350 - output1_loss: 1.1369 - output2_accuracy: 0.6455 - output2_loss: 0.9269\n",
      "Epoch 41: Average accuracy did not improve (current: 0.6117, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.0638 - output1_accuracy: 0.5350 - output1_loss: 1.1369 - output2_accuracy: 0.6455 - output2_loss: 0.9269 - val_loss: 1.9603 - val_output1_accuracy: 0.5659 - val_output1_loss: 1.0605 - val_output2_accuracy: 0.6575 - val_output2_loss: 0.8998\n",
      "Epoch 42/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0534 - output1_accuracy: 0.5455 - output1_loss: 1.1219 - output2_accuracy: 0.6399 - output2_loss: 0.9315\n",
      "Epoch 42: Average accuracy did not improve (current: 0.5983, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.0534 - output1_accuracy: 0.5455 - output1_loss: 1.1219 - output2_accuracy: 0.6399 - output2_loss: 0.9315 - val_loss: 1.9900 - val_output1_accuracy: 0.5457 - val_output1_loss: 1.0985 - val_output2_accuracy: 0.6508 - val_output2_loss: 0.8915\n",
      "Epoch 43/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0453 - output1_accuracy: 0.5391 - output1_loss: 1.1298 - output2_accuracy: 0.6485 - output2_loss: 0.9155\n",
      "Epoch 43: Average accuracy did not improve (current: 0.5978, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.0453 - output1_accuracy: 0.5391 - output1_loss: 1.1298 - output2_accuracy: 0.6485 - output2_loss: 0.9155 - val_loss: 2.0060 - val_output1_accuracy: 0.5477 - val_output1_loss: 1.1034 - val_output2_accuracy: 0.6478 - val_output2_loss: 0.9026\n",
      "Epoch 44/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0434 - output1_accuracy: 0.5399 - output1_loss: 1.1237 - output2_accuracy: 0.6459 - output2_loss: 0.9198\n",
      "Epoch 44: Average accuracy did not improve (current: 0.5934, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0434 - output1_accuracy: 0.5399 - output1_loss: 1.1237 - output2_accuracy: 0.6459 - output2_loss: 0.9197 - val_loss: 2.0401 - val_output1_accuracy: 0.5537 - val_output1_loss: 1.0851 - val_output2_accuracy: 0.6332 - val_output2_loss: 0.9550\n",
      "Epoch 45/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0328 - output1_accuracy: 0.5399 - output1_loss: 1.1255 - output2_accuracy: 0.6532 - output2_loss: 0.9073\n",
      "Epoch 45: Average accuracy did not improve (current: 0.6063, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.0328 - output1_accuracy: 0.5399 - output1_loss: 1.1255 - output2_accuracy: 0.6532 - output2_loss: 0.9073 - val_loss: 1.9819 - val_output1_accuracy: 0.5505 - val_output1_loss: 1.0976 - val_output2_accuracy: 0.6621 - val_output2_loss: 0.8843\n",
      "Epoch 46/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0389 - output1_accuracy: 0.5404 - output1_loss: 1.1303 - output2_accuracy: 0.6532 - output2_loss: 0.9086\n",
      "Epoch 46: Average accuracy did not improve (current: 0.5957, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0389 - output1_accuracy: 0.5404 - output1_loss: 1.1303 - output2_accuracy: 0.6531 - output2_loss: 0.9086 - val_loss: 2.0332 - val_output1_accuracy: 0.5559 - val_output1_loss: 1.0894 - val_output2_accuracy: 0.6354 - val_output2_loss: 0.9438\n",
      "Epoch 47/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0131 - output1_accuracy: 0.5530 - output1_loss: 1.1050 - output2_accuracy: 0.6503 - output2_loss: 0.9082\n",
      "Epoch 47: Average accuracy did not improve (current: 0.6009, best: 0.6119)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0132 - output1_accuracy: 0.5530 - output1_loss: 1.1050 - output2_accuracy: 0.6503 - output2_loss: 0.9082 - val_loss: 2.0164 - val_output1_accuracy: 0.5643 - val_output1_loss: 1.0658 - val_output2_accuracy: 0.6374 - val_output2_loss: 0.9506\n",
      "Epoch 48/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0314 - output1_accuracy: 0.5466 - output1_loss: 1.1163 - output2_accuracy: 0.6491 - output2_loss: 0.9151\n",
      "Epoch 48: Average accuracy improved to 0.6157, saving model to ./ACNN1/0.56-0.67-epoch48-loss2.03.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0314 - output1_accuracy: 0.5466 - output1_loss: 1.1163 - output2_accuracy: 0.6491 - output2_loss: 0.9150 - val_loss: 1.9360 - val_output1_accuracy: 0.5645 - val_output1_loss: 1.0771 - val_output2_accuracy: 0.6669 - val_output2_loss: 0.8589\n",
      "Epoch 49/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0108 - output1_accuracy: 0.5427 - output1_loss: 1.1151 - output2_accuracy: 0.6556 - output2_loss: 0.8957\n",
      "Epoch 49: Average accuracy did not improve (current: 0.6141, best: 0.6157)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0109 - output1_accuracy: 0.5428 - output1_loss: 1.1151 - output2_accuracy: 0.6556 - output2_loss: 0.8958 - val_loss: 1.9527 - val_output1_accuracy: 0.5669 - val_output1_loss: 1.0746 - val_output2_accuracy: 0.6613 - val_output2_loss: 0.8781\n",
      "Epoch 50/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0288 - output1_accuracy: 0.5444 - output1_loss: 1.1185 - output2_accuracy: 0.6481 - output2_loss: 0.9103\n",
      "Epoch 50: Average accuracy did not improve (current: 0.6105, best: 0.6157)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.0288 - output1_accuracy: 0.5444 - output1_loss: 1.1185 - output2_accuracy: 0.6481 - output2_loss: 0.9103 - val_loss: 1.9675 - val_output1_accuracy: 0.5649 - val_output1_loss: 1.0733 - val_output2_accuracy: 0.6560 - val_output2_loss: 0.8942\n",
      "Epoch 51/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0209 - output1_accuracy: 0.5492 - output1_loss: 1.1106 - output2_accuracy: 0.6514 - output2_loss: 0.9104\n",
      "Epoch 51: Average accuracy did not improve (current: 0.5964, best: 0.6157)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0209 - output1_accuracy: 0.5492 - output1_loss: 1.1105 - output2_accuracy: 0.6514 - output2_loss: 0.9104 - val_loss: 2.0476 - val_output1_accuracy: 0.5623 - val_output1_loss: 1.0819 - val_output2_accuracy: 0.6304 - val_output2_loss: 0.9657\n",
      "Epoch 52/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0122 - output1_accuracy: 0.5492 - output1_loss: 1.1124 - output2_accuracy: 0.6583 - output2_loss: 0.8997\n",
      "Epoch 52: Average accuracy did not improve (current: 0.6069, best: 0.6157)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.0122 - output1_accuracy: 0.5492 - output1_loss: 1.1124 - output2_accuracy: 0.6583 - output2_loss: 0.8998 - val_loss: 1.9828 - val_output1_accuracy: 0.5561 - val_output1_loss: 1.0941 - val_output2_accuracy: 0.6577 - val_output2_loss: 0.8887\n",
      "Epoch 53/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0111 - output1_accuracy: 0.5469 - output1_loss: 1.1140 - output2_accuracy: 0.6569 - output2_loss: 0.8971\n",
      "Epoch 53: Average accuracy did not improve (current: 0.5990, best: 0.6157)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0111 - output1_accuracy: 0.5469 - output1_loss: 1.1140 - output2_accuracy: 0.6569 - output2_loss: 0.8971 - val_loss: 2.0008 - val_output1_accuracy: 0.5493 - val_output1_loss: 1.0955 - val_output2_accuracy: 0.6486 - val_output2_loss: 0.9053\n",
      "Epoch 54/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0141 - output1_accuracy: 0.5488 - output1_loss: 1.1123 - output2_accuracy: 0.6577 - output2_loss: 0.9018\n",
      "Epoch 54: Average accuracy improved to 0.6255, saving model to ./ACNN1/0.58-0.67-epoch54-loss2.01.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0141 - output1_accuracy: 0.5488 - output1_loss: 1.1123 - output2_accuracy: 0.6577 - output2_loss: 0.9018 - val_loss: 1.9021 - val_output1_accuracy: 0.5775 - val_output1_loss: 1.0492 - val_output2_accuracy: 0.6735 - val_output2_loss: 0.8529\n",
      "Epoch 55/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0005 - output1_accuracy: 0.5527 - output1_loss: 1.0994 - output2_accuracy: 0.6560 - output2_loss: 0.9011\n",
      "Epoch 55: Average accuracy did not improve (current: 0.6236, best: 0.6255)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0004 - output1_accuracy: 0.5527 - output1_loss: 1.0994 - output2_accuracy: 0.6560 - output2_loss: 0.9010 - val_loss: 1.8977 - val_output1_accuracy: 0.5623 - val_output1_loss: 1.0729 - val_output2_accuracy: 0.6849 - val_output2_loss: 0.8248\n",
      "Epoch 56/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0009 - output1_accuracy: 0.5510 - output1_loss: 1.1066 - output2_accuracy: 0.6562 - output2_loss: 0.8943\n",
      "Epoch 56: Average accuracy did not improve (current: 0.6102, best: 0.6255)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0009 - output1_accuracy: 0.5510 - output1_loss: 1.1066 - output2_accuracy: 0.6562 - output2_loss: 0.8943 - val_loss: 1.9706 - val_output1_accuracy: 0.5545 - val_output1_loss: 1.0922 - val_output2_accuracy: 0.6659 - val_output2_loss: 0.8784\n",
      "Epoch 57/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9888 - output1_accuracy: 0.5516 - output1_loss: 1.1035 - output2_accuracy: 0.6599 - output2_loss: 0.8853\n",
      "Epoch 57: Average accuracy improved to 0.6282, saving model to ./ACNN1/0.58-0.68-epoch57-loss1.99.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9888 - output1_accuracy: 0.5516 - output1_loss: 1.1035 - output2_accuracy: 0.6599 - output2_loss: 0.8853 - val_loss: 1.8714 - val_output1_accuracy: 0.5787 - val_output1_loss: 1.0382 - val_output2_accuracy: 0.6777 - val_output2_loss: 0.8332\n",
      "Epoch 58/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9853 - output1_accuracy: 0.5553 - output1_loss: 1.0941 - output2_accuracy: 0.6593 - output2_loss: 0.8911\n",
      "Epoch 58: Average accuracy did not improve (current: 0.6199, best: 0.6282)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9853 - output1_accuracy: 0.5553 - output1_loss: 1.0942 - output2_accuracy: 0.6593 - output2_loss: 0.8912 - val_loss: 1.9193 - val_output1_accuracy: 0.5617 - val_output1_loss: 1.0682 - val_output2_accuracy: 0.6781 - val_output2_loss: 0.8512\n",
      "Epoch 59/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9745 - output1_accuracy: 0.5561 - output1_loss: 1.0987 - output2_accuracy: 0.6673 - output2_loss: 0.8757\n",
      "Epoch 59: Average accuracy did not improve (current: 0.6156, best: 0.6282)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9745 - output1_accuracy: 0.5561 - output1_loss: 1.0987 - output2_accuracy: 0.6673 - output2_loss: 0.8757 - val_loss: 1.9284 - val_output1_accuracy: 0.5627 - val_output1_loss: 1.0705 - val_output2_accuracy: 0.6685 - val_output2_loss: 0.8579\n",
      "Epoch 60/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9837 - output1_accuracy: 0.5568 - output1_loss: 1.0917 - output2_accuracy: 0.6582 - output2_loss: 0.8920\n",
      "Epoch 60: Average accuracy did not improve (current: 0.6234, best: 0.6282)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 1.9837 - output1_accuracy: 0.5568 - output1_loss: 1.0917 - output2_accuracy: 0.6582 - output2_loss: 0.8920 - val_loss: 1.9059 - val_output1_accuracy: 0.5739 - val_output1_loss: 1.0452 - val_output2_accuracy: 0.6729 - val_output2_loss: 0.8607\n",
      "Epoch 61/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9672 - output1_accuracy: 0.5624 - output1_loss: 1.0821 - output2_accuracy: 0.6611 - output2_loss: 0.8851\n",
      "Epoch 61: Average accuracy improved to 0.6307, saving model to ./ACNN1/0.58-0.69-epoch61-loss1.98.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9672 - output1_accuracy: 0.5624 - output1_loss: 1.0821 - output2_accuracy: 0.6611 - output2_loss: 0.8851 - val_loss: 1.8746 - val_output1_accuracy: 0.5763 - val_output1_loss: 1.0430 - val_output2_accuracy: 0.6851 - val_output2_loss: 0.8316\n",
      "Epoch 62/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9729 - output1_accuracy: 0.5534 - output1_loss: 1.0946 - output2_accuracy: 0.6638 - output2_loss: 0.8783\n",
      "Epoch 62: Average accuracy did not improve (current: 0.6251, best: 0.6307)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9729 - output1_accuracy: 0.5534 - output1_loss: 1.0946 - output2_accuracy: 0.6638 - output2_loss: 0.8783 - val_loss: 1.9198 - val_output1_accuracy: 0.5751 - val_output1_loss: 1.0666 - val_output2_accuracy: 0.6751 - val_output2_loss: 0.8532\n",
      "Epoch 63/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9680 - output1_accuracy: 0.5616 - output1_loss: 1.0882 - output2_accuracy: 0.6655 - output2_loss: 0.8798\n",
      "Epoch 63: Average accuracy did not improve (current: 0.6267, best: 0.6307)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9680 - output1_accuracy: 0.5616 - output1_loss: 1.0882 - output2_accuracy: 0.6655 - output2_loss: 0.8798 - val_loss: 1.9060 - val_output1_accuracy: 0.5689 - val_output1_loss: 1.0751 - val_output2_accuracy: 0.6845 - val_output2_loss: 0.8309\n",
      "Epoch 64/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9701 - output1_accuracy: 0.5585 - output1_loss: 1.0901 - output2_accuracy: 0.6674 - output2_loss: 0.8800\n",
      "Epoch 64: Average accuracy did not improve (current: 0.6265, best: 0.6307)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9701 - output1_accuracy: 0.5585 - output1_loss: 1.0902 - output2_accuracy: 0.6674 - output2_loss: 0.8800 - val_loss: 1.8990 - val_output1_accuracy: 0.5651 - val_output1_loss: 1.0717 - val_output2_accuracy: 0.6879 - val_output2_loss: 0.8274\n",
      "Epoch 65/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9468 - output1_accuracy: 0.5594 - output1_loss: 1.0858 - output2_accuracy: 0.6704 - output2_loss: 0.8611\n",
      "Epoch 65: Average accuracy improved to 0.6397, saving model to ./ACNN1/0.59-0.69-epoch65-loss1.95.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9469 - output1_accuracy: 0.5594 - output1_loss: 1.0857 - output2_accuracy: 0.6704 - output2_loss: 0.8611 - val_loss: 1.8542 - val_output1_accuracy: 0.5921 - val_output1_loss: 1.0304 - val_output2_accuracy: 0.6873 - val_output2_loss: 0.8238\n",
      "Epoch 66/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9451 - output1_accuracy: 0.5651 - output1_loss: 1.0764 - output2_accuracy: 0.6652 - output2_loss: 0.8687\n",
      "Epoch 66: Average accuracy did not improve (current: 0.6177, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9451 - output1_accuracy: 0.5651 - output1_loss: 1.0764 - output2_accuracy: 0.6652 - output2_loss: 0.8687 - val_loss: 1.9118 - val_output1_accuracy: 0.5589 - val_output1_loss: 1.0621 - val_output2_accuracy: 0.6765 - val_output2_loss: 0.8497\n",
      "Epoch 67/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9606 - output1_accuracy: 0.5603 - output1_loss: 1.0891 - output2_accuracy: 0.6671 - output2_loss: 0.8715\n",
      "Epoch 67: Average accuracy did not improve (current: 0.6326, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9606 - output1_accuracy: 0.5603 - output1_loss: 1.0890 - output2_accuracy: 0.6671 - output2_loss: 0.8715 - val_loss: 1.8537 - val_output1_accuracy: 0.5761 - val_output1_loss: 1.0363 - val_output2_accuracy: 0.6891 - val_output2_loss: 0.8175\n",
      "Epoch 68/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9446 - output1_accuracy: 0.5649 - output1_loss: 1.0766 - output2_accuracy: 0.6683 - output2_loss: 0.8681\n",
      "Epoch 68: Average accuracy did not improve (current: 0.6285, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9447 - output1_accuracy: 0.5649 - output1_loss: 1.0766 - output2_accuracy: 0.6683 - output2_loss: 0.8681 - val_loss: 1.8883 - val_output1_accuracy: 0.5839 - val_output1_loss: 1.0388 - val_output2_accuracy: 0.6731 - val_output2_loss: 0.8495\n",
      "Epoch 69/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9560 - output1_accuracy: 0.5629 - output1_loss: 1.0821 - output2_accuracy: 0.6670 - output2_loss: 0.8739\n",
      "Epoch 69: Average accuracy did not improve (current: 0.6343, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9560 - output1_accuracy: 0.5629 - output1_loss: 1.0821 - output2_accuracy: 0.6670 - output2_loss: 0.8739 - val_loss: 1.8552 - val_output1_accuracy: 0.5813 - val_output1_loss: 1.0348 - val_output2_accuracy: 0.6873 - val_output2_loss: 0.8203\n",
      "Epoch 70/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9387 - output1_accuracy: 0.5678 - output1_loss: 1.0748 - output2_accuracy: 0.6734 - output2_loss: 0.8639\n",
      "Epoch 70: Average accuracy did not improve (current: 0.6300, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9387 - output1_accuracy: 0.5678 - output1_loss: 1.0748 - output2_accuracy: 0.6734 - output2_loss: 0.8638 - val_loss: 1.8664 - val_output1_accuracy: 0.5839 - val_output1_loss: 1.0364 - val_output2_accuracy: 0.6761 - val_output2_loss: 0.8300\n",
      "Epoch 71/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9383 - output1_accuracy: 0.5642 - output1_loss: 1.0796 - output2_accuracy: 0.6734 - output2_loss: 0.8587\n",
      "Epoch 71: Average accuracy did not improve (current: 0.6288, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9383 - output1_accuracy: 0.5642 - output1_loss: 1.0796 - output2_accuracy: 0.6734 - output2_loss: 0.8587 - val_loss: 1.8797 - val_output1_accuracy: 0.5845 - val_output1_loss: 1.0286 - val_output2_accuracy: 0.6731 - val_output2_loss: 0.8512\n",
      "Epoch 72/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9209 - output1_accuracy: 0.5686 - output1_loss: 1.0646 - output2_accuracy: 0.6732 - output2_loss: 0.8564\n",
      "Epoch 72: Average accuracy did not improve (current: 0.6262, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9209 - output1_accuracy: 0.5686 - output1_loss: 1.0646 - output2_accuracy: 0.6732 - output2_loss: 0.8564 - val_loss: 1.8842 - val_output1_accuracy: 0.5857 - val_output1_loss: 1.0308 - val_output2_accuracy: 0.6667 - val_output2_loss: 0.8535\n",
      "Epoch 73/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9367 - output1_accuracy: 0.5679 - output1_loss: 1.0729 - output2_accuracy: 0.6693 - output2_loss: 0.8638\n",
      "Epoch 73: Average accuracy did not improve (current: 0.6355, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9368 - output1_accuracy: 0.5679 - output1_loss: 1.0730 - output2_accuracy: 0.6692 - output2_loss: 0.8638 - val_loss: 1.8568 - val_output1_accuracy: 0.5905 - val_output1_loss: 1.0210 - val_output2_accuracy: 0.6805 - val_output2_loss: 0.8358\n",
      "Epoch 74/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9281 - output1_accuracy: 0.5676 - output1_loss: 1.0705 - output2_accuracy: 0.6735 - output2_loss: 0.8576\n",
      "Epoch 74: Average accuracy did not improve (current: 0.6301, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9281 - output1_accuracy: 0.5676 - output1_loss: 1.0705 - output2_accuracy: 0.6735 - output2_loss: 0.8576 - val_loss: 1.8451 - val_output1_accuracy: 0.5853 - val_output1_loss: 1.0141 - val_output2_accuracy: 0.6749 - val_output2_loss: 0.8310\n",
      "Epoch 75/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9441 - output1_accuracy: 0.5647 - output1_loss: 1.0765 - output2_accuracy: 0.6660 - output2_loss: 0.8676\n",
      "Epoch 75: Average accuracy did not improve (current: 0.6281, best: 0.6397)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9440 - output1_accuracy: 0.5647 - output1_loss: 1.0765 - output2_accuracy: 0.6660 - output2_loss: 0.8676 - val_loss: 1.8659 - val_output1_accuracy: 0.5759 - val_output1_loss: 1.0404 - val_output2_accuracy: 0.6803 - val_output2_loss: 0.8255\n",
      "Epoch 76/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9374 - output1_accuracy: 0.5655 - output1_loss: 1.0792 - output2_accuracy: 0.6726 - output2_loss: 0.8582\n",
      "Epoch 76: Average accuracy improved to 0.6448, saving model to ./ACNN1/0.60-0.69-epoch76-loss1.93.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9373 - output1_accuracy: 0.5655 - output1_loss: 1.0791 - output2_accuracy: 0.6726 - output2_loss: 0.8582 - val_loss: 1.8134 - val_output1_accuracy: 0.6040 - val_output1_loss: 0.9970 - val_output2_accuracy: 0.6857 - val_output2_loss: 0.8164\n",
      "Epoch 77/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9221 - output1_accuracy: 0.5669 - output1_loss: 1.0643 - output2_accuracy: 0.6738 - output2_loss: 0.8577\n",
      "Epoch 77: Average accuracy did not improve (current: 0.6419, best: 0.6448)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9221 - output1_accuracy: 0.5669 - output1_loss: 1.0644 - output2_accuracy: 0.6738 - output2_loss: 0.8577 - val_loss: 1.8354 - val_output1_accuracy: 0.6016 - val_output1_loss: 1.0180 - val_output2_accuracy: 0.6823 - val_output2_loss: 0.8174\n",
      "Epoch 78/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9123 - output1_accuracy: 0.5725 - output1_loss: 1.0643 - output2_accuracy: 0.6770 - output2_loss: 0.8480\n",
      "Epoch 78: Average accuracy did not improve (current: 0.6148, best: 0.6448)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.9124 - output1_accuracy: 0.5725 - output1_loss: 1.0643 - output2_accuracy: 0.6770 - output2_loss: 0.8480 - val_loss: 1.9225 - val_output1_accuracy: 0.5755 - val_output1_loss: 1.0326 - val_output2_accuracy: 0.6540 - val_output2_loss: 0.8899\n",
      "Epoch 79/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9188 - output1_accuracy: 0.5750 - output1_loss: 1.0572 - output2_accuracy: 0.6752 - output2_loss: 0.8616\n",
      "Epoch 79: Average accuracy improved to 0.6455, saving model to ./ACNN1/0.59-0.70-epoch79-loss1.92.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9188 - output1_accuracy: 0.5749 - output1_loss: 1.0572 - output2_accuracy: 0.6752 - output2_loss: 0.8615 - val_loss: 1.8389 - val_output1_accuracy: 0.5881 - val_output1_loss: 1.0304 - val_output2_accuracy: 0.7029 - val_output2_loss: 0.8084\n",
      "Epoch 80/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9187 - output1_accuracy: 0.5704 - output1_loss: 1.0662 - output2_accuracy: 0.6769 - output2_loss: 0.8525\n",
      "Epoch 80: Average accuracy did not improve (current: 0.6328, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9187 - output1_accuracy: 0.5703 - output1_loss: 1.0662 - output2_accuracy: 0.6769 - output2_loss: 0.8525 - val_loss: 1.8527 - val_output1_accuracy: 0.5803 - val_output1_loss: 1.0419 - val_output2_accuracy: 0.6853 - val_output2_loss: 0.8107\n",
      "Epoch 81/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9056 - output1_accuracy: 0.5701 - output1_loss: 1.0605 - output2_accuracy: 0.6773 - output2_loss: 0.8451\n",
      "Epoch 81: Average accuracy did not improve (current: 0.6343, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9056 - output1_accuracy: 0.5701 - output1_loss: 1.0605 - output2_accuracy: 0.6773 - output2_loss: 0.8451 - val_loss: 1.8845 - val_output1_accuracy: 0.5964 - val_output1_loss: 1.0174 - val_output2_accuracy: 0.6723 - val_output2_loss: 0.8671\n",
      "Epoch 82/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9014 - output1_accuracy: 0.5725 - output1_loss: 1.0595 - output2_accuracy: 0.6802 - output2_loss: 0.8419\n",
      "Epoch 82: Average accuracy did not improve (current: 0.6372, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9014 - output1_accuracy: 0.5726 - output1_loss: 1.0595 - output2_accuracy: 0.6802 - output2_loss: 0.8419 - val_loss: 1.8318 - val_output1_accuracy: 0.5933 - val_output1_loss: 1.0015 - val_output2_accuracy: 0.6811 - val_output2_loss: 0.8303\n",
      "Epoch 83/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9093 - output1_accuracy: 0.5746 - output1_loss: 1.0607 - output2_accuracy: 0.6769 - output2_loss: 0.8486\n",
      "Epoch 83: Average accuracy did not improve (current: 0.6330, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.9093 - output1_accuracy: 0.5746 - output1_loss: 1.0607 - output2_accuracy: 0.6769 - output2_loss: 0.8486 - val_loss: 1.8556 - val_output1_accuracy: 0.5809 - val_output1_loss: 1.0234 - val_output2_accuracy: 0.6851 - val_output2_loss: 0.8322\n",
      "Epoch 84/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9042 - output1_accuracy: 0.5769 - output1_loss: 1.0501 - output2_accuracy: 0.6688 - output2_loss: 0.8541\n",
      "Epoch 84: Average accuracy did not improve (current: 0.6124, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9042 - output1_accuracy: 0.5769 - output1_loss: 1.0502 - output2_accuracy: 0.6688 - output2_loss: 0.8541 - val_loss: 1.9575 - val_output1_accuracy: 0.5607 - val_output1_loss: 1.0793 - val_output2_accuracy: 0.6641 - val_output2_loss: 0.8781\n",
      "Epoch 85/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9123 - output1_accuracy: 0.5753 - output1_loss: 1.0567 - output2_accuracy: 0.6731 - output2_loss: 0.8556\n",
      "Epoch 85: Average accuracy did not improve (current: 0.6296, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9123 - output1_accuracy: 0.5753 - output1_loss: 1.0567 - output2_accuracy: 0.6731 - output2_loss: 0.8556 - val_loss: 1.8492 - val_output1_accuracy: 0.5861 - val_output1_loss: 1.0180 - val_output2_accuracy: 0.6731 - val_output2_loss: 0.8313\n",
      "Epoch 86/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9066 - output1_accuracy: 0.5777 - output1_loss: 1.0566 - output2_accuracy: 0.6786 - output2_loss: 0.8500\n",
      "Epoch 86: Average accuracy did not improve (current: 0.6319, best: 0.6455)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9066 - output1_accuracy: 0.5777 - output1_loss: 1.0566 - output2_accuracy: 0.6786 - output2_loss: 0.8500 - val_loss: 1.8607 - val_output1_accuracy: 0.5809 - val_output1_loss: 1.0420 - val_output2_accuracy: 0.6829 - val_output2_loss: 0.8187\n",
      "Epoch 86: early stopping\n",
      "Restoring model weights from the end of the best epoch: 76.\n"
     ]
    }
   ],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./ACNN1/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.8077306419610977\n",
      "standard deviation =  0.002342914916912416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = model.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ACCN1-80.6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.8078694552183151\n",
      "standard deviation =  0.0028045642861268295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACCN180 = load_model('ACCN1-80.6.keras')\n",
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = ACCN180.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "def ACCN2(): # Adds data augmentation\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Data Augmentation\n",
    "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    # x = layers.Dropout(0.2)(x) # removed after unable to train\n",
    "    # x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # x = layers.Normalization()(x)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    # Classifers\n",
    "    x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "\n",
    "    # # Feature Extractor\n",
    "    # x = layers.Conv2D(96, (3,3), activation='relu')(inputs\n",
    "\n",
    "    # x1 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # print(x1.shape)\n",
    "    # x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    # print(x1.shape)\n",
    "    # output1 = layers.Activation('softmax', name='output1')(x1)\n",
    "    # print(output1.shape)\n",
    "    # x2 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    # output2 = layers.Activation('softmax', name='output2')(x2)\n",
    "\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN2',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "model = ACCN2()\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0626 - output1_accuracy: 0.2891 - output1_loss: 1.5358 - output2_accuracy: 0.2974 - output2_loss: 1.5268\n",
      "Epoch 1: Average accuracy improved to 0.3861, saving model to ./ACNN2/0.37-0.40-epoch01-loss2.95.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 3.0618 - output1_accuracy: 0.2894 - output1_loss: 1.5354 - output2_accuracy: 0.2977 - output2_loss: 1.5264 - val_loss: 2.8076 - val_output1_accuracy: 0.3720 - val_output1_loss: 1.4096 - val_output2_accuracy: 0.4002 - val_output2_loss: 1.3981\n",
      "Epoch 2/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7777 - output1_accuracy: 0.3954 - output1_loss: 1.3996 - output2_accuracy: 0.4173 - output2_loss: 1.3782\n",
      "Epoch 2: Average accuracy improved to 0.4502, saving model to ./ACNN2/0.43-0.47-epoch02-loss2.73.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.7775 - output1_accuracy: 0.3955 - output1_loss: 1.3995 - output2_accuracy: 0.4174 - output2_loss: 1.3780 - val_loss: 2.6215 - val_output1_accuracy: 0.4279 - val_output1_loss: 1.3331 - val_output2_accuracy: 0.4726 - val_output2_loss: 1.2885\n",
      "Epoch 3/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.6051 - output1_accuracy: 0.4339 - output1_loss: 1.3327 - output2_accuracy: 0.4727 - output2_loss: 1.2724\n",
      "Epoch 3: Average accuracy improved to 0.4784, saving model to ./ACNN2/0.44-0.52-epoch03-loss2.58.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.6049 - output1_accuracy: 0.4340 - output1_loss: 1.3326 - output2_accuracy: 0.4728 - output2_loss: 1.2723 - val_loss: 2.5050 - val_output1_accuracy: 0.4393 - val_output1_loss: 1.3170 - val_output2_accuracy: 0.5174 - val_output2_loss: 1.1880\n",
      "Epoch 4/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.5203 - output1_accuracy: 0.4541 - output1_loss: 1.2990 - output2_accuracy: 0.5030 - output2_loss: 1.2213\n",
      "Epoch 4: Average accuracy improved to 0.5072, saving model to ./ACNN2/0.48-0.53-epoch04-loss2.50.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5202 - output1_accuracy: 0.4541 - output1_loss: 1.2990 - output2_accuracy: 0.5030 - output2_loss: 1.2212 - val_loss: 2.3773 - val_output1_accuracy: 0.4808 - val_output1_loss: 1.2226 - val_output2_accuracy: 0.5337 - val_output2_loss: 1.1547\n",
      "Epoch 5/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4416 - output1_accuracy: 0.4649 - output1_loss: 1.2714 - output2_accuracy: 0.5293 - output2_loss: 1.1702\n",
      "Epoch 5: Average accuracy improved to 0.5091, saving model to ./ACNN2/0.47-0.55-epoch05-loss2.44.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.4416 - output1_accuracy: 0.4649 - output1_loss: 1.2715 - output2_accuracy: 0.5293 - output2_loss: 1.1701 - val_loss: 2.3970 - val_output1_accuracy: 0.4718 - val_output1_loss: 1.2536 - val_output2_accuracy: 0.5465 - val_output2_loss: 1.1434\n",
      "Epoch 6/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3934 - output1_accuracy: 0.4689 - output1_loss: 1.2651 - output2_accuracy: 0.5545 - output2_loss: 1.1283\n",
      "Epoch 6: Average accuracy improved to 0.5216, saving model to ./ACNN2/0.48-0.57-epoch06-loss2.39.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3934 - output1_accuracy: 0.4690 - output1_loss: 1.2651 - output2_accuracy: 0.5545 - output2_loss: 1.1282 - val_loss: 2.3216 - val_output1_accuracy: 0.4774 - val_output1_loss: 1.2293 - val_output2_accuracy: 0.5659 - val_output2_loss: 1.0924\n",
      "Epoch 7/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3388 - output1_accuracy: 0.4826 - output1_loss: 1.2373 - output2_accuracy: 0.5650 - output2_loss: 1.1016\n",
      "Epoch 7: Average accuracy improved to 0.5492, saving model to ./ACNN2/0.50-0.60-epoch07-loss2.34.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3388 - output1_accuracy: 0.4826 - output1_loss: 1.2373 - output2_accuracy: 0.5650 - output2_loss: 1.1016 - val_loss: 2.2493 - val_output1_accuracy: 0.5028 - val_output1_loss: 1.1999 - val_output2_accuracy: 0.5956 - val_output2_loss: 1.0495\n",
      "Epoch 8/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3319 - output1_accuracy: 0.4752 - output1_loss: 1.2445 - output2_accuracy: 0.5730 - output2_loss: 1.0874\n",
      "Epoch 8: Average accuracy improved to 0.5550, saving model to ./ACNN2/0.50-0.61-epoch08-loss2.32.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3319 - output1_accuracy: 0.4752 - output1_loss: 1.2445 - output2_accuracy: 0.5730 - output2_loss: 1.0874 - val_loss: 2.2027 - val_output1_accuracy: 0.5036 - val_output1_loss: 1.1925 - val_output2_accuracy: 0.6064 - val_output2_loss: 1.0102\n",
      "Epoch 9/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2937 - output1_accuracy: 0.4940 - output1_loss: 1.2212 - output2_accuracy: 0.5802 - output2_loss: 1.0724\n",
      "Epoch 9: Average accuracy improved to 0.5569, saving model to ./ACNN2/0.51-0.60-epoch09-loss2.29.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2937 - output1_accuracy: 0.4940 - output1_loss: 1.2212 - output2_accuracy: 0.5802 - output2_loss: 1.0724 - val_loss: 2.1965 - val_output1_accuracy: 0.5112 - val_output1_loss: 1.1795 - val_output2_accuracy: 0.6026 - val_output2_loss: 1.0170\n",
      "Epoch 10/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2713 - output1_accuracy: 0.4932 - output1_loss: 1.2186 - output2_accuracy: 0.5868 - output2_loss: 1.0526\n",
      "Epoch 10: Average accuracy improved to 0.5691, saving model to ./ACNN2/0.52-0.62-epoch10-loss2.26.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2712 - output1_accuracy: 0.4932 - output1_loss: 1.2186 - output2_accuracy: 0.5868 - output2_loss: 1.0526 - val_loss: 2.1597 - val_output1_accuracy: 0.5216 - val_output1_loss: 1.1734 - val_output2_accuracy: 0.6166 - val_output2_loss: 0.9863\n",
      "Epoch 11/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2218 - output1_accuracy: 0.5018 - output1_loss: 1.2010 - output2_accuracy: 0.6015 - output2_loss: 1.0208\n",
      "Epoch 11: Average accuracy did not improve (current: 0.5546, best: 0.5691)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2219 - output1_accuracy: 0.5018 - output1_loss: 1.2011 - output2_accuracy: 0.6015 - output2_loss: 1.0208 - val_loss: 2.1865 - val_output1_accuracy: 0.5024 - val_output1_loss: 1.1825 - val_output2_accuracy: 0.6068 - val_output2_loss: 1.0040\n",
      "Epoch 12/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2369 - output1_accuracy: 0.5022 - output1_loss: 1.1967 - output2_accuracy: 0.5947 - output2_loss: 1.0401\n",
      "Epoch 12: Average accuracy did not improve (current: 0.5635, best: 0.5691)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2368 - output1_accuracy: 0.5022 - output1_loss: 1.1967 - output2_accuracy: 0.5948 - output2_loss: 1.0401 - val_loss: 2.1702 - val_output1_accuracy: 0.5160 - val_output1_loss: 1.1685 - val_output2_accuracy: 0.6110 - val_output2_loss: 1.0017\n",
      "Epoch 13/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1956 - output1_accuracy: 0.5139 - output1_loss: 1.1865 - output2_accuracy: 0.6042 - output2_loss: 1.0091\n",
      "Epoch 13: Average accuracy improved to 0.5844, saving model to ./ACNN2/0.54-0.63-epoch13-loss2.20.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1956 - output1_accuracy: 0.5139 - output1_loss: 1.1865 - output2_accuracy: 0.6042 - output2_loss: 1.0091 - val_loss: 2.0639 - val_output1_accuracy: 0.5417 - val_output1_loss: 1.1106 - val_output2_accuracy: 0.6272 - val_output2_loss: 0.9532\n",
      "Epoch 14/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1684 - output1_accuracy: 0.5144 - output1_loss: 1.1836 - output2_accuracy: 0.6203 - output2_loss: 0.9847\n",
      "Epoch 14: Average accuracy did not improve (current: 0.5690, best: 0.5844)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1684 - output1_accuracy: 0.5144 - output1_loss: 1.1836 - output2_accuracy: 0.6203 - output2_loss: 0.9847 - val_loss: 2.1555 - val_output1_accuracy: 0.5090 - val_output1_loss: 1.1835 - val_output2_accuracy: 0.6290 - val_output2_loss: 0.9719\n",
      "Epoch 15/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1582 - output1_accuracy: 0.5187 - output1_loss: 1.1690 - output2_accuracy: 0.6192 - output2_loss: 0.9892\n",
      "Epoch 15: Average accuracy did not improve (current: 0.5817, best: 0.5844)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1582 - output1_accuracy: 0.5187 - output1_loss: 1.1690 - output2_accuracy: 0.6192 - output2_loss: 0.9892 - val_loss: 2.0784 - val_output1_accuracy: 0.5355 - val_output1_loss: 1.1345 - val_output2_accuracy: 0.6280 - val_output2_loss: 0.9439\n",
      "Epoch 16/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1454 - output1_accuracy: 0.5224 - output1_loss: 1.1659 - output2_accuracy: 0.6186 - output2_loss: 0.9794\n",
      "Epoch 16: Average accuracy did not improve (current: 0.5842, best: 0.5844)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1453 - output1_accuracy: 0.5223 - output1_loss: 1.1660 - output2_accuracy: 0.6186 - output2_loss: 0.9794 - val_loss: 2.0960 - val_output1_accuracy: 0.5489 - val_output1_loss: 1.1249 - val_output2_accuracy: 0.6196 - val_output2_loss: 0.9711\n",
      "Epoch 17/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1257 - output1_accuracy: 0.5257 - output1_loss: 1.1551 - output2_accuracy: 0.6277 - output2_loss: 0.9706\n",
      "Epoch 17: Average accuracy improved to 0.5881, saving model to ./ACNN2/0.54-0.63-epoch17-loss2.13.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.1258 - output1_accuracy: 0.5257 - output1_loss: 1.1552 - output2_accuracy: 0.6277 - output2_loss: 0.9706 - val_loss: 2.0560 - val_output1_accuracy: 0.5423 - val_output1_loss: 1.1068 - val_output2_accuracy: 0.6340 - val_output2_loss: 0.9492\n",
      "Epoch 18/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1242 - output1_accuracy: 0.5279 - output1_loss: 1.1533 - output2_accuracy: 0.6270 - output2_loss: 0.9709\n",
      "Epoch 18: Average accuracy did not improve (current: 0.5832, best: 0.5881)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.1242 - output1_accuracy: 0.5279 - output1_loss: 1.1533 - output2_accuracy: 0.6270 - output2_loss: 0.9709 - val_loss: 2.0567 - val_output1_accuracy: 0.5174 - val_output1_loss: 1.1486 - val_output2_accuracy: 0.6490 - val_output2_loss: 0.9081\n",
      "Epoch 19/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0970 - output1_accuracy: 0.5298 - output1_loss: 1.1515 - output2_accuracy: 0.6374 - output2_loss: 0.9454\n",
      "Epoch 19: Average accuracy improved to 0.6040, saving model to ./ACNN2/0.55-0.66-epoch19-loss2.10.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.0970 - output1_accuracy: 0.5298 - output1_loss: 1.1515 - output2_accuracy: 0.6374 - output2_loss: 0.9454 - val_loss: 1.9993 - val_output1_accuracy: 0.5505 - val_output1_loss: 1.0968 - val_output2_accuracy: 0.6575 - val_output2_loss: 0.9025\n",
      "Epoch 20/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0786 - output1_accuracy: 0.5407 - output1_loss: 1.1354 - output2_accuracy: 0.6372 - output2_loss: 0.9432\n",
      "Epoch 20: Average accuracy did not improve (current: 0.6035, best: 0.6040)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0787 - output1_accuracy: 0.5407 - output1_loss: 1.1355 - output2_accuracy: 0.6372 - output2_loss: 0.9432 - val_loss: 1.9849 - val_output1_accuracy: 0.5411 - val_output1_loss: 1.1270 - val_output2_accuracy: 0.6659 - val_output2_loss: 0.8579\n",
      "Epoch 21/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0704 - output1_accuracy: 0.5338 - output1_loss: 1.1400 - output2_accuracy: 0.6399 - output2_loss: 0.9303\n",
      "Epoch 21: Average accuracy did not improve (current: 0.5982, best: 0.6040)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0704 - output1_accuracy: 0.5338 - output1_loss: 1.1400 - output2_accuracy: 0.6399 - output2_loss: 0.9304 - val_loss: 2.0049 - val_output1_accuracy: 0.5435 - val_output1_loss: 1.1046 - val_output2_accuracy: 0.6528 - val_output2_loss: 0.9003\n",
      "Epoch 22/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0472 - output1_accuracy: 0.5390 - output1_loss: 1.1317 - output2_accuracy: 0.6493 - output2_loss: 0.9155\n",
      "Epoch 22: Average accuracy improved to 0.6174, saving model to ./ACNN2/0.56-0.67-epoch22-loss2.06.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0473 - output1_accuracy: 0.5390 - output1_loss: 1.1318 - output2_accuracy: 0.6493 - output2_loss: 0.9155 - val_loss: 1.9305 - val_output1_accuracy: 0.5637 - val_output1_loss: 1.0802 - val_output2_accuracy: 0.6711 - val_output2_loss: 0.8503\n",
      "Epoch 23/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0437 - output1_accuracy: 0.5353 - output1_loss: 1.1331 - output2_accuracy: 0.6509 - output2_loss: 0.9107\n",
      "Epoch 23: Average accuracy did not improve (current: 0.6156, best: 0.6174)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0437 - output1_accuracy: 0.5353 - output1_loss: 1.1331 - output2_accuracy: 0.6509 - output2_loss: 0.9107 - val_loss: 1.9377 - val_output1_accuracy: 0.5639 - val_output1_loss: 1.0724 - val_output2_accuracy: 0.6673 - val_output2_loss: 0.8653\n",
      "Epoch 24/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0602 - output1_accuracy: 0.5366 - output1_loss: 1.1408 - output2_accuracy: 0.6498 - output2_loss: 0.9194\n",
      "Epoch 24: Average accuracy did not improve (current: 0.6099, best: 0.6174)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0602 - output1_accuracy: 0.5366 - output1_loss: 1.1408 - output2_accuracy: 0.6498 - output2_loss: 0.9194 - val_loss: 1.9866 - val_output1_accuracy: 0.5435 - val_output1_loss: 1.1197 - val_output2_accuracy: 0.6763 - val_output2_loss: 0.8669\n",
      "Epoch 25/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0322 - output1_accuracy: 0.5430 - output1_loss: 1.1273 - output2_accuracy: 0.6566 - output2_loss: 0.9049\n",
      "Epoch 25: Average accuracy did not improve (current: 0.6158, best: 0.6174)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0322 - output1_accuracy: 0.5430 - output1_loss: 1.1273 - output2_accuracy: 0.6566 - output2_loss: 0.9049 - val_loss: 1.9574 - val_output1_accuracy: 0.5549 - val_output1_loss: 1.0987 - val_output2_accuracy: 0.6767 - val_output2_loss: 0.8588\n",
      "Epoch 26/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0232 - output1_accuracy: 0.5450 - output1_loss: 1.1194 - output2_accuracy: 0.6522 - output2_loss: 0.9037\n",
      "Epoch 26: Average accuracy improved to 0.6309, saving model to ./ACNN2/0.57-0.69-epoch26-loss2.02.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0232 - output1_accuracy: 0.5450 - output1_loss: 1.1195 - output2_accuracy: 0.6522 - output2_loss: 0.9037 - val_loss: 1.8940 - val_output1_accuracy: 0.5727 - val_output1_loss: 1.0612 - val_output2_accuracy: 0.6891 - val_output2_loss: 0.8328\n",
      "Epoch 27/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0208 - output1_accuracy: 0.5466 - output1_loss: 1.1186 - output2_accuracy: 0.6550 - output2_loss: 0.9022\n",
      "Epoch 27: Average accuracy did not improve (current: 0.6234, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0208 - output1_accuracy: 0.5466 - output1_loss: 1.1186 - output2_accuracy: 0.6550 - output2_loss: 0.9022 - val_loss: 1.9308 - val_output1_accuracy: 0.5635 - val_output1_loss: 1.0813 - val_output2_accuracy: 0.6833 - val_output2_loss: 0.8495\n",
      "Epoch 28/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0193 - output1_accuracy: 0.5513 - output1_loss: 1.1091 - output2_accuracy: 0.6488 - output2_loss: 0.9101\n",
      "Epoch 28: Average accuracy did not improve (current: 0.6169, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0193 - output1_accuracy: 0.5513 - output1_loss: 1.1091 - output2_accuracy: 0.6488 - output2_loss: 0.9101 - val_loss: 1.9385 - val_output1_accuracy: 0.5637 - val_output1_loss: 1.0682 - val_output2_accuracy: 0.6701 - val_output2_loss: 0.8703\n",
      "Epoch 29/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0062 - output1_accuracy: 0.5470 - output1_loss: 1.1101 - output2_accuracy: 0.6574 - output2_loss: 0.8961\n",
      "Epoch 29: Average accuracy did not improve (current: 0.6187, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0062 - output1_accuracy: 0.5470 - output1_loss: 1.1101 - output2_accuracy: 0.6574 - output2_loss: 0.8961 - val_loss: 1.9192 - val_output1_accuracy: 0.5581 - val_output1_loss: 1.0840 - val_output2_accuracy: 0.6793 - val_output2_loss: 0.8351\n",
      "Epoch 30/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0008 - output1_accuracy: 0.5494 - output1_loss: 1.1097 - output2_accuracy: 0.6596 - output2_loss: 0.8910\n",
      "Epoch 30: Average accuracy did not improve (current: 0.6132, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.0008 - output1_accuracy: 0.5494 - output1_loss: 1.1097 - output2_accuracy: 0.6597 - output2_loss: 0.8910 - val_loss: 1.9527 - val_output1_accuracy: 0.5377 - val_output1_loss: 1.1172 - val_output2_accuracy: 0.6887 - val_output2_loss: 0.8355\n",
      "Epoch 31/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9946 - output1_accuracy: 0.5563 - output1_loss: 1.1035 - output2_accuracy: 0.6597 - output2_loss: 0.8910\n",
      "Epoch 31: Average accuracy did not improve (current: 0.6274, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9946 - output1_accuracy: 0.5563 - output1_loss: 1.1035 - output2_accuracy: 0.6597 - output2_loss: 0.8910 - val_loss: 1.8875 - val_output1_accuracy: 0.5733 - val_output1_loss: 1.0550 - val_output2_accuracy: 0.6815 - val_output2_loss: 0.8325\n",
      "Epoch 32/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9741 - output1_accuracy: 0.5529 - output1_loss: 1.1011 - output2_accuracy: 0.6669 - output2_loss: 0.8730\n",
      "Epoch 32: Average accuracy did not improve (current: 0.6000, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9741 - output1_accuracy: 0.5529 - output1_loss: 1.1011 - output2_accuracy: 0.6669 - output2_loss: 0.8730 - val_loss: 1.9637 - val_output1_accuracy: 0.5190 - val_output1_loss: 1.1299 - val_output2_accuracy: 0.6809 - val_output2_loss: 0.8338\n",
      "Epoch 33/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9829 - output1_accuracy: 0.5531 - output1_loss: 1.0947 - output2_accuracy: 0.6620 - output2_loss: 0.8882\n",
      "Epoch 33: Average accuracy did not improve (current: 0.6134, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9829 - output1_accuracy: 0.5531 - output1_loss: 1.0946 - output2_accuracy: 0.6620 - output2_loss: 0.8882 - val_loss: 1.9373 - val_output1_accuracy: 0.5397 - val_output1_loss: 1.1085 - val_output2_accuracy: 0.6871 - val_output2_loss: 0.8288\n",
      "Epoch 34/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9778 - output1_accuracy: 0.5531 - output1_loss: 1.1087 - output2_accuracy: 0.6691 - output2_loss: 0.8691\n",
      "Epoch 34: Average accuracy did not improve (current: 0.6201, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9778 - output1_accuracy: 0.5531 - output1_loss: 1.1087 - output2_accuracy: 0.6691 - output2_loss: 0.8692 - val_loss: 1.9260 - val_output1_accuracy: 0.5659 - val_output1_loss: 1.0728 - val_output2_accuracy: 0.6743 - val_output2_loss: 0.8532\n",
      "Epoch 35/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9490 - output1_accuracy: 0.5569 - output1_loss: 1.0905 - output2_accuracy: 0.6726 - output2_loss: 0.8586\n",
      "Epoch 35: Average accuracy did not improve (current: 0.6150, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9491 - output1_accuracy: 0.5569 - output1_loss: 1.0905 - output2_accuracy: 0.6726 - output2_loss: 0.8586 - val_loss: 1.9553 - val_output1_accuracy: 0.5499 - val_output1_loss: 1.1113 - val_output2_accuracy: 0.6801 - val_output2_loss: 0.8441\n",
      "Epoch 36/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9752 - output1_accuracy: 0.5579 - output1_loss: 1.0897 - output2_accuracy: 0.6617 - output2_loss: 0.8855\n",
      "Epoch 36: Average accuracy did not improve (current: 0.6090, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9752 - output1_accuracy: 0.5579 - output1_loss: 1.0897 - output2_accuracy: 0.6617 - output2_loss: 0.8855 - val_loss: 1.9547 - val_output1_accuracy: 0.5531 - val_output1_loss: 1.0886 - val_output2_accuracy: 0.6649 - val_output2_loss: 0.8661\n",
      "Epoch 37/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9531 - output1_accuracy: 0.5575 - output1_loss: 1.0902 - output2_accuracy: 0.6721 - output2_loss: 0.8629\n",
      "Epoch 37: Average accuracy did not improve (current: 0.6309, best: 0.6309)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9530 - output1_accuracy: 0.5576 - output1_loss: 1.0901 - output2_accuracy: 0.6721 - output2_loss: 0.8629 - val_loss: 1.8696 - val_output1_accuracy: 0.5855 - val_output1_loss: 1.0336 - val_output2_accuracy: 0.6763 - val_output2_loss: 0.8359\n",
      "Epoch 38/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9266 - output1_accuracy: 0.5612 - output1_loss: 1.0787 - output2_accuracy: 0.6766 - output2_loss: 0.8479\n",
      "Epoch 38: Average accuracy improved to 0.6317, saving model to ./ACNN2/0.59-0.67-epoch38-loss1.93.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9266 - output1_accuracy: 0.5612 - output1_loss: 1.0787 - output2_accuracy: 0.6766 - output2_loss: 0.8479 - val_loss: 1.8562 - val_output1_accuracy: 0.5905 - val_output1_loss: 1.0235 - val_output2_accuracy: 0.6729 - val_output2_loss: 0.8327\n",
      "Epoch 39/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9395 - output1_accuracy: 0.5611 - output1_loss: 1.0821 - output2_accuracy: 0.6748 - output2_loss: 0.8574\n",
      "Epoch 39: Average accuracy did not improve (current: 0.6247, best: 0.6317)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9395 - output1_accuracy: 0.5611 - output1_loss: 1.0821 - output2_accuracy: 0.6748 - output2_loss: 0.8574 - val_loss: 1.9042 - val_output1_accuracy: 0.5605 - val_output1_loss: 1.0791 - val_output2_accuracy: 0.6889 - val_output2_loss: 0.8251\n",
      "Epoch 40/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9261 - output1_accuracy: 0.5715 - output1_loss: 1.0711 - output2_accuracy: 0.6762 - output2_loss: 0.8550\n",
      "Epoch 40: Average accuracy improved to 0.6433, saving model to ./ACNN2/0.59-0.70-epoch40-loss1.93.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9261 - output1_accuracy: 0.5715 - output1_loss: 1.0711 - output2_accuracy: 0.6762 - output2_loss: 0.8550 - val_loss: 1.8240 - val_output1_accuracy: 0.5893 - val_output1_loss: 1.0362 - val_output2_accuracy: 0.6973 - val_output2_loss: 0.7878\n",
      "Epoch 41/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9225 - output1_accuracy: 0.5697 - output1_loss: 1.0726 - output2_accuracy: 0.6775 - output2_loss: 0.8499\n",
      "Epoch 41: Average accuracy improved to 0.6504, saving model to ./ACNN2/0.60-0.70-epoch41-loss1.92.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.9225 - output1_accuracy: 0.5697 - output1_loss: 1.0726 - output2_accuracy: 0.6775 - output2_loss: 0.8499 - val_loss: 1.8073 - val_output1_accuracy: 0.5984 - val_output1_loss: 1.0138 - val_output2_accuracy: 0.7025 - val_output2_loss: 0.7935\n",
      "Epoch 42/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9218 - output1_accuracy: 0.5709 - output1_loss: 1.0607 - output2_accuracy: 0.6727 - output2_loss: 0.8612\n",
      "Epoch 42: Average accuracy did not improve (current: 0.6476, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9218 - output1_accuracy: 0.5709 - output1_loss: 1.0607 - output2_accuracy: 0.6727 - output2_loss: 0.8612 - val_loss: 1.8102 - val_output1_accuracy: 0.5940 - val_output1_loss: 1.0231 - val_output2_accuracy: 0.7013 - val_output2_loss: 0.7870\n",
      "Epoch 43/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9220 - output1_accuracy: 0.5713 - output1_loss: 1.0664 - output2_accuracy: 0.6748 - output2_loss: 0.8555\n",
      "Epoch 43: Average accuracy did not improve (current: 0.6398, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9219 - output1_accuracy: 0.5713 - output1_loss: 1.0664 - output2_accuracy: 0.6748 - output2_loss: 0.8555 - val_loss: 1.8344 - val_output1_accuracy: 0.5925 - val_output1_loss: 1.0099 - val_output2_accuracy: 0.6871 - val_output2_loss: 0.8246\n",
      "Epoch 44/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9164 - output1_accuracy: 0.5681 - output1_loss: 1.0685 - output2_accuracy: 0.6776 - output2_loss: 0.8479\n",
      "Epoch 44: Average accuracy did not improve (current: 0.6495, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9164 - output1_accuracy: 0.5681 - output1_loss: 1.0685 - output2_accuracy: 0.6776 - output2_loss: 0.8479 - val_loss: 1.8071 - val_output1_accuracy: 0.6050 - val_output1_loss: 1.0055 - val_output2_accuracy: 0.6941 - val_output2_loss: 0.8015\n",
      "Epoch 45/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9072 - output1_accuracy: 0.5680 - output1_loss: 1.0657 - output2_accuracy: 0.6807 - output2_loss: 0.8415\n",
      "Epoch 45: Average accuracy did not improve (current: 0.6424, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9072 - output1_accuracy: 0.5680 - output1_loss: 1.0657 - output2_accuracy: 0.6806 - output2_loss: 0.8415 - val_loss: 1.8524 - val_output1_accuracy: 0.5984 - val_output1_loss: 1.0079 - val_output2_accuracy: 0.6865 - val_output2_loss: 0.8444\n",
      "Epoch 46/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9019 - output1_accuracy: 0.5713 - output1_loss: 1.0660 - output2_accuracy: 0.6819 - output2_loss: 0.8359\n",
      "Epoch 46: Average accuracy did not improve (current: 0.6373, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9019 - output1_accuracy: 0.5713 - output1_loss: 1.0660 - output2_accuracy: 0.6819 - output2_loss: 0.8359 - val_loss: 1.8384 - val_output1_accuracy: 0.5861 - val_output1_loss: 1.0357 - val_output2_accuracy: 0.6885 - val_output2_loss: 0.8027\n",
      "Epoch 47/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9048 - output1_accuracy: 0.5726 - output1_loss: 1.0568 - output2_accuracy: 0.6771 - output2_loss: 0.8480\n",
      "Epoch 47: Average accuracy did not improve (current: 0.6317, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.9049 - output1_accuracy: 0.5726 - output1_loss: 1.0568 - output2_accuracy: 0.6771 - output2_loss: 0.8480 - val_loss: 1.8892 - val_output1_accuracy: 0.5885 - val_output1_loss: 1.0253 - val_output2_accuracy: 0.6749 - val_output2_loss: 0.8639\n",
      "Epoch 48/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8931 - output1_accuracy: 0.5745 - output1_loss: 1.0550 - output2_accuracy: 0.6799 - output2_loss: 0.8381\n",
      "Epoch 48: Average accuracy did not improve (current: 0.6435, best: 0.6504)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8931 - output1_accuracy: 0.5745 - output1_loss: 1.0550 - output2_accuracy: 0.6799 - output2_loss: 0.8381 - val_loss: 1.8025 - val_output1_accuracy: 0.5933 - val_output1_loss: 1.0056 - val_output2_accuracy: 0.6937 - val_output2_loss: 0.7970\n",
      "Epoch 49/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8974 - output1_accuracy: 0.5746 - output1_loss: 1.0615 - output2_accuracy: 0.6850 - output2_loss: 0.8359\n",
      "Epoch 49: Average accuracy improved to 0.6591, saving model to ./ACNN2/0.61-0.71-epoch49-loss1.89.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8973 - output1_accuracy: 0.5746 - output1_loss: 1.0614 - output2_accuracy: 0.6850 - output2_loss: 0.8359 - val_loss: 1.7677 - val_output1_accuracy: 0.6096 - val_output1_loss: 0.9881 - val_output2_accuracy: 0.7085 - val_output2_loss: 0.7796\n",
      "Epoch 50/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8737 - output1_accuracy: 0.5748 - output1_loss: 1.0531 - output2_accuracy: 0.6916 - output2_loss: 0.8206\n",
      "Epoch 50: Average accuracy did not improve (current: 0.6408, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8737 - output1_accuracy: 0.5748 - output1_loss: 1.0531 - output2_accuracy: 0.6916 - output2_loss: 0.8207 - val_loss: 1.8093 - val_output1_accuracy: 0.5825 - val_output1_loss: 1.0267 - val_output2_accuracy: 0.6991 - val_output2_loss: 0.7826\n",
      "Epoch 51/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8933 - output1_accuracy: 0.5754 - output1_loss: 1.0536 - output2_accuracy: 0.6847 - output2_loss: 0.8397\n",
      "Epoch 51: Average accuracy did not improve (current: 0.6380, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8933 - output1_accuracy: 0.5754 - output1_loss: 1.0536 - output2_accuracy: 0.6847 - output2_loss: 0.8397 - val_loss: 1.8265 - val_output1_accuracy: 0.5847 - val_output1_loss: 1.0192 - val_output2_accuracy: 0.6913 - val_output2_loss: 0.8073\n",
      "Epoch 52/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8968 - output1_accuracy: 0.5794 - output1_loss: 1.0521 - output2_accuracy: 0.6797 - output2_loss: 0.8447\n",
      "Epoch 52: Average accuracy did not improve (current: 0.6409, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8967 - output1_accuracy: 0.5794 - output1_loss: 1.0521 - output2_accuracy: 0.6797 - output2_loss: 0.8446 - val_loss: 1.8364 - val_output1_accuracy: 0.5923 - val_output1_loss: 1.0068 - val_output2_accuracy: 0.6895 - val_output2_loss: 0.8296\n",
      "Epoch 53/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8654 - output1_accuracy: 0.5816 - output1_loss: 1.0413 - output2_accuracy: 0.6927 - output2_loss: 0.8241\n",
      "Epoch 53: Average accuracy did not improve (current: 0.6383, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 1.8654 - output1_accuracy: 0.5816 - output1_loss: 1.0413 - output2_accuracy: 0.6927 - output2_loss: 0.8241 - val_loss: 1.8210 - val_output1_accuracy: 0.5717 - val_output1_loss: 1.0539 - val_output2_accuracy: 0.7049 - val_output2_loss: 0.7671\n",
      "Epoch 54/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8588 - output1_accuracy: 0.5807 - output1_loss: 1.0330 - output2_accuracy: 0.6871 - output2_loss: 0.8258\n",
      "Epoch 54: Average accuracy did not improve (current: 0.6264, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 1.8588 - output1_accuracy: 0.5807 - output1_loss: 1.0331 - output2_accuracy: 0.6871 - output2_loss: 0.8258 - val_loss: 1.8713 - val_output1_accuracy: 0.5651 - val_output1_loss: 1.0677 - val_output2_accuracy: 0.6877 - val_output2_loss: 0.8036\n",
      "Epoch 55/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8829 - output1_accuracy: 0.5781 - output1_loss: 1.0492 - output2_accuracy: 0.6856 - output2_loss: 0.8337\n",
      "Epoch 55: Average accuracy did not improve (current: 0.6579, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8829 - output1_accuracy: 0.5781 - output1_loss: 1.0492 - output2_accuracy: 0.6856 - output2_loss: 0.8336 - val_loss: 1.7660 - val_output1_accuracy: 0.6068 - val_output1_loss: 0.9944 - val_output2_accuracy: 0.7089 - val_output2_loss: 0.7715\n",
      "Epoch 56/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8781 - output1_accuracy: 0.5783 - output1_loss: 1.0506 - output2_accuracy: 0.6880 - output2_loss: 0.8275\n",
      "Epoch 56: Average accuracy did not improve (current: 0.6492, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8781 - output1_accuracy: 0.5783 - output1_loss: 1.0506 - output2_accuracy: 0.6880 - output2_loss: 0.8275 - val_loss: 1.8099 - val_output1_accuracy: 0.5929 - val_output1_loss: 1.0214 - val_output2_accuracy: 0.7055 - val_output2_loss: 0.7885\n",
      "Epoch 57/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8480 - output1_accuracy: 0.5848 - output1_loss: 1.0276 - output2_accuracy: 0.6871 - output2_loss: 0.8205\n",
      "Epoch 57: Average accuracy did not improve (current: 0.6528, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8480 - output1_accuracy: 0.5849 - output1_loss: 1.0276 - output2_accuracy: 0.6871 - output2_loss: 0.8205 - val_loss: 1.7759 - val_output1_accuracy: 0.5927 - val_output1_loss: 1.0131 - val_output2_accuracy: 0.7129 - val_output2_loss: 0.7628\n",
      "Epoch 58/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8677 - output1_accuracy: 0.5801 - output1_loss: 1.0483 - output2_accuracy: 0.6912 - output2_loss: 0.8194\n",
      "Epoch 58: Average accuracy did not improve (current: 0.6564, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8677 - output1_accuracy: 0.5801 - output1_loss: 1.0483 - output2_accuracy: 0.6912 - output2_loss: 0.8194 - val_loss: 1.7497 - val_output1_accuracy: 0.5931 - val_output1_loss: 1.0052 - val_output2_accuracy: 0.7196 - val_output2_loss: 0.7444\n",
      "Epoch 59/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8729 - output1_accuracy: 0.5796 - output1_loss: 1.0465 - output2_accuracy: 0.6910 - output2_loss: 0.8263\n",
      "Epoch 59: Average accuracy did not improve (current: 0.6509, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8728 - output1_accuracy: 0.5796 - output1_loss: 1.0465 - output2_accuracy: 0.6910 - output2_loss: 0.8263 - val_loss: 1.8020 - val_output1_accuracy: 0.5964 - val_output1_loss: 1.0208 - val_output2_accuracy: 0.7055 - val_output2_loss: 0.7811\n",
      "Epoch 60/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8521 - output1_accuracy: 0.5837 - output1_loss: 1.0383 - output2_accuracy: 0.6938 - output2_loss: 0.8138\n",
      "Epoch 60: Average accuracy did not improve (current: 0.6585, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8521 - output1_accuracy: 0.5837 - output1_loss: 1.0383 - output2_accuracy: 0.6938 - output2_loss: 0.8139 - val_loss: 1.7603 - val_output1_accuracy: 0.6104 - val_output1_loss: 0.9844 - val_output2_accuracy: 0.7065 - val_output2_loss: 0.7760\n",
      "Epoch 61/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8324 - output1_accuracy: 0.5857 - output1_loss: 1.0264 - output2_accuracy: 0.6962 - output2_loss: 0.8059\n",
      "Epoch 61: Average accuracy did not improve (current: 0.6470, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8325 - output1_accuracy: 0.5857 - output1_loss: 1.0265 - output2_accuracy: 0.6962 - output2_loss: 0.8060 - val_loss: 1.7639 - val_output1_accuracy: 0.5960 - val_output1_loss: 0.9880 - val_output2_accuracy: 0.6981 - val_output2_loss: 0.7760\n",
      "Epoch 62/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8432 - output1_accuracy: 0.5876 - output1_loss: 1.0241 - output2_accuracy: 0.6914 - output2_loss: 0.8192\n",
      "Epoch 62: Average accuracy did not improve (current: 0.6509, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8432 - output1_accuracy: 0.5876 - output1_loss: 1.0241 - output2_accuracy: 0.6914 - output2_loss: 0.8192 - val_loss: 1.8148 - val_output1_accuracy: 0.6038 - val_output1_loss: 1.0018 - val_output2_accuracy: 0.6981 - val_output2_loss: 0.8130\n",
      "Epoch 63/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8511 - output1_accuracy: 0.5875 - output1_loss: 1.0363 - output2_accuracy: 0.6955 - output2_loss: 0.8148\n",
      "Epoch 63: Average accuracy did not improve (current: 0.6441, best: 0.6591)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8511 - output1_accuracy: 0.5875 - output1_loss: 1.0363 - output2_accuracy: 0.6955 - output2_loss: 0.8148 - val_loss: 1.8026 - val_output1_accuracy: 0.5799 - val_output1_loss: 1.0292 - val_output2_accuracy: 0.7083 - val_output2_loss: 0.7734\n",
      "Epoch 64/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8608 - output1_accuracy: 0.5806 - output1_loss: 1.0396 - output2_accuracy: 0.6887 - output2_loss: 0.8212\n",
      "Epoch 64: Average accuracy improved to 0.6640, saving model to ./ACNN2/0.61-0.72-epoch64-loss1.85.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8607 - output1_accuracy: 0.5807 - output1_loss: 1.0396 - output2_accuracy: 0.6887 - output2_loss: 0.8211 - val_loss: 1.7543 - val_output1_accuracy: 0.6080 - val_output1_loss: 0.9990 - val_output2_accuracy: 0.7200 - val_output2_loss: 0.7553\n",
      "Epoch 65/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8204 - output1_accuracy: 0.5933 - output1_loss: 1.0165 - output2_accuracy: 0.6998 - output2_loss: 0.8039\n",
      "Epoch 65: Average accuracy did not improve (current: 0.6589, best: 0.6640)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8204 - output1_accuracy: 0.5933 - output1_loss: 1.0165 - output2_accuracy: 0.6998 - output2_loss: 0.8039 - val_loss: 1.7800 - val_output1_accuracy: 0.6074 - val_output1_loss: 0.9952 - val_output2_accuracy: 0.7103 - val_output2_loss: 0.7848\n",
      "Epoch 66/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8295 - output1_accuracy: 0.5950 - output1_loss: 1.0154 - output2_accuracy: 0.6955 - output2_loss: 0.8141\n",
      "Epoch 66: Average accuracy did not improve (current: 0.6558, best: 0.6640)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.8295 - output1_accuracy: 0.5950 - output1_loss: 1.0154 - output2_accuracy: 0.6955 - output2_loss: 0.8141 - val_loss: 1.7566 - val_output1_accuracy: 0.5946 - val_output1_loss: 1.0005 - val_output2_accuracy: 0.7171 - val_output2_loss: 0.7561\n",
      "Epoch 67/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8226 - output1_accuracy: 0.5898 - output1_loss: 1.0236 - output2_accuracy: 0.7009 - output2_loss: 0.7990\n",
      "Epoch 67: Average accuracy did not improve (current: 0.6582, best: 0.6640)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8226 - output1_accuracy: 0.5898 - output1_loss: 1.0236 - output2_accuracy: 0.7009 - output2_loss: 0.7990 - val_loss: 1.7566 - val_output1_accuracy: 0.6070 - val_output1_loss: 0.9897 - val_output2_accuracy: 0.7093 - val_output2_loss: 0.7669\n",
      "Epoch 68/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8172 - output1_accuracy: 0.5888 - output1_loss: 1.0257 - output2_accuracy: 0.7019 - output2_loss: 0.7915\n",
      "Epoch 68: Average accuracy did not improve (current: 0.6483, best: 0.6640)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.8172 - output1_accuracy: 0.5888 - output1_loss: 1.0257 - output2_accuracy: 0.7018 - output2_loss: 0.7915 - val_loss: 1.7931 - val_output1_accuracy: 0.5887 - val_output1_loss: 1.0368 - val_output2_accuracy: 0.7079 - val_output2_loss: 0.7563\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n"
     ]
    }
   ],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./ACNN2/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7978636801242829\n",
      "standard deviation =  0.002850393049580842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = model.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to fine tune without random somehow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736615949.920146   17527 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13499 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:0a:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "def ACCN3(): # Adds dropout\n",
    "    # Input CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    x = layers.Dropout(0.2)\n",
    "    # Data Augmentation\n",
    "    # x = layers.RandomFlip(\"horizontal\")(x)\n",
    "    # x = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(x)\n",
    "    # x = layers.Normalization()(x)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    # Classifers\n",
    "    x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "\n",
    "    # # Feature Extractor\n",
    "    # x = layers.Conv2D(96, (3,3), activation='relu')(inputs\n",
    "\n",
    "    # x1 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # print(x1.shape)\n",
    "    # x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    # print(x1.shape)\n",
    "    # output1 = layers.Activation('softmax', name='output1')(x1)\n",
    "    # print(output1.shape)\n",
    "    # x2 = layers.Conv2D(5, (2,2), activation='relu')(x)\n",
    "    # x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    # output2 = layers.Activation('softmax', name='output2')(x2)\n",
    "\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN3',\n",
    "        )\n",
    "    return model\n",
    "\n",
    "K.clear_session()\n",
    "model = ACCN3()\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2188 - output1_accuracy: 0.2086 - output1_loss: 1.6095 - output2_accuracy: 0.2095 - output2_loss: 1.6093\n",
      "Epoch 1: Average accuracy improved to 0.2490, saving model to ./ACNN3/0.24-0.25-epoch01-loss3.22.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 3.2188 - output1_accuracy: 0.2086 - output1_loss: 1.6095 - output2_accuracy: 0.2095 - output2_loss: 1.6093 - val_loss: 3.2170 - val_output1_accuracy: 0.2444 - val_output1_loss: 1.6089 - val_output2_accuracy: 0.2536 - val_output2_loss: 1.6081\n",
      "Epoch 2/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2169 - output1_accuracy: 0.2372 - output1_loss: 1.6087 - output2_accuracy: 0.2498 - output2_loss: 1.6082\n",
      "Epoch 2: Average accuracy improved to 0.2904, saving model to ./ACNN3/0.27-0.31-epoch02-loss3.22.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.2169 - output1_accuracy: 0.2372 - output1_loss: 1.6087 - output2_accuracy: 0.2499 - output2_loss: 1.6082 - val_loss: 3.2117 - val_output1_accuracy: 0.2744 - val_output1_loss: 1.6064 - val_output2_accuracy: 0.3063 - val_output2_loss: 1.6052\n",
      "Epoch 3/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2099 - output1_accuracy: 0.2542 - output1_loss: 1.6055 - output2_accuracy: 0.2922 - output2_loss: 1.6044\n",
      "Epoch 3: Average accuracy did not improve (current: 0.2882, best: 0.2904)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 3.2099 - output1_accuracy: 0.2542 - output1_loss: 1.6055 - output2_accuracy: 0.2922 - output2_loss: 1.6044 - val_loss: 3.1860 - val_output1_accuracy: 0.2853 - val_output1_loss: 1.5957 - val_output2_accuracy: 0.2911 - val_output2_loss: 1.5903\n",
      "Epoch 4/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1564 - output1_accuracy: 0.2829 - output1_loss: 1.5819 - output2_accuracy: 0.2990 - output2_loss: 1.5746\n",
      "Epoch 4: Average accuracy improved to 0.3141, saving model to ./ACNN3/0.31-0.32-epoch04-loss3.11.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 3.1562 - output1_accuracy: 0.2829 - output1_loss: 1.5818 - output2_accuracy: 0.2990 - output2_loss: 1.5744 - val_loss: 3.0236 - val_output1_accuracy: 0.3091 - val_output1_loss: 1.5163 - val_output2_accuracy: 0.3191 - val_output2_loss: 1.5073\n",
      "Epoch 5/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0075 - output1_accuracy: 0.3111 - output1_loss: 1.5197 - output2_accuracy: 0.3341 - output2_loss: 1.4878\n",
      "Epoch 5: Average accuracy improved to 0.3361, saving model to ./ACNN3/0.33-0.34-epoch05-loss3.00.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 3.0075 - output1_accuracy: 0.3111 - output1_loss: 1.5197 - output2_accuracy: 0.3341 - output2_loss: 1.4878 - val_loss: 2.9756 - val_output1_accuracy: 0.3325 - val_output1_loss: 1.4959 - val_output2_accuracy: 0.3397 - val_output2_loss: 1.4797\n",
      "Epoch 6/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9886 - output1_accuracy: 0.3209 - output1_loss: 1.5127 - output2_accuracy: 0.3433 - output2_loss: 1.4759\n",
      "Epoch 6: Average accuracy improved to 0.3464, saving model to ./ACNN3/0.34-0.35-epoch06-loss2.98.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.9886 - output1_accuracy: 0.3210 - output1_loss: 1.5127 - output2_accuracy: 0.3433 - output2_loss: 1.4759 - val_loss: 2.9559 - val_output1_accuracy: 0.3442 - val_output1_loss: 1.4867 - val_output2_accuracy: 0.3486 - val_output2_loss: 1.4692\n",
      "Epoch 7/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.9606 - output1_accuracy: 0.3408 - output1_loss: 1.4922 - output2_accuracy: 0.3510 - output2_loss: 1.4684\n",
      "Epoch 7: Average accuracy improved to 0.3569, saving model to ./ACNN3/0.35-0.36-epoch07-loss2.95.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.9606 - output1_accuracy: 0.3408 - output1_loss: 1.4922 - output2_accuracy: 0.3510 - output2_loss: 1.4684 - val_loss: 2.9162 - val_output1_accuracy: 0.3508 - val_output1_loss: 1.4626 - val_output2_accuracy: 0.3630 - val_output2_loss: 1.4536\n",
      "Epoch 8/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.9249 - output1_accuracy: 0.3532 - output1_loss: 1.4752 - output2_accuracy: 0.3603 - output2_loss: 1.4497\n",
      "Epoch 8: Average accuracy did not improve (current: 0.3542, best: 0.3569)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.9249 - output1_accuracy: 0.3532 - output1_loss: 1.4752 - output2_accuracy: 0.3603 - output2_loss: 1.4497 - val_loss: 2.9198 - val_output1_accuracy: 0.3351 - val_output1_loss: 1.4809 - val_output2_accuracy: 0.3732 - val_output2_loss: 1.4389\n",
      "Epoch 9/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9083 - output1_accuracy: 0.3512 - output1_loss: 1.4728 - output2_accuracy: 0.3739 - output2_loss: 1.4354\n",
      "Epoch 9: Average accuracy improved to 0.3716, saving model to ./ACNN3/0.36-0.38-epoch09-loss2.90.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.9082 - output1_accuracy: 0.3512 - output1_loss: 1.4728 - output2_accuracy: 0.3739 - output2_loss: 1.4354 - val_loss: 2.8812 - val_output1_accuracy: 0.3640 - val_output1_loss: 1.4511 - val_output2_accuracy: 0.3792 - val_output2_loss: 1.4301\n",
      "Epoch 10/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8789 - output1_accuracy: 0.3711 - output1_loss: 1.4532 - output2_accuracy: 0.3863 - output2_loss: 1.4257\n",
      "Epoch 10: Average accuracy improved to 0.3820, saving model to ./ACNN3/0.38-0.39-epoch10-loss2.87.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.8789 - output1_accuracy: 0.3711 - output1_loss: 1.4532 - output2_accuracy: 0.3863 - output2_loss: 1.4257 - val_loss: 2.8469 - val_output1_accuracy: 0.3772 - val_output1_loss: 1.4320 - val_output2_accuracy: 0.3868 - val_output2_loss: 1.4148\n",
      "Epoch 11/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8635 - output1_accuracy: 0.3768 - output1_loss: 1.4417 - output2_accuracy: 0.3903 - output2_loss: 1.4219\n",
      "Epoch 11: Average accuracy improved to 0.3887, saving model to ./ACNN3/0.36-0.41-epoch11-loss2.85.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.8634 - output1_accuracy: 0.3768 - output1_loss: 1.4416 - output2_accuracy: 0.3904 - output2_loss: 1.4218 - val_loss: 2.8434 - val_output1_accuracy: 0.3642 - val_output1_loss: 1.4454 - val_output2_accuracy: 0.4133 - val_output2_loss: 1.3980\n",
      "Epoch 12/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8332 - output1_accuracy: 0.3778 - output1_loss: 1.4313 - output2_accuracy: 0.4055 - output2_loss: 1.4019\n",
      "Epoch 12: Average accuracy improved to 0.3994, saving model to ./ACNN3/0.37-0.42-epoch12-loss2.82.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.8331 - output1_accuracy: 0.3778 - output1_loss: 1.4313 - output2_accuracy: 0.4055 - output2_loss: 1.4018 - val_loss: 2.8035 - val_output1_accuracy: 0.3748 - val_output1_loss: 1.4275 - val_output2_accuracy: 0.4241 - val_output2_loss: 1.3761\n",
      "Epoch 13/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8153 - output1_accuracy: 0.3934 - output1_loss: 1.4213 - output2_accuracy: 0.4078 - output2_loss: 1.3940\n",
      "Epoch 13: Average accuracy improved to 0.4000, saving model to ./ACNN3/0.38-0.42-epoch13-loss2.81.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.8153 - output1_accuracy: 0.3933 - output1_loss: 1.4213 - output2_accuracy: 0.4078 - output2_loss: 1.3940 - val_loss: 2.7816 - val_output1_accuracy: 0.3788 - val_output1_loss: 1.4145 - val_output2_accuracy: 0.4213 - val_output2_loss: 1.3670\n",
      "Epoch 14/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7987 - output1_accuracy: 0.3887 - output1_loss: 1.4205 - output2_accuracy: 0.4161 - output2_loss: 1.3782\n",
      "Epoch 14: Average accuracy improved to 0.4051, saving model to ./ACNN3/0.38-0.43-epoch14-loss2.79.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.7986 - output1_accuracy: 0.3887 - output1_loss: 1.4205 - output2_accuracy: 0.4161 - output2_loss: 1.3781 - val_loss: 2.7707 - val_output1_accuracy: 0.3840 - val_output1_loss: 1.4087 - val_output2_accuracy: 0.4263 - val_output2_loss: 1.3620\n",
      "Epoch 15/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7843 - output1_accuracy: 0.3953 - output1_loss: 1.4125 - output2_accuracy: 0.4230 - output2_loss: 1.3718\n",
      "Epoch 15: Average accuracy improved to 0.4061, saving model to ./ACNN3/0.38-0.43-epoch15-loss2.78.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.7843 - output1_accuracy: 0.3953 - output1_loss: 1.4125 - output2_accuracy: 0.4230 - output2_loss: 1.3718 - val_loss: 2.7658 - val_output1_accuracy: 0.3846 - val_output1_loss: 1.3994 - val_output2_accuracy: 0.4277 - val_output2_loss: 1.3665\n",
      "Epoch 16/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7671 - output1_accuracy: 0.3963 - output1_loss: 1.4005 - output2_accuracy: 0.4236 - output2_loss: 1.3666\n",
      "Epoch 16: Average accuracy improved to 0.4241, saving model to ./ACNN3/0.41-0.44-epoch16-loss2.76.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.7671 - output1_accuracy: 0.3963 - output1_loss: 1.4004 - output2_accuracy: 0.4236 - output2_loss: 1.3666 - val_loss: 2.7272 - val_output1_accuracy: 0.4079 - val_output1_loss: 1.3826 - val_output2_accuracy: 0.4403 - val_output2_loss: 1.3446\n",
      "Epoch 17/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7421 - output1_accuracy: 0.4077 - output1_loss: 1.3890 - output2_accuracy: 0.4305 - output2_loss: 1.3532\n",
      "Epoch 17: Average accuracy did not improve (current: 0.4209, best: 0.4241)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.7422 - output1_accuracy: 0.4077 - output1_loss: 1.3890 - output2_accuracy: 0.4305 - output2_loss: 1.3532 - val_loss: 2.7222 - val_output1_accuracy: 0.4089 - val_output1_loss: 1.3748 - val_output2_accuracy: 0.4329 - val_output2_loss: 1.3474\n",
      "Epoch 18/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7394 - output1_accuracy: 0.4041 - output1_loss: 1.3945 - output2_accuracy: 0.4373 - output2_loss: 1.3449\n",
      "Epoch 18: Average accuracy improved to 0.4242, saving model to ./ACNN3/0.42-0.43-epoch18-loss2.74.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.7393 - output1_accuracy: 0.4041 - output1_loss: 1.3944 - output2_accuracy: 0.4372 - output2_loss: 1.3449 - val_loss: 2.7222 - val_output1_accuracy: 0.4169 - val_output1_loss: 1.3641 - val_output2_accuracy: 0.4315 - val_output2_loss: 1.3582\n",
      "Epoch 19/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7276 - output1_accuracy: 0.4112 - output1_loss: 1.3773 - output2_accuracy: 0.4337 - output2_loss: 1.3503\n",
      "Epoch 19: Average accuracy did not improve (current: 0.4237, best: 0.4242)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.7275 - output1_accuracy: 0.4113 - output1_loss: 1.3773 - output2_accuracy: 0.4337 - output2_loss: 1.3503 - val_loss: 2.7128 - val_output1_accuracy: 0.4149 - val_output1_loss: 1.3714 - val_output2_accuracy: 0.4325 - val_output2_loss: 1.3414\n",
      "Epoch 20/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7125 - output1_accuracy: 0.4166 - output1_loss: 1.3728 - output2_accuracy: 0.4392 - output2_loss: 1.3398\n",
      "Epoch 20: Average accuracy improved to 0.4351, saving model to ./ACNN3/0.43-0.44-epoch20-loss2.70.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.7124 - output1_accuracy: 0.4167 - output1_loss: 1.3727 - output2_accuracy: 0.4392 - output2_loss: 1.3397 - val_loss: 2.6941 - val_output1_accuracy: 0.4257 - val_output1_loss: 1.3541 - val_output2_accuracy: 0.4445 - val_output2_loss: 1.3400\n",
      "Epoch 21/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7020 - output1_accuracy: 0.4206 - output1_loss: 1.3649 - output2_accuracy: 0.4376 - output2_loss: 1.3372\n",
      "Epoch 21: Average accuracy improved to 0.4431, saving model to ./ACNN3/0.43-0.46-epoch21-loss2.70.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.7020 - output1_accuracy: 0.4206 - output1_loss: 1.3649 - output2_accuracy: 0.4377 - output2_loss: 1.3372 - val_loss: 2.6737 - val_output1_accuracy: 0.4285 - val_output1_loss: 1.3626 - val_output2_accuracy: 0.4577 - val_output2_loss: 1.3112\n",
      "Epoch 22/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6979 - output1_accuracy: 0.4213 - output1_loss: 1.3612 - output2_accuracy: 0.4471 - output2_loss: 1.3367\n",
      "Epoch 22: Average accuracy did not improve (current: 0.4386, best: 0.4431)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6979 - output1_accuracy: 0.4213 - output1_loss: 1.3612 - output2_accuracy: 0.4471 - output2_loss: 1.3367 - val_loss: 2.6773 - val_output1_accuracy: 0.4215 - val_output1_loss: 1.3594 - val_output2_accuracy: 0.4557 - val_output2_loss: 1.3179\n",
      "Epoch 23/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6831 - output1_accuracy: 0.4220 - output1_loss: 1.3604 - output2_accuracy: 0.4486 - output2_loss: 1.3228\n",
      "Epoch 23: Average accuracy improved to 0.4538, saving model to ./ACNN3/0.43-0.47-epoch23-loss2.68.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6831 - output1_accuracy: 0.4220 - output1_loss: 1.3603 - output2_accuracy: 0.4486 - output2_loss: 1.3228 - val_loss: 2.6267 - val_output1_accuracy: 0.4349 - val_output1_loss: 1.3404 - val_output2_accuracy: 0.4728 - val_output2_loss: 1.2863\n",
      "Epoch 24/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6703 - output1_accuracy: 0.4294 - output1_loss: 1.3537 - output2_accuracy: 0.4501 - output2_loss: 1.3167\n",
      "Epoch 24: Average accuracy did not improve (current: 0.4502, best: 0.4538)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.6703 - output1_accuracy: 0.4294 - output1_loss: 1.3536 - output2_accuracy: 0.4501 - output2_loss: 1.3167 - val_loss: 2.6245 - val_output1_accuracy: 0.4423 - val_output1_loss: 1.3239 - val_output2_accuracy: 0.4581 - val_output2_loss: 1.3006\n",
      "Epoch 25/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6632 - output1_accuracy: 0.4266 - output1_loss: 1.3492 - output2_accuracy: 0.4528 - output2_loss: 1.3140\n",
      "Epoch 25: Average accuracy did not improve (current: 0.4535, best: 0.4538)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.6632 - output1_accuracy: 0.4266 - output1_loss: 1.3492 - output2_accuracy: 0.4528 - output2_loss: 1.3140 - val_loss: 2.6175 - val_output1_accuracy: 0.4345 - val_output1_loss: 1.3325 - val_output2_accuracy: 0.4726 - val_output2_loss: 1.2850\n",
      "Epoch 26/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6630 - output1_accuracy: 0.4306 - output1_loss: 1.3443 - output2_accuracy: 0.4515 - output2_loss: 1.3187\n",
      "Epoch 26: Average accuracy did not improve (current: 0.4473, best: 0.4538)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6630 - output1_accuracy: 0.4306 - output1_loss: 1.3443 - output2_accuracy: 0.4515 - output2_loss: 1.3187 - val_loss: 2.6097 - val_output1_accuracy: 0.4367 - val_output1_loss: 1.3182 - val_output2_accuracy: 0.4579 - val_output2_loss: 1.2915\n",
      "Epoch 27/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6455 - output1_accuracy: 0.4339 - output1_loss: 1.3336 - output2_accuracy: 0.4507 - output2_loss: 1.3118\n",
      "Epoch 27: Average accuracy did not improve (current: 0.4479, best: 0.4538)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6454 - output1_accuracy: 0.4339 - output1_loss: 1.3336 - output2_accuracy: 0.4507 - output2_loss: 1.3118 - val_loss: 2.6170 - val_output1_accuracy: 0.4375 - val_output1_loss: 1.3237 - val_output2_accuracy: 0.4583 - val_output2_loss: 1.2933\n",
      "Epoch 28/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6355 - output1_accuracy: 0.4434 - output1_loss: 1.3286 - output2_accuracy: 0.4559 - output2_loss: 1.3068\n",
      "Epoch 28: Average accuracy did not improve (current: 0.4528, best: 0.4538)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6354 - output1_accuracy: 0.4433 - output1_loss: 1.3286 - output2_accuracy: 0.4559 - output2_loss: 1.3068 - val_loss: 2.6127 - val_output1_accuracy: 0.4483 - val_output1_loss: 1.3150 - val_output2_accuracy: 0.4573 - val_output2_loss: 1.2976\n",
      "Epoch 29/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6224 - output1_accuracy: 0.4462 - output1_loss: 1.3185 - output2_accuracy: 0.4574 - output2_loss: 1.3039\n",
      "Epoch 29: Average accuracy improved to 0.4559, saving model to ./ACNN3/0.44-0.47-epoch29-loss2.62.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6223 - output1_accuracy: 0.4462 - output1_loss: 1.3185 - output2_accuracy: 0.4574 - output2_loss: 1.3038 - val_loss: 2.6173 - val_output1_accuracy: 0.4399 - val_output1_loss: 1.3254 - val_output2_accuracy: 0.4720 - val_output2_loss: 1.2919\n",
      "Epoch 30/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6389 - output1_accuracy: 0.4363 - output1_loss: 1.3300 - output2_accuracy: 0.4564 - output2_loss: 1.3089\n",
      "Epoch 30: Average accuracy improved to 0.4614, saving model to ./ACNN3/0.45-0.47-epoch30-loss2.63.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6389 - output1_accuracy: 0.4363 - output1_loss: 1.3300 - output2_accuracy: 0.4564 - output2_loss: 1.3089 - val_loss: 2.5970 - val_output1_accuracy: 0.4497 - val_output1_loss: 1.3162 - val_output2_accuracy: 0.4732 - val_output2_loss: 1.2808\n",
      "Epoch 31/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6122 - output1_accuracy: 0.4467 - output1_loss: 1.3199 - output2_accuracy: 0.4616 - output2_loss: 1.2923\n",
      "Epoch 31: Average accuracy did not improve (current: 0.4542, best: 0.4614)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6122 - output1_accuracy: 0.4467 - output1_loss: 1.3199 - output2_accuracy: 0.4616 - output2_loss: 1.2923 - val_loss: 2.6050 - val_output1_accuracy: 0.4315 - val_output1_loss: 1.3217 - val_output2_accuracy: 0.4770 - val_output2_loss: 1.2833\n",
      "Epoch 32/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6160 - output1_accuracy: 0.4412 - output1_loss: 1.3256 - output2_accuracy: 0.4660 - output2_loss: 1.2904\n",
      "Epoch 32: Average accuracy did not improve (current: 0.4590, best: 0.4614)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6160 - output1_accuracy: 0.4412 - output1_loss: 1.3256 - output2_accuracy: 0.4660 - output2_loss: 1.2904 - val_loss: 2.5830 - val_output1_accuracy: 0.4505 - val_output1_loss: 1.2997 - val_output2_accuracy: 0.4675 - val_output2_loss: 1.2833\n",
      "Epoch 33/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6007 - output1_accuracy: 0.4476 - output1_loss: 1.3058 - output2_accuracy: 0.4638 - output2_loss: 1.2950\n",
      "Epoch 33: Average accuracy improved to 0.4622, saving model to ./ACNN3/0.44-0.48-epoch33-loss2.61.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.6008 - output1_accuracy: 0.4476 - output1_loss: 1.3059 - output2_accuracy: 0.4638 - output2_loss: 1.2949 - val_loss: 2.5680 - val_output1_accuracy: 0.4403 - val_output1_loss: 1.3028 - val_output2_accuracy: 0.4842 - val_output2_loss: 1.2652\n",
      "Epoch 34/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6025 - output1_accuracy: 0.4451 - output1_loss: 1.3139 - output2_accuracy: 0.4695 - output2_loss: 1.2886\n",
      "Epoch 34: Average accuracy improved to 0.4636, saving model to ./ACNN3/0.45-0.47-epoch34-loss2.60.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.6025 - output1_accuracy: 0.4451 - output1_loss: 1.3139 - output2_accuracy: 0.4695 - output2_loss: 1.2886 - val_loss: 2.5661 - val_output1_accuracy: 0.4527 - val_output1_loss: 1.2970 - val_output2_accuracy: 0.4746 - val_output2_loss: 1.2692\n",
      "Epoch 35/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5935 - output1_accuracy: 0.4488 - output1_loss: 1.3096 - output2_accuracy: 0.4685 - output2_loss: 1.2839\n",
      "Epoch 35: Average accuracy did not improve (current: 0.4579, best: 0.4636)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5936 - output1_accuracy: 0.4488 - output1_loss: 1.3096 - output2_accuracy: 0.4685 - output2_loss: 1.2839 - val_loss: 2.5802 - val_output1_accuracy: 0.4455 - val_output1_loss: 1.2982 - val_output2_accuracy: 0.4704 - val_output2_loss: 1.2820\n",
      "Epoch 36/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5886 - output1_accuracy: 0.4507 - output1_loss: 1.3112 - output2_accuracy: 0.4724 - output2_loss: 1.2774\n",
      "Epoch 36: Average accuracy improved to 0.4675, saving model to ./ACNN3/0.45-0.48-epoch36-loss2.59.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5886 - output1_accuracy: 0.4507 - output1_loss: 1.3112 - output2_accuracy: 0.4724 - output2_loss: 1.2774 - val_loss: 2.5635 - val_output1_accuracy: 0.4539 - val_output1_loss: 1.3027 - val_output2_accuracy: 0.4812 - val_output2_loss: 1.2608\n",
      "Epoch 37/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5830 - output1_accuracy: 0.4542 - output1_loss: 1.3034 - output2_accuracy: 0.4671 - output2_loss: 1.2796\n",
      "Epoch 37: Average accuracy improved to 0.4686, saving model to ./ACNN3/0.45-0.49-epoch37-loss2.59.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5830 - output1_accuracy: 0.4542 - output1_loss: 1.3034 - output2_accuracy: 0.4672 - output2_loss: 1.2796 - val_loss: 2.5853 - val_output1_accuracy: 0.4475 - val_output1_loss: 1.3202 - val_output2_accuracy: 0.4898 - val_output2_loss: 1.2651\n",
      "Epoch 38/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5726 - output1_accuracy: 0.4505 - output1_loss: 1.3033 - output2_accuracy: 0.4790 - output2_loss: 1.2693\n",
      "Epoch 38: Average accuracy did not improve (current: 0.4625, best: 0.4686)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5726 - output1_accuracy: 0.4505 - output1_loss: 1.3033 - output2_accuracy: 0.4789 - output2_loss: 1.2693 - val_loss: 2.5548 - val_output1_accuracy: 0.4523 - val_output1_loss: 1.2876 - val_output2_accuracy: 0.4728 - val_output2_loss: 1.2672\n",
      "Epoch 39/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5672 - output1_accuracy: 0.4542 - output1_loss: 1.3011 - output2_accuracy: 0.4796 - output2_loss: 1.2661\n",
      "Epoch 39: Average accuracy improved to 0.4743, saving model to ./ACNN3/0.46-0.49-epoch39-loss2.57.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5672 - output1_accuracy: 0.4542 - output1_loss: 1.3011 - output2_accuracy: 0.4796 - output2_loss: 1.2661 - val_loss: 2.5406 - val_output1_accuracy: 0.4555 - val_output1_loss: 1.2935 - val_output2_accuracy: 0.4930 - val_output2_loss: 1.2471\n",
      "Epoch 40/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5654 - output1_accuracy: 0.4573 - output1_loss: 1.2933 - output2_accuracy: 0.4774 - output2_loss: 1.2720\n",
      "Epoch 40: Average accuracy did not improve (current: 0.4628, best: 0.4743)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5654 - output1_accuracy: 0.4573 - output1_loss: 1.2933 - output2_accuracy: 0.4774 - output2_loss: 1.2720 - val_loss: 2.5720 - val_output1_accuracy: 0.4389 - val_output1_loss: 1.3162 - val_output2_accuracy: 0.4868 - val_output2_loss: 1.2558\n",
      "Epoch 41/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5762 - output1_accuracy: 0.4538 - output1_loss: 1.3053 - output2_accuracy: 0.4782 - output2_loss: 1.2710\n",
      "Epoch 41: Average accuracy did not improve (current: 0.4736, best: 0.4743)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.5762 - output1_accuracy: 0.4538 - output1_loss: 1.3053 - output2_accuracy: 0.4782 - output2_loss: 1.2709 - val_loss: 2.5316 - val_output1_accuracy: 0.4555 - val_output1_loss: 1.2884 - val_output2_accuracy: 0.4916 - val_output2_loss: 1.2432\n",
      "Epoch 42/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5547 - output1_accuracy: 0.4574 - output1_loss: 1.2898 - output2_accuracy: 0.4811 - output2_loss: 1.2649\n",
      "Epoch 42: Average accuracy improved to 0.4795, saving model to ./ACNN3/0.46-0.50-epoch42-loss2.56.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5547 - output1_accuracy: 0.4574 - output1_loss: 1.2898 - output2_accuracy: 0.4811 - output2_loss: 1.2649 - val_loss: 2.5178 - val_output1_accuracy: 0.4553 - val_output1_loss: 1.2815 - val_output2_accuracy: 0.5036 - val_output2_loss: 1.2363\n",
      "Epoch 43/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5526 - output1_accuracy: 0.4541 - output1_loss: 1.2952 - output2_accuracy: 0.4874 - output2_loss: 1.2574\n",
      "Epoch 43: Average accuracy did not improve (current: 0.4777, best: 0.4795)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5526 - output1_accuracy: 0.4542 - output1_loss: 1.2952 - output2_accuracy: 0.4874 - output2_loss: 1.2574 - val_loss: 2.5333 - val_output1_accuracy: 0.4609 - val_output1_loss: 1.2861 - val_output2_accuracy: 0.4944 - val_output2_loss: 1.2472\n",
      "Epoch 44/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5398 - output1_accuracy: 0.4589 - output1_loss: 1.2852 - output2_accuracy: 0.4835 - output2_loss: 1.2547\n",
      "Epoch 44: Average accuracy improved to 0.4796, saving model to ./ACNN3/0.46-0.50-epoch44-loss2.55.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5399 - output1_accuracy: 0.4589 - output1_loss: 1.2852 - output2_accuracy: 0.4835 - output2_loss: 1.2547 - val_loss: 2.5101 - val_output1_accuracy: 0.4579 - val_output1_loss: 1.2771 - val_output2_accuracy: 0.5012 - val_output2_loss: 1.2330\n",
      "Epoch 45/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5350 - output1_accuracy: 0.4621 - output1_loss: 1.2852 - output2_accuracy: 0.4890 - output2_loss: 1.2498\n",
      "Epoch 45: Average accuracy improved to 0.4807, saving model to ./ACNN3/0.45-0.51-epoch45-loss2.54.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5350 - output1_accuracy: 0.4621 - output1_loss: 1.2852 - output2_accuracy: 0.4890 - output2_loss: 1.2498 - val_loss: 2.5064 - val_output1_accuracy: 0.4521 - val_output1_loss: 1.2967 - val_output2_accuracy: 0.5092 - val_output2_loss: 1.2097\n",
      "Epoch 46/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5408 - output1_accuracy: 0.4625 - output1_loss: 1.2840 - output2_accuracy: 0.4827 - output2_loss: 1.2569\n",
      "Epoch 46: Average accuracy did not improve (current: 0.4773, best: 0.4807)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.5408 - output1_accuracy: 0.4625 - output1_loss: 1.2840 - output2_accuracy: 0.4827 - output2_loss: 1.2569 - val_loss: 2.5192 - val_output1_accuracy: 0.4597 - val_output1_loss: 1.2848 - val_output2_accuracy: 0.4948 - val_output2_loss: 1.2344\n",
      "Epoch 47/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5287 - output1_accuracy: 0.4679 - output1_loss: 1.2714 - output2_accuracy: 0.4819 - output2_loss: 1.2573\n",
      "Epoch 47: Average accuracy did not improve (current: 0.4756, best: 0.4807)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5288 - output1_accuracy: 0.4678 - output1_loss: 1.2715 - output2_accuracy: 0.4819 - output2_loss: 1.2573 - val_loss: 2.5345 - val_output1_accuracy: 0.4631 - val_output1_loss: 1.2784 - val_output2_accuracy: 0.4880 - val_output2_loss: 1.2562\n",
      "Epoch 48/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5293 - output1_accuracy: 0.4611 - output1_loss: 1.2806 - output2_accuracy: 0.4858 - output2_loss: 1.2487\n",
      "Epoch 48: Average accuracy improved to 0.4907, saving model to ./ACNN3/0.48-0.50-epoch48-loss2.53.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5293 - output1_accuracy: 0.4611 - output1_loss: 1.2806 - output2_accuracy: 0.4858 - output2_loss: 1.2487 - val_loss: 2.4909 - val_output1_accuracy: 0.4816 - val_output1_loss: 1.2558 - val_output2_accuracy: 0.4998 - val_output2_loss: 1.2351\n",
      "Epoch 49/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5106 - output1_accuracy: 0.4696 - output1_loss: 1.2751 - output2_accuracy: 0.4928 - output2_loss: 1.2355\n",
      "Epoch 49: Average accuracy did not improve (current: 0.4800, best: 0.4907)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5107 - output1_accuracy: 0.4696 - output1_loss: 1.2751 - output2_accuracy: 0.4928 - output2_loss: 1.2355 - val_loss: 2.5101 - val_output1_accuracy: 0.4529 - val_output1_loss: 1.2815 - val_output2_accuracy: 0.5070 - val_output2_loss: 1.2286\n",
      "Epoch 50/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5182 - output1_accuracy: 0.4695 - output1_loss: 1.2733 - output2_accuracy: 0.4892 - output2_loss: 1.2449\n",
      "Epoch 50: Average accuracy improved to 0.4915, saving model to ./ACNN3/0.46-0.52-epoch50-loss2.52.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5182 - output1_accuracy: 0.4695 - output1_loss: 1.2733 - output2_accuracy: 0.4892 - output2_loss: 1.2449 - val_loss: 2.4925 - val_output1_accuracy: 0.4597 - val_output1_loss: 1.2821 - val_output2_accuracy: 0.5232 - val_output2_loss: 1.2104\n",
      "Epoch 51/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5226 - output1_accuracy: 0.4650 - output1_loss: 1.2768 - output2_accuracy: 0.4908 - output2_loss: 1.2458\n",
      "Epoch 51: Average accuracy did not improve (current: 0.4863, best: 0.4915)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.5225 - output1_accuracy: 0.4650 - output1_loss: 1.2768 - output2_accuracy: 0.4908 - output2_loss: 1.2457 - val_loss: 2.4711 - val_output1_accuracy: 0.4665 - val_output1_loss: 1.2559 - val_output2_accuracy: 0.5060 - val_output2_loss: 1.2153\n",
      "Epoch 52/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4997 - output1_accuracy: 0.4730 - output1_loss: 1.2678 - output2_accuracy: 0.4954 - output2_loss: 1.2318\n",
      "Epoch 52: Average accuracy improved to 0.4934, saving model to ./ACNN3/0.48-0.51-epoch52-loss2.50.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4997 - output1_accuracy: 0.4730 - output1_loss: 1.2678 - output2_accuracy: 0.4954 - output2_loss: 1.2318 - val_loss: 2.4752 - val_output1_accuracy: 0.4752 - val_output1_loss: 1.2702 - val_output2_accuracy: 0.5116 - val_output2_loss: 1.2051\n",
      "Epoch 53/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5073 - output1_accuracy: 0.4697 - output1_loss: 1.2728 - output2_accuracy: 0.4951 - output2_loss: 1.2345\n",
      "Epoch 53: Average accuracy improved to 0.4954, saving model to ./ACNN3/0.47-0.52-epoch53-loss2.51.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.5073 - output1_accuracy: 0.4697 - output1_loss: 1.2728 - output2_accuracy: 0.4951 - output2_loss: 1.2345 - val_loss: 2.4667 - val_output1_accuracy: 0.4724 - val_output1_loss: 1.2593 - val_output2_accuracy: 0.5184 - val_output2_loss: 1.2074\n",
      "Epoch 54/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5045 - output1_accuracy: 0.4715 - output1_loss: 1.2716 - output2_accuracy: 0.4983 - output2_loss: 1.2329\n",
      "Epoch 54: Average accuracy did not improve (current: 0.4817, best: 0.4954)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5045 - output1_accuracy: 0.4714 - output1_loss: 1.2716 - output2_accuracy: 0.4983 - output2_loss: 1.2329 - val_loss: 2.4872 - val_output1_accuracy: 0.4708 - val_output1_loss: 1.2532 - val_output2_accuracy: 0.4926 - val_output2_loss: 1.2339\n",
      "Epoch 55/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4892 - output1_accuracy: 0.4721 - output1_loss: 1.2621 - output2_accuracy: 0.4993 - output2_loss: 1.2271\n",
      "Epoch 55: Average accuracy did not improve (current: 0.4926, best: 0.4954)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4892 - output1_accuracy: 0.4722 - output1_loss: 1.2621 - output2_accuracy: 0.4993 - output2_loss: 1.2271 - val_loss: 2.5039 - val_output1_accuracy: 0.4814 - val_output1_loss: 1.2739 - val_output2_accuracy: 0.5038 - val_output2_loss: 1.2300\n",
      "Epoch 56/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4904 - output1_accuracy: 0.4746 - output1_loss: 1.2614 - output2_accuracy: 0.5006 - output2_loss: 1.2290\n",
      "Epoch 56: Average accuracy did not improve (current: 0.4946, best: 0.4954)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4904 - output1_accuracy: 0.4746 - output1_loss: 1.2614 - output2_accuracy: 0.5006 - output2_loss: 1.2290 - val_loss: 2.4657 - val_output1_accuracy: 0.4694 - val_output1_loss: 1.2631 - val_output2_accuracy: 0.5198 - val_output2_loss: 1.2026\n",
      "Epoch 57/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4828 - output1_accuracy: 0.4769 - output1_loss: 1.2540 - output2_accuracy: 0.4960 - output2_loss: 1.2287\n",
      "Epoch 57: Average accuracy did not improve (current: 0.4923, best: 0.4954)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4828 - output1_accuracy: 0.4769 - output1_loss: 1.2541 - output2_accuracy: 0.4960 - output2_loss: 1.2287 - val_loss: 2.4565 - val_output1_accuracy: 0.4712 - val_output1_loss: 1.2495 - val_output2_accuracy: 0.5134 - val_output2_loss: 1.2070\n",
      "Epoch 58/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4801 - output1_accuracy: 0.4764 - output1_loss: 1.2601 - output2_accuracy: 0.5047 - output2_loss: 1.2199\n",
      "Epoch 58: Average accuracy did not improve (current: 0.4931, best: 0.4954)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4801 - output1_accuracy: 0.4764 - output1_loss: 1.2602 - output2_accuracy: 0.5047 - output2_loss: 1.2199 - val_loss: 2.4450 - val_output1_accuracy: 0.4704 - val_output1_loss: 1.2549 - val_output2_accuracy: 0.5158 - val_output2_loss: 1.1901\n",
      "Epoch 59/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4806 - output1_accuracy: 0.4744 - output1_loss: 1.2579 - output2_accuracy: 0.4993 - output2_loss: 1.2227\n",
      "Epoch 59: Average accuracy did not improve (current: 0.4892, best: 0.4954)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4806 - output1_accuracy: 0.4744 - output1_loss: 1.2579 - output2_accuracy: 0.4993 - output2_loss: 1.2227 - val_loss: 2.4605 - val_output1_accuracy: 0.4752 - val_output1_loss: 1.2494 - val_output2_accuracy: 0.5032 - val_output2_loss: 1.2111\n",
      "Epoch 60/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4745 - output1_accuracy: 0.4769 - output1_loss: 1.2581 - output2_accuracy: 0.5031 - output2_loss: 1.2164\n",
      "Epoch 60: Average accuracy improved to 0.4955, saving model to ./ACNN3/0.48-0.51-epoch60-loss2.47.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4745 - output1_accuracy: 0.4769 - output1_loss: 1.2581 - output2_accuracy: 0.5031 - output2_loss: 1.2165 - val_loss: 2.4533 - val_output1_accuracy: 0.4850 - val_output1_loss: 1.2312 - val_output2_accuracy: 0.5060 - val_output2_loss: 1.2221\n",
      "Epoch 61/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4670 - output1_accuracy: 0.4806 - output1_loss: 1.2492 - output2_accuracy: 0.5032 - output2_loss: 1.2177\n",
      "Epoch 61: Average accuracy improved to 0.5008, saving model to ./ACNN3/0.48-0.52-epoch61-loss2.47.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4670 - output1_accuracy: 0.4806 - output1_loss: 1.2493 - output2_accuracy: 0.5032 - output2_loss: 1.2177 - val_loss: 2.4276 - val_output1_accuracy: 0.4796 - val_output1_loss: 1.2321 - val_output2_accuracy: 0.5220 - val_output2_loss: 1.1955\n",
      "Epoch 62/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4828 - output1_accuracy: 0.4743 - output1_loss: 1.2627 - output2_accuracy: 0.5048 - output2_loss: 1.2201\n",
      "Epoch 62: Average accuracy did not improve (current: 0.4968, best: 0.5008)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4828 - output1_accuracy: 0.4743 - output1_loss: 1.2627 - output2_accuracy: 0.5048 - output2_loss: 1.2201 - val_loss: 2.4428 - val_output1_accuracy: 0.4780 - val_output1_loss: 1.2422 - val_output2_accuracy: 0.5156 - val_output2_loss: 1.2006\n",
      "Epoch 63/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4650 - output1_accuracy: 0.4774 - output1_loss: 1.2497 - output2_accuracy: 0.5081 - output2_loss: 1.2153\n",
      "Epoch 63: Average accuracy did not improve (current: 0.4947, best: 0.5008)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4650 - output1_accuracy: 0.4774 - output1_loss: 1.2497 - output2_accuracy: 0.5081 - output2_loss: 1.2153 - val_loss: 2.4420 - val_output1_accuracy: 0.4756 - val_output1_loss: 1.2386 - val_output2_accuracy: 0.5138 - val_output2_loss: 1.2034\n",
      "Epoch 64/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4542 - output1_accuracy: 0.4800 - output1_loss: 1.2432 - output2_accuracy: 0.5051 - output2_loss: 1.2110\n",
      "Epoch 64: Average accuracy improved to 0.5029, saving model to ./ACNN3/0.47-0.53-epoch64-loss2.45.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4542 - output1_accuracy: 0.4800 - output1_loss: 1.2432 - output2_accuracy: 0.5052 - output2_loss: 1.2110 - val_loss: 2.4275 - val_output1_accuracy: 0.4716 - val_output1_loss: 1.2562 - val_output2_accuracy: 0.5343 - val_output2_loss: 1.1714\n",
      "Epoch 65/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4502 - output1_accuracy: 0.4849 - output1_loss: 1.2442 - output2_accuracy: 0.5125 - output2_loss: 1.2059\n",
      "Epoch 65: Average accuracy did not improve (current: 0.4970, best: 0.5029)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4502 - output1_accuracy: 0.4849 - output1_loss: 1.2443 - output2_accuracy: 0.5125 - output2_loss: 1.2059 - val_loss: 2.4365 - val_output1_accuracy: 0.4770 - val_output1_loss: 1.2370 - val_output2_accuracy: 0.5170 - val_output2_loss: 1.1995\n",
      "Epoch 66/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4602 - output1_accuracy: 0.4787 - output1_loss: 1.2503 - output2_accuracy: 0.5073 - output2_loss: 1.2099\n",
      "Epoch 66: Average accuracy improved to 0.5045, saving model to ./ACNN3/0.49-0.52-epoch66-loss2.45.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4602 - output1_accuracy: 0.4787 - output1_loss: 1.2503 - output2_accuracy: 0.5073 - output2_loss: 1.2099 - val_loss: 2.4130 - val_output1_accuracy: 0.4884 - val_output1_loss: 1.2252 - val_output2_accuracy: 0.5206 - val_output2_loss: 1.1877\n",
      "Epoch 67/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4675 - output1_accuracy: 0.4797 - output1_loss: 1.2568 - output2_accuracy: 0.5065 - output2_loss: 1.2106\n",
      "Epoch 67: Average accuracy improved to 0.5112, saving model to ./ACNN3/0.50-0.52-epoch67-loss2.46.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4674 - output1_accuracy: 0.4797 - output1_loss: 1.2568 - output2_accuracy: 0.5065 - output2_loss: 1.2106 - val_loss: 2.4066 - val_output1_accuracy: 0.4984 - val_output1_loss: 1.2242 - val_output2_accuracy: 0.5240 - val_output2_loss: 1.1823\n",
      "Epoch 68/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.4549 - output1_accuracy: 0.4807 - output1_loss: 1.2534 - output2_accuracy: 0.5151 - output2_loss: 1.2014\n",
      "Epoch 68: Average accuracy did not improve (current: 0.5080, best: 0.5112)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4549 - output1_accuracy: 0.4807 - output1_loss: 1.2534 - output2_accuracy: 0.5151 - output2_loss: 1.2014 - val_loss: 2.4040 - val_output1_accuracy: 0.4884 - val_output1_loss: 1.2359 - val_output2_accuracy: 0.5276 - val_output2_loss: 1.1681\n",
      "Epoch 69/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4539 - output1_accuracy: 0.4845 - output1_loss: 1.2486 - output2_accuracy: 0.5110 - output2_loss: 1.2052\n",
      "Epoch 69: Average accuracy did not improve (current: 0.5105, best: 0.5112)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4538 - output1_accuracy: 0.4845 - output1_loss: 1.2486 - output2_accuracy: 0.5110 - output2_loss: 1.2052 - val_loss: 2.4045 - val_output1_accuracy: 0.4906 - val_output1_loss: 1.2273 - val_output2_accuracy: 0.5304 - val_output2_loss: 1.1772\n",
      "Epoch 70/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4464 - output1_accuracy: 0.4821 - output1_loss: 1.2453 - output2_accuracy: 0.5100 - output2_loss: 1.2012\n",
      "Epoch 70: Average accuracy did not improve (current: 0.5040, best: 0.5112)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4464 - output1_accuracy: 0.4821 - output1_loss: 1.2453 - output2_accuracy: 0.5100 - output2_loss: 1.2012 - val_loss: 2.4141 - val_output1_accuracy: 0.4826 - val_output1_loss: 1.2296 - val_output2_accuracy: 0.5254 - val_output2_loss: 1.1845\n",
      "Epoch 71/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4494 - output1_accuracy: 0.4850 - output1_loss: 1.2428 - output2_accuracy: 0.5092 - output2_loss: 1.2066\n",
      "Epoch 71: Average accuracy did not improve (current: 0.5014, best: 0.5112)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4494 - output1_accuracy: 0.4850 - output1_loss: 1.2428 - output2_accuracy: 0.5092 - output2_loss: 1.2066 - val_loss: 2.4180 - val_output1_accuracy: 0.4792 - val_output1_loss: 1.2339 - val_output2_accuracy: 0.5236 - val_output2_loss: 1.1840\n",
      "Epoch 72/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4434 - output1_accuracy: 0.4862 - output1_loss: 1.2409 - output2_accuracy: 0.5162 - output2_loss: 1.2025\n",
      "Epoch 72: Average accuracy did not improve (current: 0.5089, best: 0.5112)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4434 - output1_accuracy: 0.4862 - output1_loss: 1.2409 - output2_accuracy: 0.5162 - output2_loss: 1.2025 - val_loss: 2.3989 - val_output1_accuracy: 0.4860 - val_output1_loss: 1.2131 - val_output2_accuracy: 0.5319 - val_output2_loss: 1.1857\n",
      "Epoch 73/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4305 - output1_accuracy: 0.4860 - output1_loss: 1.2434 - output2_accuracy: 0.5191 - output2_loss: 1.1870\n",
      "Epoch 73: Average accuracy did not improve (current: 0.4956, best: 0.5112)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4305 - output1_accuracy: 0.4860 - output1_loss: 1.2434 - output2_accuracy: 0.5191 - output2_loss: 1.1871 - val_loss: 2.4227 - val_output1_accuracy: 0.4696 - val_output1_loss: 1.2449 - val_output2_accuracy: 0.5216 - val_output2_loss: 1.1778\n",
      "Epoch 74/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4353 - output1_accuracy: 0.4864 - output1_loss: 1.2425 - output2_accuracy: 0.5141 - output2_loss: 1.1928\n",
      "Epoch 74: Average accuracy improved to 0.5117, saving model to ./ACNN3/0.49-0.53-epoch74-loss2.43.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4353 - output1_accuracy: 0.4864 - output1_loss: 1.2425 - output2_accuracy: 0.5141 - output2_loss: 1.1928 - val_loss: 2.3904 - val_output1_accuracy: 0.4904 - val_output1_loss: 1.2229 - val_output2_accuracy: 0.5331 - val_output2_loss: 1.1675\n",
      "Epoch 75/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4249 - output1_accuracy: 0.4899 - output1_loss: 1.2353 - output2_accuracy: 0.5166 - output2_loss: 1.1896\n",
      "Epoch 75: Average accuracy did not improve (current: 0.5060, best: 0.5117)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4249 - output1_accuracy: 0.4899 - output1_loss: 1.2353 - output2_accuracy: 0.5166 - output2_loss: 1.1896 - val_loss: 2.4099 - val_output1_accuracy: 0.4866 - val_output1_loss: 1.2331 - val_output2_accuracy: 0.5254 - val_output2_loss: 1.1768\n",
      "Epoch 76/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.4252 - output1_accuracy: 0.4925 - output1_loss: 1.2298 - output2_accuracy: 0.5152 - output2_loss: 1.1953\n",
      "Epoch 76: Average accuracy improved to 0.5118, saving model to ./ACNN3/0.49-0.54-epoch76-loss2.43.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4252 - output1_accuracy: 0.4925 - output1_loss: 1.2298 - output2_accuracy: 0.5152 - output2_loss: 1.1953 - val_loss: 2.3872 - val_output1_accuracy: 0.4858 - val_output1_loss: 1.2293 - val_output2_accuracy: 0.5379 - val_output2_loss: 1.1579\n",
      "Epoch 77/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4175 - output1_accuracy: 0.4869 - output1_loss: 1.2367 - output2_accuracy: 0.5224 - output2_loss: 1.1808\n",
      "Epoch 77: Average accuracy improved to 0.5154, saving model to ./ACNN3/0.49-0.54-epoch77-loss2.42.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4175 - output1_accuracy: 0.4869 - output1_loss: 1.2367 - output2_accuracy: 0.5224 - output2_loss: 1.1809 - val_loss: 2.3950 - val_output1_accuracy: 0.4890 - val_output1_loss: 1.2357 - val_output2_accuracy: 0.5419 - val_output2_loss: 1.1592\n",
      "Epoch 78/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4193 - output1_accuracy: 0.4902 - output1_loss: 1.2335 - output2_accuracy: 0.5223 - output2_loss: 1.1858\n",
      "Epoch 78: Average accuracy did not improve (current: 0.5018, best: 0.5154)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4193 - output1_accuracy: 0.4902 - output1_loss: 1.2335 - output2_accuracy: 0.5223 - output2_loss: 1.1858 - val_loss: 2.4103 - val_output1_accuracy: 0.4804 - val_output1_loss: 1.2276 - val_output2_accuracy: 0.5232 - val_output2_loss: 1.1827\n",
      "Epoch 79/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4042 - output1_accuracy: 0.4936 - output1_loss: 1.2296 - output2_accuracy: 0.5310 - output2_loss: 1.1746\n",
      "Epoch 79: Average accuracy did not improve (current: 0.5133, best: 0.5154)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4042 - output1_accuracy: 0.4936 - output1_loss: 1.2297 - output2_accuracy: 0.5310 - output2_loss: 1.1746 - val_loss: 2.3875 - val_output1_accuracy: 0.4928 - val_output1_loss: 1.2201 - val_output2_accuracy: 0.5339 - val_output2_loss: 1.1675\n",
      "Epoch 80/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4047 - output1_accuracy: 0.4931 - output1_loss: 1.2291 - output2_accuracy: 0.5238 - output2_loss: 1.1756\n",
      "Epoch 80: Average accuracy did not improve (current: 0.5072, best: 0.5154)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4047 - output1_accuracy: 0.4931 - output1_loss: 1.2291 - output2_accuracy: 0.5238 - output2_loss: 1.1756 - val_loss: 2.3874 - val_output1_accuracy: 0.4798 - val_output1_loss: 1.2325 - val_output2_accuracy: 0.5347 - val_output2_loss: 1.1549\n",
      "Epoch 81/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4091 - output1_accuracy: 0.4922 - output1_loss: 1.2329 - output2_accuracy: 0.5239 - output2_loss: 1.1762\n",
      "Epoch 81: Average accuracy did not improve (current: 0.5139, best: 0.5154)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4091 - output1_accuracy: 0.4922 - output1_loss: 1.2329 - output2_accuracy: 0.5239 - output2_loss: 1.1762 - val_loss: 2.3771 - val_output1_accuracy: 0.4902 - val_output1_loss: 1.2193 - val_output2_accuracy: 0.5377 - val_output2_loss: 1.1578\n",
      "Epoch 82/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4123 - output1_accuracy: 0.4900 - output1_loss: 1.2290 - output2_accuracy: 0.5239 - output2_loss: 1.1833\n",
      "Epoch 82: Average accuracy did not improve (current: 0.5079, best: 0.5154)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4123 - output1_accuracy: 0.4900 - output1_loss: 1.2290 - output2_accuracy: 0.5239 - output2_loss: 1.1833 - val_loss: 2.4049 - val_output1_accuracy: 0.4838 - val_output1_loss: 1.2347 - val_output2_accuracy: 0.5321 - val_output2_loss: 1.1702\n",
      "Epoch 83/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4076 - output1_accuracy: 0.4907 - output1_loss: 1.2301 - output2_accuracy: 0.5265 - output2_loss: 1.1774\n",
      "Epoch 83: Average accuracy did not improve (current: 0.5150, best: 0.5154)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4076 - output1_accuracy: 0.4907 - output1_loss: 1.2301 - output2_accuracy: 0.5265 - output2_loss: 1.1774 - val_loss: 2.3631 - val_output1_accuracy: 0.4930 - val_output1_loss: 1.2143 - val_output2_accuracy: 0.5371 - val_output2_loss: 1.1487\n",
      "Epoch 84/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4132 - output1_accuracy: 0.4893 - output1_loss: 1.2298 - output2_accuracy: 0.5235 - output2_loss: 1.1834\n",
      "Epoch 84: Average accuracy improved to 0.5172, saving model to ./ACNN3/0.48-0.55-epoch84-loss2.41.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4132 - output1_accuracy: 0.4893 - output1_loss: 1.2298 - output2_accuracy: 0.5236 - output2_loss: 1.1834 - val_loss: 2.3990 - val_output1_accuracy: 0.4838 - val_output1_loss: 1.2487 - val_output2_accuracy: 0.5507 - val_output2_loss: 1.1504\n",
      "Epoch 85/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3932 - output1_accuracy: 0.4960 - output1_loss: 1.2237 - output2_accuracy: 0.5267 - output2_loss: 1.1696\n",
      "Epoch 85: Average accuracy did not improve (current: 0.5107, best: 0.5172)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.3932 - output1_accuracy: 0.4960 - output1_loss: 1.2237 - output2_accuracy: 0.5267 - output2_loss: 1.1696 - val_loss: 2.3947 - val_output1_accuracy: 0.4898 - val_output1_loss: 1.2269 - val_output2_accuracy: 0.5317 - val_output2_loss: 1.1678\n",
      "Epoch 86/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3880 - output1_accuracy: 0.4907 - output1_loss: 1.2246 - output2_accuracy: 0.5302 - output2_loss: 1.1634\n",
      "Epoch 86: Average accuracy improved to 0.5202, saving model to ./ACNN3/0.49-0.55-epoch86-loss2.39.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3880 - output1_accuracy: 0.4907 - output1_loss: 1.2246 - output2_accuracy: 0.5302 - output2_loss: 1.1634 - val_loss: 2.3652 - val_output1_accuracy: 0.4898 - val_output1_loss: 1.2258 - val_output2_accuracy: 0.5507 - val_output2_loss: 1.1394\n",
      "Epoch 87/100\n",
      "\u001b[1m698/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3995 - output1_accuracy: 0.4927 - output1_loss: 1.2311 - output2_accuracy: 0.5280 - output2_loss: 1.1685\n",
      "Epoch 87: Average accuracy did not improve (current: 0.5189, best: 0.5202)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.3995 - output1_accuracy: 0.4926 - output1_loss: 1.2311 - output2_accuracy: 0.5280 - output2_loss: 1.1685 - val_loss: 2.3517 - val_output1_accuracy: 0.5028 - val_output1_loss: 1.1958 - val_output2_accuracy: 0.5351 - val_output2_loss: 1.1559\n",
      "Epoch 88/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3954 - output1_accuracy: 0.4936 - output1_loss: 1.2242 - output2_accuracy: 0.5301 - output2_loss: 1.1712\n",
      "Epoch 88: Average accuracy improved to 0.5204, saving model to ./ACNN3/0.49-0.55-epoch88-loss2.40.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3954 - output1_accuracy: 0.4936 - output1_loss: 1.2242 - output2_accuracy: 0.5301 - output2_loss: 1.1712 - val_loss: 2.3762 - val_output1_accuracy: 0.4944 - val_output1_loss: 1.2196 - val_output2_accuracy: 0.5465 - val_output2_loss: 1.1565\n",
      "Epoch 89/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3877 - output1_accuracy: 0.4947 - output1_loss: 1.2224 - output2_accuracy: 0.5265 - output2_loss: 1.1653\n",
      "Epoch 89: Average accuracy improved to 0.5226, saving model to ./ACNN3/0.49-0.55-epoch89-loss2.39.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3877 - output1_accuracy: 0.4947 - output1_loss: 1.2224 - output2_accuracy: 0.5265 - output2_loss: 1.1653 - val_loss: 2.3626 - val_output1_accuracy: 0.4932 - val_output1_loss: 1.2234 - val_output2_accuracy: 0.5521 - val_output2_loss: 1.1392\n",
      "Epoch 90/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3885 - output1_accuracy: 0.5012 - output1_loss: 1.2120 - output2_accuracy: 0.5288 - output2_loss: 1.1765\n",
      "Epoch 90: Average accuracy improved to 0.5247, saving model to ./ACNN3/0.50-0.55-epoch90-loss2.38.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3885 - output1_accuracy: 0.5012 - output1_loss: 1.2120 - output2_accuracy: 0.5288 - output2_loss: 1.1765 - val_loss: 2.3524 - val_output1_accuracy: 0.4976 - val_output1_loss: 1.2156 - val_output2_accuracy: 0.5519 - val_output2_loss: 1.1368\n",
      "Epoch 91/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3850 - output1_accuracy: 0.4965 - output1_loss: 1.2192 - output2_accuracy: 0.5295 - output2_loss: 1.1658\n",
      "Epoch 91: Average accuracy improved to 0.5253, saving model to ./ACNN3/0.50-0.55-epoch91-loss2.39.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3850 - output1_accuracy: 0.4965 - output1_loss: 1.2192 - output2_accuracy: 0.5295 - output2_loss: 1.1658 - val_loss: 2.3474 - val_output1_accuracy: 0.5004 - val_output1_loss: 1.2131 - val_output2_accuracy: 0.5503 - val_output2_loss: 1.1342\n",
      "Epoch 92/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3685 - output1_accuracy: 0.5038 - output1_loss: 1.2098 - output2_accuracy: 0.5306 - output2_loss: 1.1587\n",
      "Epoch 92: Average accuracy did not improve (current: 0.5097, best: 0.5253)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3685 - output1_accuracy: 0.5038 - output1_loss: 1.2098 - output2_accuracy: 0.5306 - output2_loss: 1.1587 - val_loss: 2.3819 - val_output1_accuracy: 0.4870 - val_output1_loss: 1.2208 - val_output2_accuracy: 0.5325 - val_output2_loss: 1.1612\n",
      "Epoch 93/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3653 - output1_accuracy: 0.5009 - output1_loss: 1.2157 - output2_accuracy: 0.5372 - output2_loss: 1.1496\n",
      "Epoch 93: Average accuracy improved to 0.5331, saving model to ./ACNN3/0.51-0.56-epoch93-loss2.37.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3653 - output1_accuracy: 0.5008 - output1_loss: 1.2157 - output2_accuracy: 0.5372 - output2_loss: 1.1496 - val_loss: 2.3493 - val_output1_accuracy: 0.5072 - val_output1_loss: 1.2078 - val_output2_accuracy: 0.5589 - val_output2_loss: 1.1415\n",
      "Epoch 94/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3744 - output1_accuracy: 0.4956 - output1_loss: 1.2152 - output2_accuracy: 0.5365 - output2_loss: 1.1592\n",
      "Epoch 94: Average accuracy did not improve (current: 0.5224, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3744 - output1_accuracy: 0.4956 - output1_loss: 1.2152 - output2_accuracy: 0.5364 - output2_loss: 1.1592 - val_loss: 2.3615 - val_output1_accuracy: 0.4958 - val_output1_loss: 1.2296 - val_output2_accuracy: 0.5491 - val_output2_loss: 1.1319\n",
      "Epoch 95/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3800 - output1_accuracy: 0.4948 - output1_loss: 1.2217 - output2_accuracy: 0.5343 - output2_loss: 1.1583\n",
      "Epoch 95: Average accuracy did not improve (current: 0.5209, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3799 - output1_accuracy: 0.4948 - output1_loss: 1.2217 - output2_accuracy: 0.5343 - output2_loss: 1.1583 - val_loss: 2.3730 - val_output1_accuracy: 0.4958 - val_output1_loss: 1.2215 - val_output2_accuracy: 0.5461 - val_output2_loss: 1.1516\n",
      "Epoch 96/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3634 - output1_accuracy: 0.5006 - output1_loss: 1.2106 - output2_accuracy: 0.5310 - output2_loss: 1.1528\n",
      "Epoch 96: Average accuracy did not improve (current: 0.5306, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3635 - output1_accuracy: 0.5006 - output1_loss: 1.2106 - output2_accuracy: 0.5310 - output2_loss: 1.1528 - val_loss: 2.3362 - val_output1_accuracy: 0.5120 - val_output1_loss: 1.2003 - val_output2_accuracy: 0.5493 - val_output2_loss: 1.1359\n",
      "Epoch 97/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3614 - output1_accuracy: 0.5006 - output1_loss: 1.2107 - output2_accuracy: 0.5409 - output2_loss: 1.1508\n",
      "Epoch 97: Average accuracy did not improve (current: 0.5189, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3614 - output1_accuracy: 0.5006 - output1_loss: 1.2107 - output2_accuracy: 0.5409 - output2_loss: 1.1508 - val_loss: 2.3772 - val_output1_accuracy: 0.4940 - val_output1_loss: 1.2190 - val_output2_accuracy: 0.5439 - val_output2_loss: 1.1583\n",
      "Epoch 98/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3723 - output1_accuracy: 0.4974 - output1_loss: 1.2167 - output2_accuracy: 0.5366 - output2_loss: 1.1556\n",
      "Epoch 98: Average accuracy did not improve (current: 0.5214, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3723 - output1_accuracy: 0.4974 - output1_loss: 1.2167 - output2_accuracy: 0.5366 - output2_loss: 1.1556 - val_loss: 2.3335 - val_output1_accuracy: 0.4896 - val_output1_loss: 1.2142 - val_output2_accuracy: 0.5533 - val_output2_loss: 1.1193\n",
      "Epoch 99/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3651 - output1_accuracy: 0.5011 - output1_loss: 1.2125 - output2_accuracy: 0.5350 - output2_loss: 1.1526\n",
      "Epoch 99: Average accuracy did not improve (current: 0.5193, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3651 - output1_accuracy: 0.5011 - output1_loss: 1.2125 - output2_accuracy: 0.5350 - output2_loss: 1.1526 - val_loss: 2.3388 - val_output1_accuracy: 0.4970 - val_output1_loss: 1.2030 - val_output2_accuracy: 0.5417 - val_output2_loss: 1.1357\n",
      "Epoch 100/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3531 - output1_accuracy: 0.5025 - output1_loss: 1.2130 - output2_accuracy: 0.5430 - output2_loss: 1.1401\n",
      "Epoch 100: Average accuracy did not improve (current: 0.5144, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3532 - output1_accuracy: 0.5025 - output1_loss: 1.2130 - output2_accuracy: 0.5429 - output2_loss: 1.1401 - val_loss: 2.3789 - val_output1_accuracy: 0.4868 - val_output1_loss: 1.2306 - val_output2_accuracy: 0.5421 - val_output2_loss: 1.1483\n",
      "Restoring model weights from the end of the best epoch: 98.\n"
     ]
    }
   ],
   "source": [
    "val_model_checkpoint_callback = MeanAccModelCheckpoint(\n",
    "    filepath=\"./ACNN3/{output1_accuracy:.2f}-{output2_accuracy:.2f}-epoch{epoch:02d}-loss{loss:.2f}.keras\",\n",
    "    monitor1='val_output1_accuracy',\n",
    "    monitor2='val_output2_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "val_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.8551178485155105\n",
      "standard deviation =  0.002060303693756444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = model.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ACNN3-85.5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.8558160707354545\n",
      "standard deviation =  0.0031677117740428074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACCN3 = load_model('ACNN3-85.5.keras')\n",
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = ACCN3.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,750,998</span> (10.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,750,998\u001b[0m (10.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,500</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,375,500\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3531 - output1_accuracy: 0.4956 - output1_loss: 1.2195 - output2_accuracy: 0.5448 - output2_loss: 1.1335\n",
      "Epoch 1: Average accuracy did not improve (current: 0.5233, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3531 - output1_accuracy: 0.4956 - output1_loss: 1.2195 - output2_accuracy: 0.5448 - output2_loss: 1.1336 - val_loss: 2.3300 - val_output1_accuracy: 0.4906 - val_output1_loss: 1.2147 - val_output2_accuracy: 0.5561 - val_output2_loss: 1.1153\n",
      "Epoch 2/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3490 - output1_accuracy: 0.5079 - output1_loss: 1.2009 - output2_accuracy: 0.5393 - output2_loss: 1.1481\n",
      "Epoch 2: Average accuracy did not improve (current: 0.5246, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3491 - output1_accuracy: 0.5078 - output1_loss: 1.2009 - output2_accuracy: 0.5393 - output2_loss: 1.1481 - val_loss: 2.3400 - val_output1_accuracy: 0.4928 - val_output1_loss: 1.2176 - val_output2_accuracy: 0.5565 - val_output2_loss: 1.1224\n",
      "Epoch 3/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3758 - output1_accuracy: 0.5006 - output1_loss: 1.2233 - output2_accuracy: 0.5359 - output2_loss: 1.1525\n",
      "Epoch 3: Average accuracy did not improve (current: 0.5283, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3757 - output1_accuracy: 0.5006 - output1_loss: 1.2233 - output2_accuracy: 0.5359 - output2_loss: 1.1524 - val_loss: 2.3219 - val_output1_accuracy: 0.4962 - val_output1_loss: 1.2023 - val_output2_accuracy: 0.5605 - val_output2_loss: 1.1196\n",
      "Epoch 4/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3567 - output1_accuracy: 0.5041 - output1_loss: 1.2122 - output2_accuracy: 0.5402 - output2_loss: 1.1445\n",
      "Epoch 4: Average accuracy did not improve (current: 0.5258, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3567 - output1_accuracy: 0.5041 - output1_loss: 1.2122 - output2_accuracy: 0.5402 - output2_loss: 1.1445 - val_loss: 2.3250 - val_output1_accuracy: 0.5008 - val_output1_loss: 1.1975 - val_output2_accuracy: 0.5509 - val_output2_loss: 1.1275\n",
      "Epoch 5/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3606 - output1_accuracy: 0.5002 - output1_loss: 1.2113 - output2_accuracy: 0.5380 - output2_loss: 1.1493\n",
      "Epoch 5: Average accuracy did not improve (current: 0.5277, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3606 - output1_accuracy: 0.5002 - output1_loss: 1.2113 - output2_accuracy: 0.5380 - output2_loss: 1.1493 - val_loss: 2.3238 - val_output1_accuracy: 0.5002 - val_output1_loss: 1.2069 - val_output2_accuracy: 0.5553 - val_output2_loss: 1.1169\n",
      "Epoch 6/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3568 - output1_accuracy: 0.4981 - output1_loss: 1.2139 - output2_accuracy: 0.5447 - output2_loss: 1.1429\n",
      "Epoch 6: Average accuracy did not improve (current: 0.5207, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3568 - output1_accuracy: 0.4981 - output1_loss: 1.2139 - output2_accuracy: 0.5447 - output2_loss: 1.1429 - val_loss: 2.3607 - val_output1_accuracy: 0.4908 - val_output1_loss: 1.2322 - val_output2_accuracy: 0.5507 - val_output2_loss: 1.1285\n",
      "Epoch 7/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3525 - output1_accuracy: 0.5016 - output1_loss: 1.2145 - output2_accuracy: 0.5475 - output2_loss: 1.1380\n",
      "Epoch 7: Average accuracy did not improve (current: 0.5241, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3525 - output1_accuracy: 0.5016 - output1_loss: 1.2145 - output2_accuracy: 0.5475 - output2_loss: 1.1380 - val_loss: 2.3332 - val_output1_accuracy: 0.5012 - val_output1_loss: 1.1996 - val_output2_accuracy: 0.5471 - val_output2_loss: 1.1336\n",
      "Epoch 8/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3492 - output1_accuracy: 0.5038 - output1_loss: 1.2129 - output2_accuracy: 0.5444 - output2_loss: 1.1364\n",
      "Epoch 8: Average accuracy did not improve (current: 0.5223, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3492 - output1_accuracy: 0.5038 - output1_loss: 1.2129 - output2_accuracy: 0.5444 - output2_loss: 1.1364 - val_loss: 2.3461 - val_output1_accuracy: 0.4948 - val_output1_loss: 1.2098 - val_output2_accuracy: 0.5499 - val_output2_loss: 1.1363\n",
      "Epoch 9/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3508 - output1_accuracy: 0.5043 - output1_loss: 1.2117 - output2_accuracy: 0.5425 - output2_loss: 1.1391\n",
      "Epoch 9: Average accuracy did not improve (current: 0.5314, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3508 - output1_accuracy: 0.5043 - output1_loss: 1.2117 - output2_accuracy: 0.5425 - output2_loss: 1.1391 - val_loss: 2.3060 - val_output1_accuracy: 0.4998 - val_output1_loss: 1.2039 - val_output2_accuracy: 0.5629 - val_output2_loss: 1.1021\n",
      "Epoch 10/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3536 - output1_accuracy: 0.5036 - output1_loss: 1.2094 - output2_accuracy: 0.5399 - output2_loss: 1.1442\n",
      "Epoch 10: Average accuracy did not improve (current: 0.5304, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3536 - output1_accuracy: 0.5036 - output1_loss: 1.2094 - output2_accuracy: 0.5399 - output2_loss: 1.1442 - val_loss: 2.3156 - val_output1_accuracy: 0.4982 - val_output1_loss: 1.2056 - val_output2_accuracy: 0.5627 - val_output2_loss: 1.1100\n",
      "Epoch 11/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3384 - output1_accuracy: 0.5002 - output1_loss: 1.2132 - output2_accuracy: 0.5488 - output2_loss: 1.1251\n",
      "Epoch 11: Average accuracy did not improve (current: 0.5318, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3384 - output1_accuracy: 0.5002 - output1_loss: 1.2132 - output2_accuracy: 0.5487 - output2_loss: 1.1252 - val_loss: 2.3039 - val_output1_accuracy: 0.5048 - val_output1_loss: 1.1923 - val_output2_accuracy: 0.5587 - val_output2_loss: 1.1116\n",
      "Epoch 12/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3562 - output1_accuracy: 0.4975 - output1_loss: 1.2210 - output2_accuracy: 0.5441 - output2_loss: 1.1352\n",
      "Epoch 12: Average accuracy did not improve (current: 0.5304, best: 0.5331)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3562 - output1_accuracy: 0.4975 - output1_loss: 1.2210 - output2_accuracy: 0.5441 - output2_loss: 1.1352 - val_loss: 2.3053 - val_output1_accuracy: 0.5082 - val_output1_loss: 1.1887 - val_output2_accuracy: 0.5527 - val_output2_loss: 1.1166\n",
      "Epoch 13/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3433 - output1_accuracy: 0.5048 - output1_loss: 1.2111 - output2_accuracy: 0.5506 - output2_loss: 1.1323\n",
      "Epoch 13: Average accuracy improved to 0.5333, saving model to ./ACNN3/0.50-0.57-epoch13-loss2.34.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3433 - output1_accuracy: 0.5048 - output1_loss: 1.2110 - output2_accuracy: 0.5506 - output2_loss: 1.1323 - val_loss: 2.3015 - val_output1_accuracy: 0.5004 - val_output1_loss: 1.2079 - val_output2_accuracy: 0.5661 - val_output2_loss: 1.0936\n",
      "Epoch 14/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3344 - output1_accuracy: 0.5078 - output1_loss: 1.1996 - output2_accuracy: 0.5419 - output2_loss: 1.1348\n",
      "Epoch 14: Average accuracy did not improve (current: 0.5279, best: 0.5333)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3344 - output1_accuracy: 0.5078 - output1_loss: 1.1996 - output2_accuracy: 0.5419 - output2_loss: 1.1348 - val_loss: 2.3241 - val_output1_accuracy: 0.5082 - val_output1_loss: 1.2004 - val_output2_accuracy: 0.5477 - val_output2_loss: 1.1237\n",
      "Epoch 15/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3436 - output1_accuracy: 0.5039 - output1_loss: 1.2073 - output2_accuracy: 0.5416 - output2_loss: 1.1363\n",
      "Epoch 15: Average accuracy did not improve (current: 0.5327, best: 0.5333)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3436 - output1_accuracy: 0.5039 - output1_loss: 1.2073 - output2_accuracy: 0.5417 - output2_loss: 1.1363 - val_loss: 2.3094 - val_output1_accuracy: 0.5010 - val_output1_loss: 1.2079 - val_output2_accuracy: 0.5643 - val_output2_loss: 1.1015\n",
      "Epoch 16/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3406 - output1_accuracy: 0.5015 - output1_loss: 1.2094 - output2_accuracy: 0.5479 - output2_loss: 1.1312\n",
      "Epoch 16: Average accuracy did not improve (current: 0.5269, best: 0.5333)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3406 - output1_accuracy: 0.5015 - output1_loss: 1.2094 - output2_accuracy: 0.5479 - output2_loss: 1.1312 - val_loss: 2.3129 - val_output1_accuracy: 0.5002 - val_output1_loss: 1.1941 - val_output2_accuracy: 0.5537 - val_output2_loss: 1.1187\n",
      "Epoch 17/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3256 - output1_accuracy: 0.5099 - output1_loss: 1.1996 - output2_accuracy: 0.5517 - output2_loss: 1.1261\n",
      "Epoch 17: Average accuracy improved to 0.5360, saving model to ./ACNN3/0.51-0.56-epoch17-loss2.32.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3256 - output1_accuracy: 0.5099 - output1_loss: 1.1996 - output2_accuracy: 0.5517 - output2_loss: 1.1260 - val_loss: 2.3013 - val_output1_accuracy: 0.5132 - val_output1_loss: 1.2032 - val_output2_accuracy: 0.5587 - val_output2_loss: 1.0981\n",
      "Epoch 18/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3335 - output1_accuracy: 0.5026 - output1_loss: 1.2068 - output2_accuracy: 0.5537 - output2_loss: 1.1267\n",
      "Epoch 18: Average accuracy did not improve (current: 0.5257, best: 0.5360)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3334 - output1_accuracy: 0.5026 - output1_loss: 1.2068 - output2_accuracy: 0.5537 - output2_loss: 1.1267 - val_loss: 2.3403 - val_output1_accuracy: 0.5060 - val_output1_loss: 1.2006 - val_output2_accuracy: 0.5455 - val_output2_loss: 1.1397\n",
      "Epoch 19/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3228 - output1_accuracy: 0.5023 - output1_loss: 1.2081 - output2_accuracy: 0.5532 - output2_loss: 1.1147\n",
      "Epoch 19: Average accuracy improved to 0.5404, saving model to ./ACNN3/0.51-0.57-epoch19-loss2.32.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3228 - output1_accuracy: 0.5024 - output1_loss: 1.2081 - output2_accuracy: 0.5532 - output2_loss: 1.1147 - val_loss: 2.2801 - val_output1_accuracy: 0.5072 - val_output1_loss: 1.1957 - val_output2_accuracy: 0.5735 - val_output2_loss: 1.0844\n",
      "Epoch 20/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3083 - output1_accuracy: 0.5079 - output1_loss: 1.2001 - output2_accuracy: 0.5575 - output2_loss: 1.1081\n",
      "Epoch 20: Average accuracy did not improve (current: 0.5359, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3083 - output1_accuracy: 0.5079 - output1_loss: 1.2001 - output2_accuracy: 0.5575 - output2_loss: 1.1081 - val_loss: 2.3074 - val_output1_accuracy: 0.5128 - val_output1_loss: 1.1901 - val_output2_accuracy: 0.5589 - val_output2_loss: 1.1172\n",
      "Epoch 21/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3280 - output1_accuracy: 0.5088 - output1_loss: 1.2038 - output2_accuracy: 0.5505 - output2_loss: 1.1242\n",
      "Epoch 21: Average accuracy did not improve (current: 0.5253, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3280 - output1_accuracy: 0.5088 - output1_loss: 1.2038 - output2_accuracy: 0.5505 - output2_loss: 1.1242 - val_loss: 2.3329 - val_output1_accuracy: 0.4878 - val_output1_loss: 1.2232 - val_output2_accuracy: 0.5629 - val_output2_loss: 1.1097\n",
      "Epoch 22/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3212 - output1_accuracy: 0.5092 - output1_loss: 1.1985 - output2_accuracy: 0.5493 - output2_loss: 1.1226\n",
      "Epoch 22: Average accuracy did not improve (current: 0.5365, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3212 - output1_accuracy: 0.5092 - output1_loss: 1.1986 - output2_accuracy: 0.5493 - output2_loss: 1.1226 - val_loss: 2.2768 - val_output1_accuracy: 0.5060 - val_output1_loss: 1.1862 - val_output2_accuracy: 0.5669 - val_output2_loss: 1.0905\n",
      "Epoch 23/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3197 - output1_accuracy: 0.5015 - output1_loss: 1.2009 - output2_accuracy: 0.5556 - output2_loss: 1.1188\n",
      "Epoch 23: Average accuracy did not improve (current: 0.5268, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3197 - output1_accuracy: 0.5015 - output1_loss: 1.2009 - output2_accuracy: 0.5556 - output2_loss: 1.1188 - val_loss: 2.3232 - val_output1_accuracy: 0.4928 - val_output1_loss: 1.2154 - val_output2_accuracy: 0.5609 - val_output2_loss: 1.1078\n",
      "Epoch 24/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3139 - output1_accuracy: 0.5090 - output1_loss: 1.1991 - output2_accuracy: 0.5568 - output2_loss: 1.1147\n",
      "Epoch 24: Average accuracy did not improve (current: 0.5391, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3139 - output1_accuracy: 0.5090 - output1_loss: 1.1991 - output2_accuracy: 0.5568 - output2_loss: 1.1147 - val_loss: 2.2867 - val_output1_accuracy: 0.5100 - val_output1_loss: 1.1859 - val_output2_accuracy: 0.5681 - val_output2_loss: 1.1008\n",
      "Epoch 25/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3145 - output1_accuracy: 0.5057 - output1_loss: 1.2005 - output2_accuracy: 0.5534 - output2_loss: 1.1139\n",
      "Epoch 25: Average accuracy did not improve (current: 0.5352, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3145 - output1_accuracy: 0.5057 - output1_loss: 1.2005 - output2_accuracy: 0.5534 - output2_loss: 1.1139 - val_loss: 2.2941 - val_output1_accuracy: 0.5036 - val_output1_loss: 1.2108 - val_output2_accuracy: 0.5667 - val_output2_loss: 1.0833\n",
      "Epoch 26/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3065 - output1_accuracy: 0.5127 - output1_loss: 1.1945 - output2_accuracy: 0.5583 - output2_loss: 1.1120\n",
      "Epoch 26: Average accuracy did not improve (current: 0.5248, best: 0.5404)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3066 - output1_accuracy: 0.5127 - output1_loss: 1.1945 - output2_accuracy: 0.5583 - output2_loss: 1.1120 - val_loss: 2.3170 - val_output1_accuracy: 0.4994 - val_output1_loss: 1.2072 - val_output2_accuracy: 0.5503 - val_output2_loss: 1.1098\n",
      "Epoch 27/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2988 - output1_accuracy: 0.5118 - output1_loss: 1.1926 - output2_accuracy: 0.5589 - output2_loss: 1.1061\n",
      "Epoch 27: Average accuracy improved to 0.5425, saving model to ./ACNN3/0.51-0.58-epoch27-loss2.30.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2988 - output1_accuracy: 0.5118 - output1_loss: 1.1926 - output2_accuracy: 0.5589 - output2_loss: 1.1062 - val_loss: 2.2944 - val_output1_accuracy: 0.5096 - val_output1_loss: 1.1962 - val_output2_accuracy: 0.5753 - val_output2_loss: 1.0982\n",
      "Epoch 28/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3051 - output1_accuracy: 0.5081 - output1_loss: 1.1946 - output2_accuracy: 0.5571 - output2_loss: 1.1105\n",
      "Epoch 28: Average accuracy did not improve (current: 0.5344, best: 0.5425)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3051 - output1_accuracy: 0.5081 - output1_loss: 1.1946 - output2_accuracy: 0.5571 - output2_loss: 1.1104 - val_loss: 2.2917 - val_output1_accuracy: 0.5106 - val_output1_loss: 1.1946 - val_output2_accuracy: 0.5581 - val_output2_loss: 1.0971\n",
      "Epoch 29/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3047 - output1_accuracy: 0.5091 - output1_loss: 1.1953 - output2_accuracy: 0.5599 - output2_loss: 1.1094\n",
      "Epoch 29: Average accuracy did not improve (current: 0.5410, best: 0.5425)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3047 - output1_accuracy: 0.5092 - output1_loss: 1.1953 - output2_accuracy: 0.5599 - output2_loss: 1.1094 - val_loss: 2.2990 - val_output1_accuracy: 0.5158 - val_output1_loss: 1.1971 - val_output2_accuracy: 0.5661 - val_output2_loss: 1.1019\n",
      "Epoch 30/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2935 - output1_accuracy: 0.5133 - output1_loss: 1.1946 - output2_accuracy: 0.5621 - output2_loss: 1.0989\n",
      "Epoch 30: Average accuracy did not improve (current: 0.5341, best: 0.5425)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2935 - output1_accuracy: 0.5133 - output1_loss: 1.1946 - output2_accuracy: 0.5621 - output2_loss: 1.0989 - val_loss: 2.2959 - val_output1_accuracy: 0.5070 - val_output1_loss: 1.1859 - val_output2_accuracy: 0.5611 - val_output2_loss: 1.1100\n",
      "Epoch 31/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3005 - output1_accuracy: 0.5075 - output1_loss: 1.1982 - output2_accuracy: 0.5625 - output2_loss: 1.1023\n",
      "Epoch 31: Average accuracy improved to 0.5471, saving model to ./ACNN3/0.52-0.57-epoch31-loss2.30.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3005 - output1_accuracy: 0.5075 - output1_loss: 1.1982 - output2_accuracy: 0.5625 - output2_loss: 1.1023 - val_loss: 2.2625 - val_output1_accuracy: 0.5196 - val_output1_loss: 1.1833 - val_output2_accuracy: 0.5745 - val_output2_loss: 1.0792\n",
      "Epoch 32/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3008 - output1_accuracy: 0.5060 - output1_loss: 1.2014 - output2_accuracy: 0.5621 - output2_loss: 1.0994\n",
      "Epoch 32: Average accuracy did not improve (current: 0.5342, best: 0.5471)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3008 - output1_accuracy: 0.5060 - output1_loss: 1.2014 - output2_accuracy: 0.5621 - output2_loss: 1.0994 - val_loss: 2.2929 - val_output1_accuracy: 0.4988 - val_output1_loss: 1.1940 - val_output2_accuracy: 0.5695 - val_output2_loss: 1.0988\n",
      "Epoch 33/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2922 - output1_accuracy: 0.5117 - output1_loss: 1.1915 - output2_accuracy: 0.5619 - output2_loss: 1.1007\n",
      "Epoch 33: Average accuracy did not improve (current: 0.5392, best: 0.5471)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2922 - output1_accuracy: 0.5117 - output1_loss: 1.1915 - output2_accuracy: 0.5619 - output2_loss: 1.1007 - val_loss: 2.2710 - val_output1_accuracy: 0.5064 - val_output1_loss: 1.1895 - val_output2_accuracy: 0.5719 - val_output2_loss: 1.0815\n",
      "Epoch 34/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2884 - output1_accuracy: 0.5117 - output1_loss: 1.1930 - output2_accuracy: 0.5665 - output2_loss: 1.0954\n",
      "Epoch 34: Average accuracy improved to 0.5494, saving model to ./ACNN3/0.52-0.58-epoch34-loss2.29.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2885 - output1_accuracy: 0.5117 - output1_loss: 1.1930 - output2_accuracy: 0.5665 - output2_loss: 1.0954 - val_loss: 2.2675 - val_output1_accuracy: 0.5166 - val_output1_loss: 1.1831 - val_output2_accuracy: 0.5821 - val_output2_loss: 1.0844\n",
      "Epoch 35/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3051 - output1_accuracy: 0.5154 - output1_loss: 1.1932 - output2_accuracy: 0.5551 - output2_loss: 1.1119\n",
      "Epoch 35: Average accuracy did not improve (current: 0.5370, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3051 - output1_accuracy: 0.5154 - output1_loss: 1.1932 - output2_accuracy: 0.5551 - output2_loss: 1.1119 - val_loss: 2.2639 - val_output1_accuracy: 0.5000 - val_output1_loss: 1.1891 - val_output2_accuracy: 0.5739 - val_output2_loss: 1.0749\n",
      "Epoch 36/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3019 - output1_accuracy: 0.5110 - output1_loss: 1.1921 - output2_accuracy: 0.5551 - output2_loss: 1.1098\n",
      "Epoch 36: Average accuracy did not improve (current: 0.5348, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3019 - output1_accuracy: 0.5109 - output1_loss: 1.1921 - output2_accuracy: 0.5551 - output2_loss: 1.1098 - val_loss: 2.2844 - val_output1_accuracy: 0.4978 - val_output1_loss: 1.2010 - val_output2_accuracy: 0.5717 - val_output2_loss: 1.0834\n",
      "Epoch 37/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2873 - output1_accuracy: 0.5157 - output1_loss: 1.1860 - output2_accuracy: 0.5622 - output2_loss: 1.1013\n",
      "Epoch 37: Average accuracy did not improve (current: 0.5393, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2873 - output1_accuracy: 0.5157 - output1_loss: 1.1861 - output2_accuracy: 0.5622 - output2_loss: 1.1013 - val_loss: 2.2654 - val_output1_accuracy: 0.5052 - val_output1_loss: 1.1917 - val_output2_accuracy: 0.5733 - val_output2_loss: 1.0737\n",
      "Epoch 38/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2835 - output1_accuracy: 0.5124 - output1_loss: 1.1894 - output2_accuracy: 0.5619 - output2_loss: 1.0941\n",
      "Epoch 38: Average accuracy did not improve (current: 0.5363, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2835 - output1_accuracy: 0.5124 - output1_loss: 1.1894 - output2_accuracy: 0.5619 - output2_loss: 1.0941 - val_loss: 2.2919 - val_output1_accuracy: 0.5030 - val_output1_loss: 1.1978 - val_output2_accuracy: 0.5695 - val_output2_loss: 1.0941\n",
      "Epoch 39/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2925 - output1_accuracy: 0.5110 - output1_loss: 1.1879 - output2_accuracy: 0.5634 - output2_loss: 1.1046\n",
      "Epoch 39: Average accuracy did not improve (current: 0.5470, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2925 - output1_accuracy: 0.5111 - output1_loss: 1.1879 - output2_accuracy: 0.5634 - output2_loss: 1.1046 - val_loss: 2.2740 - val_output1_accuracy: 0.5164 - val_output1_loss: 1.1841 - val_output2_accuracy: 0.5775 - val_output2_loss: 1.0899\n",
      "Epoch 40/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2911 - output1_accuracy: 0.5077 - output1_loss: 1.1967 - output2_accuracy: 0.5633 - output2_loss: 1.0944\n",
      "Epoch 40: Average accuracy did not improve (current: 0.5343, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2910 - output1_accuracy: 0.5077 - output1_loss: 1.1967 - output2_accuracy: 0.5633 - output2_loss: 1.0944 - val_loss: 2.2837 - val_output1_accuracy: 0.5016 - val_output1_loss: 1.2046 - val_output2_accuracy: 0.5669 - val_output2_loss: 1.0791\n",
      "Epoch 41/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2814 - output1_accuracy: 0.5131 - output1_loss: 1.1845 - output2_accuracy: 0.5642 - output2_loss: 1.0969\n",
      "Epoch 41: Average accuracy did not improve (current: 0.5429, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2814 - output1_accuracy: 0.5131 - output1_loss: 1.1845 - output2_accuracy: 0.5642 - output2_loss: 1.0969 - val_loss: 2.2605 - val_output1_accuracy: 0.5126 - val_output1_loss: 1.1844 - val_output2_accuracy: 0.5731 - val_output2_loss: 1.0761\n",
      "Epoch 42/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2836 - output1_accuracy: 0.5165 - output1_loss: 1.1854 - output2_accuracy: 0.5654 - output2_loss: 1.0982\n",
      "Epoch 42: Average accuracy did not improve (current: 0.5400, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2836 - output1_accuracy: 0.5165 - output1_loss: 1.1854 - output2_accuracy: 0.5654 - output2_loss: 1.0982 - val_loss: 2.2795 - val_output1_accuracy: 0.5076 - val_output1_loss: 1.1816 - val_output2_accuracy: 0.5723 - val_output2_loss: 1.0979\n",
      "Epoch 43/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2821 - output1_accuracy: 0.5144 - output1_loss: 1.1881 - output2_accuracy: 0.5646 - output2_loss: 1.0941\n",
      "Epoch 43: Average accuracy did not improve (current: 0.5474, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2822 - output1_accuracy: 0.5144 - output1_loss: 1.1881 - output2_accuracy: 0.5646 - output2_loss: 1.0941 - val_loss: 2.2824 - val_output1_accuracy: 0.5120 - val_output1_loss: 1.1975 - val_output2_accuracy: 0.5827 - val_output2_loss: 1.0849\n",
      "Epoch 44/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2847 - output1_accuracy: 0.5132 - output1_loss: 1.1851 - output2_accuracy: 0.5640 - output2_loss: 1.0996\n",
      "Epoch 44: Average accuracy did not improve (current: 0.5459, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2847 - output1_accuracy: 0.5132 - output1_loss: 1.1851 - output2_accuracy: 0.5640 - output2_loss: 1.0996 - val_loss: 2.2568 - val_output1_accuracy: 0.5088 - val_output1_loss: 1.1904 - val_output2_accuracy: 0.5829 - val_output2_loss: 1.0663\n",
      "Epoch 45/100\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2764 - output1_accuracy: 0.5111 - output1_loss: 1.1867 - output2_accuracy: 0.5685 - output2_loss: 1.0896\n",
      "Epoch 45: Average accuracy did not improve (current: 0.5447, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2764 - output1_accuracy: 0.5111 - output1_loss: 1.1867 - output2_accuracy: 0.5685 - output2_loss: 1.0896 - val_loss: 2.2540 - val_output1_accuracy: 0.5054 - val_output1_loss: 1.1925 - val_output2_accuracy: 0.5839 - val_output2_loss: 1.0615\n",
      "Epoch 46/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2823 - output1_accuracy: 0.5179 - output1_loss: 1.1807 - output2_accuracy: 0.5640 - output2_loss: 1.1016\n",
      "Epoch 46: Average accuracy did not improve (current: 0.5459, best: 0.5494)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2823 - output1_accuracy: 0.5179 - output1_loss: 1.1807 - output2_accuracy: 0.5640 - output2_loss: 1.1016 - val_loss: 2.2622 - val_output1_accuracy: 0.5084 - val_output1_loss: 1.1907 - val_output2_accuracy: 0.5833 - val_output2_loss: 1.0715\n",
      "Epoch 47/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2829 - output1_accuracy: 0.5128 - output1_loss: 1.1936 - output2_accuracy: 0.5657 - output2_loss: 1.0892\n",
      "Epoch 47: Average accuracy improved to 0.5530, saving model to ./ACNN3/0.51-0.60-epoch47-loss2.28.keras\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2829 - output1_accuracy: 0.5129 - output1_loss: 1.1936 - output2_accuracy: 0.5657 - output2_loss: 1.0892 - val_loss: 2.2170 - val_output1_accuracy: 0.5068 - val_output1_loss: 1.1904 - val_output2_accuracy: 0.5992 - val_output2_loss: 1.0266\n",
      "Epoch 48/100\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2608 - output1_accuracy: 0.5144 - output1_loss: 1.1834 - output2_accuracy: 0.5732 - output2_loss: 1.0774\n",
      "Epoch 48: Average accuracy did not improve (current: 0.5491, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2608 - output1_accuracy: 0.5144 - output1_loss: 1.1834 - output2_accuracy: 0.5732 - output2_loss: 1.0775 - val_loss: 2.2346 - val_output1_accuracy: 0.5246 - val_output1_loss: 1.1603 - val_output2_accuracy: 0.5735 - val_output2_loss: 1.0744\n",
      "Epoch 49/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2636 - output1_accuracy: 0.5198 - output1_loss: 1.1790 - output2_accuracy: 0.5682 - output2_loss: 1.0846\n",
      "Epoch 49: Average accuracy did not improve (current: 0.5480, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2636 - output1_accuracy: 0.5198 - output1_loss: 1.1790 - output2_accuracy: 0.5682 - output2_loss: 1.0846 - val_loss: 2.2499 - val_output1_accuracy: 0.5136 - val_output1_loss: 1.1768 - val_output2_accuracy: 0.5823 - val_output2_loss: 1.0732\n",
      "Epoch 50/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2706 - output1_accuracy: 0.5192 - output1_loss: 1.1764 - output2_accuracy: 0.5668 - output2_loss: 1.0942\n",
      "Epoch 50: Average accuracy did not improve (current: 0.5512, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2706 - output1_accuracy: 0.5192 - output1_loss: 1.1764 - output2_accuracy: 0.5668 - output2_loss: 1.0942 - val_loss: 2.2265 - val_output1_accuracy: 0.5174 - val_output1_loss: 1.1711 - val_output2_accuracy: 0.5849 - val_output2_loss: 1.0553\n",
      "Epoch 51/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2576 - output1_accuracy: 0.5202 - output1_loss: 1.1783 - output2_accuracy: 0.5725 - output2_loss: 1.0793\n",
      "Epoch 51: Average accuracy did not improve (current: 0.5417, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2577 - output1_accuracy: 0.5202 - output1_loss: 1.1784 - output2_accuracy: 0.5725 - output2_loss: 1.0793 - val_loss: 2.2645 - val_output1_accuracy: 0.5124 - val_output1_loss: 1.1843 - val_output2_accuracy: 0.5709 - val_output2_loss: 1.0802\n",
      "Epoch 52/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2760 - output1_accuracy: 0.5141 - output1_loss: 1.1868 - output2_accuracy: 0.5665 - output2_loss: 1.0892\n",
      "Epoch 52: Average accuracy did not improve (current: 0.5493, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.2760 - output1_accuracy: 0.5141 - output1_loss: 1.1868 - output2_accuracy: 0.5665 - output2_loss: 1.0892 - val_loss: 2.2310 - val_output1_accuracy: 0.5228 - val_output1_loss: 1.1520 - val_output2_accuracy: 0.5757 - val_output2_loss: 1.0790\n",
      "Epoch 53/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2545 - output1_accuracy: 0.5131 - output1_loss: 1.1795 - output2_accuracy: 0.5741 - output2_loss: 1.0751\n",
      "Epoch 53: Average accuracy did not improve (current: 0.5469, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2545 - output1_accuracy: 0.5131 - output1_loss: 1.1795 - output2_accuracy: 0.5741 - output2_loss: 1.0751 - val_loss: 2.2428 - val_output1_accuracy: 0.5120 - val_output1_loss: 1.1803 - val_output2_accuracy: 0.5817 - val_output2_loss: 1.0624\n",
      "Epoch 54/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2576 - output1_accuracy: 0.5212 - output1_loss: 1.1723 - output2_accuracy: 0.5680 - output2_loss: 1.0853\n",
      "Epoch 54: Average accuracy did not improve (current: 0.5496, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2576 - output1_accuracy: 0.5212 - output1_loss: 1.1723 - output2_accuracy: 0.5680 - output2_loss: 1.0853 - val_loss: 2.2281 - val_output1_accuracy: 0.5146 - val_output1_loss: 1.1773 - val_output2_accuracy: 0.5845 - val_output2_loss: 1.0508\n",
      "Epoch 55/100\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2552 - output1_accuracy: 0.5217 - output1_loss: 1.1782 - output2_accuracy: 0.5747 - output2_loss: 1.0770\n",
      "Epoch 55: Average accuracy did not improve (current: 0.5489, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2552 - output1_accuracy: 0.5217 - output1_loss: 1.1782 - output2_accuracy: 0.5747 - output2_loss: 1.0770 - val_loss: 2.2259 - val_output1_accuracy: 0.5102 - val_output1_loss: 1.1805 - val_output2_accuracy: 0.5875 - val_output2_loss: 1.0454\n",
      "Epoch 56/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2713 - output1_accuracy: 0.5131 - output1_loss: 1.1846 - output2_accuracy: 0.5686 - output2_loss: 1.0867\n",
      "Epoch 56: Average accuracy did not improve (current: 0.5499, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2712 - output1_accuracy: 0.5131 - output1_loss: 1.1845 - output2_accuracy: 0.5686 - output2_loss: 1.0867 - val_loss: 2.2457 - val_output1_accuracy: 0.5180 - val_output1_loss: 1.1805 - val_output2_accuracy: 0.5817 - val_output2_loss: 1.0652\n",
      "Epoch 57/100\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2518 - output1_accuracy: 0.5211 - output1_loss: 1.1747 - output2_accuracy: 0.5722 - output2_loss: 1.0771\n",
      "Epoch 57: Average accuracy did not improve (current: 0.5527, best: 0.5530)\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2518 - output1_accuracy: 0.5211 - output1_loss: 1.1747 - output2_accuracy: 0.5722 - output2_loss: 1.0771 - val_loss: 2.2211 - val_output1_accuracy: 0.5298 - val_output1_loss: 1.1531 - val_output2_accuracy: 0.5755 - val_output2_loss: 1.0680\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.8476039469242096\n",
      "standard deviation =  0.002697744617377782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "for i in tqdm(range(10)):\n",
    "    loss, acc1, loss1, acc2, loss2 = model.evaluate(testgensmall, batch_size=1000, steps=10, verbose=False)\n",
    "    evaluation_results.append(np.mean([acc1, acc2]))\n",
    "print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,750,998</span> (10.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,750,998\u001b[0m (10.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,500</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,375,500\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4843 - output1_accuracy: 0.4787 - output1_loss: 1.2502 - output2_accuracy: 0.4968 - output2_loss: 1.2341 - val_loss: 2.4948 - val_output1_accuracy: 0.4708 - val_output1_loss: 1.2724 - val_output2_accuracy: 0.5024 - val_output2_loss: 1.2224\n",
      "Epoch 2/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4939 - output1_accuracy: 0.4732 - output1_loss: 1.2644 - output2_accuracy: 0.4912 - output2_loss: 1.2296 - val_loss: 2.4797 - val_output1_accuracy: 0.4768 - val_output1_loss: 1.2599 - val_output2_accuracy: 0.5010 - val_output2_loss: 1.2198\n",
      "Epoch 3/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 2.4852 - output1_accuracy: 0.4734 - output1_loss: 1.2606 - output2_accuracy: 0.5010 - output2_loss: 1.2246 - val_loss: 2.4748 - val_output1_accuracy: 0.4665 - val_output1_loss: 1.2629 - val_output2_accuracy: 0.5058 - val_output2_loss: 1.2119\n",
      "Epoch 4/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4816 - output1_accuracy: 0.4756 - output1_loss: 1.2521 - output2_accuracy: 0.4962 - output2_loss: 1.2295 - val_loss: 2.4880 - val_output1_accuracy: 0.4740 - val_output1_loss: 1.2578 - val_output2_accuracy: 0.4952 - val_output2_loss: 1.2302\n",
      "Epoch 5/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4853 - output1_accuracy: 0.4684 - output1_loss: 1.2694 - output2_accuracy: 0.5071 - output2_loss: 1.2160 - val_loss: 2.4911 - val_output1_accuracy: 0.4738 - val_output1_loss: 1.2772 - val_output2_accuracy: 0.5090 - val_output2_loss: 1.2139\n",
      "Epoch 6/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4684 - output1_accuracy: 0.4823 - output1_loss: 1.2538 - output2_accuracy: 0.5013 - output2_loss: 1.2146 - val_loss: 2.4775 - val_output1_accuracy: 0.4814 - val_output1_loss: 1.2508 - val_output2_accuracy: 0.5020 - val_output2_loss: 1.2267\n",
      "Epoch 7/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4779 - output1_accuracy: 0.4759 - output1_loss: 1.2567 - output2_accuracy: 0.5028 - output2_loss: 1.2212 - val_loss: 2.4578 - val_output1_accuracy: 0.4844 - val_output1_loss: 1.2417 - val_output2_accuracy: 0.5152 - val_output2_loss: 1.2161\n",
      "Epoch 8/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4610 - output1_accuracy: 0.4799 - output1_loss: 1.2535 - output2_accuracy: 0.5101 - output2_loss: 1.2075 - val_loss: 2.4617 - val_output1_accuracy: 0.4844 - val_output1_loss: 1.2459 - val_output2_accuracy: 0.5100 - val_output2_loss: 1.2158\n",
      "Epoch 9/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4649 - output1_accuracy: 0.4786 - output1_loss: 1.2538 - output2_accuracy: 0.5055 - output2_loss: 1.2111 - val_loss: 2.4520 - val_output1_accuracy: 0.4830 - val_output1_loss: 1.2377 - val_output2_accuracy: 0.5142 - val_output2_loss: 1.2144\n",
      "Epoch 10/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4411 - output1_accuracy: 0.4831 - output1_loss: 1.2437 - output2_accuracy: 0.5162 - output2_loss: 1.1974 - val_loss: 2.4573 - val_output1_accuracy: 0.4842 - val_output1_loss: 1.2628 - val_output2_accuracy: 0.5180 - val_output2_loss: 1.1946\n",
      "Epoch 11/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4563 - output1_accuracy: 0.4796 - output1_loss: 1.2534 - output2_accuracy: 0.5111 - output2_loss: 1.2029 - val_loss: 2.4547 - val_output1_accuracy: 0.4730 - val_output1_loss: 1.2537 - val_output2_accuracy: 0.5150 - val_output2_loss: 1.2010\n",
      "Epoch 12/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4485 - output1_accuracy: 0.4782 - output1_loss: 1.2526 - output2_accuracy: 0.5149 - output2_loss: 1.1959 - val_loss: 2.4571 - val_output1_accuracy: 0.4868 - val_output1_loss: 1.2537 - val_output2_accuracy: 0.5104 - val_output2_loss: 1.2034\n",
      "Epoch 13/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4423 - output1_accuracy: 0.4881 - output1_loss: 1.2409 - output2_accuracy: 0.5127 - output2_loss: 1.2014 - val_loss: 2.4640 - val_output1_accuracy: 0.4692 - val_output1_loss: 1.2668 - val_output2_accuracy: 0.5124 - val_output2_loss: 1.1972\n",
      "Epoch 14/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.4375 - output1_accuracy: 0.4798 - output1_loss: 1.2452 - output2_accuracy: 0.5144 - output2_loss: 1.1923 - val_loss: 2.4508 - val_output1_accuracy: 0.4890 - val_output1_loss: 1.2438 - val_output2_accuracy: 0.5042 - val_output2_loss: 1.2070\n",
      "Epoch 15/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4411 - output1_accuracy: 0.4856 - output1_loss: 1.2397 - output2_accuracy: 0.5149 - output2_loss: 1.2014 - val_loss: 2.4796 - val_output1_accuracy: 0.4694 - val_output1_loss: 1.2750 - val_output2_accuracy: 0.5112 - val_output2_loss: 1.2047\n",
      "Epoch 16/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4370 - output1_accuracy: 0.4811 - output1_loss: 1.2475 - output2_accuracy: 0.5189 - output2_loss: 1.1895 - val_loss: 2.4345 - val_output1_accuracy: 0.4834 - val_output1_loss: 1.2524 - val_output2_accuracy: 0.5152 - val_output2_loss: 1.1821\n",
      "Epoch 17/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4279 - output1_accuracy: 0.4933 - output1_loss: 1.2352 - output2_accuracy: 0.5142 - output2_loss: 1.1928 - val_loss: 2.4342 - val_output1_accuracy: 0.4876 - val_output1_loss: 1.2293 - val_output2_accuracy: 0.5100 - val_output2_loss: 1.2049\n",
      "Epoch 18/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4331 - output1_accuracy: 0.4858 - output1_loss: 1.2382 - output2_accuracy: 0.5144 - output2_loss: 1.1949 - val_loss: 2.4079 - val_output1_accuracy: 0.4840 - val_output1_loss: 1.2348 - val_output2_accuracy: 0.5216 - val_output2_loss: 1.1731\n",
      "Epoch 19/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4306 - output1_accuracy: 0.4885 - output1_loss: 1.2345 - output2_accuracy: 0.5116 - output2_loss: 1.1961 - val_loss: 2.4241 - val_output1_accuracy: 0.4834 - val_output1_loss: 1.2363 - val_output2_accuracy: 0.5230 - val_output2_loss: 1.1878\n",
      "Epoch 20/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4229 - output1_accuracy: 0.4827 - output1_loss: 1.2379 - output2_accuracy: 0.5201 - output2_loss: 1.1851 - val_loss: 2.4325 - val_output1_accuracy: 0.4776 - val_output1_loss: 1.2493 - val_output2_accuracy: 0.5238 - val_output2_loss: 1.1832\n",
      "Epoch 21/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4276 - output1_accuracy: 0.4840 - output1_loss: 1.2371 - output2_accuracy: 0.5166 - output2_loss: 1.1905 - val_loss: 2.4145 - val_output1_accuracy: 0.4842 - val_output1_loss: 1.2285 - val_output2_accuracy: 0.5204 - val_output2_loss: 1.1860\n",
      "Epoch 22/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4132 - output1_accuracy: 0.4930 - output1_loss: 1.2273 - output2_accuracy: 0.5206 - output2_loss: 1.1859 - val_loss: 2.4133 - val_output1_accuracy: 0.4864 - val_output1_loss: 1.2315 - val_output2_accuracy: 0.5208 - val_output2_loss: 1.1817\n",
      "Epoch 23/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4085 - output1_accuracy: 0.4909 - output1_loss: 1.2322 - output2_accuracy: 0.5225 - output2_loss: 1.1762 - val_loss: 2.4152 - val_output1_accuracy: 0.4844 - val_output1_loss: 1.2413 - val_output2_accuracy: 0.5258 - val_output2_loss: 1.1739\n",
      "Epoch 24/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4252 - output1_accuracy: 0.4840 - output1_loss: 1.2390 - output2_accuracy: 0.5216 - output2_loss: 1.1862 - val_loss: 2.4183 - val_output1_accuracy: 0.4998 - val_output1_loss: 1.2359 - val_output2_accuracy: 0.5174 - val_output2_loss: 1.1824\n",
      "Epoch 25/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4161 - output1_accuracy: 0.4818 - output1_loss: 1.2356 - output2_accuracy: 0.5245 - output2_loss: 1.1804 - val_loss: 2.4469 - val_output1_accuracy: 0.4796 - val_output1_loss: 1.2465 - val_output2_accuracy: 0.5186 - val_output2_loss: 1.2003\n",
      "Epoch 26/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.4181 - output1_accuracy: 0.4850 - output1_loss: 1.2406 - output2_accuracy: 0.5210 - output2_loss: 1.1775 - val_loss: 2.3971 - val_output1_accuracy: 0.4864 - val_output1_loss: 1.2284 - val_output2_accuracy: 0.5244 - val_output2_loss: 1.1687\n",
      "Epoch 27/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.4038 - output1_accuracy: 0.4889 - output1_loss: 1.2311 - output2_accuracy: 0.5264 - output2_loss: 1.1727 - val_loss: 2.4030 - val_output1_accuracy: 0.4814 - val_output1_loss: 1.2384 - val_output2_accuracy: 0.5379 - val_output2_loss: 1.1646\n",
      "Epoch 28/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3913 - output1_accuracy: 0.4944 - output1_loss: 1.2190 - output2_accuracy: 0.5285 - output2_loss: 1.1723 - val_loss: 2.3823 - val_output1_accuracy: 0.5002 - val_output1_loss: 1.2146 - val_output2_accuracy: 0.5315 - val_output2_loss: 1.1677\n",
      "Epoch 29/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3939 - output1_accuracy: 0.4930 - output1_loss: 1.2288 - output2_accuracy: 0.5307 - output2_loss: 1.1651 - val_loss: 2.4098 - val_output1_accuracy: 0.4858 - val_output1_loss: 1.2360 - val_output2_accuracy: 0.5280 - val_output2_loss: 1.1738\n",
      "Epoch 30/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3951 - output1_accuracy: 0.4907 - output1_loss: 1.2285 - output2_accuracy: 0.5277 - output2_loss: 1.1666 - val_loss: 2.3707 - val_output1_accuracy: 0.5002 - val_output1_loss: 1.2076 - val_output2_accuracy: 0.5292 - val_output2_loss: 1.1631\n",
      "Epoch 31/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3976 - output1_accuracy: 0.4849 - output1_loss: 1.2325 - output2_accuracy: 0.5255 - output2_loss: 1.1651 - val_loss: 2.3884 - val_output1_accuracy: 0.4994 - val_output1_loss: 1.2251 - val_output2_accuracy: 0.5280 - val_output2_loss: 1.1633\n",
      "Epoch 32/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3894 - output1_accuracy: 0.4938 - output1_loss: 1.2251 - output2_accuracy: 0.5311 - output2_loss: 1.1643 - val_loss: 2.4125 - val_output1_accuracy: 0.4882 - val_output1_loss: 1.2441 - val_output2_accuracy: 0.5315 - val_output2_loss: 1.1684\n",
      "Epoch 33/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3915 - output1_accuracy: 0.4905 - output1_loss: 1.2317 - output2_accuracy: 0.5334 - output2_loss: 1.1598 - val_loss: 2.3859 - val_output1_accuracy: 0.4908 - val_output1_loss: 1.2404 - val_output2_accuracy: 0.5447 - val_output2_loss: 1.1454\n",
      "Epoch 34/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3836 - output1_accuracy: 0.4935 - output1_loss: 1.2240 - output2_accuracy: 0.5342 - output2_loss: 1.1597 - val_loss: 2.3920 - val_output1_accuracy: 0.4886 - val_output1_loss: 1.2302 - val_output2_accuracy: 0.5387 - val_output2_loss: 1.1618\n",
      "Epoch 35/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3808 - output1_accuracy: 0.4941 - output1_loss: 1.2243 - output2_accuracy: 0.5341 - output2_loss: 1.1565 - val_loss: 2.3888 - val_output1_accuracy: 0.4896 - val_output1_loss: 1.2337 - val_output2_accuracy: 0.5337 - val_output2_loss: 1.1551\n",
      "Epoch 36/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3873 - output1_accuracy: 0.4925 - output1_loss: 1.2291 - output2_accuracy: 0.5342 - output2_loss: 1.1582 - val_loss: 2.4088 - val_output1_accuracy: 0.4856 - val_output1_loss: 1.2249 - val_output2_accuracy: 0.5192 - val_output2_loss: 1.1839\n",
      "Epoch 37/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3693 - output1_accuracy: 0.5036 - output1_loss: 1.2184 - output2_accuracy: 0.5284 - output2_loss: 1.1509 - val_loss: 2.4350 - val_output1_accuracy: 0.4690 - val_output1_loss: 1.2720 - val_output2_accuracy: 0.5333 - val_output2_loss: 1.1629\n",
      "Epoch 38/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3833 - output1_accuracy: 0.4974 - output1_loss: 1.2235 - output2_accuracy: 0.5374 - output2_loss: 1.1598 - val_loss: 2.3667 - val_output1_accuracy: 0.4882 - val_output1_loss: 1.2329 - val_output2_accuracy: 0.5493 - val_output2_loss: 1.1338\n",
      "Epoch 39/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3708 - output1_accuracy: 0.5012 - output1_loss: 1.2176 - output2_accuracy: 0.5337 - output2_loss: 1.1532 - val_loss: 2.3773 - val_output1_accuracy: 0.4986 - val_output1_loss: 1.2272 - val_output2_accuracy: 0.5371 - val_output2_loss: 1.1501\n",
      "Epoch 40/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3736 - output1_accuracy: 0.4964 - output1_loss: 1.2192 - output2_accuracy: 0.5343 - output2_loss: 1.1544 - val_loss: 2.3965 - val_output1_accuracy: 0.4836 - val_output1_loss: 1.2487 - val_output2_accuracy: 0.5381 - val_output2_loss: 1.1477\n",
      "Epoch 41/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3798 - output1_accuracy: 0.4967 - output1_loss: 1.2250 - output2_accuracy: 0.5346 - output2_loss: 1.1549 - val_loss: 2.4075 - val_output1_accuracy: 0.4784 - val_output1_loss: 1.2514 - val_output2_accuracy: 0.5325 - val_output2_loss: 1.1561\n",
      "Epoch 42/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3666 - output1_accuracy: 0.4960 - output1_loss: 1.2225 - output2_accuracy: 0.5349 - output2_loss: 1.1441 - val_loss: 2.3722 - val_output1_accuracy: 0.4936 - val_output1_loss: 1.2254 - val_output2_accuracy: 0.5445 - val_output2_loss: 1.1468\n",
      "Epoch 43/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3595 - output1_accuracy: 0.5022 - output1_loss: 1.2080 - output2_accuracy: 0.5364 - output2_loss: 1.1515 - val_loss: 2.3826 - val_output1_accuracy: 0.4898 - val_output1_loss: 1.2241 - val_output2_accuracy: 0.5367 - val_output2_loss: 1.1585\n",
      "Epoch 44/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3540 - output1_accuracy: 0.5016 - output1_loss: 1.2089 - output2_accuracy: 0.5411 - output2_loss: 1.1451 - val_loss: 2.3754 - val_output1_accuracy: 0.4876 - val_output1_loss: 1.2315 - val_output2_accuracy: 0.5401 - val_output2_loss: 1.1440\n",
      "Epoch 45/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3577 - output1_accuracy: 0.4980 - output1_loss: 1.2152 - output2_accuracy: 0.5428 - output2_loss: 1.1425 - val_loss: 2.3754 - val_output1_accuracy: 0.4834 - val_output1_loss: 1.2411 - val_output2_accuracy: 0.5475 - val_output2_loss: 1.1344\n",
      "Epoch 46/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3369 - output1_accuracy: 0.4990 - output1_loss: 1.2081 - output2_accuracy: 0.5509 - output2_loss: 1.1288 - val_loss: 2.3621 - val_output1_accuracy: 0.4912 - val_output1_loss: 1.2222 - val_output2_accuracy: 0.5433 - val_output2_loss: 1.1398\n",
      "Epoch 47/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3616 - output1_accuracy: 0.4997 - output1_loss: 1.2143 - output2_accuracy: 0.5383 - output2_loss: 1.1473 - val_loss: 2.3553 - val_output1_accuracy: 0.4878 - val_output1_loss: 1.2227 - val_output2_accuracy: 0.5499 - val_output2_loss: 1.1326\n",
      "Epoch 48/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3564 - output1_accuracy: 0.4988 - output1_loss: 1.2119 - output2_accuracy: 0.5383 - output2_loss: 1.1445 - val_loss: 2.3664 - val_output1_accuracy: 0.4968 - val_output1_loss: 1.2331 - val_output2_accuracy: 0.5453 - val_output2_loss: 1.1333\n",
      "Epoch 49/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3604 - output1_accuracy: 0.4988 - output1_loss: 1.2177 - output2_accuracy: 0.5429 - output2_loss: 1.1427 - val_loss: 2.3818 - val_output1_accuracy: 0.4868 - val_output1_loss: 1.2513 - val_output2_accuracy: 0.5417 - val_output2_loss: 1.1306\n",
      "Epoch 50/50\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3437 - output1_accuracy: 0.5021 - output1_loss: 1.2047 - output2_accuracy: 0.5460 - output2_loss: 1.1390 - val_loss: 2.3639 - val_output1_accuracy: 0.4888 - val_output1_loss: 1.2392 - val_output2_accuracy: 0.5549 - val_output2_loss: 1.1247\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=50,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    # callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,750,998</span> (10.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,750,998\u001b[0m (10.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,500</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,375,500\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3523 - output1_accuracy: 0.4991 - output1_loss: 1.2048 - output2_accuracy: 0.5351 - output2_loss: 1.1474 - val_loss: 2.3706 - val_output1_accuracy: 0.4898 - val_output1_loss: 1.2364 - val_output2_accuracy: 0.5493 - val_output2_loss: 1.1342\n",
      "Epoch 2/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3364 - output1_accuracy: 0.5025 - output1_loss: 1.2107 - output2_accuracy: 0.5453 - output2_loss: 1.1257 - val_loss: 2.3529 - val_output1_accuracy: 0.4948 - val_output1_loss: 1.2242 - val_output2_accuracy: 0.5503 - val_output2_loss: 1.1286\n",
      "Epoch 3/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3211 - output1_accuracy: 0.5090 - output1_loss: 1.1996 - output2_accuracy: 0.5534 - output2_loss: 1.1215 - val_loss: 2.3393 - val_output1_accuracy: 0.4954 - val_output1_loss: 1.2202 - val_output2_accuracy: 0.5549 - val_output2_loss: 1.1191\n",
      "Epoch 4/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3492 - output1_accuracy: 0.4990 - output1_loss: 1.2162 - output2_accuracy: 0.5457 - output2_loss: 1.1330 - val_loss: 2.3452 - val_output1_accuracy: 0.4904 - val_output1_loss: 1.2256 - val_output2_accuracy: 0.5499 - val_output2_loss: 1.1197\n",
      "Epoch 5/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3379 - output1_accuracy: 0.5048 - output1_loss: 1.2070 - output2_accuracy: 0.5452 - output2_loss: 1.1309 - val_loss: 2.3178 - val_output1_accuracy: 0.4986 - val_output1_loss: 1.2082 - val_output2_accuracy: 0.5549 - val_output2_loss: 1.1097\n",
      "Epoch 6/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3407 - output1_accuracy: 0.5017 - output1_loss: 1.2116 - output2_accuracy: 0.5484 - output2_loss: 1.1291 - val_loss: 2.3408 - val_output1_accuracy: 0.4904 - val_output1_loss: 1.2277 - val_output2_accuracy: 0.5621 - val_output2_loss: 1.1131\n",
      "Epoch 7/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.3204 - output1_accuracy: 0.5016 - output1_loss: 1.2067 - output2_accuracy: 0.5564 - output2_loss: 1.1136 - val_loss: 2.3420 - val_output1_accuracy: 0.5082 - val_output1_loss: 1.2074 - val_output2_accuracy: 0.5437 - val_output2_loss: 1.1346\n",
      "Epoch 8/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3415 - output1_accuracy: 0.5101 - output1_loss: 1.2040 - output2_accuracy: 0.5444 - output2_loss: 1.1375 - val_loss: 2.3147 - val_output1_accuracy: 0.5062 - val_output1_loss: 1.2123 - val_output2_accuracy: 0.5629 - val_output2_loss: 1.1024\n",
      "Epoch 9/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3455 - output1_accuracy: 0.5025 - output1_loss: 1.2144 - output2_accuracy: 0.5448 - output2_loss: 1.1311 - val_loss: 2.2796 - val_output1_accuracy: 0.5136 - val_output1_loss: 1.1938 - val_output2_accuracy: 0.5745 - val_output2_loss: 1.0858\n",
      "Epoch 10/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3232 - output1_accuracy: 0.5067 - output1_loss: 1.1995 - output2_accuracy: 0.5503 - output2_loss: 1.1236 - val_loss: 2.3127 - val_output1_accuracy: 0.5024 - val_output1_loss: 1.2094 - val_output2_accuracy: 0.5591 - val_output2_loss: 1.1033\n",
      "Epoch 11/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3120 - output1_accuracy: 0.5107 - output1_loss: 1.1938 - output2_accuracy: 0.5554 - output2_loss: 1.1182 - val_loss: 2.3293 - val_output1_accuracy: 0.4966 - val_output1_loss: 1.2143 - val_output2_accuracy: 0.5543 - val_output2_loss: 1.1150\n",
      "Epoch 12/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3232 - output1_accuracy: 0.5074 - output1_loss: 1.1967 - output2_accuracy: 0.5489 - output2_loss: 1.1265 - val_loss: 2.3342 - val_output1_accuracy: 0.4920 - val_output1_loss: 1.2180 - val_output2_accuracy: 0.5487 - val_output2_loss: 1.1163\n",
      "Epoch 13/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3003 - output1_accuracy: 0.5084 - output1_loss: 1.1930 - output2_accuracy: 0.5588 - output2_loss: 1.1074 - val_loss: 2.3627 - val_output1_accuracy: 0.4940 - val_output1_loss: 1.2313 - val_output2_accuracy: 0.5611 - val_output2_loss: 1.1314\n",
      "Epoch 14/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3075 - output1_accuracy: 0.5052 - output1_loss: 1.1984 - output2_accuracy: 0.5571 - output2_loss: 1.1091 - val_loss: 2.3062 - val_output1_accuracy: 0.5074 - val_output1_loss: 1.2008 - val_output2_accuracy: 0.5615 - val_output2_loss: 1.1053\n",
      "Epoch 15/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3169 - output1_accuracy: 0.5066 - output1_loss: 1.1964 - output2_accuracy: 0.5557 - output2_loss: 1.1205 - val_loss: 2.3171 - val_output1_accuracy: 0.5070 - val_output1_loss: 1.2068 - val_output2_accuracy: 0.5561 - val_output2_loss: 1.1103\n",
      "Epoch 16/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3195 - output1_accuracy: 0.5071 - output1_loss: 1.1971 - output2_accuracy: 0.5477 - output2_loss: 1.1224 - val_loss: 2.3326 - val_output1_accuracy: 0.4998 - val_output1_loss: 1.2228 - val_output2_accuracy: 0.5593 - val_output2_loss: 1.1098\n",
      "Epoch 17/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3174 - output1_accuracy: 0.5076 - output1_loss: 1.2017 - output2_accuracy: 0.5514 - output2_loss: 1.1156 - val_loss: 2.3127 - val_output1_accuracy: 0.5110 - val_output1_loss: 1.2071 - val_output2_accuracy: 0.5643 - val_output2_loss: 1.1056\n",
      "Epoch 18/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3016 - output1_accuracy: 0.5127 - output1_loss: 1.1903 - output2_accuracy: 0.5579 - output2_loss: 1.1113 - val_loss: 2.3305 - val_output1_accuracy: 0.5036 - val_output1_loss: 1.2170 - val_output2_accuracy: 0.5679 - val_output2_loss: 1.1135\n",
      "Epoch 19/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.3083 - output1_accuracy: 0.5106 - output1_loss: 1.1948 - output2_accuracy: 0.5542 - output2_loss: 1.1135 - val_loss: 2.3274 - val_output1_accuracy: 0.5054 - val_output1_loss: 1.2144 - val_output2_accuracy: 0.5557 - val_output2_loss: 1.1129\n",
      "Epoch 20/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3077 - output1_accuracy: 0.5053 - output1_loss: 1.2033 - output2_accuracy: 0.5616 - output2_loss: 1.1045 - val_loss: 2.3020 - val_output1_accuracy: 0.5058 - val_output1_loss: 1.1978 - val_output2_accuracy: 0.5691 - val_output2_loss: 1.1042\n",
      "Epoch 21/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2971 - output1_accuracy: 0.5086 - output1_loss: 1.1897 - output2_accuracy: 0.5583 - output2_loss: 1.1074 - val_loss: 2.3056 - val_output1_accuracy: 0.5098 - val_output1_loss: 1.1948 - val_output2_accuracy: 0.5611 - val_output2_loss: 1.1108\n",
      "Epoch 22/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2961 - output1_accuracy: 0.5144 - output1_loss: 1.1863 - output2_accuracy: 0.5575 - output2_loss: 1.1097 - val_loss: 2.3063 - val_output1_accuracy: 0.5040 - val_output1_loss: 1.2116 - val_output2_accuracy: 0.5647 - val_output2_loss: 1.0947\n",
      "Epoch 23/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2902 - output1_accuracy: 0.5166 - output1_loss: 1.1843 - output2_accuracy: 0.5569 - output2_loss: 1.1058 - val_loss: 2.3195 - val_output1_accuracy: 0.4940 - val_output1_loss: 1.2153 - val_output2_accuracy: 0.5593 - val_output2_loss: 1.1042\n",
      "Epoch 24/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.3035 - output1_accuracy: 0.5107 - output1_loss: 1.1957 - output2_accuracy: 0.5588 - output2_loss: 1.1077 - val_loss: 2.3292 - val_output1_accuracy: 0.5018 - val_output1_loss: 1.2196 - val_output2_accuracy: 0.5583 - val_output2_loss: 1.1096\n",
      "Epoch 25/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2996 - output1_accuracy: 0.5101 - output1_loss: 1.1954 - output2_accuracy: 0.5580 - output2_loss: 1.1042 - val_loss: 2.3111 - val_output1_accuracy: 0.5176 - val_output1_loss: 1.2027 - val_output2_accuracy: 0.5499 - val_output2_loss: 1.1083\n",
      "Epoch 26/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2944 - output1_accuracy: 0.5095 - output1_loss: 1.1931 - output2_accuracy: 0.5590 - output2_loss: 1.1013 - val_loss: 2.2970 - val_output1_accuracy: 0.5080 - val_output1_loss: 1.1921 - val_output2_accuracy: 0.5647 - val_output2_loss: 1.1049\n",
      "Epoch 27/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2987 - output1_accuracy: 0.5079 - output1_loss: 1.1954 - output2_accuracy: 0.5595 - output2_loss: 1.1034 - val_loss: 2.2990 - val_output1_accuracy: 0.5150 - val_output1_loss: 1.1857 - val_output2_accuracy: 0.5565 - val_output2_loss: 1.1133\n",
      "Epoch 28/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2909 - output1_accuracy: 0.5087 - output1_loss: 1.1872 - output2_accuracy: 0.5595 - output2_loss: 1.1038 - val_loss: 2.2933 - val_output1_accuracy: 0.4956 - val_output1_loss: 1.2096 - val_output2_accuracy: 0.5681 - val_output2_loss: 1.0837\n",
      "Epoch 29/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2735 - output1_accuracy: 0.5156 - output1_loss: 1.1835 - output2_accuracy: 0.5677 - output2_loss: 1.0900 - val_loss: 2.2716 - val_output1_accuracy: 0.5110 - val_output1_loss: 1.1918 - val_output2_accuracy: 0.5709 - val_output2_loss: 1.0799\n",
      "Epoch 30/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2834 - output1_accuracy: 0.5161 - output1_loss: 1.1878 - output2_accuracy: 0.5633 - output2_loss: 1.0956 - val_loss: 2.3000 - val_output1_accuracy: 0.5106 - val_output1_loss: 1.1960 - val_output2_accuracy: 0.5729 - val_output2_loss: 1.1040\n",
      "Epoch 31/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2684 - output1_accuracy: 0.5228 - output1_loss: 1.1751 - output2_accuracy: 0.5631 - output2_loss: 1.0934 - val_loss: 2.2969 - val_output1_accuracy: 0.5042 - val_output1_loss: 1.2065 - val_output2_accuracy: 0.5675 - val_output2_loss: 1.0903\n",
      "Epoch 32/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2868 - output1_accuracy: 0.5108 - output1_loss: 1.1923 - output2_accuracy: 0.5653 - output2_loss: 1.0945 - val_loss: 2.2926 - val_output1_accuracy: 0.5146 - val_output1_loss: 1.1880 - val_output2_accuracy: 0.5709 - val_output2_loss: 1.1046\n",
      "Epoch 33/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2916 - output1_accuracy: 0.5093 - output1_loss: 1.1913 - output2_accuracy: 0.5625 - output2_loss: 1.1003 - val_loss: 2.2819 - val_output1_accuracy: 0.5182 - val_output1_loss: 1.1872 - val_output2_accuracy: 0.5693 - val_output2_loss: 1.0947\n",
      "Epoch 34/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2820 - output1_accuracy: 0.5166 - output1_loss: 1.1830 - output2_accuracy: 0.5610 - output2_loss: 1.0990 - val_loss: 2.2859 - val_output1_accuracy: 0.5120 - val_output1_loss: 1.1935 - val_output2_accuracy: 0.5587 - val_output2_loss: 1.0925\n",
      "Epoch 35/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2855 - output1_accuracy: 0.5125 - output1_loss: 1.1845 - output2_accuracy: 0.5616 - output2_loss: 1.1010 - val_loss: 2.2590 - val_output1_accuracy: 0.5132 - val_output1_loss: 1.1839 - val_output2_accuracy: 0.5777 - val_output2_loss: 1.0750\n",
      "Epoch 36/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2721 - output1_accuracy: 0.5116 - output1_loss: 1.1821 - output2_accuracy: 0.5619 - output2_loss: 1.0900 - val_loss: 2.2933 - val_output1_accuracy: 0.5050 - val_output1_loss: 1.2036 - val_output2_accuracy: 0.5639 - val_output2_loss: 1.0896\n",
      "Epoch 37/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2814 - output1_accuracy: 0.5144 - output1_loss: 1.1862 - output2_accuracy: 0.5640 - output2_loss: 1.0952 - val_loss: 2.2988 - val_output1_accuracy: 0.5092 - val_output1_loss: 1.2107 - val_output2_accuracy: 0.5661 - val_output2_loss: 1.0881\n",
      "Epoch 38/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2689 - output1_accuracy: 0.5133 - output1_loss: 1.1774 - output2_accuracy: 0.5696 - output2_loss: 1.0915 - val_loss: 2.2763 - val_output1_accuracy: 0.5080 - val_output1_loss: 1.1976 - val_output2_accuracy: 0.5747 - val_output2_loss: 1.0787\n",
      "Epoch 39/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2703 - output1_accuracy: 0.5151 - output1_loss: 1.1839 - output2_accuracy: 0.5652 - output2_loss: 1.0865 - val_loss: 2.2763 - val_output1_accuracy: 0.5110 - val_output1_loss: 1.1925 - val_output2_accuracy: 0.5697 - val_output2_loss: 1.0838\n",
      "Epoch 40/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2629 - output1_accuracy: 0.5208 - output1_loss: 1.1756 - output2_accuracy: 0.5680 - output2_loss: 1.0873 - val_loss: 2.2792 - val_output1_accuracy: 0.5176 - val_output1_loss: 1.1801 - val_output2_accuracy: 0.5675 - val_output2_loss: 1.0991\n",
      "Epoch 41/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2741 - output1_accuracy: 0.5214 - output1_loss: 1.1788 - output2_accuracy: 0.5661 - output2_loss: 1.0953 - val_loss: 2.2967 - val_output1_accuracy: 0.5086 - val_output1_loss: 1.2053 - val_output2_accuracy: 0.5695 - val_output2_loss: 1.0914\n",
      "Epoch 42/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2502 - output1_accuracy: 0.5221 - output1_loss: 1.1682 - output2_accuracy: 0.5731 - output2_loss: 1.0820 - val_loss: 2.2731 - val_output1_accuracy: 0.5084 - val_output1_loss: 1.1912 - val_output2_accuracy: 0.5667 - val_output2_loss: 1.0819\n",
      "Epoch 43/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2759 - output1_accuracy: 0.5174 - output1_loss: 1.1770 - output2_accuracy: 0.5653 - output2_loss: 1.0988 - val_loss: 2.2597 - val_output1_accuracy: 0.5088 - val_output1_loss: 1.1875 - val_output2_accuracy: 0.5837 - val_output2_loss: 1.0722\n",
      "Epoch 44/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2636 - output1_accuracy: 0.5218 - output1_loss: 1.1764 - output2_accuracy: 0.5660 - output2_loss: 1.0872 - val_loss: 2.2755 - val_output1_accuracy: 0.5064 - val_output1_loss: 1.1877 - val_output2_accuracy: 0.5669 - val_output2_loss: 1.0878\n",
      "Epoch 45/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2627 - output1_accuracy: 0.5140 - output1_loss: 1.1803 - output2_accuracy: 0.5703 - output2_loss: 1.0824 - val_loss: 2.2676 - val_output1_accuracy: 0.5088 - val_output1_loss: 1.2003 - val_output2_accuracy: 0.5757 - val_output2_loss: 1.0672\n",
      "Epoch 46/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2632 - output1_accuracy: 0.5171 - output1_loss: 1.1801 - output2_accuracy: 0.5676 - output2_loss: 1.0831 - val_loss: 2.2813 - val_output1_accuracy: 0.5106 - val_output1_loss: 1.2091 - val_output2_accuracy: 0.5793 - val_output2_loss: 1.0722\n",
      "Epoch 47/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2602 - output1_accuracy: 0.5186 - output1_loss: 1.1717 - output2_accuracy: 0.5707 - output2_loss: 1.0885 - val_loss: 2.2737 - val_output1_accuracy: 0.5178 - val_output1_loss: 1.1903 - val_output2_accuracy: 0.5717 - val_output2_loss: 1.0835\n",
      "Epoch 48/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2762 - output1_accuracy: 0.5124 - output1_loss: 1.1824 - output2_accuracy: 0.5656 - output2_loss: 1.0937 - val_loss: 2.2687 - val_output1_accuracy: 0.5048 - val_output1_loss: 1.1989 - val_output2_accuracy: 0.5781 - val_output2_loss: 1.0698\n",
      "Epoch 49/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2502 - output1_accuracy: 0.5228 - output1_loss: 1.1702 - output2_accuracy: 0.5724 - output2_loss: 1.0800 - val_loss: 2.2456 - val_output1_accuracy: 0.5140 - val_output1_loss: 1.1917 - val_output2_accuracy: 0.5741 - val_output2_loss: 1.0539\n",
      "Epoch 50/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2523 - output1_accuracy: 0.5184 - output1_loss: 1.1729 - output2_accuracy: 0.5714 - output2_loss: 1.0793 - val_loss: 2.2700 - val_output1_accuracy: 0.5074 - val_output1_loss: 1.1936 - val_output2_accuracy: 0.5825 - val_output2_loss: 1.0763\n",
      "Epoch 51/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2423 - output1_accuracy: 0.5245 - output1_loss: 1.1673 - output2_accuracy: 0.5774 - output2_loss: 1.0750 - val_loss: 2.2763 - val_output1_accuracy: 0.5198 - val_output1_loss: 1.1873 - val_output2_accuracy: 0.5643 - val_output2_loss: 1.0889\n",
      "Epoch 52/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 2.2299 - output1_accuracy: 0.5232 - output1_loss: 1.1657 - output2_accuracy: 0.5784 - output2_loss: 1.0642 - val_loss: 2.2539 - val_output1_accuracy: 0.5126 - val_output1_loss: 1.1927 - val_output2_accuracy: 0.5785 - val_output2_loss: 1.0612\n",
      "Epoch 53/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2654 - output1_accuracy: 0.5140 - output1_loss: 1.1811 - output2_accuracy: 0.5672 - output2_loss: 1.0843 - val_loss: 2.2479 - val_output1_accuracy: 0.5226 - val_output1_loss: 1.1815 - val_output2_accuracy: 0.5849 - val_output2_loss: 1.0665\n",
      "Epoch 54/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2408 - output1_accuracy: 0.5257 - output1_loss: 1.1616 - output2_accuracy: 0.5702 - output2_loss: 1.0792 - val_loss: 2.2480 - val_output1_accuracy: 0.5030 - val_output1_loss: 1.1874 - val_output2_accuracy: 0.5857 - val_output2_loss: 1.0606\n",
      "Epoch 55/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2365 - output1_accuracy: 0.5227 - output1_loss: 1.1644 - output2_accuracy: 0.5788 - output2_loss: 1.0722 - val_loss: 2.2592 - val_output1_accuracy: 0.5176 - val_output1_loss: 1.1927 - val_output2_accuracy: 0.5743 - val_output2_loss: 1.0665\n",
      "Epoch 56/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2500 - output1_accuracy: 0.5191 - output1_loss: 1.1798 - output2_accuracy: 0.5764 - output2_loss: 1.0702 - val_loss: 2.2513 - val_output1_accuracy: 0.5156 - val_output1_loss: 1.1801 - val_output2_accuracy: 0.5757 - val_output2_loss: 1.0712\n",
      "Epoch 57/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2468 - output1_accuracy: 0.5202 - output1_loss: 1.1769 - output2_accuracy: 0.5788 - output2_loss: 1.0699 - val_loss: 2.2449 - val_output1_accuracy: 0.5302 - val_output1_loss: 1.1751 - val_output2_accuracy: 0.5811 - val_output2_loss: 1.0699\n",
      "Epoch 58/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2462 - output1_accuracy: 0.5256 - output1_loss: 1.1690 - output2_accuracy: 0.5728 - output2_loss: 1.0772 - val_loss: 2.2044 - val_output1_accuracy: 0.5254 - val_output1_loss: 1.1561 - val_output2_accuracy: 0.5881 - val_output2_loss: 1.0482\n",
      "Epoch 59/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2449 - output1_accuracy: 0.5208 - output1_loss: 1.1711 - output2_accuracy: 0.5710 - output2_loss: 1.0738 - val_loss: 2.2613 - val_output1_accuracy: 0.5144 - val_output1_loss: 1.1911 - val_output2_accuracy: 0.5855 - val_output2_loss: 1.0702\n",
      "Epoch 60/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2477 - output1_accuracy: 0.5165 - output1_loss: 1.1740 - output2_accuracy: 0.5753 - output2_loss: 1.0737 - val_loss: 2.2518 - val_output1_accuracy: 0.5164 - val_output1_loss: 1.1844 - val_output2_accuracy: 0.5863 - val_output2_loss: 1.0675\n",
      "Epoch 61/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2327 - output1_accuracy: 0.5212 - output1_loss: 1.1692 - output2_accuracy: 0.5790 - output2_loss: 1.0635 - val_loss: 2.2567 - val_output1_accuracy: 0.5080 - val_output1_loss: 1.2080 - val_output2_accuracy: 0.5873 - val_output2_loss: 1.0487\n",
      "Epoch 62/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2429 - output1_accuracy: 0.5218 - output1_loss: 1.1679 - output2_accuracy: 0.5781 - output2_loss: 1.0750 - val_loss: 2.2548 - val_output1_accuracy: 0.5144 - val_output1_loss: 1.1939 - val_output2_accuracy: 0.5829 - val_output2_loss: 1.0608\n",
      "Epoch 63/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2343 - output1_accuracy: 0.5206 - output1_loss: 1.1659 - output2_accuracy: 0.5790 - output2_loss: 1.0684 - val_loss: 2.2531 - val_output1_accuracy: 0.5152 - val_output1_loss: 1.1905 - val_output2_accuracy: 0.5887 - val_output2_loss: 1.0627\n",
      "Epoch 64/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2153 - output1_accuracy: 0.5269 - output1_loss: 1.1594 - output2_accuracy: 0.5860 - output2_loss: 1.0558 - val_loss: 2.2540 - val_output1_accuracy: 0.5076 - val_output1_loss: 1.2012 - val_output2_accuracy: 0.5867 - val_output2_loss: 1.0528\n",
      "Epoch 65/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2317 - output1_accuracy: 0.5249 - output1_loss: 1.1652 - output2_accuracy: 0.5786 - output2_loss: 1.0665 - val_loss: 2.2320 - val_output1_accuracy: 0.5232 - val_output1_loss: 1.1796 - val_output2_accuracy: 0.5741 - val_output2_loss: 1.0524\n",
      "Epoch 66/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2166 - output1_accuracy: 0.5287 - output1_loss: 1.1601 - output2_accuracy: 0.5841 - output2_loss: 1.0565 - val_loss: 2.2445 - val_output1_accuracy: 0.5196 - val_output1_loss: 1.1889 - val_output2_accuracy: 0.5849 - val_output2_loss: 1.0555\n",
      "Epoch 67/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2318 - output1_accuracy: 0.5223 - output1_loss: 1.1718 - output2_accuracy: 0.5807 - output2_loss: 1.0600 - val_loss: 2.2506 - val_output1_accuracy: 0.5194 - val_output1_loss: 1.1724 - val_output2_accuracy: 0.5763 - val_output2_loss: 1.0782\n",
      "Epoch 68/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2338 - output1_accuracy: 0.5271 - output1_loss: 1.1635 - output2_accuracy: 0.5777 - output2_loss: 1.0704 - val_loss: 2.2101 - val_output1_accuracy: 0.5331 - val_output1_loss: 1.1514 - val_output2_accuracy: 0.5721 - val_output2_loss: 1.0587\n",
      "Epoch 69/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2289 - output1_accuracy: 0.5236 - output1_loss: 1.1646 - output2_accuracy: 0.5791 - output2_loss: 1.0643 - val_loss: 2.2291 - val_output1_accuracy: 0.5198 - val_output1_loss: 1.1719 - val_output2_accuracy: 0.5847 - val_output2_loss: 1.0572\n",
      "Epoch 70/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2223 - output1_accuracy: 0.5222 - output1_loss: 1.1610 - output2_accuracy: 0.5794 - output2_loss: 1.0613 - val_loss: 2.2306 - val_output1_accuracy: 0.5282 - val_output1_loss: 1.1623 - val_output2_accuracy: 0.5809 - val_output2_loss: 1.0683\n",
      "Epoch 71/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2282 - output1_accuracy: 0.5239 - output1_loss: 1.1619 - output2_accuracy: 0.5783 - output2_loss: 1.0663 - val_loss: 2.2542 - val_output1_accuracy: 0.5142 - val_output1_loss: 1.1878 - val_output2_accuracy: 0.5841 - val_output2_loss: 1.0664\n",
      "Epoch 72/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2261 - output1_accuracy: 0.5262 - output1_loss: 1.1572 - output2_accuracy: 0.5775 - output2_loss: 1.0689 - val_loss: 2.2631 - val_output1_accuracy: 0.5154 - val_output1_loss: 1.1883 - val_output2_accuracy: 0.5737 - val_output2_loss: 1.0748\n",
      "Epoch 73/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2220 - output1_accuracy: 0.5312 - output1_loss: 1.1550 - output2_accuracy: 0.5774 - output2_loss: 1.0670 - val_loss: 2.2367 - val_output1_accuracy: 0.5208 - val_output1_loss: 1.1662 - val_output2_accuracy: 0.5747 - val_output2_loss: 1.0704\n",
      "Epoch 74/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2273 - output1_accuracy: 0.5247 - output1_loss: 1.1641 - output2_accuracy: 0.5792 - output2_loss: 1.0631 - val_loss: 2.2603 - val_output1_accuracy: 0.5100 - val_output1_loss: 1.1872 - val_output2_accuracy: 0.5775 - val_output2_loss: 1.0731\n",
      "Epoch 75/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2395 - output1_accuracy: 0.5216 - output1_loss: 1.1741 - output2_accuracy: 0.5770 - output2_loss: 1.0654 - val_loss: 2.2489 - val_output1_accuracy: 0.5094 - val_output1_loss: 1.2000 - val_output2_accuracy: 0.5905 - val_output2_loss: 1.0489\n",
      "Epoch 76/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2271 - output1_accuracy: 0.5219 - output1_loss: 1.1639 - output2_accuracy: 0.5784 - output2_loss: 1.0632 - val_loss: 2.2521 - val_output1_accuracy: 0.5118 - val_output1_loss: 1.2070 - val_output2_accuracy: 0.5958 - val_output2_loss: 1.0451\n",
      "Epoch 77/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2246 - output1_accuracy: 0.5228 - output1_loss: 1.1695 - output2_accuracy: 0.5849 - output2_loss: 1.0551 - val_loss: 2.2292 - val_output1_accuracy: 0.5292 - val_output1_loss: 1.1715 - val_output2_accuracy: 0.5849 - val_output2_loss: 1.0577\n",
      "Epoch 78/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2039 - output1_accuracy: 0.5289 - output1_loss: 1.1541 - output2_accuracy: 0.5886 - output2_loss: 1.0498 - val_loss: 2.2196 - val_output1_accuracy: 0.5178 - val_output1_loss: 1.1860 - val_output2_accuracy: 0.5968 - val_output2_loss: 1.0336\n",
      "Epoch 79/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2108 - output1_accuracy: 0.5308 - output1_loss: 1.1506 - output2_accuracy: 0.5839 - output2_loss: 1.0602 - val_loss: 2.1957 - val_output1_accuracy: 0.5296 - val_output1_loss: 1.1590 - val_output2_accuracy: 0.5899 - val_output2_loss: 1.0366\n",
      "Epoch 80/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2266 - output1_accuracy: 0.5269 - output1_loss: 1.1600 - output2_accuracy: 0.5756 - output2_loss: 1.0666 - val_loss: 2.2298 - val_output1_accuracy: 0.5234 - val_output1_loss: 1.1831 - val_output2_accuracy: 0.5899 - val_output2_loss: 1.0468\n",
      "Epoch 81/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2154 - output1_accuracy: 0.5288 - output1_loss: 1.1542 - output2_accuracy: 0.5846 - output2_loss: 1.0612 - val_loss: 2.2278 - val_output1_accuracy: 0.5323 - val_output1_loss: 1.1654 - val_output2_accuracy: 0.5785 - val_output2_loss: 1.0623\n",
      "Epoch 82/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2016 - output1_accuracy: 0.5338 - output1_loss: 1.1518 - output2_accuracy: 0.5838 - output2_loss: 1.0498 - val_loss: 2.2203 - val_output1_accuracy: 0.5202 - val_output1_loss: 1.1714 - val_output2_accuracy: 0.5823 - val_output2_loss: 1.0489\n",
      "Epoch 83/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2068 - output1_accuracy: 0.5334 - output1_loss: 1.1543 - output2_accuracy: 0.5827 - output2_loss: 1.0525 - val_loss: 2.2526 - val_output1_accuracy: 0.5162 - val_output1_loss: 1.1782 - val_output2_accuracy: 0.5765 - val_output2_loss: 1.0744\n",
      "Epoch 84/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2178 - output1_accuracy: 0.5228 - output1_loss: 1.1641 - output2_accuracy: 0.5841 - output2_loss: 1.0536 - val_loss: 2.2007 - val_output1_accuracy: 0.5232 - val_output1_loss: 1.1657 - val_output2_accuracy: 0.5899 - val_output2_loss: 1.0351\n",
      "Epoch 85/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.2021 - output1_accuracy: 0.5275 - output1_loss: 1.1568 - output2_accuracy: 0.5894 - output2_loss: 1.0453 - val_loss: 2.2281 - val_output1_accuracy: 0.5280 - val_output1_loss: 1.1715 - val_output2_accuracy: 0.5875 - val_output2_loss: 1.0565\n",
      "Epoch 86/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2124 - output1_accuracy: 0.5306 - output1_loss: 1.1570 - output2_accuracy: 0.5834 - output2_loss: 1.0554 - val_loss: 2.2191 - val_output1_accuracy: 0.5250 - val_output1_loss: 1.1745 - val_output2_accuracy: 0.5883 - val_output2_loss: 1.0446\n",
      "Epoch 87/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2002 - output1_accuracy: 0.5295 - output1_loss: 1.1493 - output2_accuracy: 0.5893 - output2_loss: 1.0509 - val_loss: 2.2123 - val_output1_accuracy: 0.5298 - val_output1_loss: 1.1529 - val_output2_accuracy: 0.5797 - val_output2_loss: 1.0593\n",
      "Epoch 88/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2137 - output1_accuracy: 0.5280 - output1_loss: 1.1590 - output2_accuracy: 0.5857 - output2_loss: 1.0547 - val_loss: 2.2182 - val_output1_accuracy: 0.5250 - val_output1_loss: 1.1769 - val_output2_accuracy: 0.5988 - val_output2_loss: 1.0413\n",
      "Epoch 89/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2196 - output1_accuracy: 0.5228 - output1_loss: 1.1650 - output2_accuracy: 0.5848 - output2_loss: 1.0546 - val_loss: 2.1718 - val_output1_accuracy: 0.5387 - val_output1_loss: 1.1435 - val_output2_accuracy: 0.5974 - val_output2_loss: 1.0283\n",
      "Epoch 90/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 2.1927 - output1_accuracy: 0.5315 - output1_loss: 1.1574 - output2_accuracy: 0.5944 - output2_loss: 1.0352 - val_loss: 2.2251 - val_output1_accuracy: 0.5302 - val_output1_loss: 1.1627 - val_output2_accuracy: 0.5817 - val_output2_loss: 1.0624\n",
      "Epoch 91/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 2.2057 - output1_accuracy: 0.5276 - output1_loss: 1.1609 - output2_accuracy: 0.5873 - output2_loss: 1.0448 - val_loss: 2.2176 - val_output1_accuracy: 0.5210 - val_output1_loss: 1.1681 - val_output2_accuracy: 0.5873 - val_output2_loss: 1.0495\n",
      "Epoch 92/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2003 - output1_accuracy: 0.5287 - output1_loss: 1.1536 - output2_accuracy: 0.5901 - output2_loss: 1.0467 - val_loss: 2.2373 - val_output1_accuracy: 0.5180 - val_output1_loss: 1.1771 - val_output2_accuracy: 0.5799 - val_output2_loss: 1.0602\n",
      "Epoch 93/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1984 - output1_accuracy: 0.5333 - output1_loss: 1.1477 - output2_accuracy: 0.5877 - output2_loss: 1.0507 - val_loss: 2.2244 - val_output1_accuracy: 0.5262 - val_output1_loss: 1.1769 - val_output2_accuracy: 0.5915 - val_output2_loss: 1.0475\n",
      "Epoch 94/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.2029 - output1_accuracy: 0.5334 - output1_loss: 1.1516 - output2_accuracy: 0.5857 - output2_loss: 1.0513 - val_loss: 2.2030 - val_output1_accuracy: 0.5385 - val_output1_loss: 1.1505 - val_output2_accuracy: 0.5817 - val_output2_loss: 1.0526\n",
      "Epoch 95/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1940 - output1_accuracy: 0.5310 - output1_loss: 1.1498 - output2_accuracy: 0.5884 - output2_loss: 1.0441 - val_loss: 2.2094 - val_output1_accuracy: 0.5210 - val_output1_loss: 1.1676 - val_output2_accuracy: 0.5825 - val_output2_loss: 1.0419\n",
      "Epoch 96/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1927 - output1_accuracy: 0.5307 - output1_loss: 1.1529 - output2_accuracy: 0.5939 - output2_loss: 1.0398 - val_loss: 2.2194 - val_output1_accuracy: 0.5166 - val_output1_loss: 1.1857 - val_output2_accuracy: 0.5952 - val_output2_loss: 1.0337\n",
      "Epoch 97/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1798 - output1_accuracy: 0.5363 - output1_loss: 1.1446 - output2_accuracy: 0.5932 - output2_loss: 1.0352 - val_loss: 2.1916 - val_output1_accuracy: 0.5210 - val_output1_loss: 1.1618 - val_output2_accuracy: 0.5978 - val_output2_loss: 1.0298\n",
      "Epoch 98/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1967 - output1_accuracy: 0.5346 - output1_loss: 1.1461 - output2_accuracy: 0.5868 - output2_loss: 1.0506 - val_loss: 2.1900 - val_output1_accuracy: 0.5339 - val_output1_loss: 1.1506 - val_output2_accuracy: 0.5942 - val_output2_loss: 1.0394\n",
      "Epoch 99/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.1937 - output1_accuracy: 0.5313 - output1_loss: 1.1501 - output2_accuracy: 0.5932 - output2_loss: 1.0436 - val_loss: 2.1940 - val_output1_accuracy: 0.5288 - val_output1_loss: 1.1579 - val_output2_accuracy: 0.6008 - val_output2_loss: 1.0362\n",
      "Epoch 100/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1945 - output1_accuracy: 0.5316 - output1_loss: 1.1501 - output2_accuracy: 0.5931 - output2_loss: 1.0444 - val_loss: 2.1946 - val_output1_accuracy: 0.5244 - val_output1_loss: 1.1612 - val_output2_accuracy: 0.5966 - val_output2_loss: 1.0334\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            # Training data generator\n",
    "    epochs=100,          # Number of epochs to train\n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize,\n",
    "    validation_data=valgen,  # Validation data generator\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # Steps per validation epoch (if using a generator)\n",
    "    # callbacks=[val_early_stopping, val_model_checkpoint_callback],  # Early stopping callback\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ACNN3-200epochs-60acc.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
