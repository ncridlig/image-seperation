{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to CIFAR Back!\n",
    "The CIFAR-10 dataset is a benchmark for computer vision tasks dating to [2009](https://www.cs.toronto.edu/~kriz/cifar.html). We construct a model capable of disentangling an input image created by averaging two random samples from CIFAR-10 and predicting the categories of the two components. We achieve 80% accuracy with an F1 Score of ?. \n",
    "\n",
    "This novel task requires training on small datasets (order of 50,000 samples) with small spatial resolution (32x32x3). We overcome this difficulty by eliminating max pooling operations in favor of an All Convolutional Model, inspired by the (second place CIFAR-10 holders)[https://arxiv.org/abs/1412.6806]. The writeup takes the form of a Jupyter notebook, first displaying our most capable model, then chronologically detailing how we arrived to this result.\n",
    "\n",
    "### 80% Accuracy ACNN3\n",
    "![ACCN3](ACCN3.png)\n",
    "### Description\n",
    "The model has a feature extractor composed purely of two dimensional convolutions. Instead of maxpooling, down sampling the spatial resolution is accomplished by a stride of 2. The extractor reduces the resolution to a stack of 192 2x2 filters. This is flattened and passed to two independent classifiers. They are single layer fully connected layers, with a softmax to produce the 5 possible class probabilities. The network has 20% dropout layers after the stride 2 convolutions to prevent overfitting and no data augmentation, as it did not lead to better results. The standard optimizer has been replaced with [Adagrad](https://keras.io/api/optimizers/adagrad/) which lead to slow but stable convergence. Each classifier has its own cross entropy loss to back propagate through the network, and we observe they do not improve equally, an area for further research on the task.\n",
    "\n",
    "# Experimental Setup\n",
    "The reader is invited to train locally by uncommenting the **fit()** calls where indicated.\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 09:48:47.677757: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736617727.698840   34466 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736617727.705181   34466 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-11 09:48:47.726231: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.nn import fractional_max_pool\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.saving import load_model, save_model, save_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
    "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
    "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
    "assert cifar10_y_train.shape == (50000, 1)\n",
    "assert cifar10_y_test.shape == (10000, 1)\n",
    "\n",
    "# Split part of the training set into validation set\n",
    "cifar10_x_train, cifar10_x_val, cifar10_y_train, cifar10_y_val = train_test_split(\n",
    "    cifar10_x_train, cifar10_y_train, test_size=0.1\n",
    ")\n",
    "\n",
    "# First classifier: \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\"\n",
    "# Second classifier: \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Normalizing to range (0,1)\n",
    "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
    "cifar10_x_val = (cifar10_x_val / 255.).astype(np.float32)\n",
    "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the images in two groups, according to their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_1 = cifar10_y_train[:,0] < 5\n",
    "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
    "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
    "\n",
    "cond_2 = cifar10_y_train[:,0] >= 5\n",
    "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
    "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
    "\n",
    "cond_1_val = cifar10_y_val[:,0] < 5\n",
    "cifar10_x_val_1 = cifar10_x_val[cond_1_val]\n",
    "cifar10_y_val_1 = cifar10_y_val[cond_1_val]\n",
    "\n",
    "cond_2_val = cifar10_y_val[:,0] >= 5\n",
    "cifar10_x_val_2 = cifar10_x_val[cond_2_val]\n",
    "cifar10_y_val_2 = cifar10_y_val[cond_2_val]\n",
    "\n",
    "cond_1_test = cifar10_y_test[:,0] < 5\n",
    "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
    "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
    "\n",
    "cond_2_test = cifar10_y_test[:,0] >= 5\n",
    "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
    "cifar10_y_test_2 = cifar10_y_test[cond_2_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generator. The input consists of two datasets (X1,X2), their corresponding labels (Y1,Y2), and a batch size.\n",
    "\n",
    "The generator returns (x_data,y_data), where:\n",
    "* x_data is a batch of images obtained by averaging random samples from X1 and X2.\n",
    "* y_data is a dictionary of batches of labels corresponding to the component images, expressed in categorical format, in other words, one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "\n",
    "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
    "  size1 = X1.shape[0]\n",
    "  size2 = X2.shape[0]\n",
    "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
    "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
    "\n",
    "  while True:\n",
    "    num1 = np.random.randint(0, size1, batchsize)\n",
    "    num2 = np.random.randint(0, size2, batchsize)\n",
    "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
    "    y_data = {'output1': Y1_cat[num1], 'output2': Y2_cat[num2]}\n",
    "    yield tf.convert_to_tensor(x_data), y_data\n",
    "\n",
    "traingen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,batchsize)\n",
    "valgen = datagenerator(cifar10_x_val_1,cifar10_x_val_2,cifar10_y_val_1,cifar10_y_val_2,batchsize)\n",
    "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate an example, display the image that the model will take as input, and print the categories of the two overlapping components.\n",
    "\n",
    "The reader is invited to re-run the cell to display new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: airplane, second = truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736617740.388300   34466 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13058 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:0a:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAALyFJREFUeJzt3X1s3fV5///XuT++PY7j+I44ISEFSiGZlkFq0TJKMpJMQlCiCdpKCx2CH8xBg6xrm6mFwjaZUX1b2ioNf4yRVWqgZWpAoBUGoTHqlrAlI0oprUeCIYHEzg347hyf+8/vDxp3hoS8L8fO23aeD+lIsX3l8vtzd65z7HNeDgVBEAgAgLMs7HsBAIBzEwMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOBF1PcCPqxcLuvQoUOqqalRKBTyvRwAgFEQBBoaGlJra6vC4VM/z5lyA+jQoUNqa2vzvQwAwBk6ePCg5s6de8qvT9oA2rhxo7797W+rt7dXS5Ys0Q9+8ANdccUVp/1/NTU1kqS1d/5/iicSTt8rbHiiVFlT614sqWZWg3NtJF5h6h2Luu/+zHDG1LvCcd9JUtkYxtRw3gJTfSSadK4NlW3PekOhkvs6DLWSFDWcWNGI7VKKfMyjwpMy/DTAnK4VGLYzFjO1jifd6y3XsSRlcwXn2lzBduytP30JBWXn2qBUNPUeSo8412Zy7uuQpFzefS0Dw2n3viMZ/b+vfnn0/vxUJmUA/eQnP9H69ev1yCOPaNmyZXr44Ye1cuVKdXd3q7Gx8WP/74kDH08kJmUAJZLud4aSlKxwHyr2AeR+cZZLtjuVZMJ9O8vGO6yKqipTfSTqvl/CDKCTmyIDKBa3DqC4c611AEVieffa/PQdQKXA/VwJIrYBFI66ryVnvA+STr8fJ+VFCN/5znd022236ctf/rIuueQSPfLII6qsrNQ///M/T8a3AwBMQxM+gPL5vHbv3q0VK1b8/puEw1qxYoV27NjxkfpcLqfBwcExNwDAzDfhA+jYsWMqlUpqamoa8/mmpib19vZ+pL6zs1OpVGr0xgsQAODc4P19QBs2bNDAwMDo7eDBg76XBAA4Cyb8RQgNDQ2KRCLq6+sb8/m+vj41Nzd/pD6RSChheMUWAGBmmPBnQPF4XEuXLtW2bdtGP1cul7Vt2za1t7dP9LcDAExTk/Iy7PXr12vt2rX6oz/6I11xxRV6+OGHlU6n9eUvf3kyvh0AYBqalAF000036ejRo7r33nvV29urP/iDP9Bzzz33kRcmAADOXZOWhLBu3TqtW7du3P+/XMir7PjOtEjE/Y2OiYj7G+MkqZgbcq4NAvc3xklSPPzx7xL+v+pT7rWSlM24ryVm3CfJsO3NiGXDm/RCsr2RLhpxf8NgMmHbzmjE8kZh2xsdrfET8bj72svG3pm8+z4vGGolKVvOOddakx/LgWWf2/aJ9Y3CkZDhzaLhiKl3dZX7m8qtv04fMSQhlA37MO64id5fBQcAODcxgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF5MWhTPmRoaHHSOH4mF3eMkwsY/PB9Kusd9lEq2mJJEosq5dsH5F5p6W6JHknFbfkc8YosSGU6nnWtDYds+nNPw0T/xcSoVSfdIkw+4b+dIJmPqXCi4n7OSlEy6x03l8gVT71zafe25gq13qey+nYEhskmSIpYYppjxsXbcFjeliHv/WNR2/cSi7tdnqWCLhLLcH+aL7tdPRG7r4BkQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwIspmwUXjcYUjbrlMZWK7vlUEWMOU0Wle15bsZg39c7n3HOy3n//fVPvWMx93VU11abe8bjttEmW3DL9JCmdGTT1LpXdM++GR4zHx5CrVS4ZM7hCtsd+xwfc98vISM7Ue6TgnsFWNuxvSQpC7r0D2bLgAsMuL4aM6zZuZ8yQS1cyZimq7L6hhbztHB/Jud93ZjPuvbMZt/xHngEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALyYslE8FZVViicSTrXZkYxz3/o5DaZ1ZA1xLFVVtkibRYtanGuHhrOm3jlDvEpNXcrU2xpnlKx0O46SlMnbTsljxweca4tl27pLgfs+dA9i+V19yPY/ymVLTI0tRiYcct8vYUPkjCRTuE7YGFETDbs/fg4Ftn1SLtligfKG+qIhnkiSwobjaUwQUjjivg8rEoZrs+RWyzMgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBdTNgsuGospFos51eaz7nltyUTctI5kdY1z7XvH+ky9Y1H3tdTWuO2LE473DzvXloz5UblC0VRfLrkfH1N4mKRQyH3xiYQtayxkeXxmyI2TpFLRtg+DsPt2Row5c6VC2rk2X8qbeocMWWPRSJWpt2WXh4zZbmXj8ZQhay4wBgeWDfWW80SSIo73sZKUDLtfP+WS2/nNMyAAgBcTPoC+9a1vKRQKjbldfPHFE/1tAADT3KT8CO5Tn/qUXnzxxd9/k+iU/UkfAMCTSZkM0WhUzc3Nk9EaADBDTMrvgN544w21trZq4cKF+tKXvqQDBw6csjaXy2lwcHDMDQAw8034AFq2bJk2b96s5557Tps2bVJPT48++9nPamho6KT1nZ2dSqVSo7e2traJXhIAYAqa8AG0evVq/dmf/ZkWL16slStX6t/+7d/U39+vn/70pyet37BhgwYGBkZvBw8enOglAQCmoEl/dUBdXZ0uvPBC7du376RfTyQSSiQSk70MAMAUM+nvAxoeHtb+/fvV0tIy2d8KADCNTPgA+spXvqKuri699dZb+s///E99/vOfVyQS0Re+8IWJ/lYAgGlswn8E98477+gLX/iCjh8/rjlz5ugzn/mMdu7cqTlz5pj6xJNxxR1jc7Inf33DSRXztgiU8+ad51w7PDxg6r1//8l/LHkysxuaTL2jhpifkiXrQ1IxMEbx5LPOtUEhZ+odr3SPEknV2aJeIoY0llxmxNQ7U7TVS+4RK7mRjK1zyf34ZDO2c3wo5967dtZcU++qytnOtYH5HLdF8RQNUTwh41pChmNfDhlirySFDfWlvHvtyIjbdTzhA+iJJ56Y6JYAgBmILDgAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBeT/ucYxitQREEo4lQbknseWNaQZyRJxbDbGiSppn6WqfeB/ceca0MJWwbX7Eb3DLuRXNrUO2fNAxt437m2nM+besfC7n/6PR51z9SSpONHjzvXFnMFU+9w2JYHZql/8033jEFJqqhwv36qa21/OmVkyP1cyQ3bcgCjhoD9itpGU+8gcL/uJVueYkm2Y18uuGcvhsq2DDsZMuxKhmszm3Wr5RkQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLKRvFk6yqUSKZdKpNJ4ed+5ZDxk02JPckYnFT66qqSufacsk9juMD7gvPpAdNnY++a4t6UeAeUxOP2qJeMsP9hlrbdv7mN28419bPnm3qnUzatrOmttq5NhK1neMDQxnn2pGsLbYpmXR/jJvP9Jt69771W+fa2a22qKRErS1WS4Y4sHLRFsUTMkT3hGWLmwqF3O9XInH3mJ9S0W0dPAMCAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeDFls+AqKmuUrKhwqi3Ods95qqtN2RaSds+ZSx87YmodLeeda0MFQyidpFJmyLk25rabR+WH3XtLUtw9JkvxhFv+3wmhwJJ5Z8sxK5bcz6tQxJbvFYRtmV2RqPtjxVjSsMMlFQz7MJmw9U5G3bcz2+9+rUnS0ID79VZd6Z6lJ0kN9TWm+kjCPQeyVLY97g+F3OuLZdv9xOCg+z4/cuSgc212ZMSpjmdAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC+mbBacgsgHNwcNjU3ObSsTtk3ue/N/nWuPv/euqXeh5JaXJEmVFVWm3uli2bk2VJ019a4OGcPjykXn0mLWPX9NktJh931YLLnvE0mKRAwZXCX3bZSkRCRhqh/Jux+jkGHdkhSJuee7ReOTmNWXcc9GlKR4xO3+QZKqK2zrHjjWZ6pPVFY616aHMqbehaL7Pqystd1PDA++71x7/LD7/Vsul3Oq4xkQAMAL8wB6+eWXdd1116m1tVWhUEhPPfXUmK8HQaB7771XLS0tqqio0IoVK/TGG29M1HoBADOEeQCl02ktWbJEGzduPOnXH3roIX3/+9/XI488oldeeUVVVVVauXKlslnbj3kAADOb+XdAq1ev1urVq0/6tSAI9PDDD+sb3/iGrr/+eknSj370IzU1Nempp57SzTfffGarBQDMGBP6O6Cenh719vZqxYoVo59LpVJatmyZduzYcdL/k8vlNDg4OOYGAJj5JnQA9fb2SpKamsa+Kq2pqWn0ax/W2dmpVCo1emtra5vIJQEApijvr4LbsGGDBgYGRm8HD7r/2VcAwPQ1oQOoublZktTXN/Y19H19faNf+7BEIqHa2toxNwDAzDehA2jBggVqbm7Wtm3bRj83ODioV155Re3t7RP5rQAA05z5VXDDw8Pat2/f6Mc9PT3as2eP6uvrNW/ePN199936+7//e33iE5/QggUL9M1vflOtra264YYbJnLdAIBpzjyAdu3apc997nOjH69fv16StHbtWm3evFlf/epXlU6ndfvtt6u/v1+f+cxn9NxzzymZtEVhlEtllR2jU6JR981IDx03rePQ293OtUHgFj9xQigcONdGDNsoSYV+94iN4bQt/iaZsMV9yLD2kZwt0iaSdN+HTaf4MfCpBIYfEATG+JtEPG6qt8QChcIhU+9Zs+qda+MR23kY5N3jdapqZ5l6J+PuEUK5kvt5Iklvv/2mqb6iyj2e6uBbB0y9S4Yonpa5c0296+vrnGsLWUOkluN1bB5AV199tYLg1AczFArpgQce0AMPPGBtDQA4h3h/FRwA4NzEAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhhjuI5W7JDhxUU3PLj8oaMImWHTevIF99zri1kbFlwVdU1zrUjmRFT75Dc86OOHR0w9a6tsf3JjNQc94yvomw5ZpaEr7qUbd2xwH0t2YItT69utnv+miT1Hu07fdHv5IznYUWi0rm2rs62DysS7hlp57XZcswikYhzbSyeMPWuaWgw1Y+MuF+faeO1/M677zrX9hyy/T21aKX7fokajmXJ8bkNz4AAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF5M2Sie48cOK56IO9XGK9wjU5Ix9/gOScoYRnTOEN0iScmIW9SQJGULltAZKWHYzFS1exSLJFXGbfuwutJ9O/PGSJt43O0ckWzRLZI0e5Z7hNDQcNrUu//4cVN9bVW1c23FfPfIFElqaW11rq2srDL1jhsicEIh2+PhIHC/JkK2S1OzjVE8wxn34z+3bZ6p9/63epxrf939G1Pvkbz79RardL+fKIeJ4gEATGEMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF1M2C64UBCq5Zj0FMee+6YItFOqt99wznkIlW9ZYvOS++xtraky9W1N1zrX1SVsWXCxie9xSqnDPAysFJVPvmtpaQ61tHwY597XEDJlnkjQ4PGyqr6l2X7s1x6xYdN/OocEhU+9A7ttZUWHLsMvncs61pXLZ1NuaGziUyTjXWs+V1rltzrWHjx4x9c5n88612WzWvW/OrS/PgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXkzZKJ5yOVC55BbFUyy5x+uUw+6xPZIUiVa7947YYn7eOXrMuXb4+Hum3tXnuz+2iOXd4zgkKRq1xZRkMu71/XKMX/qdUsz9eL518B1T77AhFej48eOm3u8P9Jvq00X3Y5QxRNRIUjyRdK4tlWxRSVWV7tdPLlcw9U6PuG/n0LB7VI4kpQ3ROtb+g8O2OKORjHsc2Bv7/9fUOxZzHwFVFe7niWtMEs+AAABeMIAAAF6YB9DLL7+s6667Tq2trQqFQnrqqafGfP2WW25RKBQac1u1atVErRcAMEOYB1A6ndaSJUu0cePGU9asWrVKhw8fHr09/vjjZ7RIAMDMY34RwurVq7V69eqPrUkkEmpubh73ogAAM9+k/A5o+/btamxs1EUXXaQ777zzY18hlMvlNDg4OOYGAJj5JnwArVq1Sj/60Y+0bds2/eM//qO6urq0evXqU758s7OzU6lUavTW1ub+1/8AANPXhL8P6Oabbx7992WXXabFixfrggsu0Pbt27V8+fKP1G/YsEHr168f/XhwcJAhBADngEl/GfbChQvV0NCgffv2nfTriURCtbW1Y24AgJlv0gfQO++8o+PHj6ulpWWyvxUAYBox/whueHh4zLOZnp4e7dmzR/X19aqvr9f999+vNWvWqLm5Wfv379dXv/pVLVq0SCtXrpzQhQMApjfzANq1a5c+97nPjX584vc3a9eu1aZNm7R37179y7/8i/r7+9Xa2qprr71Wf/d3f6dEImH6PkGxrCBcdqotFtzzqRpbzzOtoybV6FwbS9hy5t59q8e5dvDdQ6beBw8ddK59L2LLdosn4qb6YkWlc206bFtLpKrKvTZiO90Thoy0ujlzTL373n/fVH/gnXeda/PGvLbzFyx0rq2qdN/fklSZqHCuLZZtOYCH3nzbuXbAmAWXMeTMSVKxWHSuzeWypt55Q1bj0JAtZ64i6X4ttzS6n+P5uFtf8wC6+uqrFQSnPlGef/55a0sAwDmILDgAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcT/veAJkplPKG4Y55Qqn62c19b0pgUj7r/j/TggKl3erDfubZYds+akqT3M8POtQOGHCtJKhnX0rLoQvfesuWBDQ647/Nk1Ha6j2RGnGtzBfe8LklKGPP0FLjlIkpSKV8wtc4Mu58r+awtIy2fMOSehWxXZzbnfnyiEdtj7bDxoXksEnKundUwy9T73Xfdj8+I4XqQJOXcz8ORYfecuXzO7TzhGRAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwIspG8VTKBQVCrnNx8F+9/iJTO6oaR0l9wQUZbMZU+/s0KBzbWCIYpGkUCLhXFtVlzL1rqisMNW3nX++c20mb4wFKpWca8OBLeanJPfeg/3vmXof7Ttiqq+sqHSufevN/abeb7/V41xbUVll6n3e3LnOtZkRQ2yPpKzhXIklkqbehbztWk4aLs/ho+7XvSRlh9zv32qTMVPvWMz9OUhhxD0SqJB3i6biGRAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAiymbBdc/MKBYzC3XKNfnniGVy7llFJ1QNuSHxR3XO1ofjzvXhqIhU++aVK1zbVvbPFPvWfUNpvqhobRzbcGYB1ZZ6Z6RFovYTvdIyJAdZ8ikk6RZtTWm+mLRPffs0MEDpt6D/e7ZZDHDOStJb+57w7l27rz5pt7xpHu+W7Fku+5DZVv2okbc+x/Y97+2tVS67/PZKdt5lc+7X2/l3IhzbUAWHABgKmMAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvJiyUTxBuazAMQ6jVHCPKQmHbJE2ZUMESihq252lQsG5NmKMkamurHKuTcRs8SrHjx0z1afT7hEeMeM+zKTdI3By2Yypdzzhvl9qamwRKLMam031r7/+unPtyPCwbS2GtRsDavT+saPu65hVZ+rd0jTHubZQtEUlhRO2WK3MQL9zbTxiuw+yPE3I5HOm1pboq0TM/dp0vd/kGRAAwAvTAOrs7NTll1+umpoaNTY26oYbblB3d/eYmmw2q46ODs2ePVvV1dVas2aN+vr6JnTRAIDpzzSAurq61NHRoZ07d+qFF15QoVDQtddeq3T692nH99xzj5555hk9+eST6urq0qFDh3TjjTdO+MIBANOb6Qfuzz333JiPN2/erMbGRu3evVtXXXWVBgYG9Oijj2rLli265pprJEmPPfaYPvnJT2rnzp369Kc/PXErBwBMa2f0O6CBgQFJUn19vSRp9+7dKhQKWrFixWjNxRdfrHnz5mnHjh0n7ZHL5TQ4ODjmBgCY+cY9gMrlsu6++25deeWVuvTSSyVJvb29isfjqqurG1Pb1NSk3t7ek/bp7OxUKpUavbW1tY13SQCAaWTcA6ijo0OvvfaannjiiTNawIYNGzQwMDB6O3jw4Bn1AwBMD+N6H9C6dev07LPP6uWXX9bcuXNHP9/c3Kx8Pq/+/v4xz4L6+vrU3Hzy9z0kEgklEonxLAMAMI2ZngEFQaB169Zp69ateumll7RgwYIxX1+6dKlisZi2bds2+rnu7m4dOHBA7e3tE7NiAMCMYHoG1NHRoS1btujpp59WTU3N6O91UqmUKioqlEqldOutt2r9+vWqr69XbW2t7rrrLrW3t/MKOADAGKYBtGnTJknS1VdfPebzjz32mG655RZJ0ne/+12Fw2GtWbNGuVxOK1eu1A9/+MMJWSwAYOYwDaAgCE5bk0wmtXHjRm3cuHHci5KkXDancskteSqTcc/4ctiED9W7p1+Fw7bXdLjsz9+z5UcNDbnngRWLthd+HDt23FQflN23M2TM6rPsc/PxMayluso9e0+SopGIqf7dd991ro0be0cj7vul7JjPeEJ1ZYVzbe87B0y9y1n3jEHr/s6V3DMgJSmad68fGh4w9VbOfe2ZofTpi/6PiOHYVyUrnWvz4bxTHVlwAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvxvXnGM6GWbNmKR6PO9W+9557NIw16iViiPDIZXOm3iVDrEnJGA1y6JB7dEsykTT1LuTdYjZOsOzxeCxm6j2Z8gX3ff7+0WOm3mXj8QyF3c/Dqkr3yBRJSkbde0fjtnMl//57zrXFQsHU+2DPm861cWMMU94QwSVJ5aL78SwZYnskqWi4gGJh2116lSFCKjM05FxbcDyWPAMCAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeDFls+CGBgcVc8wFy45knfu69jyh0pCrlc26r0OS8nlDdlxgaq3BgUHn2kw0Y+odi9hOm+oK931o2d+SFI27H89sdsTUO5cvmeotQsbjWRFxf6xYU2HLa6uprnautexvScoX3fPdjh635emp7H58RtK2czwXNmbBldwPaKhsO/gFQy5dKFZh6j0y4n5NFAru91dFx2w8ngEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALyYslE8x44fUzTqtrxINOLcNxwOmdaRy7rHTxQK7rEjklRyjKuQpLIxviNk2MyyIdJEkkJRW0xJ1lCezqZNvQP3Q6+wMUKonDesI2R7LJcIbMczWnY/t8Ih23n47uF3nGuDwLad1Sn3mJ9Syf16kKRszhANkzPGZBnOK0kKDNdn2HjsDSk/ygW27cxm3SOKLPcpxZLbfQrPgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeTNksuNl1tYrFYk61haJ79lXJMaPohKNHjzrXZtIjpt5FQxZcKpUy9a5L1TnXJpNJU+9IxO24nBAU3fd5ZmTY1Ds96F4/YsgOk6TKavd9HoRt4WG5jG07M4YsuEzJtp3J6jrn2kjItp3lsnsQYDwWt/VOuJ9XUWMOYFy2vLbAkO9mS6OUQmH35wkRa96h4f4wMBxL1/s2ngEBALwwDaDOzk5dfvnlqqmpUWNjo2644QZ1d3ePqbn66qsVCoXG3O64444JXTQAYPozDaCuri51dHRo586deuGFF1QoFHTttdcqnR4boX/bbbfp8OHDo7eHHnpoQhcNAJj+TD8wfO6558Z8vHnzZjU2Nmr37t266qqrRj9fWVmp5ubmiVkhAGBGOqPfAQ0MDEiS6uvrx3z+xz/+sRoaGnTppZdqw4YNymRO/UePcrmcBgcHx9wAADPfuF8FVy6Xdffdd+vKK6/UpZdeOvr5L37xi5o/f75aW1u1d+9efe1rX1N3d7d+9rOfnbRPZ2en7r///vEuAwAwTY17AHV0dOi1117TL3/5yzGfv/3220f/fdlll6mlpUXLly/X/v37dcEFF3ykz4YNG7R+/frRjwcHB9XW1jbeZQEApolxDaB169bp2Wef1csvv6y5c+d+bO2yZcskSfv27TvpAEokEkokEuNZBgBgGjMNoCAIdNddd2nr1q3avn27FixYcNr/s2fPHklSS0vLuBYIAJiZTAOoo6NDW7Zs0dNPP62amhr19vZK+uBd+hUVFdq/f7+2bNmiP/3TP9Xs2bO1d+9e3XPPPbrqqqu0ePHiSdkAAMD0ZBpAmzZtkvTBm03/r8cee0y33HKL4vG4XnzxRT388MNKp9Nqa2vTmjVr9I1vfGPCFgwAmBnMP4L7OG1tberq6jqjBZ2QTMads+Bq49XOfSMRW5ZVXW2tc20QuGclSVK57J4fVV3jvo2SVJGscK61ZE1JUi7vnksmSbmsezZZYsiWlBVk3fP3Mvm8qfdwesC5Npt3z/WTpCrjPs8Pu789IVrlfuwlqek898y7UGBbt6U8ETdmwRlyzPLGALaoObHNwNg6YsgZjMZsv9a33B+GQ+4Hs1Bwu48gCw4A4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MW4/x7QZKufVa+4YzRH2BBrEonaonhmz57tXBsOG2NkDNE9xYIt6sUUCxSyrTuesMUCJZLuESvlkbSpd6qy0rm2WLRFCA2V3aNeGufUn77o/6iJ2f4ESX7YfTtrZtWZekdj7tdEuegeHyVJxZL7eVsq2s7xctn9HLfE9kiSbSttMTXWOLCQ4fosWvdhyX0fWmJ+So7XDs+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF5M2Sy4bDbnnPUUT7hnjeXzedM6YrGYc200astUC0fc53+pbMt4ymaz7r2LtpysWDxpqh/OuOe7ZQy1ki3fLQhsCV+LFi5wrp3V0GDqrWzOVB43nCsD2RFT7+H0sHNtuGw7x0fy7udhznht5nLu9SVD5tl4lGXIdTTk40lSNOJ+Nx2y5lGW3a+JXN79nHXNpOMZEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAiykbxTM4NOAcg5NIJJz75g3xHZItfqIi6b4OSSqVDBE4toQNZQ1RL3FD3JAkGRNtTPswamw+nHOPnSkHtjiW6opK59pQ2RZnVFFhizOKx92PUSFiO1nyA0POtVnD/pakkuF4BsbjEzJsZjhke6xticmSJBlO27LxXLGctxFFTL0jEff6mOUcLLhFZPEMCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFlM2CS1ZUOGeURcLueUYDAwOmdRTybplGklRTU2vqXSplnWv7evtMvS35eKWiLX8tHrPlTcWjcefaRMKWS5ctuOfMKWvLASzl3I99KOG+jZJUDtnywIoF9+CzWNy2lrq6lHNtubLK1LtoCEkLjDmAhYL7PizbYuYUjdruGoOy+9rzBdt5aOkdsgTkafKy4PKO95s8AwIAeGEaQJs2bdLixYtVW1ur2tpatbe36+c///no17PZrDo6OjR79mxVV1drzZo16uuzPXIHAJwbTANo7ty5evDBB7V7927t2rVL11xzja6//nr9+te/liTdc889euaZZ/Tkk0+qq6tLhw4d0o033jgpCwcATG+mH3Red911Yz7+h3/4B23atEk7d+7U3Llz9eijj2rLli265pprJEmPPfaYPvnJT2rnzp369Kc/PXGrBgBMe+P+HVCpVNITTzyhdDqt9vZ27d69W4VCQStWrBitufjiizVv3jzt2LHjlH1yuZwGBwfH3AAAM595AP3qV79SdXW1EomE7rjjDm3dulWXXHKJent7FY/HVVdXN6a+qalJvb29p+zX2dmpVCo1emtrazNvBABg+jEPoIsuukh79uzRK6+8ojvvvFNr167V66+/Pu4FbNiwQQMDA6O3gwcPjrsXAGD6ML8PKB6Pa9GiRZKkpUuX6r//+7/1ve99TzfddJPy+bz6+/vHPAvq6+tTc3PzKfslEgnTe1YAADPDGb8PqFwuK5fLaenSpYrFYtq2bdvo17q7u3XgwAG1t7ef6bcBAMwwpmdAGzZs0OrVqzVv3jwNDQ1py5Yt2r59u55//nmlUindeuutWr9+verr61VbW6u77rpL7e3tvAIOAPARpgF05MgR/fmf/7kOHz6sVCqlxYsX6/nnn9ef/MmfSJK++93vKhwOa82aNcrlclq5cqV++MMfjmthkUhUEcc4DEuCR1VVtWkdR9JHnGuPH3vP1Dscdn8CGg7Z4m9yhhiZ4eG0qXcosOWaRCPup1myKmnqnZpV715bXWPqXRmrcK6NxG0/TCiXiqb6QtFQH7P9ZD0ScV97zBg5FDbEyFhiYSRJ7odHJWMUTzxm205LBE7RciwllQw5QqWSLeKpUHC/nzAmJTkxnamPPvrox349mUxq48aN2rhx4xktCgAw85EFBwDwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8MKchj3Zgt/lPUxWRISlr2SLzYiEbREbIUMUjzW+o2zYKUVjfIc1ikfB5MWUWI5nPm879tHAPRombHwsFxijeGQ4xwPj8Skb6sPGQ1+YzCgeA2sUj2V/S5IMUTylcyCK50Tf4DT/KRScruIse+edd/ijdAAwAxw8eFBz58495den3AAql8s6dOiQampqxgT8DQ4Oqq2tTQcPHlRtba3HFU4utnPmOBe2UWI7Z5qJ2M4gCDQ0NKTW1taPDV2ecj+CC4fDHzsxa2trZ/TBP4HtnDnOhW2U2M6Z5ky3M5VKnbaGFyEAALxgAAEAvJg2AyiRSOi+++5TIpHwvZRJxXbOHOfCNkps50xzNrdzyr0IAQBwbpg2z4AAADMLAwgA4AUDCADgBQMIAODFtBlAGzdu1Pnnn69kMqlly5bpv/7rv3wvaUJ961vfUigUGnO7+OKLfS/rjLz88su67rrr1NraqlAopKeeemrM14Mg0L333quWlhZVVFRoxYoVeuONN/ws9gycbjtvueWWjxzbVatW+VnsOHV2duryyy9XTU2NGhsbdcMNN6i7u3tMTTabVUdHh2bPnq3q6mqtWbNGfX19nlY8Pi7befXVV3/keN5xxx2eVjw+mzZt0uLFi0ffbNre3q6f//zno18/W8dyWgygn/zkJ1q/fr3uu+8+/c///I+WLFmilStX6siRI76XNqE+9alP6fDhw6O3X/7yl76XdEbS6bSWLFmijRs3nvTrDz30kL7//e/rkUce0SuvvKKqqiqtXLlS2Wz2LK/0zJxuOyVp1apVY47t448/fhZXeOa6urrU0dGhnTt36oUXXlChUNC1116rdDo9WnPPPffomWee0ZNPPqmuri4dOnRIN954o8dV27lspyTddtttY47nQw895GnF4zN37lw9+OCD2r17t3bt2qVrrrlG119/vX79619LOovHMpgGrrjiiqCjo2P041KpFLS2tgadnZ0eVzWx7rvvvmDJkiW+lzFpJAVbt24d/bhcLgfNzc3Bt7/97dHP9ff3B4lEInj88cc9rHBifHg7gyAI1q5dG1x//fVe1jNZjhw5EkgKurq6giD44NjFYrHgySefHK35zW9+E0gKduzY4WuZZ+zD2xkEQfDHf/zHwV/91V/5W9QkmTVrVvBP//RPZ/VYTvlnQPl8Xrt379aKFStGPxcOh7VixQrt2LHD48om3htvvKHW1lYtXLhQX/rSl3TgwAHfS5o0PT096u3tHXNcU6mUli1bNuOOqyRt375djY2Nuuiii3TnnXfq+PHjvpd0RgYGBiRJ9fX1kqTdu3erUCiMOZ4XX3yx5s2bN62P54e384Qf//jHamho0KWXXqoNGzYok8n4WN6EKJVKeuKJJ5ROp9Xe3n5Wj+WUCyP9sGPHjqlUKqmpqWnM55uamvTb3/7W06om3rJly7R582ZddNFFOnz4sO6//3599rOf1Wuvvaaamhrfy5twvb29knTS43riazPFqlWrdOONN2rBggXav3+//vZv/1arV6/Wjh07JvVv4EyWcrmsu+++W1deeaUuvfRSSR8cz3g8rrq6ujG10/l4nmw7JemLX/yi5s+fr9bWVu3du1df+9rX1N3drZ/97GceV2v3q1/9Su3t7cpms6qurtbWrVt1ySWXaM+ePWftWE75AXSuWL169ei/Fy9erGXLlmn+/Pn66U9/qltvvdXjynCmbr755tF/X3bZZVq8eLEuuOACbd++XcuXL/e4svHp6OjQa6+9Nu1/R3k6p9rO22+/ffTfl112mVpaWrR8+XLt379fF1xwwdle5rhddNFF2rNnjwYGBvSv//qvWrt2rbq6us7qGqb8j+AaGhoUiUQ+8gqMvr4+NTc3e1rV5Kurq9OFF16offv2+V7KpDhx7M614ypJCxcuVENDw7Q8tuvWrdOzzz6rX/ziF2P+bEpzc7Py+bz6+/vH1E/X43mq7TyZZcuWSdK0O57xeFyLFi3S0qVL1dnZqSVLluh73/veWT2WU34AxeNxLV26VNu2bRv9XLlc1rZt29Te3u5xZZNreHhY+/fvV0tLi++lTIoFCxaoubl5zHEdHBzUK6+8MqOPq/TBX/09fvz4tDq2QRBo3bp12rp1q1566SUtWLBgzNeXLl2qWCw25nh2d3frwIED0+p4nm47T2bPnj2SNK2O58mUy2Xlcrmzeywn9CUNk+SJJ54IEolEsHnz5uD1118Pbr/99qCuri7o7e31vbQJ89d//dfB9u3bg56enuA//uM/ghUrVgQNDQ3BkSNHfC9t3IaGhoJXX301ePXVVwNJwXe+853g1VdfDd5+++0gCILgwQcfDOrq6oKnn3462Lt3b3D99dcHCxYsCEZGRjyv3ObjtnNoaCj4yle+EuzYsSPo6ekJXnzxxeAP//APg0984hNBNpv1vXRnd955Z5BKpYLt27cHhw8fHr1lMpnRmjvuuCOYN29e8NJLLwW7du0K2tvbg/b2do+rtjvddu7bty944IEHgl27dgU9PT3B008/HSxcuDC46qqrPK/c5utf/3rQ1dUV9PT0BHv37g2+/vWvB6FQKPj3f//3IAjO3rGcFgMoCILgBz/4QTBv3rwgHo8HV1xxRbBz507fS5pQN910U9DS0hLE4/HgvPPOC2666aZg3759vpd1Rn7xi18Ekj5yW7t2bRAEH7wU+5vf/GbQ1NQUJBKJYPny5UF3d7ffRY/Dx21nJpMJrr322mDOnDlBLBYL5s+fH9x2223T7sHTybZPUvDYY4+N1oyMjAR/+Zd/GcyaNSuorKwMPv/5zweHDx/2t+hxON12HjhwILjqqquC+vr6IJFIBIsWLQr+5m/+JhgYGPC7cKO/+Iu/CObPnx/E4/Fgzpw5wfLly0eHTxCcvWPJn2MAAHgx5X8HBACYmRhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/+f/DdbQVo7xPsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)\n",
    "x, y = next(datagen)\n",
    "print(\"first: {}, second = {}\".format(classes[np.argmax(y['output1'][0])],classes[np.argmax(y['output2'][0])+5]))\n",
    "plt.imshow(x[0])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "We test our evaluation method with a model which generated random classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_model():\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    x = layers.Flatten()(inputs)\n",
    "    output1 = layers.Dense(5, name='output1')(x)\n",
    "    output2 = layers.Dense(5, name='output2')(x)\n",
    "    model = keras.Model(\n",
    "    inputs,\n",
    "    outputs={'output1':output1, 'output2':output2}, name='Toy',\n",
    "    )\n",
    "    model.compile(\n",
    "    optimizer='Adam', \n",
    "    loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "    metrics={'output1':'accuracy', 'output2':'accuracy'})\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, gen, repeat=10, steps=10, batchsize=1000):\n",
    "    evaluation_results = []\n",
    "    for i in tqdm(range(repeat)):\n",
    "        results = model.evaluate(gen, batch_size=batchsize, steps=steps, verbose=False, return_dict=True)\n",
    "        acc1 = results['output1_accuracy']\n",
    "        acc2 = results['output2_accuracy']\n",
    "        evaluation_results.append(np.mean([acc1, acc2]))\n",
    "    print(\"mean accuracy = \", np.mean(evaluation_results))\n",
    "    print(\"standard deviation = \", np.std(evaluation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736617746.400180   34660 service.cc:148] XLA service 0x7f7938004670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1736617746.400248   34660 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 SUPER, Compute Capability 8.9\n",
      "I0000 00:00:1736617746.452295   34660 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1736617746.878792   34660 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "100%|██████████| 50/50 [00:25<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.1973150008916855\n",
      "standard deviation =  0.002223358911651219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = random_model()\n",
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the accuracy is around 1/5 = 0.2! We repeat the evaluation ten times, and compute the standard deviation. This is our official project result. We load our top model weights to report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2025-01-11 09:49:32.419288: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.5209750041365624\n",
      "standard deviation =  0.0021657860217249303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ACNN3-85.5.keras')\n",
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6460500001907349\n",
      "standard deviation =  0.002171180665960431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ACCN1-80.6.keras')\n",
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6572750031948089\n",
      "standard deviation =  0.0027546531026423804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ACNN2/0.61-0.72-epoch64-loss1.85.keras')\n",
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.6833250015974045\n",
      "standard deviation =  0.0029996816623369497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model('ACNN/0.64-0.74-epoch39-loss1.43.keras')\n",
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoints\n",
    "We implement a custom model callback to save the model weights when the average accuracy of both classifiers improves during training. Without this, we would be forced to use a proxy like loss for the metric we care about the most. We use the validation accuracy since it is representative of the unseen data the model will see during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback which does not use loss as a proxy!\n",
    "class MeanAccModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, monitor1='val_output1_accuracy', monitor2='val_output2_accuracy', mode='max', verbose=1):\n",
    "        super(MeanAccModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.monitor1 = monitor1\n",
    "        self.monitor2 = monitor2\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.best_score = -float('inf') if mode == 'max' else float('inf')\n",
    "\n",
    "    # Called at the end of an epoch during training\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc1 = logs.get(self.monitor1)\n",
    "        acc2 = logs.get(self.monitor2)\n",
    "\n",
    "        # Compute the average accuracy\n",
    "        avg_accuracy = (acc1 + acc2) / 2 if acc1 is not None and acc2 is not None else None\n",
    "\n",
    "        if avg_accuracy is not None:\n",
    "            if (self.mode == 'max' and avg_accuracy > self.best_score) or \\\n",
    "               (self.mode == 'min' and avg_accuracy < self.best_score):\n",
    "                # Update the best score\n",
    "                self.best_score = avg_accuracy\n",
    "                \n",
    "                # Format the filepath\n",
    "                save_path = self.filepath.format(\n",
    "                    output1_accuracy=acc1,\n",
    "                    output2_accuracy=acc2,\n",
    "                    epoch=epoch + 1,  # Epoch is zero-indexed\n",
    "                    loss=logs.get('loss')\n",
    "                )\n",
    "                \n",
    "                # Save the model\n",
    "                if self.verbose:\n",
    "                    print(f\"\\nEpoch {epoch + 1}: Average accuracy improved to {avg_accuracy:.4f}, saving model to {save_path}\")\n",
    "                self.model.save(save_path)\n",
    "            elif self.verbose:\n",
    "                print(f\"\\nEpoch {epoch + 1}: Average accuracy did not improve (current: {avg_accuracy:.4f}, best: {self.best_score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the built in callback for early stopping so we do not have to worry about training for too few or too many epochs. When the validation loss stops decreasing, the model will try ten more times to improve or revert to the best weights. The validation loss metric is an average of the validation losses of each one of the two classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=10,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation\n",
    "We use the Keras Functional API to create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCN4():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    # Classifers\n",
    "    x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN3',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │      \u001b[38;5;34m3,845\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,375,498</span> (5.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,375,498\u001b[0m (5.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 3.2188 - output1_accuracy: 0.2030 - output1_loss: 1.6094 - output2_accuracy: 0.2106 - output2_loss: 1.6094 - val_loss: 3.2175 - val_output1_accuracy: 0.2234 - val_output1_loss: 1.6091 - val_output2_accuracy: 0.2738 - val_output2_loss: 1.6084\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.2171 - output1_accuracy: 0.2218 - output1_loss: 1.6088 - output2_accuracy: 0.2287 - output2_loss: 1.6082 - val_loss: 3.2150 - val_output1_accuracy: 0.2658 - val_output1_loss: 1.6079 - val_output2_accuracy: 0.1999 - val_output2_loss: 1.6070\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.2140 - output1_accuracy: 0.2428 - output1_loss: 1.6077 - output2_accuracy: 0.2074 - output2_loss: 1.6063 - val_loss: 3.2080 - val_output1_accuracy: 0.2678 - val_output1_loss: 1.6049 - val_output2_accuracy: 0.2194 - val_output2_loss: 1.6031\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 3.2008 - output1_accuracy: 0.2826 - output1_loss: 1.6022 - output2_accuracy: 0.2400 - output2_loss: 1.5986 - val_loss: 3.1531 - val_output1_accuracy: 0.2971 - val_output1_loss: 1.5749 - val_output2_accuracy: 0.2440 - val_output2_loss: 1.5782\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 3.0793 - output1_accuracy: 0.2992 - output1_loss: 1.5489 - output2_accuracy: 0.3072 - output2_loss: 1.5304 - val_loss: 2.9840 - val_output1_accuracy: 0.3275 - val_output1_loss: 1.5159 - val_output2_accuracy: 0.3552 - val_output2_loss: 1.4682\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 2.9893 - output1_accuracy: 0.3244 - output1_loss: 1.5131 - output2_accuracy: 0.3499 - output2_loss: 1.4762 - val_loss: 2.9628 - val_output1_accuracy: 0.3431 - val_output1_loss: 1.5021 - val_output2_accuracy: 0.3622 - val_output2_loss: 1.4607\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 2.9505 - output1_accuracy: 0.3385 - output1_loss: 1.4932 - output2_accuracy: 0.3566 - output2_loss: 1.4573 - val_loss: 2.9564 - val_output1_accuracy: 0.3285 - val_output1_loss: 1.4921 - val_output2_accuracy: 0.3586 - val_output2_loss: 1.4643\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 2.9251 - output1_accuracy: 0.3461 - output1_loss: 1.4832 - output2_accuracy: 0.3697 - output2_loss: 1.4419 - val_loss: 2.9030 - val_output1_accuracy: 0.3570 - val_output1_loss: 1.4710 - val_output2_accuracy: 0.3864 - val_output2_loss: 1.4320\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 2.9068 - output1_accuracy: 0.3532 - output1_loss: 1.4777 - output2_accuracy: 0.3752 - output2_loss: 1.4290 - val_loss: 2.8844 - val_output1_accuracy: 0.3594 - val_output1_loss: 1.4735 - val_output2_accuracy: 0.3910 - val_output2_loss: 1.4109\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 2.8747 - output1_accuracy: 0.3681 - output1_loss: 1.4601 - output2_accuracy: 0.3905 - output2_loss: 1.4146 - val_loss: 2.8655 - val_output1_accuracy: 0.3694 - val_output1_loss: 1.4583 - val_output2_accuracy: 0.4012 - val_output2_loss: 1.4072\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.8530 - output1_accuracy: 0.3716 - output1_loss: 1.4493 - output2_accuracy: 0.4013 - output2_loss: 1.4036 - val_loss: 2.8261 - val_output1_accuracy: 0.3800 - val_output1_loss: 1.4368 - val_output2_accuracy: 0.4111 - val_output2_loss: 1.3894\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.8319 - output1_accuracy: 0.3873 - output1_loss: 1.4343 - output2_accuracy: 0.4023 - output2_loss: 1.3977 - val_loss: 2.8228 - val_output1_accuracy: 0.3700 - val_output1_loss: 1.4528 - val_output2_accuracy: 0.4251 - val_output2_loss: 1.3700\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.8063 - output1_accuracy: 0.3904 - output1_loss: 1.4204 - output2_accuracy: 0.4123 - output2_loss: 1.3859 - val_loss: 2.8113 - val_output1_accuracy: 0.3686 - val_output1_loss: 1.4486 - val_output2_accuracy: 0.4293 - val_output2_loss: 1.3626\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.7913 - output1_accuracy: 0.3990 - output1_loss: 1.4118 - output2_accuracy: 0.4150 - output2_loss: 1.3794 - val_loss: 2.7914 - val_output1_accuracy: 0.3966 - val_output1_loss: 1.4210 - val_output2_accuracy: 0.4247 - val_output2_loss: 1.3704\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.7741 - output1_accuracy: 0.4019 - output1_loss: 1.4053 - output2_accuracy: 0.4240 - output2_loss: 1.3688 - val_loss: 2.7791 - val_output1_accuracy: 0.3990 - val_output1_loss: 1.4143 - val_output2_accuracy: 0.4297 - val_output2_loss: 1.3648\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.7467 - output1_accuracy: 0.4059 - output1_loss: 1.3954 - output2_accuracy: 0.4311 - output2_loss: 1.3514 - val_loss: 2.7676 - val_output1_accuracy: 0.3914 - val_output1_loss: 1.4159 - val_output2_accuracy: 0.4437 - val_output2_loss: 1.3517\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.7301 - output1_accuracy: 0.4113 - output1_loss: 1.3825 - output2_accuracy: 0.4303 - output2_loss: 1.3476 - val_loss: 2.7586 - val_output1_accuracy: 0.4050 - val_output1_loss: 1.4064 - val_output2_accuracy: 0.4319 - val_output2_loss: 1.3522\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.7168 - output1_accuracy: 0.4170 - output1_loss: 1.3761 - output2_accuracy: 0.4362 - output2_loss: 1.3407 - val_loss: 2.7160 - val_output1_accuracy: 0.4083 - val_output1_loss: 1.3881 - val_output2_accuracy: 0.4441 - val_output2_loss: 1.3279\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.7231 - output1_accuracy: 0.4161 - output1_loss: 1.3750 - output2_accuracy: 0.4330 - output2_loss: 1.3481 - val_loss: 2.7397 - val_output1_accuracy: 0.4046 - val_output1_loss: 1.3936 - val_output2_accuracy: 0.4457 - val_output2_loss: 1.3461\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6888 - output1_accuracy: 0.4219 - output1_loss: 1.3610 - output2_accuracy: 0.4467 - output2_loss: 1.3278 - val_loss: 2.7207 - val_output1_accuracy: 0.4075 - val_output1_loss: 1.3859 - val_output2_accuracy: 0.4563 - val_output2_loss: 1.3348\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6884 - output1_accuracy: 0.4206 - output1_loss: 1.3626 - output2_accuracy: 0.4495 - output2_loss: 1.3258 - val_loss: 2.6822 - val_output1_accuracy: 0.4185 - val_output1_loss: 1.3697 - val_output2_accuracy: 0.4533 - val_output2_loss: 1.3125\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6834 - output1_accuracy: 0.4248 - output1_loss: 1.3519 - output2_accuracy: 0.4437 - output2_loss: 1.3316 - val_loss: 2.6643 - val_output1_accuracy: 0.4303 - val_output1_loss: 1.3505 - val_output2_accuracy: 0.4613 - val_output2_loss: 1.3137\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6660 - output1_accuracy: 0.4335 - output1_loss: 1.3462 - output2_accuracy: 0.4508 - output2_loss: 1.3199 - val_loss: 2.6979 - val_output1_accuracy: 0.4279 - val_output1_loss: 1.3645 - val_output2_accuracy: 0.4477 - val_output2_loss: 1.3333\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6509 - output1_accuracy: 0.4402 - output1_loss: 1.3370 - output2_accuracy: 0.4511 - output2_loss: 1.3139 - val_loss: 2.6601 - val_output1_accuracy: 0.4225 - val_output1_loss: 1.3524 - val_output2_accuracy: 0.4688 - val_output2_loss: 1.3077\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6447 - output1_accuracy: 0.4368 - output1_loss: 1.3343 - output2_accuracy: 0.4553 - output2_loss: 1.3104 - val_loss: 2.6491 - val_output1_accuracy: 0.4377 - val_output1_loss: 1.3386 - val_output2_accuracy: 0.4599 - val_output2_loss: 1.3106\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6517 - output1_accuracy: 0.4336 - output1_loss: 1.3344 - output2_accuracy: 0.4526 - output2_loss: 1.3173 - val_loss: 2.6125 - val_output1_accuracy: 0.4439 - val_output1_loss: 1.3259 - val_output2_accuracy: 0.4778 - val_output2_loss: 1.2866\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6384 - output1_accuracy: 0.4421 - output1_loss: 1.3283 - output2_accuracy: 0.4556 - output2_loss: 1.3101 - val_loss: 2.6775 - val_output1_accuracy: 0.4291 - val_output1_loss: 1.3521 - val_output2_accuracy: 0.4531 - val_output2_loss: 1.3254\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6317 - output1_accuracy: 0.4419 - output1_loss: 1.3268 - output2_accuracy: 0.4599 - output2_loss: 1.3049 - val_loss: 2.6479 - val_output1_accuracy: 0.4283 - val_output1_loss: 1.3477 - val_output2_accuracy: 0.4683 - val_output2_loss: 1.3002\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6261 - output1_accuracy: 0.4433 - output1_loss: 1.3268 - output2_accuracy: 0.4593 - output2_loss: 1.2993 - val_loss: 2.6318 - val_output1_accuracy: 0.4399 - val_output1_loss: 1.3420 - val_output2_accuracy: 0.4718 - val_output2_loss: 1.2898\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6182 - output1_accuracy: 0.4500 - output1_loss: 1.3151 - output2_accuracy: 0.4570 - output2_loss: 1.3031 - val_loss: 2.6096 - val_output1_accuracy: 0.4393 - val_output1_loss: 1.3228 - val_output2_accuracy: 0.4671 - val_output2_loss: 1.2868\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.6159 - output1_accuracy: 0.4509 - output1_loss: 1.3091 - output2_accuracy: 0.4577 - output2_loss: 1.3068 - val_loss: 2.6143 - val_output1_accuracy: 0.4425 - val_output1_loss: 1.3282 - val_output2_accuracy: 0.4728 - val_output2_loss: 1.2862\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5925 - output1_accuracy: 0.4501 - output1_loss: 1.3082 - output2_accuracy: 0.4689 - output2_loss: 1.2843 - val_loss: 2.6309 - val_output1_accuracy: 0.4339 - val_output1_loss: 1.3453 - val_output2_accuracy: 0.4760 - val_output2_loss: 1.2856\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5904 - output1_accuracy: 0.4530 - output1_loss: 1.3012 - output2_accuracy: 0.4642 - output2_loss: 1.2892 - val_loss: 2.5962 - val_output1_accuracy: 0.4509 - val_output1_loss: 1.3134 - val_output2_accuracy: 0.4740 - val_output2_loss: 1.2828\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5944 - output1_accuracy: 0.4524 - output1_loss: 1.3032 - output2_accuracy: 0.4626 - output2_loss: 1.2913 - val_loss: 2.5782 - val_output1_accuracy: 0.4577 - val_output1_loss: 1.3000 - val_output2_accuracy: 0.4746 - val_output2_loss: 1.2782\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5794 - output1_accuracy: 0.4648 - output1_loss: 1.2934 - output2_accuracy: 0.4681 - output2_loss: 1.2859 - val_loss: 2.5500 - val_output1_accuracy: 0.4575 - val_output1_loss: 1.2938 - val_output2_accuracy: 0.4830 - val_output2_loss: 1.2563\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5814 - output1_accuracy: 0.4512 - output1_loss: 1.3039 - output2_accuracy: 0.4727 - output2_loss: 1.2775 - val_loss: 2.5735 - val_output1_accuracy: 0.4557 - val_output1_loss: 1.3067 - val_output2_accuracy: 0.4810 - val_output2_loss: 1.2668\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5705 - output1_accuracy: 0.4584 - output1_loss: 1.2892 - output2_accuracy: 0.4724 - output2_loss: 1.2813 - val_loss: 2.5600 - val_output1_accuracy: 0.4475 - val_output1_loss: 1.3061 - val_output2_accuracy: 0.4870 - val_output2_loss: 1.2539\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5510 - output1_accuracy: 0.4616 - output1_loss: 1.2878 - output2_accuracy: 0.4800 - output2_loss: 1.2632 - val_loss: 2.5739 - val_output1_accuracy: 0.4541 - val_output1_loss: 1.3040 - val_output2_accuracy: 0.4744 - val_output2_loss: 1.2698\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5517 - output1_accuracy: 0.4646 - output1_loss: 1.2845 - output2_accuracy: 0.4756 - output2_loss: 1.2672 - val_loss: 2.5822 - val_output1_accuracy: 0.4413 - val_output1_loss: 1.3311 - val_output2_accuracy: 0.4854 - val_output2_loss: 1.2512\n",
      "Epoch 40/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5419 - output1_accuracy: 0.4617 - output1_loss: 1.2852 - output2_accuracy: 0.4792 - output2_loss: 1.2567 - val_loss: 2.5869 - val_output1_accuracy: 0.4433 - val_output1_loss: 1.3230 - val_output2_accuracy: 0.4788 - val_output2_loss: 1.2639\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5531 - output1_accuracy: 0.4593 - output1_loss: 1.2906 - output2_accuracy: 0.4779 - output2_loss: 1.2625 - val_loss: 2.5311 - val_output1_accuracy: 0.4605 - val_output1_loss: 1.2894 - val_output2_accuracy: 0.4914 - val_output2_loss: 1.2418\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5393 - output1_accuracy: 0.4655 - output1_loss: 1.2789 - output2_accuracy: 0.4853 - output2_loss: 1.2604 - val_loss: 2.5673 - val_output1_accuracy: 0.4445 - val_output1_loss: 1.3124 - val_output2_accuracy: 0.4924 - val_output2_loss: 1.2549\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5237 - output1_accuracy: 0.4714 - output1_loss: 1.2671 - output2_accuracy: 0.4803 - output2_loss: 1.2565 - val_loss: 2.5235 - val_output1_accuracy: 0.4740 - val_output1_loss: 1.2730 - val_output2_accuracy: 0.4840 - val_output2_loss: 1.2504\n",
      "Epoch 44/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5193 - output1_accuracy: 0.4734 - output1_loss: 1.2665 - output2_accuracy: 0.4865 - output2_loss: 1.2528 - val_loss: 2.5871 - val_output1_accuracy: 0.4457 - val_output1_loss: 1.3214 - val_output2_accuracy: 0.4790 - val_output2_loss: 1.2656\n",
      "Epoch 45/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5077 - output1_accuracy: 0.4708 - output1_loss: 1.2645 - output2_accuracy: 0.4913 - output2_loss: 1.2432 - val_loss: 2.5454 - val_output1_accuracy: 0.4473 - val_output1_loss: 1.3022 - val_output2_accuracy: 0.5004 - val_output2_loss: 1.2432\n",
      "Epoch 46/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5248 - output1_accuracy: 0.4640 - output1_loss: 1.2784 - output2_accuracy: 0.4907 - output2_loss: 1.2464 - val_loss: 2.4993 - val_output1_accuracy: 0.4694 - val_output1_loss: 1.2743 - val_output2_accuracy: 0.5010 - val_output2_loss: 1.2250\n",
      "Epoch 47/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5115 - output1_accuracy: 0.4695 - output1_loss: 1.2737 - output2_accuracy: 0.4917 - output2_loss: 1.2377 - val_loss: 2.4967 - val_output1_accuracy: 0.4760 - val_output1_loss: 1.2670 - val_output2_accuracy: 0.5004 - val_output2_loss: 1.2297\n",
      "Epoch 48/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5053 - output1_accuracy: 0.4728 - output1_loss: 1.2615 - output2_accuracy: 0.4901 - output2_loss: 1.2438 - val_loss: 2.5429 - val_output1_accuracy: 0.4611 - val_output1_loss: 1.3095 - val_output2_accuracy: 0.4970 - val_output2_loss: 1.2334\n",
      "Epoch 49/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.5032 - output1_accuracy: 0.4739 - output1_loss: 1.2638 - output2_accuracy: 0.4940 - output2_loss: 1.2394 - val_loss: 2.5123 - val_output1_accuracy: 0.4752 - val_output1_loss: 1.2726 - val_output2_accuracy: 0.4956 - val_output2_loss: 1.2397\n",
      "Epoch 50/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4926 - output1_accuracy: 0.4689 - output1_loss: 1.2674 - output2_accuracy: 0.5005 - output2_loss: 1.2252 - val_loss: 2.5052 - val_output1_accuracy: 0.4657 - val_output1_loss: 1.2814 - val_output2_accuracy: 0.5042 - val_output2_loss: 1.2237\n",
      "Epoch 51/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.5078 - output1_accuracy: 0.4696 - output1_loss: 1.2698 - output2_accuracy: 0.4910 - output2_loss: 1.2380 - val_loss: 2.5011 - val_output1_accuracy: 0.4651 - val_output1_loss: 1.2780 - val_output2_accuracy: 0.4948 - val_output2_loss: 1.2230\n",
      "Epoch 52/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4699 - output1_accuracy: 0.4828 - output1_loss: 1.2471 - output2_accuracy: 0.5042 - output2_loss: 1.2228 - val_loss: 2.4759 - val_output1_accuracy: 0.4740 - val_output1_loss: 1.2721 - val_output2_accuracy: 0.5174 - val_output2_loss: 1.2037\n",
      "Epoch 53/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4760 - output1_accuracy: 0.4810 - output1_loss: 1.2491 - output2_accuracy: 0.5005 - output2_loss: 1.2268 - val_loss: 2.5024 - val_output1_accuracy: 0.4712 - val_output1_loss: 1.2751 - val_output2_accuracy: 0.5070 - val_output2_loss: 1.2273\n",
      "Epoch 54/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4766 - output1_accuracy: 0.4747 - output1_loss: 1.2595 - output2_accuracy: 0.5059 - output2_loss: 1.2170 - val_loss: 2.4922 - val_output1_accuracy: 0.4579 - val_output1_loss: 1.2883 - val_output2_accuracy: 0.5174 - val_output2_loss: 1.2040\n",
      "Epoch 55/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4565 - output1_accuracy: 0.4783 - output1_loss: 1.2495 - output2_accuracy: 0.5065 - output2_loss: 1.2070 - val_loss: 2.5235 - val_output1_accuracy: 0.4629 - val_output1_loss: 1.2838 - val_output2_accuracy: 0.4924 - val_output2_loss: 1.2397\n",
      "Epoch 56/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4717 - output1_accuracy: 0.4876 - output1_loss: 1.2467 - output2_accuracy: 0.4997 - output2_loss: 1.2250 - val_loss: 2.5111 - val_output1_accuracy: 0.4647 - val_output1_loss: 1.2933 - val_output2_accuracy: 0.5044 - val_output2_loss: 1.2177\n",
      "Epoch 57/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4618 - output1_accuracy: 0.4780 - output1_loss: 1.2508 - output2_accuracy: 0.5067 - output2_loss: 1.2110 - val_loss: 2.5193 - val_output1_accuracy: 0.4603 - val_output1_loss: 1.3065 - val_output2_accuracy: 0.5090 - val_output2_loss: 1.2128\n",
      "Epoch 58/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4552 - output1_accuracy: 0.4813 - output1_loss: 1.2437 - output2_accuracy: 0.5058 - output2_loss: 1.2115 - val_loss: 2.4897 - val_output1_accuracy: 0.4758 - val_output1_loss: 1.2620 - val_output2_accuracy: 0.5030 - val_output2_loss: 1.2277\n",
      "Epoch 59/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4709 - output1_accuracy: 0.4732 - output1_loss: 1.2610 - output2_accuracy: 0.5081 - output2_loss: 1.2099 - val_loss: 2.4741 - val_output1_accuracy: 0.4812 - val_output1_loss: 1.2642 - val_output2_accuracy: 0.5038 - val_output2_loss: 1.2098\n",
      "Epoch 60/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4467 - output1_accuracy: 0.4799 - output1_loss: 1.2427 - output2_accuracy: 0.5088 - output2_loss: 1.2041 - val_loss: 2.4921 - val_output1_accuracy: 0.4577 - val_output1_loss: 1.2913 - val_output2_accuracy: 0.5246 - val_output2_loss: 1.2008\n",
      "Epoch 61/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4427 - output1_accuracy: 0.4834 - output1_loss: 1.2426 - output2_accuracy: 0.5127 - output2_loss: 1.2001 - val_loss: 2.4914 - val_output1_accuracy: 0.4645 - val_output1_loss: 1.2783 - val_output2_accuracy: 0.5036 - val_output2_loss: 1.2131\n",
      "Epoch 62/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4445 - output1_accuracy: 0.4836 - output1_loss: 1.2441 - output2_accuracy: 0.5121 - output2_loss: 1.2003 - val_loss: 2.4418 - val_output1_accuracy: 0.4712 - val_output1_loss: 1.2660 - val_output2_accuracy: 0.5278 - val_output2_loss: 1.1758\n",
      "Epoch 63/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4448 - output1_accuracy: 0.4832 - output1_loss: 1.2450 - output2_accuracy: 0.5145 - output2_loss: 1.1998 - val_loss: 2.4677 - val_output1_accuracy: 0.4746 - val_output1_loss: 1.2614 - val_output2_accuracy: 0.5120 - val_output2_loss: 1.2063\n",
      "Epoch 64/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4409 - output1_accuracy: 0.4828 - output1_loss: 1.2409 - output2_accuracy: 0.5156 - output2_loss: 1.2000 - val_loss: 2.4315 - val_output1_accuracy: 0.4760 - val_output1_loss: 1.2655 - val_output2_accuracy: 0.5276 - val_output2_loss: 1.1660\n",
      "Epoch 65/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4493 - output1_accuracy: 0.4806 - output1_loss: 1.2509 - output2_accuracy: 0.5177 - output2_loss: 1.1984 - val_loss: 2.4778 - val_output1_accuracy: 0.4679 - val_output1_loss: 1.2729 - val_output2_accuracy: 0.5076 - val_output2_loss: 1.2049\n",
      "Epoch 66/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4251 - output1_accuracy: 0.4892 - output1_loss: 1.2327 - output2_accuracy: 0.5149 - output2_loss: 1.1924 - val_loss: 2.4434 - val_output1_accuracy: 0.4613 - val_output1_loss: 1.2725 - val_output2_accuracy: 0.5232 - val_output2_loss: 1.1708\n",
      "Epoch 67/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4369 - output1_accuracy: 0.4858 - output1_loss: 1.2376 - output2_accuracy: 0.5119 - output2_loss: 1.1993 - val_loss: 2.4486 - val_output1_accuracy: 0.4683 - val_output1_loss: 1.2595 - val_output2_accuracy: 0.5210 - val_output2_loss: 1.1892\n",
      "Epoch 68/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4373 - output1_accuracy: 0.4873 - output1_loss: 1.2437 - output2_accuracy: 0.5172 - output2_loss: 1.1936 - val_loss: 2.4461 - val_output1_accuracy: 0.4810 - val_output1_loss: 1.2612 - val_output2_accuracy: 0.5274 - val_output2_loss: 1.1850\n",
      "Epoch 69/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4210 - output1_accuracy: 0.4880 - output1_loss: 1.2364 - output2_accuracy: 0.5226 - output2_loss: 1.1846 - val_loss: 2.4533 - val_output1_accuracy: 0.4696 - val_output1_loss: 1.2638 - val_output2_accuracy: 0.5268 - val_output2_loss: 1.1895\n",
      "Epoch 70/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4330 - output1_accuracy: 0.4866 - output1_loss: 1.2455 - output2_accuracy: 0.5199 - output2_loss: 1.1876 - val_loss: 2.4313 - val_output1_accuracy: 0.4848 - val_output1_loss: 1.2380 - val_output2_accuracy: 0.5184 - val_output2_loss: 1.1933\n",
      "Epoch 71/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4155 - output1_accuracy: 0.4903 - output1_loss: 1.2369 - output2_accuracy: 0.5213 - output2_loss: 1.1786 - val_loss: 2.4381 - val_output1_accuracy: 0.4866 - val_output1_loss: 1.2542 - val_output2_accuracy: 0.5188 - val_output2_loss: 1.1839\n",
      "Epoch 72/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.4167 - output1_accuracy: 0.4854 - output1_loss: 1.2341 - output2_accuracy: 0.5249 - output2_loss: 1.1826 - val_loss: 2.4352 - val_output1_accuracy: 0.4752 - val_output1_loss: 1.2642 - val_output2_accuracy: 0.5373 - val_output2_loss: 1.1710\n",
      "Epoch 73/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3954 - output1_accuracy: 0.4930 - output1_loss: 1.2261 - output2_accuracy: 0.5255 - output2_loss: 1.1693 - val_loss: 2.4474 - val_output1_accuracy: 0.4858 - val_output1_loss: 1.2521 - val_output2_accuracy: 0.5146 - val_output2_loss: 1.1953\n",
      "Epoch 74/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3946 - output1_accuracy: 0.4930 - output1_loss: 1.2257 - output2_accuracy: 0.5274 - output2_loss: 1.1688 - val_loss: 2.4088 - val_output1_accuracy: 0.4852 - val_output1_loss: 1.2444 - val_output2_accuracy: 0.5377 - val_output2_loss: 1.1643\n",
      "Epoch 75/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3961 - output1_accuracy: 0.4976 - output1_loss: 1.2233 - output2_accuracy: 0.5229 - output2_loss: 1.1728 - val_loss: 2.4131 - val_output1_accuracy: 0.4870 - val_output1_loss: 1.2443 - val_output2_accuracy: 0.5232 - val_output2_loss: 1.1687\n",
      "Epoch 76/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4080 - output1_accuracy: 0.4929 - output1_loss: 1.2274 - output2_accuracy: 0.5198 - output2_loss: 1.1806 - val_loss: 2.4043 - val_output1_accuracy: 0.4920 - val_output1_loss: 1.2309 - val_output2_accuracy: 0.5276 - val_output2_loss: 1.1734\n",
      "Epoch 77/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4042 - output1_accuracy: 0.4867 - output1_loss: 1.2301 - output2_accuracy: 0.5303 - output2_loss: 1.1741 - val_loss: 2.4241 - val_output1_accuracy: 0.4792 - val_output1_loss: 1.2514 - val_output2_accuracy: 0.5280 - val_output2_loss: 1.1727\n",
      "Epoch 78/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3917 - output1_accuracy: 0.4949 - output1_loss: 1.2255 - output2_accuracy: 0.5296 - output2_loss: 1.1663 - val_loss: 2.4280 - val_output1_accuracy: 0.4906 - val_output1_loss: 1.2484 - val_output2_accuracy: 0.5238 - val_output2_loss: 1.1796\n",
      "Epoch 79/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3960 - output1_accuracy: 0.4935 - output1_loss: 1.2253 - output2_accuracy: 0.5253 - output2_loss: 1.1707 - val_loss: 2.4174 - val_output1_accuracy: 0.4876 - val_output1_loss: 1.2424 - val_output2_accuracy: 0.5361 - val_output2_loss: 1.1750\n",
      "Epoch 80/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3888 - output1_accuracy: 0.4880 - output1_loss: 1.2249 - output2_accuracy: 0.5348 - output2_loss: 1.1639 - val_loss: 2.3947 - val_output1_accuracy: 0.4862 - val_output1_loss: 1.2371 - val_output2_accuracy: 0.5443 - val_output2_loss: 1.1576\n",
      "Epoch 81/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3776 - output1_accuracy: 0.4956 - output1_loss: 1.2149 - output2_accuracy: 0.5336 - output2_loss: 1.1627 - val_loss: 2.3998 - val_output1_accuracy: 0.4874 - val_output1_loss: 1.2482 - val_output2_accuracy: 0.5343 - val_output2_loss: 1.1517\n",
      "Epoch 82/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3773 - output1_accuracy: 0.4961 - output1_loss: 1.2161 - output2_accuracy: 0.5315 - output2_loss: 1.1612 - val_loss: 2.4373 - val_output1_accuracy: 0.4824 - val_output1_loss: 1.2481 - val_output2_accuracy: 0.5220 - val_output2_loss: 1.1892\n",
      "Epoch 83/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3817 - output1_accuracy: 0.5003 - output1_loss: 1.2166 - output2_accuracy: 0.5330 - output2_loss: 1.1651 - val_loss: 2.4159 - val_output1_accuracy: 0.4830 - val_output1_loss: 1.2422 - val_output2_accuracy: 0.5327 - val_output2_loss: 1.1737\n",
      "Epoch 84/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3727 - output1_accuracy: 0.4929 - output1_loss: 1.2238 - output2_accuracy: 0.5402 - output2_loss: 1.1488 - val_loss: 2.4020 - val_output1_accuracy: 0.4800 - val_output1_loss: 1.2429 - val_output2_accuracy: 0.5369 - val_output2_loss: 1.1591\n",
      "Epoch 85/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3787 - output1_accuracy: 0.5024 - output1_loss: 1.2095 - output2_accuracy: 0.5246 - output2_loss: 1.1692 - val_loss: 2.4080 - val_output1_accuracy: 0.4850 - val_output1_loss: 1.2449 - val_output2_accuracy: 0.5395 - val_output2_loss: 1.1631\n",
      "Epoch 86/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3774 - output1_accuracy: 0.4919 - output1_loss: 1.2238 - output2_accuracy: 0.5368 - output2_loss: 1.1536 - val_loss: 2.3891 - val_output1_accuracy: 0.4842 - val_output1_loss: 1.2332 - val_output2_accuracy: 0.5349 - val_output2_loss: 1.1558\n",
      "Epoch 87/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3698 - output1_accuracy: 0.4981 - output1_loss: 1.2128 - output2_accuracy: 0.5356 - output2_loss: 1.1571 - val_loss: 2.3997 - val_output1_accuracy: 0.4856 - val_output1_loss: 1.2348 - val_output2_accuracy: 0.5298 - val_output2_loss: 1.1649\n",
      "Epoch 88/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3690 - output1_accuracy: 0.4973 - output1_loss: 1.2139 - output2_accuracy: 0.5386 - output2_loss: 1.1550 - val_loss: 2.3955 - val_output1_accuracy: 0.4782 - val_output1_loss: 1.2355 - val_output2_accuracy: 0.5359 - val_output2_loss: 1.1599\n",
      "Epoch 89/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3677 - output1_accuracy: 0.5004 - output1_loss: 1.2196 - output2_accuracy: 0.5390 - output2_loss: 1.1481 - val_loss: 2.4126 - val_output1_accuracy: 0.4778 - val_output1_loss: 1.2545 - val_output2_accuracy: 0.5435 - val_output2_loss: 1.1581\n",
      "Epoch 90/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3585 - output1_accuracy: 0.5038 - output1_loss: 1.2094 - output2_accuracy: 0.5416 - output2_loss: 1.1491 - val_loss: 2.4050 - val_output1_accuracy: 0.4896 - val_output1_loss: 1.2414 - val_output2_accuracy: 0.5292 - val_output2_loss: 1.1635\n",
      "Epoch 91/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3605 - output1_accuracy: 0.4969 - output1_loss: 1.2135 - output2_accuracy: 0.5418 - output2_loss: 1.1470 - val_loss: 2.4062 - val_output1_accuracy: 0.4872 - val_output1_loss: 1.2420 - val_output2_accuracy: 0.5409 - val_output2_loss: 1.1642\n",
      "Epoch 92/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3710 - output1_accuracy: 0.4984 - output1_loss: 1.2207 - output2_accuracy: 0.5356 - output2_loss: 1.1503 - val_loss: 2.3934 - val_output1_accuracy: 0.4842 - val_output1_loss: 1.2403 - val_output2_accuracy: 0.5363 - val_output2_loss: 1.1531\n",
      "Epoch 93/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3635 - output1_accuracy: 0.5027 - output1_loss: 1.2110 - output2_accuracy: 0.5406 - output2_loss: 1.1525 - val_loss: 2.3887 - val_output1_accuracy: 0.4796 - val_output1_loss: 1.2436 - val_output2_accuracy: 0.5489 - val_output2_loss: 1.1451\n",
      "Epoch 94/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3557 - output1_accuracy: 0.5009 - output1_loss: 1.2102 - output2_accuracy: 0.5433 - output2_loss: 1.1455 - val_loss: 2.3902 - val_output1_accuracy: 0.4852 - val_output1_loss: 1.2326 - val_output2_accuracy: 0.5341 - val_output2_loss: 1.1576\n",
      "Epoch 95/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3484 - output1_accuracy: 0.5006 - output1_loss: 1.2088 - output2_accuracy: 0.5448 - output2_loss: 1.1396 - val_loss: 2.3703 - val_output1_accuracy: 0.4992 - val_output1_loss: 1.2281 - val_output2_accuracy: 0.5475 - val_output2_loss: 1.1421\n",
      "Epoch 96/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3526 - output1_accuracy: 0.4992 - output1_loss: 1.2136 - output2_accuracy: 0.5417 - output2_loss: 1.1390 - val_loss: 2.3766 - val_output1_accuracy: 0.4960 - val_output1_loss: 1.2245 - val_output2_accuracy: 0.5359 - val_output2_loss: 1.1520\n",
      "Epoch 97/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3506 - output1_accuracy: 0.5034 - output1_loss: 1.2058 - output2_accuracy: 0.5412 - output2_loss: 1.1448 - val_loss: 2.3737 - val_output1_accuracy: 0.4836 - val_output1_loss: 1.2466 - val_output2_accuracy: 0.5519 - val_output2_loss: 1.1271\n",
      "Epoch 98/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3465 - output1_accuracy: 0.5009 - output1_loss: 1.2146 - output2_accuracy: 0.5454 - output2_loss: 1.1318 - val_loss: 2.3880 - val_output1_accuracy: 0.4872 - val_output1_loss: 1.2393 - val_output2_accuracy: 0.5415 - val_output2_loss: 1.1487\n",
      "Epoch 99/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3488 - output1_accuracy: 0.5020 - output1_loss: 1.2094 - output2_accuracy: 0.5400 - output2_loss: 1.1394 - val_loss: 2.3484 - val_output1_accuracy: 0.4862 - val_output1_loss: 1.2234 - val_output2_accuracy: 0.5499 - val_output2_loss: 1.1250\n",
      "Epoch 100/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3318 - output1_accuracy: 0.5055 - output1_loss: 1.2002 - output2_accuracy: 0.5494 - output2_loss: 1.1315 - val_loss: 2.3658 - val_output1_accuracy: 0.4926 - val_output1_loss: 1.2357 - val_output2_accuracy: 0.5451 - val_output2_loss: 1.1301\n",
      "Epoch 101/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3425 - output1_accuracy: 0.4989 - output1_loss: 1.2122 - output2_accuracy: 0.5476 - output2_loss: 1.1303 - val_loss: 2.3644 - val_output1_accuracy: 0.4828 - val_output1_loss: 1.2342 - val_output2_accuracy: 0.5535 - val_output2_loss: 1.1302\n",
      "Epoch 102/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3344 - output1_accuracy: 0.5066 - output1_loss: 1.2094 - output2_accuracy: 0.5497 - output2_loss: 1.1249 - val_loss: 2.3639 - val_output1_accuracy: 0.4832 - val_output1_loss: 1.2376 - val_output2_accuracy: 0.5515 - val_output2_loss: 1.1262\n",
      "Epoch 103/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3337 - output1_accuracy: 0.5052 - output1_loss: 1.2043 - output2_accuracy: 0.5453 - output2_loss: 1.1294 - val_loss: 2.3573 - val_output1_accuracy: 0.4860 - val_output1_loss: 1.2343 - val_output2_accuracy: 0.5559 - val_output2_loss: 1.1230\n",
      "Epoch 104/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.3283 - output1_accuracy: 0.5052 - output1_loss: 1.2005 - output2_accuracy: 0.5450 - output2_loss: 1.1278 - val_loss: 2.3600 - val_output1_accuracy: 0.4860 - val_output1_loss: 1.2247 - val_output2_accuracy: 0.5425 - val_output2_loss: 1.1353\n",
      "Epoch 105/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3341 - output1_accuracy: 0.5068 - output1_loss: 1.2054 - output2_accuracy: 0.5505 - output2_loss: 1.1286 - val_loss: 2.3423 - val_output1_accuracy: 0.5012 - val_output1_loss: 1.2149 - val_output2_accuracy: 0.5539 - val_output2_loss: 1.1274\n",
      "Epoch 106/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3199 - output1_accuracy: 0.5146 - output1_loss: 1.1906 - output2_accuracy: 0.5489 - output2_loss: 1.1293 - val_loss: 2.3865 - val_output1_accuracy: 0.4908 - val_output1_loss: 1.2352 - val_output2_accuracy: 0.5417 - val_output2_loss: 1.1512\n",
      "Epoch 107/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3152 - output1_accuracy: 0.5099 - output1_loss: 1.1967 - output2_accuracy: 0.5550 - output2_loss: 1.1185 - val_loss: 2.3648 - val_output1_accuracy: 0.4950 - val_output1_loss: 1.2274 - val_output2_accuracy: 0.5541 - val_output2_loss: 1.1373\n",
      "Epoch 108/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3091 - output1_accuracy: 0.5108 - output1_loss: 1.1950 - output2_accuracy: 0.5529 - output2_loss: 1.1141 - val_loss: 2.3538 - val_output1_accuracy: 0.4808 - val_output1_loss: 1.2425 - val_output2_accuracy: 0.5655 - val_output2_loss: 1.1113\n",
      "Epoch 109/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3166 - output1_accuracy: 0.5053 - output1_loss: 1.1981 - output2_accuracy: 0.5526 - output2_loss: 1.1185 - val_loss: 2.3351 - val_output1_accuracy: 0.5060 - val_output1_loss: 1.2163 - val_output2_accuracy: 0.5603 - val_output2_loss: 1.1188\n",
      "Epoch 110/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3241 - output1_accuracy: 0.5051 - output1_loss: 1.2037 - output2_accuracy: 0.5541 - output2_loss: 1.1204 - val_loss: 2.3479 - val_output1_accuracy: 0.5022 - val_output1_loss: 1.2200 - val_output2_accuracy: 0.5557 - val_output2_loss: 1.1278\n",
      "Epoch 111/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3162 - output1_accuracy: 0.5051 - output1_loss: 1.1992 - output2_accuracy: 0.5537 - output2_loss: 1.1170 - val_loss: 2.3317 - val_output1_accuracy: 0.5036 - val_output1_loss: 1.2178 - val_output2_accuracy: 0.5593 - val_output2_loss: 1.1139\n",
      "Epoch 112/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2997 - output1_accuracy: 0.5084 - output1_loss: 1.1916 - output2_accuracy: 0.5626 - output2_loss: 1.1080 - val_loss: 2.3730 - val_output1_accuracy: 0.4888 - val_output1_loss: 1.2430 - val_output2_accuracy: 0.5511 - val_output2_loss: 1.1300\n",
      "Epoch 113/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3041 - output1_accuracy: 0.5095 - output1_loss: 1.1917 - output2_accuracy: 0.5593 - output2_loss: 1.1124 - val_loss: 2.3649 - val_output1_accuracy: 0.4916 - val_output1_loss: 1.2275 - val_output2_accuracy: 0.5507 - val_output2_loss: 1.1374\n",
      "Epoch 114/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3043 - output1_accuracy: 0.5068 - output1_loss: 1.1967 - output2_accuracy: 0.5606 - output2_loss: 1.1076 - val_loss: 2.3196 - val_output1_accuracy: 0.4932 - val_output1_loss: 1.2123 - val_output2_accuracy: 0.5621 - val_output2_loss: 1.1073\n",
      "Epoch 115/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3043 - output1_accuracy: 0.5070 - output1_loss: 1.1954 - output2_accuracy: 0.5579 - output2_loss: 1.1089 - val_loss: 2.3412 - val_output1_accuracy: 0.4992 - val_output1_loss: 1.2221 - val_output2_accuracy: 0.5535 - val_output2_loss: 1.1192\n",
      "Epoch 116/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.3133 - output1_accuracy: 0.5064 - output1_loss: 1.1911 - output2_accuracy: 0.5543 - output2_loss: 1.1221 - val_loss: 2.3162 - val_output1_accuracy: 0.4956 - val_output1_loss: 1.2192 - val_output2_accuracy: 0.5635 - val_output2_loss: 1.0970\n",
      "Epoch 117/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2725 - output1_accuracy: 0.5120 - output1_loss: 1.1815 - output2_accuracy: 0.5697 - output2_loss: 1.0910 - val_loss: 2.3226 - val_output1_accuracy: 0.5022 - val_output1_loss: 1.2135 - val_output2_accuracy: 0.5619 - val_output2_loss: 1.1091\n",
      "Epoch 118/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2953 - output1_accuracy: 0.5175 - output1_loss: 1.1867 - output2_accuracy: 0.5543 - output2_loss: 1.1086 - val_loss: 2.3343 - val_output1_accuracy: 0.5028 - val_output1_loss: 1.2176 - val_output2_accuracy: 0.5517 - val_output2_loss: 1.1166\n",
      "Epoch 119/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2999 - output1_accuracy: 0.5168 - output1_loss: 1.1919 - output2_accuracy: 0.5582 - output2_loss: 1.1081 - val_loss: 2.3240 - val_output1_accuracy: 0.5012 - val_output1_loss: 1.2034 - val_output2_accuracy: 0.5561 - val_output2_loss: 1.1206\n",
      "Epoch 120/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2755 - output1_accuracy: 0.5199 - output1_loss: 1.1754 - output2_accuracy: 0.5653 - output2_loss: 1.1002 - val_loss: 2.3136 - val_output1_accuracy: 0.4922 - val_output1_loss: 1.2144 - val_output2_accuracy: 0.5583 - val_output2_loss: 1.0992\n",
      "Epoch 121/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2851 - output1_accuracy: 0.5121 - output1_loss: 1.1857 - output2_accuracy: 0.5592 - output2_loss: 1.0994 - val_loss: 2.3382 - val_output1_accuracy: 0.4858 - val_output1_loss: 1.2256 - val_output2_accuracy: 0.5677 - val_output2_loss: 1.1126\n",
      "Epoch 122/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2872 - output1_accuracy: 0.5182 - output1_loss: 1.1785 - output2_accuracy: 0.5626 - output2_loss: 1.1087 - val_loss: 2.3286 - val_output1_accuracy: 0.4998 - val_output1_loss: 1.2168 - val_output2_accuracy: 0.5591 - val_output2_loss: 1.1119\n",
      "Epoch 123/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2948 - output1_accuracy: 0.5121 - output1_loss: 1.1885 - output2_accuracy: 0.5584 - output2_loss: 1.1063 - val_loss: 2.3341 - val_output1_accuracy: 0.5026 - val_output1_loss: 1.2241 - val_output2_accuracy: 0.5639 - val_output2_loss: 1.1100\n",
      "Epoch 124/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2884 - output1_accuracy: 0.5077 - output1_loss: 1.1873 - output2_accuracy: 0.5642 - output2_loss: 1.1011 - val_loss: 2.3335 - val_output1_accuracy: 0.5038 - val_output1_loss: 1.2164 - val_output2_accuracy: 0.5623 - val_output2_loss: 1.1171\n",
      "Epoch 125/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2905 - output1_accuracy: 0.5121 - output1_loss: 1.1884 - output2_accuracy: 0.5614 - output2_loss: 1.1021 - val_loss: 2.3344 - val_output1_accuracy: 0.4898 - val_output1_loss: 1.2242 - val_output2_accuracy: 0.5659 - val_output2_loss: 1.1101\n",
      "Epoch 126/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2835 - output1_accuracy: 0.5152 - output1_loss: 1.1830 - output2_accuracy: 0.5602 - output2_loss: 1.1005 - val_loss: 2.3128 - val_output1_accuracy: 0.4956 - val_output1_loss: 1.2194 - val_output2_accuracy: 0.5683 - val_output2_loss: 1.0934\n",
      "Epoch 127/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2866 - output1_accuracy: 0.5117 - output1_loss: 1.1832 - output2_accuracy: 0.5624 - output2_loss: 1.1033 - val_loss: 2.2989 - val_output1_accuracy: 0.5106 - val_output1_loss: 1.2027 - val_output2_accuracy: 0.5651 - val_output2_loss: 1.0962\n",
      "Epoch 128/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2737 - output1_accuracy: 0.5181 - output1_loss: 1.1808 - output2_accuracy: 0.5689 - output2_loss: 1.0929 - val_loss: 2.2950 - val_output1_accuracy: 0.5048 - val_output1_loss: 1.2069 - val_output2_accuracy: 0.5729 - val_output2_loss: 1.0881\n",
      "Epoch 129/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2794 - output1_accuracy: 0.5134 - output1_loss: 1.1805 - output2_accuracy: 0.5676 - output2_loss: 1.0989 - val_loss: 2.3099 - val_output1_accuracy: 0.4896 - val_output1_loss: 1.2237 - val_output2_accuracy: 0.5731 - val_output2_loss: 1.0862\n",
      "Epoch 130/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2762 - output1_accuracy: 0.5193 - output1_loss: 1.1796 - output2_accuracy: 0.5660 - output2_loss: 1.0966 - val_loss: 2.2905 - val_output1_accuracy: 0.5028 - val_output1_loss: 1.2008 - val_output2_accuracy: 0.5711 - val_output2_loss: 1.0897\n",
      "Epoch 131/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2752 - output1_accuracy: 0.5166 - output1_loss: 1.1723 - output2_accuracy: 0.5657 - output2_loss: 1.1029 - val_loss: 2.3135 - val_output1_accuracy: 0.4934 - val_output1_loss: 1.2183 - val_output2_accuracy: 0.5709 - val_output2_loss: 1.0952\n",
      "Epoch 132/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2826 - output1_accuracy: 0.5139 - output1_loss: 1.1871 - output2_accuracy: 0.5631 - output2_loss: 1.0955 - val_loss: 2.3307 - val_output1_accuracy: 0.4918 - val_output1_loss: 1.2239 - val_output2_accuracy: 0.5629 - val_output2_loss: 1.1069\n",
      "Epoch 133/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2812 - output1_accuracy: 0.5193 - output1_loss: 1.1735 - output2_accuracy: 0.5608 - output2_loss: 1.1076 - val_loss: 2.3445 - val_output1_accuracy: 0.5014 - val_output1_loss: 1.2319 - val_output2_accuracy: 0.5561 - val_output2_loss: 1.1126\n",
      "Epoch 134/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2651 - output1_accuracy: 0.5160 - output1_loss: 1.1790 - output2_accuracy: 0.5662 - output2_loss: 1.0861 - val_loss: 2.2795 - val_output1_accuracy: 0.5136 - val_output1_loss: 1.1893 - val_output2_accuracy: 0.5735 - val_output2_loss: 1.0902\n",
      "Epoch 135/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2652 - output1_accuracy: 0.5183 - output1_loss: 1.1730 - output2_accuracy: 0.5720 - output2_loss: 1.0923 - val_loss: 2.3278 - val_output1_accuracy: 0.5082 - val_output1_loss: 1.1995 - val_output2_accuracy: 0.5489 - val_output2_loss: 1.1283\n",
      "Epoch 136/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2607 - output1_accuracy: 0.5173 - output1_loss: 1.1754 - output2_accuracy: 0.5658 - output2_loss: 1.0853 - val_loss: 2.2843 - val_output1_accuracy: 0.5034 - val_output1_loss: 1.2007 - val_output2_accuracy: 0.5713 - val_output2_loss: 1.0836\n",
      "Epoch 137/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 2.2665 - output1_accuracy: 0.5187 - output1_loss: 1.1795 - output2_accuracy: 0.5664 - output2_loss: 1.0870 - val_loss: 2.3068 - val_output1_accuracy: 0.5026 - val_output1_loss: 1.1984 - val_output2_accuracy: 0.5625 - val_output2_loss: 1.1084\n",
      "Epoch 138/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2475 - output1_accuracy: 0.5238 - output1_loss: 1.1613 - output2_accuracy: 0.5698 - output2_loss: 1.0861 - val_loss: 2.2874 - val_output1_accuracy: 0.5120 - val_output1_loss: 1.1961 - val_output2_accuracy: 0.5627 - val_output2_loss: 1.0912\n",
      "Epoch 139/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2542 - output1_accuracy: 0.5195 - output1_loss: 1.1723 - output2_accuracy: 0.5744 - output2_loss: 1.0819 - val_loss: 2.2974 - val_output1_accuracy: 0.5126 - val_output1_loss: 1.1947 - val_output2_accuracy: 0.5549 - val_output2_loss: 1.1027\n",
      "Epoch 140/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2695 - output1_accuracy: 0.5133 - output1_loss: 1.1784 - output2_accuracy: 0.5674 - output2_loss: 1.0912 - val_loss: 2.3014 - val_output1_accuracy: 0.5066 - val_output1_loss: 1.2020 - val_output2_accuracy: 0.5601 - val_output2_loss: 1.0994\n",
      "Epoch 141/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2570 - output1_accuracy: 0.5221 - output1_loss: 1.1645 - output2_accuracy: 0.5715 - output2_loss: 1.0925 - val_loss: 2.3204 - val_output1_accuracy: 0.4878 - val_output1_loss: 1.2358 - val_output2_accuracy: 0.5723 - val_output2_loss: 1.0846\n",
      "Epoch 142/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2573 - output1_accuracy: 0.5205 - output1_loss: 1.1680 - output2_accuracy: 0.5673 - output2_loss: 1.0894 - val_loss: 2.3118 - val_output1_accuracy: 0.5038 - val_output1_loss: 1.2031 - val_output2_accuracy: 0.5611 - val_output2_loss: 1.1087\n",
      "Epoch 143/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.2589 - output1_accuracy: 0.5222 - output1_loss: 1.1725 - output2_accuracy: 0.5690 - output2_loss: 1.0864 - val_loss: 2.3365 - val_output1_accuracy: 0.4936 - val_output1_loss: 1.2348 - val_output2_accuracy: 0.5701 - val_output2_loss: 1.1017\n",
      "Epoch 144/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2607 - output1_accuracy: 0.5199 - output1_loss: 1.1754 - output2_accuracy: 0.5708 - output2_loss: 1.0853 - val_loss: 2.3017 - val_output1_accuracy: 0.5072 - val_output1_loss: 1.2045 - val_output2_accuracy: 0.5685 - val_output2_loss: 1.0972\n",
      "Epoch 144: early stopping\n",
      "Restoring model weights from the end of the best epoch: 134.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "model = ACCN4()\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.5425950020551682\n",
      "standard deviation =  0.0032745561629200746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCN():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    #inputs = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # Classifers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    #x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCN',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,374,730</span> (5.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,374,730\u001b[0m (5.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,372,234</span> (5.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,372,234\u001b[0m (5.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> (9.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,496\u001b[0m (9.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 2.9636 - output1_accuracy: 0.3880 - output1_loss: 1.5019 - output2_accuracy: 0.4188 - output2_loss: 1.4617 - val_loss: 2.7082 - val_output1_accuracy: 0.4233 - val_output1_loss: 1.4208 - val_output2_accuracy: 0.5280 - val_output2_loss: 1.2874\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.4176 - output1_accuracy: 0.5089 - output1_loss: 1.2855 - output2_accuracy: 0.6121 - output2_loss: 1.1321 - val_loss: 2.4614 - val_output1_accuracy: 0.4850 - val_output1_loss: 1.3249 - val_output2_accuracy: 0.6084 - val_output2_loss: 1.1365\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2226 - output1_accuracy: 0.5649 - output1_loss: 1.1966 - output2_accuracy: 0.6745 - output2_loss: 1.0260 - val_loss: 2.4530 - val_output1_accuracy: 0.4904 - val_output1_loss: 1.3271 - val_output2_accuracy: 0.6272 - val_output2_loss: 1.1259\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.1361 - output1_accuracy: 0.5889 - output1_loss: 1.1577 - output2_accuracy: 0.7009 - output2_loss: 0.9783 - val_loss: 2.3285 - val_output1_accuracy: 0.5355 - val_output1_loss: 1.2485 - val_output2_accuracy: 0.6484 - val_output2_loss: 1.0800\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.0515 - output1_accuracy: 0.6127 - output1_loss: 1.1186 - output2_accuracy: 0.7277 - output2_loss: 0.9329 - val_loss: 2.2242 - val_output1_accuracy: 0.5533 - val_output1_loss: 1.2255 - val_output2_accuracy: 0.6947 - val_output2_loss: 0.9987\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.9990 - output1_accuracy: 0.6329 - output1_loss: 1.0859 - output2_accuracy: 0.7375 - output2_loss: 0.9131 - val_loss: 2.5412 - val_output1_accuracy: 0.4553 - val_output1_loss: 1.4357 - val_output2_accuracy: 0.6332 - val_output2_loss: 1.1055\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 1.9556 - output1_accuracy: 0.6499 - output1_loss: 1.0575 - output2_accuracy: 0.7451 - output2_loss: 0.8981 - val_loss: 2.5744 - val_output1_accuracy: 0.4722 - val_output1_loss: 1.4701 - val_output2_accuracy: 0.6466 - val_output2_loss: 1.1043\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8957 - output1_accuracy: 0.6674 - output1_loss: 1.0271 - output2_accuracy: 0.7615 - output2_loss: 0.8686 - val_loss: 2.1488 - val_output1_accuracy: 0.5917 - val_output1_loss: 1.1753 - val_output2_accuracy: 0.7117 - val_output2_loss: 0.9736\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8684 - output1_accuracy: 0.6756 - output1_loss: 1.0113 - output2_accuracy: 0.7633 - output2_loss: 0.8571 - val_loss: 2.1623 - val_output1_accuracy: 0.5954 - val_output1_loss: 1.1622 - val_output2_accuracy: 0.6929 - val_output2_loss: 1.0001\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8332 - output1_accuracy: 0.6910 - output1_loss: 0.9961 - output2_accuracy: 0.7791 - output2_loss: 0.8371 - val_loss: 2.2495 - val_output1_accuracy: 0.5855 - val_output1_loss: 1.1951 - val_output2_accuracy: 0.6761 - val_output2_loss: 1.0544\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8077 - output1_accuracy: 0.6923 - output1_loss: 0.9841 - output2_accuracy: 0.7853 - output2_loss: 0.8236 - val_loss: 2.1929 - val_output1_accuracy: 0.6120 - val_output1_loss: 1.1396 - val_output2_accuracy: 0.6741 - val_output2_loss: 1.0532\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7828 - output1_accuracy: 0.7049 - output1_loss: 0.9706 - output2_accuracy: 0.7925 - output2_loss: 0.8121 - val_loss: 2.2187 - val_output1_accuracy: 0.6084 - val_output1_loss: 1.1648 - val_output2_accuracy: 0.6807 - val_output2_loss: 1.0539\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7504 - output1_accuracy: 0.7103 - output1_loss: 0.9517 - output2_accuracy: 0.8001 - output2_loss: 0.7986 - val_loss: 1.9874 - val_output1_accuracy: 0.6410 - val_output1_loss: 1.0853 - val_output2_accuracy: 0.7442 - val_output2_loss: 0.9021\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7327 - output1_accuracy: 0.7177 - output1_loss: 0.9364 - output2_accuracy: 0.7997 - output2_loss: 0.7963 - val_loss: 1.9480 - val_output1_accuracy: 0.6583 - val_output1_loss: 1.0597 - val_output2_accuracy: 0.7624 - val_output2_loss: 0.8884\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7129 - output1_accuracy: 0.7229 - output1_loss: 0.9299 - output2_accuracy: 0.8069 - output2_loss: 0.7830 - val_loss: 1.9725 - val_output1_accuracy: 0.6438 - val_output1_loss: 1.0671 - val_output2_accuracy: 0.7450 - val_output2_loss: 0.9054\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6962 - output1_accuracy: 0.7308 - output1_loss: 0.9210 - output2_accuracy: 0.8110 - output2_loss: 0.7752 - val_loss: 1.9930 - val_output1_accuracy: 0.6342 - val_output1_loss: 1.1006 - val_output2_accuracy: 0.7438 - val_output2_loss: 0.8924\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6659 - output1_accuracy: 0.7363 - output1_loss: 0.9087 - output2_accuracy: 0.8223 - output2_loss: 0.7572 - val_loss: 2.0321 - val_output1_accuracy: 0.6278 - val_output1_loss: 1.1044 - val_output2_accuracy: 0.7316 - val_output2_loss: 0.9277\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6580 - output1_accuracy: 0.7392 - output1_loss: 0.8991 - output2_accuracy: 0.8190 - output2_loss: 0.7589 - val_loss: 2.0387 - val_output1_accuracy: 0.6248 - val_output1_loss: 1.1235 - val_output2_accuracy: 0.7382 - val_output2_loss: 0.9152\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6408 - output1_accuracy: 0.7437 - output1_loss: 0.8926 - output2_accuracy: 0.8275 - output2_loss: 0.7482 - val_loss: 1.8864 - val_output1_accuracy: 0.6765 - val_output1_loss: 1.0185 - val_output2_accuracy: 0.7650 - val_output2_loss: 0.8680\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6375 - output1_accuracy: 0.7459 - output1_loss: 0.8888 - output2_accuracy: 0.8238 - output2_loss: 0.7488 - val_loss: 2.0912 - val_output1_accuracy: 0.6090 - val_output1_loss: 1.1846 - val_output2_accuracy: 0.7512 - val_output2_loss: 0.9066\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6200 - output1_accuracy: 0.7487 - output1_loss: 0.8810 - output2_accuracy: 0.8313 - output2_loss: 0.7389 - val_loss: 1.8965 - val_output1_accuracy: 0.6683 - val_output1_loss: 1.0268 - val_output2_accuracy: 0.7652 - val_output2_loss: 0.8698\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6104 - output1_accuracy: 0.7529 - output1_loss: 0.8783 - output2_accuracy: 0.8331 - output2_loss: 0.7321 - val_loss: 1.9333 - val_output1_accuracy: 0.6402 - val_output1_loss: 1.0705 - val_output2_accuracy: 0.7648 - val_output2_loss: 0.8628\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5944 - output1_accuracy: 0.7550 - output1_loss: 0.8698 - output2_accuracy: 0.8422 - output2_loss: 0.7246 - val_loss: 2.1918 - val_output1_accuracy: 0.6298 - val_output1_loss: 1.1408 - val_output2_accuracy: 0.6763 - val_output2_loss: 1.0510\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5850 - output1_accuracy: 0.7603 - output1_loss: 0.8640 - output2_accuracy: 0.8415 - output2_loss: 0.7210 - val_loss: 1.8926 - val_output1_accuracy: 0.6665 - val_output1_loss: 1.0470 - val_output2_accuracy: 0.7760 - val_output2_loss: 0.8456\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5761 - output1_accuracy: 0.7626 - output1_loss: 0.8570 - output2_accuracy: 0.8425 - output2_loss: 0.7192 - val_loss: 1.9094 - val_output1_accuracy: 0.6687 - val_output1_loss: 1.0457 - val_output2_accuracy: 0.7650 - val_output2_loss: 0.8637\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5591 - output1_accuracy: 0.7702 - output1_loss: 0.8464 - output2_accuracy: 0.8444 - output2_loss: 0.7127 - val_loss: 1.8772 - val_output1_accuracy: 0.6817 - val_output1_loss: 1.0142 - val_output2_accuracy: 0.7774 - val_output2_loss: 0.8631\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5562 - output1_accuracy: 0.7726 - output1_loss: 0.8435 - output2_accuracy: 0.8439 - output2_loss: 0.7127 - val_loss: 1.9836 - val_output1_accuracy: 0.6376 - val_output1_loss: 1.0937 - val_output2_accuracy: 0.7516 - val_output2_loss: 0.8899\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5490 - output1_accuracy: 0.7696 - output1_loss: 0.8466 - output2_accuracy: 0.8501 - output2_loss: 0.7024 - val_loss: 1.8803 - val_output1_accuracy: 0.6745 - val_output1_loss: 1.0351 - val_output2_accuracy: 0.7754 - val_output2_loss: 0.8452\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5361 - output1_accuracy: 0.7825 - output1_loss: 0.8294 - output2_accuracy: 0.8503 - output2_loss: 0.7066 - val_loss: 1.8943 - val_output1_accuracy: 0.6695 - val_output1_loss: 1.0461 - val_output2_accuracy: 0.7786 - val_output2_loss: 0.8482\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5192 - output1_accuracy: 0.7811 - output1_loss: 0.8266 - output2_accuracy: 0.8568 - output2_loss: 0.6926 - val_loss: 1.8655 - val_output1_accuracy: 0.6869 - val_output1_loss: 1.0224 - val_output2_accuracy: 0.7831 - val_output2_loss: 0.8431\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.5126 - output1_accuracy: 0.7832 - output1_loss: 0.8214 - output2_accuracy: 0.8562 - output2_loss: 0.6912 - val_loss: 1.8872 - val_output1_accuracy: 0.6753 - val_output1_loss: 1.0328 - val_output2_accuracy: 0.7744 - val_output2_loss: 0.8544\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5089 - output1_accuracy: 0.7847 - output1_loss: 0.8201 - output2_accuracy: 0.8576 - output2_loss: 0.6888 - val_loss: 1.9439 - val_output1_accuracy: 0.6573 - val_output1_loss: 1.0655 - val_output2_accuracy: 0.7604 - val_output2_loss: 0.8784\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.5039 - output1_accuracy: 0.7893 - output1_loss: 0.8163 - output2_accuracy: 0.8574 - output2_loss: 0.6876 - val_loss: 1.8503 - val_output1_accuracy: 0.6839 - val_output1_loss: 1.0279 - val_output2_accuracy: 0.7867 - val_output2_loss: 0.8224\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4947 - output1_accuracy: 0.7914 - output1_loss: 0.8107 - output2_accuracy: 0.8585 - output2_loss: 0.6841 - val_loss: 2.6457 - val_output1_accuracy: 0.5240 - val_output1_loss: 1.5188 - val_output2_accuracy: 0.6560 - val_output2_loss: 1.1269\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4842 - output1_accuracy: 0.7940 - output1_loss: 0.8041 - output2_accuracy: 0.8623 - output2_loss: 0.6802 - val_loss: 1.9125 - val_output1_accuracy: 0.6857 - val_output1_loss: 1.0167 - val_output2_accuracy: 0.7506 - val_output2_loss: 0.8958\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4696 - output1_accuracy: 0.7988 - output1_loss: 0.7898 - output2_accuracy: 0.8625 - output2_loss: 0.6798 - val_loss: 1.9091 - val_output1_accuracy: 0.6621 - val_output1_loss: 1.0600 - val_output2_accuracy: 0.7786 - val_output2_loss: 0.8490\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4746 - output1_accuracy: 0.8020 - output1_loss: 0.7923 - output2_accuracy: 0.8612 - output2_loss: 0.6823 - val_loss: 1.9428 - val_output1_accuracy: 0.6562 - val_output1_loss: 1.0762 - val_output2_accuracy: 0.7694 - val_output2_loss: 0.8666\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4570 - output1_accuracy: 0.8024 - output1_loss: 0.7896 - output2_accuracy: 0.8691 - output2_loss: 0.6674 - val_loss: 1.8284 - val_output1_accuracy: 0.6835 - val_output1_loss: 1.0079 - val_output2_accuracy: 0.7951 - val_output2_loss: 0.8205\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4573 - output1_accuracy: 0.8022 - output1_loss: 0.7866 - output2_accuracy: 0.8673 - output2_loss: 0.6708 - val_loss: 2.1252 - val_output1_accuracy: 0.6032 - val_output1_loss: 1.2089 - val_output2_accuracy: 0.7480 - val_output2_loss: 0.9163\n",
      "Epoch 40/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4612 - output1_accuracy: 0.8019 - output1_loss: 0.7903 - output2_accuracy: 0.8670 - output2_loss: 0.6710 - val_loss: 1.8753 - val_output1_accuracy: 0.6717 - val_output1_loss: 1.0306 - val_output2_accuracy: 0.7847 - val_output2_loss: 0.8446\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4424 - output1_accuracy: 0.8079 - output1_loss: 0.7809 - output2_accuracy: 0.8709 - output2_loss: 0.6615 - val_loss: 1.8667 - val_output1_accuracy: 0.6883 - val_output1_loss: 1.0034 - val_output2_accuracy: 0.7694 - val_output2_loss: 0.8634\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4447 - output1_accuracy: 0.8070 - output1_loss: 0.7786 - output2_accuracy: 0.8715 - output2_loss: 0.6661 - val_loss: 1.9017 - val_output1_accuracy: 0.6711 - val_output1_loss: 1.0436 - val_output2_accuracy: 0.7768 - val_output2_loss: 0.8581\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4329 - output1_accuracy: 0.8073 - output1_loss: 0.7786 - output2_accuracy: 0.8751 - output2_loss: 0.6543 - val_loss: 2.0538 - val_output1_accuracy: 0.6230 - val_output1_loss: 1.1600 - val_output2_accuracy: 0.7482 - val_output2_loss: 0.8937\n",
      "Epoch 44/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4373 - output1_accuracy: 0.8085 - output1_loss: 0.7766 - output2_accuracy: 0.8728 - output2_loss: 0.6607 - val_loss: 1.8353 - val_output1_accuracy: 0.6965 - val_output1_loss: 1.0018 - val_output2_accuracy: 0.7849 - val_output2_loss: 0.8335\n",
      "Epoch 45/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4324 - output1_accuracy: 0.8113 - output1_loss: 0.7774 - output2_accuracy: 0.8740 - output2_loss: 0.6550 - val_loss: 1.8718 - val_output1_accuracy: 0.6899 - val_output1_loss: 1.0113 - val_output2_accuracy: 0.7780 - val_output2_loss: 0.8605\n",
      "Epoch 46/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4119 - output1_accuracy: 0.8198 - output1_loss: 0.7575 - output2_accuracy: 0.8762 - output2_loss: 0.6544 - val_loss: 1.9552 - val_output1_accuracy: 0.6705 - val_output1_loss: 1.0731 - val_output2_accuracy: 0.7650 - val_output2_loss: 0.8822\n",
      "Epoch 47/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4159 - output1_accuracy: 0.8159 - output1_loss: 0.7622 - output2_accuracy: 0.8760 - output2_loss: 0.6537 - val_loss: 2.0706 - val_output1_accuracy: 0.6122 - val_output1_loss: 1.1894 - val_output2_accuracy: 0.7610 - val_output2_loss: 0.8812\n",
      "Epoch 48/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4071 - output1_accuracy: 0.8188 - output1_loss: 0.7591 - output2_accuracy: 0.8805 - output2_loss: 0.6481 - val_loss: 1.8576 - val_output1_accuracy: 0.6721 - val_output1_loss: 1.0291 - val_output2_accuracy: 0.7881 - val_output2_loss: 0.8285\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "model = ACCN()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2025-01-11 10:50:04.735908: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7378099918365478\n",
      "standard deviation =  0.002947435931252253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('73.7acc.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.4546 - output1_accuracy: 0.8030 - output1_loss: 0.7910 - output2_accuracy: 0.8693 - output2_loss: 0.6636 - val_loss: 1.7747 - val_output1_accuracy: 0.7071 - val_output1_loss: 0.9820 - val_output2_accuracy: 0.8059 - val_output2_loss: 0.7927\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4325 - output1_accuracy: 0.8118 - output1_loss: 0.7723 - output2_accuracy: 0.8720 - output2_loss: 0.6602 - val_loss: 1.7696 - val_output1_accuracy: 0.7031 - val_output1_loss: 0.9653 - val_output2_accuracy: 0.8047 - val_output2_loss: 0.8043\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4255 - output1_accuracy: 0.8118 - output1_loss: 0.7753 - output2_accuracy: 0.8774 - output2_loss: 0.6502 - val_loss: 1.7639 - val_output1_accuracy: 0.7073 - val_output1_loss: 0.9700 - val_output2_accuracy: 0.8021 - val_output2_loss: 0.7939\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4214 - output1_accuracy: 0.8145 - output1_loss: 0.7715 - output2_accuracy: 0.8801 - output2_loss: 0.6500 - val_loss: 1.7274 - val_output1_accuracy: 0.7129 - val_output1_loss: 0.9549 - val_output2_accuracy: 0.8111 - val_output2_loss: 0.7725\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4104 - output1_accuracy: 0.8164 - output1_loss: 0.7654 - output2_accuracy: 0.8820 - output2_loss: 0.6450 - val_loss: 1.7456 - val_output1_accuracy: 0.7151 - val_output1_loss: 0.9607 - val_output2_accuracy: 0.8053 - val_output2_loss: 0.7849\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4159 - output1_accuracy: 0.8146 - output1_loss: 0.7668 - output2_accuracy: 0.8787 - output2_loss: 0.6492 - val_loss: 1.7759 - val_output1_accuracy: 0.7157 - val_output1_loss: 0.9710 - val_output2_accuracy: 0.8029 - val_output2_loss: 0.8049\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4087 - output1_accuracy: 0.8175 - output1_loss: 0.7636 - output2_accuracy: 0.8800 - output2_loss: 0.6451 - val_loss: 1.7519 - val_output1_accuracy: 0.7139 - val_output1_loss: 0.9579 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.7940\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4080 - output1_accuracy: 0.8174 - output1_loss: 0.7630 - output2_accuracy: 0.8793 - output2_loss: 0.6450 - val_loss: 1.7502 - val_output1_accuracy: 0.7171 - val_output1_loss: 0.9641 - val_output2_accuracy: 0.8069 - val_output2_loss: 0.7861\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4044 - output1_accuracy: 0.8199 - output1_loss: 0.7589 - output2_accuracy: 0.8805 - output2_loss: 0.6454 - val_loss: 1.7153 - val_output1_accuracy: 0.7256 - val_output1_loss: 0.9327 - val_output2_accuracy: 0.8059 - val_output2_loss: 0.7827\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4087 - output1_accuracy: 0.8182 - output1_loss: 0.7588 - output2_accuracy: 0.8766 - output2_loss: 0.6500 - val_loss: 1.7507 - val_output1_accuracy: 0.7151 - val_output1_loss: 0.9563 - val_output2_accuracy: 0.8005 - val_output2_loss: 0.7945\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3962 - output1_accuracy: 0.8195 - output1_loss: 0.7587 - output2_accuracy: 0.8854 - output2_loss: 0.6375 - val_loss: 1.7411 - val_output1_accuracy: 0.7173 - val_output1_loss: 0.9588 - val_output2_accuracy: 0.8123 - val_output2_loss: 0.7823\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4035 - output1_accuracy: 0.8160 - output1_loss: 0.7637 - output2_accuracy: 0.8840 - output2_loss: 0.6398 - val_loss: 1.7266 - val_output1_accuracy: 0.7163 - val_output1_loss: 0.9498 - val_output2_accuracy: 0.8105 - val_output2_loss: 0.7769\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4013 - output1_accuracy: 0.8163 - output1_loss: 0.7619 - output2_accuracy: 0.8851 - output2_loss: 0.6395 - val_loss: 1.7454 - val_output1_accuracy: 0.7157 - val_output1_loss: 0.9609 - val_output2_accuracy: 0.8097 - val_output2_loss: 0.7846\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4056 - output1_accuracy: 0.8185 - output1_loss: 0.7594 - output2_accuracy: 0.8823 - output2_loss: 0.6462 - val_loss: 1.7722 - val_output1_accuracy: 0.7121 - val_output1_loss: 0.9692 - val_output2_accuracy: 0.7989 - val_output2_loss: 0.8030\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.3950 - output1_accuracy: 0.8227 - output1_loss: 0.7560 - output2_accuracy: 0.8820 - output2_loss: 0.6390 - val_loss: 1.7249 - val_output1_accuracy: 0.7157 - val_output1_loss: 0.9531 - val_output2_accuracy: 0.8191 - val_output2_loss: 0.7718\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.3867 - output1_accuracy: 0.8229 - output1_loss: 0.7498 - output2_accuracy: 0.8857 - output2_loss: 0.6369 - val_loss: 1.7364 - val_output1_accuracy: 0.7165 - val_output1_loss: 0.9490 - val_output2_accuracy: 0.8065 - val_output2_loss: 0.7874\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4006 - output1_accuracy: 0.8179 - output1_loss: 0.7618 - output2_accuracy: 0.8845 - output2_loss: 0.6388 - val_loss: 1.7528 - val_output1_accuracy: 0.7137 - val_output1_loss: 0.9611 - val_output2_accuracy: 0.8109 - val_output2_loss: 0.7916\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3875 - output1_accuracy: 0.8242 - output1_loss: 0.7508 - output2_accuracy: 0.8874 - output2_loss: 0.6367 - val_loss: 1.7409 - val_output1_accuracy: 0.7220 - val_output1_loss: 0.9424 - val_output2_accuracy: 0.8035 - val_output2_loss: 0.7985\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3949 - output1_accuracy: 0.8215 - output1_loss: 0.7570 - output2_accuracy: 0.8851 - output2_loss: 0.6379 - val_loss: 1.7623 - val_output1_accuracy: 0.7021 - val_output1_loss: 0.9819 - val_output2_accuracy: 0.8083 - val_output2_loss: 0.7804\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Custom small learning rate\n",
    "learning_rate = 1e-5  # You can adjust this value as needed for fine-tuning\n",
    "\n",
    "# Compile model with RMSprop optimizer and label smoothing for the loss\n",
    "model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                    'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7620449990034104\n",
      "standard deviation =  0.0027785288122172164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('76.2acc.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 1.3996 - output1_accuracy: 0.8182 - output1_loss: 0.7606 - output2_accuracy: 0.8823 - output2_loss: 0.6390 - val_loss: 1.7521 - val_output1_accuracy: 0.7173 - val_output1_loss: 0.9571 - val_output2_accuracy: 0.8025 - val_output2_loss: 0.7950\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4034 - output1_accuracy: 0.8239 - output1_loss: 0.7555 - output2_accuracy: 0.8791 - output2_loss: 0.6480 - val_loss: 1.7386 - val_output1_accuracy: 0.7137 - val_output1_loss: 0.9600 - val_output2_accuracy: 0.8135 - val_output2_loss: 0.7786\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4068 - output1_accuracy: 0.8209 - output1_loss: 0.7576 - output2_accuracy: 0.8804 - output2_loss: 0.6492 - val_loss: 1.7251 - val_output1_accuracy: 0.7145 - val_output1_loss: 0.9411 - val_output2_accuracy: 0.8103 - val_output2_loss: 0.7840\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.3956 - output1_accuracy: 0.8207 - output1_loss: 0.7572 - output2_accuracy: 0.8835 - output2_loss: 0.6384 - val_loss: 1.7400 - val_output1_accuracy: 0.7131 - val_output1_loss: 0.9621 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.7779\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.4011 - output1_accuracy: 0.8165 - output1_loss: 0.7628 - output2_accuracy: 0.8858 - output2_loss: 0.6383 - val_loss: 1.7300 - val_output1_accuracy: 0.7143 - val_output1_loss: 0.9643 - val_output2_accuracy: 0.8209 - val_output2_loss: 0.7657\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4059 - output1_accuracy: 0.8193 - output1_loss: 0.7617 - output2_accuracy: 0.8811 - output2_loss: 0.6442 - val_loss: 1.6861 - val_output1_accuracy: 0.7298 - val_output1_loss: 0.9179 - val_output2_accuracy: 0.8187 - val_output2_loss: 0.7682\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.3998 - output1_accuracy: 0.8199 - output1_loss: 0.7587 - output2_accuracy: 0.8839 - output2_loss: 0.6411 - val_loss: 1.7184 - val_output1_accuracy: 0.7157 - val_output1_loss: 0.9403 - val_output2_accuracy: 0.8073 - val_output2_loss: 0.7781\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4018 - output1_accuracy: 0.8191 - output1_loss: 0.7587 - output2_accuracy: 0.8829 - output2_loss: 0.6431 - val_loss: 1.7179 - val_output1_accuracy: 0.7216 - val_output1_loss: 0.9380 - val_output2_accuracy: 0.8059 - val_output2_loss: 0.7799\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.3988 - output1_accuracy: 0.8197 - output1_loss: 0.7613 - output2_accuracy: 0.8842 - output2_loss: 0.6375 - val_loss: 1.7344 - val_output1_accuracy: 0.7232 - val_output1_loss: 0.9404 - val_output2_accuracy: 0.8035 - val_output2_loss: 0.7940\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.3975 - output1_accuracy: 0.8236 - output1_loss: 0.7547 - output2_accuracy: 0.8789 - output2_loss: 0.6428 - val_loss: 1.7372 - val_output1_accuracy: 0.7198 - val_output1_loss: 0.9496 - val_output2_accuracy: 0.8039 - val_output2_loss: 0.7876\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.3923 - output1_accuracy: 0.8216 - output1_loss: 0.7540 - output2_accuracy: 0.8852 - output2_loss: 0.6384 - val_loss: 1.7504 - val_output1_accuracy: 0.7133 - val_output1_loss: 0.9644 - val_output2_accuracy: 0.8097 - val_output2_loss: 0.7861\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3974 - output1_accuracy: 0.8262 - output1_loss: 0.7497 - output2_accuracy: 0.8786 - output2_loss: 0.6477 - val_loss: 1.7291 - val_output1_accuracy: 0.7179 - val_output1_loss: 0.9484 - val_output2_accuracy: 0.8067 - val_output2_loss: 0.7807\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4012 - output1_accuracy: 0.8194 - output1_loss: 0.7566 - output2_accuracy: 0.8793 - output2_loss: 0.6446 - val_loss: 1.7262 - val_output1_accuracy: 0.7173 - val_output1_loss: 0.9481 - val_output2_accuracy: 0.8107 - val_output2_loss: 0.7780\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.3949 - output1_accuracy: 0.8186 - output1_loss: 0.7585 - output2_accuracy: 0.8856 - output2_loss: 0.6363 - val_loss: 1.7574 - val_output1_accuracy: 0.7039 - val_output1_loss: 0.9676 - val_output2_accuracy: 0.8055 - val_output2_loss: 0.7898\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4022 - output1_accuracy: 0.8180 - output1_loss: 0.7615 - output2_accuracy: 0.8842 - output2_loss: 0.6406 - val_loss: 1.7579 - val_output1_accuracy: 0.7045 - val_output1_loss: 0.9668 - val_output2_accuracy: 0.8059 - val_output2_loss: 0.7911\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3934 - output1_accuracy: 0.8236 - output1_loss: 0.7517 - output2_accuracy: 0.8837 - output2_loss: 0.6416 - val_loss: 1.7400 - val_output1_accuracy: 0.7173 - val_output1_loss: 0.9585 - val_output2_accuracy: 0.8121 - val_output2_loss: 0.7815\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    }
   ],
   "source": [
    "# Custom small learning rate\n",
    "learning_rate = 1e-7 # You can adjust this value as needed for fine-tuning\n",
    "\n",
    "# Compile model with RMSprop optimizer and label smoothing for the loss\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                    'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7644650042057037\n",
      "standard deviation =  0.0022757387857020393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('76.4acc.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCNR():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    inputs = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # Classifers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    #x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1')(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2')(x)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCNR',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCNR\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCNR\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_1CLONE │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ keras_tensor_1CL… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_1CLONE │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ keras_tensor_1CL… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ conv2d_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_4[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_5[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_6[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_7[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,374,730</span> (5.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,374,730\u001b[0m (5.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,372,234</span> (5.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,372,234\u001b[0m (5.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> (9.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,496\u001b[0m (9.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 2.9606 - output1_accuracy: 0.3894 - output1_loss: 1.5017 - output2_accuracy: 0.4277 - output2_loss: 1.4589 - val_loss: 2.7054 - val_output1_accuracy: 0.4345 - val_output1_loss: 1.4062 - val_output2_accuracy: 0.5254 - val_output2_loss: 1.2992\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4157 - output1_accuracy: 0.5137 - output1_loss: 1.2839 - output2_accuracy: 0.6157 - output2_loss: 1.1319 - val_loss: 2.5296 - val_output1_accuracy: 0.4830 - val_output1_loss: 1.3551 - val_output2_accuracy: 0.5811 - val_output2_loss: 1.1745\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2331 - output1_accuracy: 0.5686 - output1_loss: 1.1978 - output2_accuracy: 0.6686 - output2_loss: 1.0353 - val_loss: 2.5885 - val_output1_accuracy: 0.4587 - val_output1_loss: 1.3796 - val_output2_accuracy: 0.5663 - val_output2_loss: 1.2089\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.1317 - output1_accuracy: 0.5943 - output1_loss: 1.1534 - output2_accuracy: 0.7001 - output2_loss: 0.9784 - val_loss: 2.4049 - val_output1_accuracy: 0.5236 - val_output1_loss: 1.2441 - val_output2_accuracy: 0.6032 - val_output2_loss: 1.1608\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0442 - output1_accuracy: 0.6248 - output1_loss: 1.1053 - output2_accuracy: 0.7260 - output2_loss: 0.9389 - val_loss: 2.6052 - val_output1_accuracy: 0.5152 - val_output1_loss: 1.2868 - val_output2_accuracy: 0.5383 - val_output2_loss: 1.3184\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9739 - output1_accuracy: 0.6469 - output1_loss: 1.0672 - output2_accuracy: 0.7422 - output2_loss: 0.9067 - val_loss: 2.3275 - val_output1_accuracy: 0.5559 - val_output1_loss: 1.2240 - val_output2_accuracy: 0.6406 - val_output2_loss: 1.1035\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9307 - output1_accuracy: 0.6569 - output1_loss: 1.0425 - output2_accuracy: 0.7529 - output2_loss: 0.8883 - val_loss: 2.3464 - val_output1_accuracy: 0.5795 - val_output1_loss: 1.1851 - val_output2_accuracy: 0.6208 - val_output2_loss: 1.1613\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8876 - output1_accuracy: 0.6705 - output1_loss: 1.0227 - output2_accuracy: 0.7653 - output2_loss: 0.8649 - val_loss: 2.0353 - val_output1_accuracy: 0.6336 - val_output1_loss: 1.0957 - val_output2_accuracy: 0.7244 - val_output2_loss: 0.9396\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.8551 - output1_accuracy: 0.6800 - output1_loss: 1.0042 - output2_accuracy: 0.7731 - output2_loss: 0.8509 - val_loss: 2.1391 - val_output1_accuracy: 0.6034 - val_output1_loss: 1.1391 - val_output2_accuracy: 0.6901 - val_output2_loss: 1.0000\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8258 - output1_accuracy: 0.6883 - output1_loss: 0.9893 - output2_accuracy: 0.7790 - output2_loss: 0.8365 - val_loss: 2.2334 - val_output1_accuracy: 0.5887 - val_output1_loss: 1.1686 - val_output2_accuracy: 0.6693 - val_output2_loss: 1.0648\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7915 - output1_accuracy: 0.7014 - output1_loss: 0.9717 - output2_accuracy: 0.7896 - output2_loss: 0.8198 - val_loss: 2.1643 - val_output1_accuracy: 0.5978 - val_output1_loss: 1.1815 - val_output2_accuracy: 0.7033 - val_output2_loss: 0.9829\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7626 - output1_accuracy: 0.7105 - output1_loss: 0.9565 - output2_accuracy: 0.7950 - output2_loss: 0.8061 - val_loss: 2.1237 - val_output1_accuracy: 0.5960 - val_output1_loss: 1.1774 - val_output2_accuracy: 0.7266 - val_output2_loss: 0.9463\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7563 - output1_accuracy: 0.7066 - output1_loss: 0.9572 - output2_accuracy: 0.8000 - output2_loss: 0.7991 - val_loss: 2.0261 - val_output1_accuracy: 0.6114 - val_output1_loss: 1.1538 - val_output2_accuracy: 0.7582 - val_output2_loss: 0.8724\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7223 - output1_accuracy: 0.7181 - output1_loss: 0.9350 - output2_accuracy: 0.8062 - output2_loss: 0.7873 - val_loss: 1.8990 - val_output1_accuracy: 0.6643 - val_output1_loss: 1.0340 - val_output2_accuracy: 0.7660 - val_output2_loss: 0.8650\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7140 - output1_accuracy: 0.7227 - output1_loss: 0.9350 - output2_accuracy: 0.8077 - output2_loss: 0.7790 - val_loss: 2.0130 - val_output1_accuracy: 0.6591 - val_output1_loss: 1.0667 - val_output2_accuracy: 0.7220 - val_output2_loss: 0.9463\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6848 - output1_accuracy: 0.7302 - output1_loss: 0.9161 - output2_accuracy: 0.8167 - output2_loss: 0.7686 - val_loss: 1.9256 - val_output1_accuracy: 0.6629 - val_output1_loss: 1.0607 - val_output2_accuracy: 0.7654 - val_output2_loss: 0.8649\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6662 - output1_accuracy: 0.7342 - output1_loss: 0.9102 - output2_accuracy: 0.8199 - output2_loss: 0.7560 - val_loss: 2.2728 - val_output1_accuracy: 0.5889 - val_output1_loss: 1.1885 - val_output2_accuracy: 0.6667 - val_output2_loss: 1.0843\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6652 - output1_accuracy: 0.7412 - output1_loss: 0.8953 - output2_accuracy: 0.8157 - output2_loss: 0.7699 - val_loss: 2.0281 - val_output1_accuracy: 0.6454 - val_output1_loss: 1.0838 - val_output2_accuracy: 0.7296 - val_output2_loss: 0.9443\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6407 - output1_accuracy: 0.7413 - output1_loss: 0.8916 - output2_accuracy: 0.8246 - output2_loss: 0.7490 - val_loss: 1.9212 - val_output1_accuracy: 0.6775 - val_output1_loss: 1.0163 - val_output2_accuracy: 0.7504 - val_output2_loss: 0.9049\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6235 - output1_accuracy: 0.7488 - output1_loss: 0.8837 - output2_accuracy: 0.8289 - output2_loss: 0.7398 - val_loss: 1.9571 - val_output1_accuracy: 0.6472 - val_output1_loss: 1.0726 - val_output2_accuracy: 0.7602 - val_output2_loss: 0.8845\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6222 - output1_accuracy: 0.7538 - output1_loss: 0.8767 - output2_accuracy: 0.8264 - output2_loss: 0.7455 - val_loss: 1.8834 - val_output1_accuracy: 0.6765 - val_output1_loss: 1.0174 - val_output2_accuracy: 0.7618 - val_output2_loss: 0.8661\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5999 - output1_accuracy: 0.7602 - output1_loss: 0.8642 - output2_accuracy: 0.8322 - output2_loss: 0.7357 - val_loss: 1.9321 - val_output1_accuracy: 0.6583 - val_output1_loss: 1.0625 - val_output2_accuracy: 0.7612 - val_output2_loss: 0.8695\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5840 - output1_accuracy: 0.7651 - output1_loss: 0.8563 - output2_accuracy: 0.8377 - output2_loss: 0.7277 - val_loss: 1.9844 - val_output1_accuracy: 0.6494 - val_output1_loss: 1.0869 - val_output2_accuracy: 0.7522 - val_output2_loss: 0.8975\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5748 - output1_accuracy: 0.7655 - output1_loss: 0.8536 - output2_accuracy: 0.8398 - output2_loss: 0.7212 - val_loss: 1.8701 - val_output1_accuracy: 0.6765 - val_output1_loss: 1.0270 - val_output2_accuracy: 0.7804 - val_output2_loss: 0.8431\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5575 - output1_accuracy: 0.7686 - output1_loss: 0.8480 - output2_accuracy: 0.8436 - output2_loss: 0.7095 - val_loss: 1.9714 - val_output1_accuracy: 0.6454 - val_output1_loss: 1.1007 - val_output2_accuracy: 0.7640 - val_output2_loss: 0.8707\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5536 - output1_accuracy: 0.7702 - output1_loss: 0.8436 - output2_accuracy: 0.8445 - output2_loss: 0.7101 - val_loss: 1.8304 - val_output1_accuracy: 0.6951 - val_output1_loss: 1.0012 - val_output2_accuracy: 0.7877 - val_output2_loss: 0.8291\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5460 - output1_accuracy: 0.7733 - output1_loss: 0.8418 - output2_accuracy: 0.8490 - output2_loss: 0.7042 - val_loss: 1.8346 - val_output1_accuracy: 0.6909 - val_output1_loss: 0.9996 - val_output2_accuracy: 0.7812 - val_output2_loss: 0.8350\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5383 - output1_accuracy: 0.7785 - output1_loss: 0.8329 - output2_accuracy: 0.8494 - output2_loss: 0.7053 - val_loss: 1.8942 - val_output1_accuracy: 0.6841 - val_output1_loss: 1.0161 - val_output2_accuracy: 0.7612 - val_output2_loss: 0.8782\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5278 - output1_accuracy: 0.7810 - output1_loss: 0.8282 - output2_accuracy: 0.8518 - output2_loss: 0.6996 - val_loss: 1.9061 - val_output1_accuracy: 0.6787 - val_output1_loss: 1.0178 - val_output2_accuracy: 0.7554 - val_output2_loss: 0.8883\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5242 - output1_accuracy: 0.7801 - output1_loss: 0.8285 - output2_accuracy: 0.8555 - output2_loss: 0.6957 - val_loss: 1.8625 - val_output1_accuracy: 0.6835 - val_output1_loss: 1.0195 - val_output2_accuracy: 0.7861 - val_output2_loss: 0.8430\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5084 - output1_accuracy: 0.7844 - output1_loss: 0.8246 - output2_accuracy: 0.8599 - output2_loss: 0.6838 - val_loss: 1.8779 - val_output1_accuracy: 0.6813 - val_output1_loss: 1.0257 - val_output2_accuracy: 0.7758 - val_output2_loss: 0.8523\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5011 - output1_accuracy: 0.7881 - output1_loss: 0.8165 - output2_accuracy: 0.8578 - output2_loss: 0.6846 - val_loss: 1.8355 - val_output1_accuracy: 0.6913 - val_output1_loss: 1.0030 - val_output2_accuracy: 0.7883 - val_output2_loss: 0.8325\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5015 - output1_accuracy: 0.7904 - output1_loss: 0.8135 - output2_accuracy: 0.8588 - output2_loss: 0.6880 - val_loss: 1.7992 - val_output1_accuracy: 0.7009 - val_output1_loss: 0.9761 - val_output2_accuracy: 0.7893 - val_output2_loss: 0.8231\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4988 - output1_accuracy: 0.7933 - output1_loss: 0.8072 - output2_accuracy: 0.8545 - output2_loss: 0.6916 - val_loss: 1.8399 - val_output1_accuracy: 0.6885 - val_output1_loss: 1.0037 - val_output2_accuracy: 0.7879 - val_output2_loss: 0.8362\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4813 - output1_accuracy: 0.7964 - output1_loss: 0.8011 - output2_accuracy: 0.8606 - output2_loss: 0.6802 - val_loss: 1.8831 - val_output1_accuracy: 0.6801 - val_output1_loss: 1.0252 - val_output2_accuracy: 0.7712 - val_output2_loss: 0.8579\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4715 - output1_accuracy: 0.8014 - output1_loss: 0.7946 - output2_accuracy: 0.8648 - output2_loss: 0.6769 - val_loss: 2.0034 - val_output1_accuracy: 0.6440 - val_output1_loss: 1.1178 - val_output2_accuracy: 0.7528 - val_output2_loss: 0.8856\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4687 - output1_accuracy: 0.7968 - output1_loss: 0.7964 - output2_accuracy: 0.8671 - output2_loss: 0.6723 - val_loss: 1.8400 - val_output1_accuracy: 0.6965 - val_output1_loss: 1.0057 - val_output2_accuracy: 0.7861 - val_output2_loss: 0.8342\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4624 - output1_accuracy: 0.7981 - output1_loss: 0.7912 - output2_accuracy: 0.8673 - output2_loss: 0.6711 - val_loss: 1.8941 - val_output1_accuracy: 0.6801 - val_output1_loss: 1.0345 - val_output2_accuracy: 0.7670 - val_output2_loss: 0.8596\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4498 - output1_accuracy: 0.8042 - output1_loss: 0.7880 - output2_accuracy: 0.8709 - output2_loss: 0.6618 - val_loss: 1.9188 - val_output1_accuracy: 0.6653 - val_output1_loss: 1.0746 - val_output2_accuracy: 0.7855 - val_output2_loss: 0.8442\n",
      "Epoch 40/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4442 - output1_accuracy: 0.8091 - output1_loss: 0.7820 - output2_accuracy: 0.8721 - output2_loss: 0.6622 - val_loss: 2.0377 - val_output1_accuracy: 0.6242 - val_output1_loss: 1.1479 - val_output2_accuracy: 0.7574 - val_output2_loss: 0.8898\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4486 - output1_accuracy: 0.8079 - output1_loss: 0.7847 - output2_accuracy: 0.8701 - output2_loss: 0.6639 - val_loss: 1.8228 - val_output1_accuracy: 0.6963 - val_output1_loss: 0.9931 - val_output2_accuracy: 0.7861 - val_output2_loss: 0.8296\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4355 - output1_accuracy: 0.8084 - output1_loss: 0.7749 - output2_accuracy: 0.8730 - output2_loss: 0.6606 - val_loss: 1.8666 - val_output1_accuracy: 0.6819 - val_output1_loss: 1.0184 - val_output2_accuracy: 0.7855 - val_output2_loss: 0.8482\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4266 - output1_accuracy: 0.8159 - output1_loss: 0.7698 - output2_accuracy: 0.8743 - output2_loss: 0.6569 - val_loss: 1.8515 - val_output1_accuracy: 0.6899 - val_output1_loss: 1.0109 - val_output2_accuracy: 0.7825 - val_output2_loss: 0.8405\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "model = ACCNR()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.744294998049736\n",
      "standard deviation =  0.002647495965331791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 1.4750 - output1_accuracy: 0.7917 - output1_loss: 0.8013 - output2_accuracy: 0.8653 - output2_loss: 0.6737 - val_loss: 1.7586 - val_output1_accuracy: 0.7079 - val_output1_loss: 0.9746 - val_output2_accuracy: 0.8063 - val_output2_loss: 0.7840\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4559 - output1_accuracy: 0.8002 - output1_loss: 0.7922 - output2_accuracy: 0.8706 - output2_loss: 0.6637 - val_loss: 1.7576 - val_output1_accuracy: 0.7115 - val_output1_loss: 0.9623 - val_output2_accuracy: 0.7977 - val_output2_loss: 0.7953\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4420 - output1_accuracy: 0.8081 - output1_loss: 0.7799 - output2_accuracy: 0.8706 - output2_loss: 0.6621 - val_loss: 1.7502 - val_output1_accuracy: 0.7115 - val_output1_loss: 0.9603 - val_output2_accuracy: 0.8015 - val_output2_loss: 0.7899\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4448 - output1_accuracy: 0.8057 - output1_loss: 0.7843 - output2_accuracy: 0.8711 - output2_loss: 0.6605 - val_loss: 1.7488 - val_output1_accuracy: 0.7031 - val_output1_loss: 0.9761 - val_output2_accuracy: 0.8143 - val_output2_loss: 0.7727\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4315 - output1_accuracy: 0.8095 - output1_loss: 0.7720 - output2_accuracy: 0.8720 - output2_loss: 0.6595 - val_loss: 1.7134 - val_output1_accuracy: 0.7190 - val_output1_loss: 0.9405 - val_output2_accuracy: 0.8131 - val_output2_loss: 0.7730\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4405 - output1_accuracy: 0.8053 - output1_loss: 0.7840 - output2_accuracy: 0.8766 - output2_loss: 0.6565 - val_loss: 1.7322 - val_output1_accuracy: 0.7149 - val_output1_loss: 0.9545 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.7777\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4301 - output1_accuracy: 0.8138 - output1_loss: 0.7739 - output2_accuracy: 0.8769 - output2_loss: 0.6562 - val_loss: 1.7330 - val_output1_accuracy: 0.7161 - val_output1_loss: 0.9497 - val_output2_accuracy: 0.7977 - val_output2_loss: 0.7834\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4368 - output1_accuracy: 0.8077 - output1_loss: 0.7802 - output2_accuracy: 0.8744 - output2_loss: 0.6566 - val_loss: 1.7398 - val_output1_accuracy: 0.7167 - val_output1_loss: 0.9539 - val_output2_accuracy: 0.8091 - val_output2_loss: 0.7859\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4297 - output1_accuracy: 0.8111 - output1_loss: 0.7730 - output2_accuracy: 0.8722 - output2_loss: 0.6567 - val_loss: 1.7548 - val_output1_accuracy: 0.7143 - val_output1_loss: 0.9575 - val_output2_accuracy: 0.8037 - val_output2_loss: 0.7973\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4257 - output1_accuracy: 0.8156 - output1_loss: 0.7695 - output2_accuracy: 0.8736 - output2_loss: 0.6562 - val_loss: 1.7309 - val_output1_accuracy: 0.7147 - val_output1_loss: 0.9626 - val_output2_accuracy: 0.8207 - val_output2_loss: 0.7682\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4194 - output1_accuracy: 0.8122 - output1_loss: 0.7719 - output2_accuracy: 0.8788 - output2_loss: 0.6475 - val_loss: 1.7228 - val_output1_accuracy: 0.7185 - val_output1_loss: 0.9466 - val_output2_accuracy: 0.8165 - val_output2_loss: 0.7762\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4223 - output1_accuracy: 0.8181 - output1_loss: 0.7671 - output2_accuracy: 0.8762 - output2_loss: 0.6551 - val_loss: 1.7224 - val_output1_accuracy: 0.7204 - val_output1_loss: 0.9435 - val_output2_accuracy: 0.8117 - val_output2_loss: 0.7790\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4172 - output1_accuracy: 0.8129 - output1_loss: 0.7688 - output2_accuracy: 0.8787 - output2_loss: 0.6485 - val_loss: 1.7302 - val_output1_accuracy: 0.7185 - val_output1_loss: 0.9494 - val_output2_accuracy: 0.8137 - val_output2_loss: 0.7807\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4147 - output1_accuracy: 0.8169 - output1_loss: 0.7675 - output2_accuracy: 0.8803 - output2_loss: 0.6472 - val_loss: 1.7499 - val_output1_accuracy: 0.7145 - val_output1_loss: 0.9537 - val_output2_accuracy: 0.8051 - val_output2_loss: 0.7962\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4086 - output1_accuracy: 0.8128 - output1_loss: 0.7668 - output2_accuracy: 0.8832 - output2_loss: 0.6418 - val_loss: 1.7190 - val_output1_accuracy: 0.7117 - val_output1_loss: 0.9499 - val_output2_accuracy: 0.8163 - val_output2_loss: 0.7692\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    }
   ],
   "source": [
    "# Custom small learning rate\n",
    "learning_rate = 1e-5  # You can adjust this value as needed for fine-tuning\n",
    "\n",
    "# Compile model with RMSprop optimizer and label smoothing for the loss\n",
    "model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                    'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7637950003147125\n",
      "standard deviation =  0.0028752839783437894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - loss: 1.4774 - output1_accuracy: 0.7957 - output1_loss: 0.8000 - output2_accuracy: 0.8639 - output2_loss: 0.6774 - val_loss: 1.8565 - val_output1_accuracy: 0.6875 - val_output1_loss: 1.0168 - val_output2_accuracy: 0.7821 - val_output2_loss: 0.8397\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4984 - output1_accuracy: 0.7888 - output1_loss: 0.8117 - output2_accuracy: 0.8598 - output2_loss: 0.6867 - val_loss: 1.8383 - val_output1_accuracy: 0.6945 - val_output1_loss: 0.9821 - val_output2_accuracy: 0.7688 - val_output2_loss: 0.8562\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4799 - output1_accuracy: 0.7961 - output1_loss: 0.7988 - output2_accuracy: 0.8608 - output2_loss: 0.6811 - val_loss: 1.8162 - val_output1_accuracy: 0.6975 - val_output1_loss: 0.9789 - val_output2_accuracy: 0.7867 - val_output2_loss: 0.8373\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4774 - output1_accuracy: 0.7986 - output1_loss: 0.7974 - output2_accuracy: 0.8615 - output2_loss: 0.6800 - val_loss: 1.9060 - val_output1_accuracy: 0.6733 - val_output1_loss: 1.0288 - val_output2_accuracy: 0.7564 - val_output2_loss: 0.8772\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4732 - output1_accuracy: 0.7946 - output1_loss: 0.8003 - output2_accuracy: 0.8661 - output2_loss: 0.6730 - val_loss: 1.8642 - val_output1_accuracy: 0.6747 - val_output1_loss: 1.0314 - val_output2_accuracy: 0.7895 - val_output2_loss: 0.8329\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4571 - output1_accuracy: 0.8014 - output1_loss: 0.7920 - output2_accuracy: 0.8717 - output2_loss: 0.6652 - val_loss: 1.8431 - val_output1_accuracy: 0.6973 - val_output1_loss: 0.9870 - val_output2_accuracy: 0.7734 - val_output2_loss: 0.8560\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4682 - output1_accuracy: 0.8026 - output1_loss: 0.7917 - output2_accuracy: 0.8614 - output2_loss: 0.6765 - val_loss: 1.8638 - val_output1_accuracy: 0.6909 - val_output1_loss: 1.0100 - val_output2_accuracy: 0.7750 - val_output2_loss: 0.8537\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4527 - output1_accuracy: 0.8054 - output1_loss: 0.7865 - output2_accuracy: 0.8675 - output2_loss: 0.6662 - val_loss: 1.8566 - val_output1_accuracy: 0.6861 - val_output1_loss: 1.0041 - val_output2_accuracy: 0.7730 - val_output2_loss: 0.8525\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4554 - output1_accuracy: 0.8041 - output1_loss: 0.7865 - output2_accuracy: 0.8690 - output2_loss: 0.6689 - val_loss: 1.8876 - val_output1_accuracy: 0.6711 - val_output1_loss: 1.0433 - val_output2_accuracy: 0.7764 - val_output2_loss: 0.8442\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4463 - output1_accuracy: 0.8043 - output1_loss: 0.7828 - output2_accuracy: 0.8732 - output2_loss: 0.6635 - val_loss: 1.9082 - val_output1_accuracy: 0.6919 - val_output1_loss: 1.0234 - val_output2_accuracy: 0.7588 - val_output2_loss: 0.8848\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4278 - output1_accuracy: 0.8130 - output1_loss: 0.7733 - output2_accuracy: 0.8754 - output2_loss: 0.6545 - val_loss: 1.8718 - val_output1_accuracy: 0.6927 - val_output1_loss: 1.0223 - val_output2_accuracy: 0.7839 - val_output2_loss: 0.8495\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4323 - output1_accuracy: 0.8083 - output1_loss: 0.7756 - output2_accuracy: 0.8735 - output2_loss: 0.6568 - val_loss: 1.9422 - val_output1_accuracy: 0.6410 - val_output1_loss: 1.1227 - val_output2_accuracy: 0.7911 - val_output2_loss: 0.8195\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4272 - output1_accuracy: 0.8108 - output1_loss: 0.7737 - output2_accuracy: 0.8762 - output2_loss: 0.6535 - val_loss: 1.8815 - val_output1_accuracy: 0.6741 - val_output1_loss: 1.0337 - val_output2_accuracy: 0.7780 - val_output2_loss: 0.8478\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n"
     ]
    }
   ],
   "source": [
    "# Custom small learning rate\n",
    "learning_rate = 1e-5  # You can adjust this value as needed for fine-tuning\n",
    "\n",
    "# Compile model with RMSprop optimizer and label smoothing for the loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                    'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7420600026845932\n",
      "standard deviation =  0.003503768097391289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def ACCNRR():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    inputs = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    #inputs = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(inputs)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # Classifers\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    #x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCNRR',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCNRR\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCNRR\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_1CLONE │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ keras_tensor_1CL… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_1CLONE │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ keras_tensor_1CL… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ conv2d_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_4[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_5[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_6[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_7[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,374,730</span> (5.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,374,730\u001b[0m (5.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,372,234</span> (5.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,372,234\u001b[0m (5.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> (9.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,496\u001b[0m (9.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 3.0777 - output1_accuracy: 0.3984 - output1_loss: 1.4852 - output2_accuracy: 0.4272 - output2_loss: 1.4491 - val_loss: 3.0848 - val_output1_accuracy: 0.3924 - val_output1_loss: 1.5310 - val_output2_accuracy: 0.4299 - val_output2_loss: 1.4849\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.4576 - output1_accuracy: 0.5138 - output1_loss: 1.2717 - output2_accuracy: 0.6133 - output2_loss: 1.1300 - val_loss: 3.0116 - val_output1_accuracy: 0.4107 - val_output1_loss: 1.5836 - val_output2_accuracy: 0.5054 - val_output2_loss: 1.3981\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2501 - output1_accuracy: 0.5688 - output1_loss: 1.1965 - output2_accuracy: 0.6711 - output2_loss: 1.0279 - val_loss: 2.4327 - val_output1_accuracy: 0.4992 - val_output1_loss: 1.3186 - val_output2_accuracy: 0.6378 - val_output2_loss: 1.0951\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1262 - output1_accuracy: 0.5966 - output1_loss: 1.1411 - output2_accuracy: 0.7068 - output2_loss: 0.9668 - val_loss: 2.2156 - val_output1_accuracy: 0.5705 - val_output1_loss: 1.1885 - val_output2_accuracy: 0.6863 - val_output2_loss: 1.0105\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0574 - output1_accuracy: 0.6212 - output1_loss: 1.1042 - output2_accuracy: 0.7215 - output2_loss: 0.9367 - val_loss: 2.3460 - val_output1_accuracy: 0.5851 - val_output1_loss: 1.1829 - val_output2_accuracy: 0.6026 - val_output2_loss: 1.1473\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.9934 - output1_accuracy: 0.6440 - output1_loss: 1.0663 - output2_accuracy: 0.7340 - output2_loss: 0.9113 - val_loss: 2.4831 - val_output1_accuracy: 0.5166 - val_output1_loss: 1.3084 - val_output2_accuracy: 0.6122 - val_output2_loss: 1.1592\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9407 - output1_accuracy: 0.6590 - output1_loss: 1.0418 - output2_accuracy: 0.7525 - output2_loss: 0.8833 - val_loss: 2.5024 - val_output1_accuracy: 0.5925 - val_output1_loss: 1.1722 - val_output2_accuracy: 0.5675 - val_output2_loss: 1.3144\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.9022 - output1_accuracy: 0.6766 - output1_loss: 1.0164 - output2_accuracy: 0.7615 - output2_loss: 0.8702 - val_loss: 2.1135 - val_output1_accuracy: 0.6022 - val_output1_loss: 1.1451 - val_output2_accuracy: 0.7167 - val_output2_loss: 0.9525\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8700 - output1_accuracy: 0.6821 - output1_loss: 1.0035 - output2_accuracy: 0.7702 - output2_loss: 0.8509 - val_loss: 2.1810 - val_output1_accuracy: 0.5839 - val_output1_loss: 1.1938 - val_output2_accuracy: 0.7005 - val_output2_loss: 0.9719\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8335 - output1_accuracy: 0.6881 - output1_loss: 0.9856 - output2_accuracy: 0.7803 - output2_loss: 0.8325 - val_loss: 2.0706 - val_output1_accuracy: 0.5950 - val_output1_loss: 1.1454 - val_output2_accuracy: 0.7342 - val_output2_loss: 0.9103\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8072 - output1_accuracy: 0.6999 - output1_loss: 0.9737 - output2_accuracy: 0.7893 - output2_loss: 0.8183 - val_loss: 2.1485 - val_output1_accuracy: 0.6070 - val_output1_loss: 1.1494 - val_output2_accuracy: 0.7029 - val_output2_loss: 0.9838\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7831 - output1_accuracy: 0.7051 - output1_loss: 0.9609 - output2_accuracy: 0.7928 - output2_loss: 0.8070 - val_loss: 1.9753 - val_output1_accuracy: 0.6619 - val_output1_loss: 1.0559 - val_output2_accuracy: 0.7422 - val_output2_loss: 0.9041\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7520 - output1_accuracy: 0.7181 - output1_loss: 0.9428 - output2_accuracy: 0.7996 - output2_loss: 0.7941 - val_loss: 1.9873 - val_output1_accuracy: 0.6450 - val_output1_loss: 1.0729 - val_output2_accuracy: 0.7504 - val_output2_loss: 0.8996\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7424 - output1_accuracy: 0.7161 - output1_loss: 0.9387 - output2_accuracy: 0.8036 - output2_loss: 0.7890 - val_loss: 2.2770 - val_output1_accuracy: 0.5895 - val_output1_loss: 1.1746 - val_output2_accuracy: 0.6550 - val_output2_loss: 1.0876\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7338 - output1_accuracy: 0.7180 - output1_loss: 0.9346 - output2_accuracy: 0.8058 - output2_loss: 0.7848 - val_loss: 1.9465 - val_output1_accuracy: 0.6434 - val_output1_loss: 1.0709 - val_output2_accuracy: 0.7688 - val_output2_loss: 0.8611\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.6919 - output1_accuracy: 0.7310 - output1_loss: 0.9125 - output2_accuracy: 0.8148 - output2_loss: 0.7648 - val_loss: 2.0033 - val_output1_accuracy: 0.6322 - val_output1_loss: 1.1141 - val_output2_accuracy: 0.7546 - val_output2_loss: 0.8746\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6886 - output1_accuracy: 0.7368 - output1_loss: 0.9063 - output2_accuracy: 0.8145 - output2_loss: 0.7680 - val_loss: 1.9995 - val_output1_accuracy: 0.6418 - val_output1_loss: 1.0762 - val_output2_accuracy: 0.7430 - val_output2_loss: 0.9088\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6619 - output1_accuracy: 0.7420 - output1_loss: 0.8948 - output2_accuracy: 0.8230 - output2_loss: 0.7527 - val_loss: 1.8962 - val_output1_accuracy: 0.6757 - val_output1_loss: 1.0155 - val_output2_accuracy: 0.7640 - val_output2_loss: 0.8665\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6415 - output1_accuracy: 0.7514 - output1_loss: 0.8828 - output2_accuracy: 0.8290 - output2_loss: 0.7444 - val_loss: 2.2765 - val_output1_accuracy: 0.5547 - val_output1_loss: 1.3390 - val_output2_accuracy: 0.7374 - val_output2_loss: 0.9234\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6512 - output1_accuracy: 0.7493 - output1_loss: 0.8850 - output2_accuracy: 0.8215 - output2_loss: 0.7523 - val_loss: 1.9765 - val_output1_accuracy: 0.6508 - val_output1_loss: 1.0771 - val_output2_accuracy: 0.7596 - val_output2_loss: 0.8851\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6409 - output1_accuracy: 0.7493 - output1_loss: 0.8818 - output2_accuracy: 0.8261 - output2_loss: 0.7453 - val_loss: 2.2134 - val_output1_accuracy: 0.5733 - val_output1_loss: 1.2417 - val_output2_accuracy: 0.7192 - val_output2_loss: 0.9582\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6149 - output1_accuracy: 0.7576 - output1_loss: 0.8710 - output2_accuracy: 0.8321 - output2_loss: 0.7302 - val_loss: 1.9493 - val_output1_accuracy: 0.6679 - val_output1_loss: 1.0325 - val_output2_accuracy: 0.7484 - val_output2_loss: 0.9030\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6046 - output1_accuracy: 0.7607 - output1_loss: 0.8635 - output2_accuracy: 0.8374 - output2_loss: 0.7274 - val_loss: 1.9448 - val_output1_accuracy: 0.6663 - val_output1_loss: 1.0408 - val_output2_accuracy: 0.7544 - val_output2_loss: 0.8905\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5999 - output1_accuracy: 0.7622 - output1_loss: 0.8570 - output2_accuracy: 0.8369 - output2_loss: 0.7293 - val_loss: 1.8930 - val_output1_accuracy: 0.6711 - val_output1_loss: 1.0287 - val_output2_accuracy: 0.7734 - val_output2_loss: 0.8507\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5805 - output1_accuracy: 0.7690 - output1_loss: 0.8502 - output2_accuracy: 0.8418 - output2_loss: 0.7167 - val_loss: 1.9332 - val_output1_accuracy: 0.6558 - val_output1_loss: 1.0602 - val_output2_accuracy: 0.7682 - val_output2_loss: 0.8595\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5701 - output1_accuracy: 0.7716 - output1_loss: 0.8418 - output2_accuracy: 0.8413 - output2_loss: 0.7149 - val_loss: 1.9641 - val_output1_accuracy: 0.6571 - val_output1_loss: 1.0661 - val_output2_accuracy: 0.7538 - val_output2_loss: 0.8846\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5675 - output1_accuracy: 0.7768 - output1_loss: 0.8424 - output2_accuracy: 0.8437 - output2_loss: 0.7117 - val_loss: 1.8509 - val_output1_accuracy: 0.6847 - val_output1_loss: 1.0022 - val_output2_accuracy: 0.7837 - val_output2_loss: 0.8357\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5503 - output1_accuracy: 0.7748 - output1_loss: 0.8348 - output2_accuracy: 0.8504 - output2_loss: 0.7023 - val_loss: 2.3535 - val_output1_accuracy: 0.5497 - val_output1_loss: 1.3250 - val_output2_accuracy: 0.6991 - val_output2_loss: 1.0155\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5471 - output1_accuracy: 0.7734 - output1_loss: 0.8369 - output2_accuracy: 0.8526 - output2_loss: 0.6969 - val_loss: 1.9248 - val_output1_accuracy: 0.6685 - val_output1_loss: 1.0420 - val_output2_accuracy: 0.7640 - val_output2_loss: 0.8696\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5459 - output1_accuracy: 0.7818 - output1_loss: 0.8287 - output2_accuracy: 0.8508 - output2_loss: 0.7042 - val_loss: 1.9742 - val_output1_accuracy: 0.6661 - val_output1_loss: 1.0596 - val_output2_accuracy: 0.7478 - val_output2_loss: 0.9011\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5287 - output1_accuracy: 0.7851 - output1_loss: 0.8224 - output2_accuracy: 0.8546 - output2_loss: 0.6932 - val_loss: 1.8835 - val_output1_accuracy: 0.6853 - val_output1_loss: 1.0167 - val_output2_accuracy: 0.7740 - val_output2_loss: 0.8539\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5165 - output1_accuracy: 0.7876 - output1_loss: 0.8167 - output2_accuracy: 0.8595 - output2_loss: 0.6868 - val_loss: 1.9055 - val_output1_accuracy: 0.6769 - val_output1_loss: 1.0243 - val_output2_accuracy: 0.7692 - val_output2_loss: 0.8684\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5157 - output1_accuracy: 0.7838 - output1_loss: 0.8207 - output2_accuracy: 0.8622 - output2_loss: 0.6821 - val_loss: 1.8433 - val_output1_accuracy: 0.6997 - val_output1_loss: 0.9950 - val_output2_accuracy: 0.7808 - val_output2_loss: 0.8353\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5093 - output1_accuracy: 0.7918 - output1_loss: 0.8066 - output2_accuracy: 0.8581 - output2_loss: 0.6898 - val_loss: 1.9374 - val_output1_accuracy: 0.6667 - val_output1_loss: 1.0408 - val_output2_accuracy: 0.7578 - val_output2_loss: 0.8839\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4917 - output1_accuracy: 0.8030 - output1_loss: 0.7920 - output2_accuracy: 0.8589 - output2_loss: 0.6868 - val_loss: 1.9517 - val_output1_accuracy: 0.6436 - val_output1_loss: 1.0852 - val_output2_accuracy: 0.7742 - val_output2_loss: 0.8536\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4980 - output1_accuracy: 0.7935 - output1_loss: 0.8013 - output2_accuracy: 0.8587 - output2_loss: 0.6840 - val_loss: 1.8468 - val_output1_accuracy: 0.6951 - val_output1_loss: 1.0001 - val_output2_accuracy: 0.7845 - val_output2_loss: 0.8338\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4914 - output1_accuracy: 0.7964 - output1_loss: 0.7993 - output2_accuracy: 0.8610 - output2_loss: 0.6794 - val_loss: 1.8749 - val_output1_accuracy: 0.6793 - val_output1_loss: 1.0266 - val_output2_accuracy: 0.7825 - val_output2_loss: 0.8357\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4902 - output1_accuracy: 0.7989 - output1_loss: 0.7961 - output2_accuracy: 0.8623 - output2_loss: 0.6816 - val_loss: 1.9567 - val_output1_accuracy: 0.6609 - val_output1_loss: 1.0719 - val_output2_accuracy: 0.7592 - val_output2_loss: 0.8727\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4700 - output1_accuracy: 0.8050 - output1_loss: 0.7842 - output2_accuracy: 0.8651 - output2_loss: 0.6734 - val_loss: 1.8418 - val_output1_accuracy: 0.6939 - val_output1_loss: 1.0006 - val_output2_accuracy: 0.7855 - val_output2_loss: 0.8287\n",
      "Epoch 40/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4581 - output1_accuracy: 0.8060 - output1_loss: 0.7801 - output2_accuracy: 0.8686 - output2_loss: 0.6654 - val_loss: 1.9582 - val_output1_accuracy: 0.6577 - val_output1_loss: 1.0748 - val_output2_accuracy: 0.7648 - val_output2_loss: 0.8708\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4659 - output1_accuracy: 0.8086 - output1_loss: 0.7822 - output2_accuracy: 0.8677 - output2_loss: 0.6712 - val_loss: 1.9267 - val_output1_accuracy: 0.6703 - val_output1_loss: 1.0549 - val_output2_accuracy: 0.7720 - val_output2_loss: 0.8592\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4589 - output1_accuracy: 0.8067 - output1_loss: 0.7787 - output2_accuracy: 0.8684 - output2_loss: 0.6676 - val_loss: 1.8885 - val_output1_accuracy: 0.6837 - val_output1_loss: 1.0247 - val_output2_accuracy: 0.7738 - val_output2_loss: 0.8511\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4479 - output1_accuracy: 0.8120 - output1_loss: 0.7723 - output2_accuracy: 0.8708 - output2_loss: 0.6631 - val_loss: 1.8737 - val_output1_accuracy: 0.6851 - val_output1_loss: 1.0149 - val_output2_accuracy: 0.7746 - val_output2_loss: 0.8464\n",
      "Epoch 44/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4565 - output1_accuracy: 0.8078 - output1_loss: 0.7754 - output2_accuracy: 0.8688 - output2_loss: 0.6689 - val_loss: 1.8799 - val_output1_accuracy: 0.6811 - val_output1_loss: 1.0321 - val_output2_accuracy: 0.7845 - val_output2_loss: 0.8353\n",
      "Epoch 45/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4454 - output1_accuracy: 0.8112 - output1_loss: 0.7726 - output2_accuracy: 0.8745 - output2_loss: 0.6604 - val_loss: 1.8656 - val_output1_accuracy: 0.6833 - val_output1_loss: 1.0100 - val_output2_accuracy: 0.7808 - val_output2_loss: 0.8432\n",
      "Epoch 46/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4441 - output1_accuracy: 0.8105 - output1_loss: 0.7746 - output2_accuracy: 0.8756 - output2_loss: 0.6572 - val_loss: 1.8545 - val_output1_accuracy: 0.6843 - val_output1_loss: 1.0152 - val_output2_accuracy: 0.7897 - val_output2_loss: 0.8271\n",
      "Epoch 47/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.4202 - output1_accuracy: 0.8207 - output1_loss: 0.7606 - output2_accuracy: 0.8797 - output2_loss: 0.6472 - val_loss: 1.8365 - val_output1_accuracy: 0.6925 - val_output1_loss: 1.0000 - val_output2_accuracy: 0.7907 - val_output2_loss: 0.8245\n",
      "Epoch 48/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4233 - output1_accuracy: 0.8177 - output1_loss: 0.7612 - output2_accuracy: 0.8769 - output2_loss: 0.6499 - val_loss: 1.9116 - val_output1_accuracy: 0.6713 - val_output1_loss: 1.0383 - val_output2_accuracy: 0.7744 - val_output2_loss: 0.8611\n",
      "Epoch 49/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4281 - output1_accuracy: 0.8176 - output1_loss: 0.7587 - output2_accuracy: 0.8774 - output2_loss: 0.6574 - val_loss: 1.8439 - val_output1_accuracy: 0.6847 - val_output1_loss: 1.0215 - val_output2_accuracy: 0.7937 - val_output2_loss: 0.8106\n",
      "Epoch 50/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4250 - output1_accuracy: 0.8174 - output1_loss: 0.7625 - output2_accuracy: 0.8790 - output2_loss: 0.6506 - val_loss: 1.8628 - val_output1_accuracy: 0.6857 - val_output1_loss: 1.0142 - val_output2_accuracy: 0.7847 - val_output2_loss: 0.8365\n",
      "Epoch 51/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4143 - output1_accuracy: 0.8223 - output1_loss: 0.7537 - output2_accuracy: 0.8785 - output2_loss: 0.6485 - val_loss: 1.8800 - val_output1_accuracy: 0.6829 - val_output1_loss: 1.0229 - val_output2_accuracy: 0.7833 - val_output2_loss: 0.8452\n",
      "Epoch 52/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4190 - output1_accuracy: 0.8207 - output1_loss: 0.7569 - output2_accuracy: 0.8777 - output2_loss: 0.6501 - val_loss: 1.8639 - val_output1_accuracy: 0.6939 - val_output1_loss: 0.9938 - val_output2_accuracy: 0.7788 - val_output2_loss: 0.8580\n",
      "Epoch 53/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.4091 - output1_accuracy: 0.8251 - output1_loss: 0.7496 - output2_accuracy: 0.8796 - output2_loss: 0.6476 - val_loss: 1.8859 - val_output1_accuracy: 0.6753 - val_output1_loss: 1.0352 - val_output2_accuracy: 0.7766 - val_output2_loss: 0.8388\n",
      "Epoch 54/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.3965 - output1_accuracy: 0.8302 - output1_loss: 0.7374 - output2_accuracy: 0.8801 - output2_loss: 0.6473 - val_loss: 1.9775 - val_output1_accuracy: 0.6649 - val_output1_loss: 1.0854 - val_output2_accuracy: 0.7700 - val_output2_loss: 0.8801\n",
      "Epoch 55/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4055 - output1_accuracy: 0.8202 - output1_loss: 0.7544 - output2_accuracy: 0.8808 - output2_loss: 0.6394 - val_loss: 1.9403 - val_output1_accuracy: 0.6681 - val_output1_loss: 1.0710 - val_output2_accuracy: 0.7738 - val_output2_loss: 0.8573\n",
      "Epoch 56/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4009 - output1_accuracy: 0.8270 - output1_loss: 0.7478 - output2_accuracy: 0.8832 - output2_loss: 0.6415 - val_loss: 1.8971 - val_output1_accuracy: 0.6857 - val_output1_loss: 1.0291 - val_output2_accuracy: 0.7768 - val_output2_loss: 0.8560\n",
      "Epoch 57/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3871 - output1_accuracy: 0.8295 - output1_loss: 0.7423 - output2_accuracy: 0.8875 - output2_loss: 0.6329 - val_loss: 1.9033 - val_output1_accuracy: 0.6783 - val_output1_loss: 1.0511 - val_output2_accuracy: 0.7877 - val_output2_loss: 0.8407\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "model = ACCNRR()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.000001)\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7449000000953674\n",
      "standard deviation =  0.0023437179247066614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.3606 - output1_accuracy: 0.8392 - output1_loss: 0.7224 - output2_accuracy: 0.8925 - output2_loss: 0.6264 - val_loss: 1.9467 - val_output1_accuracy: 0.6605 - val_output1_loss: 1.0716 - val_output2_accuracy: 0.7730 - val_output2_loss: 0.8633 - learning_rate: 0.0010\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3802 - output1_accuracy: 0.8349 - output1_loss: 0.7332 - output2_accuracy: 0.8858 - output2_loss: 0.6354 - val_loss: 1.9080 - val_output1_accuracy: 0.6813 - val_output1_loss: 1.0449 - val_output2_accuracy: 0.7778 - val_output2_loss: 0.8519 - learning_rate: 0.0010\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3739 - output1_accuracy: 0.8349 - output1_loss: 0.7284 - output2_accuracy: 0.8866 - output2_loss: 0.6341 - val_loss: 1.9518 - val_output1_accuracy: 0.6593 - val_output1_loss: 1.0942 - val_output2_accuracy: 0.7804 - val_output2_loss: 0.8460 - learning_rate: 0.0010\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3691 - output1_accuracy: 0.8328 - output1_loss: 0.7350 - output2_accuracy: 0.8939 - output2_loss: 0.6226 - val_loss: 1.9034 - val_output1_accuracy: 0.6829 - val_output1_loss: 1.0337 - val_output2_accuracy: 0.7796 - val_output2_loss: 0.8582 - learning_rate: 0.0010\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3655 - output1_accuracy: 0.8369 - output1_loss: 0.7263 - output2_accuracy: 0.8918 - output2_loss: 0.6276 - val_loss: 1.8845 - val_output1_accuracy: 0.6877 - val_output1_loss: 1.0197 - val_output2_accuracy: 0.7758 - val_output2_loss: 0.8533 - learning_rate: 0.0010\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3605 - output1_accuracy: 0.8396 - output1_loss: 0.7229 - output2_accuracy: 0.8928 - output2_loss: 0.6261 - val_loss: 1.9246 - val_output1_accuracy: 0.6575 - val_output1_loss: 1.0830 - val_output2_accuracy: 0.7863 - val_output2_loss: 0.8303 - learning_rate: 0.0010\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3678 - output1_accuracy: 0.8362 - output1_loss: 0.7262 - output2_accuracy: 0.8884 - output2_loss: 0.6303 - val_loss: 1.8618 - val_output1_accuracy: 0.7019 - val_output1_loss: 1.0029 - val_output2_accuracy: 0.7863 - val_output2_loss: 0.8473 - learning_rate: 0.0010\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3617 - output1_accuracy: 0.8349 - output1_loss: 0.7277 - output2_accuracy: 0.8938 - output2_loss: 0.6226 - val_loss: 1.9011 - val_output1_accuracy: 0.6919 - val_output1_loss: 1.0232 - val_output2_accuracy: 0.7726 - val_output2_loss: 0.8663 - learning_rate: 0.0010\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3555 - output1_accuracy: 0.8388 - output1_loss: 0.7216 - output2_accuracy: 0.8954 - output2_loss: 0.6226 - val_loss: 1.8385 - val_output1_accuracy: 0.7045 - val_output1_loss: 0.9864 - val_output2_accuracy: 0.7808 - val_output2_loss: 0.8412 - learning_rate: 0.0010\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3527 - output1_accuracy: 0.8433 - output1_loss: 0.7120 - output2_accuracy: 0.8888 - output2_loss: 0.6294 - val_loss: 1.8004 - val_output1_accuracy: 0.7133 - val_output1_loss: 0.9705 - val_output2_accuracy: 0.7869 - val_output2_loss: 0.8187 - learning_rate: 0.0010\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.3483 - output1_accuracy: 0.8406 - output1_loss: 0.7184 - output2_accuracy: 0.8955 - output2_loss: 0.6186 - val_loss: 1.8121 - val_output1_accuracy: 0.7071 - val_output1_loss: 0.9824 - val_output2_accuracy: 0.7955 - val_output2_loss: 0.8184 - learning_rate: 0.0010\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.3561 - output1_accuracy: 0.8388 - output1_loss: 0.7221 - output2_accuracy: 0.8936 - output2_loss: 0.6227 - val_loss: 1.9650 - val_output1_accuracy: 0.6735 - val_output1_loss: 1.0586 - val_output2_accuracy: 0.7544 - val_output2_loss: 0.8951 - learning_rate: 0.0010\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.3556 - output1_accuracy: 0.8416 - output1_loss: 0.7199 - output2_accuracy: 0.8934 - output2_loss: 0.6244 - val_loss: 1.9423 - val_output1_accuracy: 0.6759 - val_output1_loss: 1.0775 - val_output2_accuracy: 0.7714 - val_output2_loss: 0.8536 - learning_rate: 0.0010\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.3420 - output1_accuracy: 0.8466 - output1_loss: 0.7105 - output2_accuracy: 0.8937 - output2_loss: 0.6203 - val_loss: 1.8707 - val_output1_accuracy: 0.6927 - val_output1_loss: 1.0154 - val_output2_accuracy: 0.7825 - val_output2_loss: 0.8440 - learning_rate: 0.0010\n",
      "Epoch 15/250\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3470 - output1_accuracy: 0.8416 - output1_loss: 0.7181 - output2_accuracy: 0.8930 - output2_loss: 0.6177\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.3469 - output1_accuracy: 0.8416 - output1_loss: 0.7181 - output2_accuracy: 0.8930 - output2_loss: 0.6177 - val_loss: 1.9238 - val_output1_accuracy: 0.6985 - val_output1_loss: 1.0072 - val_output2_accuracy: 0.7576 - val_output2_loss: 0.9055 - learning_rate: 0.0010\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.3131 - output1_accuracy: 0.8543 - output1_loss: 0.6952 - output2_accuracy: 0.9013 - output2_loss: 0.6069 - val_loss: 1.7406 - val_output1_accuracy: 0.7234 - val_output1_loss: 0.9528 - val_output2_accuracy: 0.8133 - val_output2_loss: 0.7770 - learning_rate: 2.0000e-04\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.2910 - output1_accuracy: 0.8594 - output1_loss: 0.6865 - output2_accuracy: 0.9090 - output2_loss: 0.5937 - val_loss: 1.7611 - val_output1_accuracy: 0.7097 - val_output1_loss: 0.9724 - val_output2_accuracy: 0.8143 - val_output2_loss: 0.7779 - learning_rate: 2.0000e-04\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2813 - output1_accuracy: 0.8634 - output1_loss: 0.6793 - output2_accuracy: 0.9097 - output2_loss: 0.5911 - val_loss: 1.7310 - val_output1_accuracy: 0.7296 - val_output1_loss: 0.9427 - val_output2_accuracy: 0.8149 - val_output2_loss: 0.7774 - learning_rate: 2.0000e-04\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2733 - output1_accuracy: 0.8637 - output1_loss: 0.6733 - output2_accuracy: 0.9111 - output2_loss: 0.5891 - val_loss: 1.7457 - val_output1_accuracy: 0.7224 - val_output1_loss: 0.9595 - val_output2_accuracy: 0.8155 - val_output2_loss: 0.7753 - learning_rate: 2.0000e-04\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2668 - output1_accuracy: 0.8695 - output1_loss: 0.6716 - output2_accuracy: 0.9146 - output2_loss: 0.5843 - val_loss: 1.7178 - val_output1_accuracy: 0.7276 - val_output1_loss: 0.9486 - val_output2_accuracy: 0.8215 - val_output2_loss: 0.7584 - learning_rate: 2.0000e-04\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2664 - output1_accuracy: 0.8661 - output1_loss: 0.6712 - output2_accuracy: 0.9155 - output2_loss: 0.5842 - val_loss: 1.7526 - val_output1_accuracy: 0.7133 - val_output1_loss: 0.9767 - val_output2_accuracy: 0.8193 - val_output2_loss: 0.7650 - learning_rate: 2.0000e-04\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2613 - output1_accuracy: 0.8674 - output1_loss: 0.6690 - output2_accuracy: 0.9153 - output2_loss: 0.5815 - val_loss: 1.7310 - val_output1_accuracy: 0.7284 - val_output1_loss: 0.9448 - val_output2_accuracy: 0.8157 - val_output2_loss: 0.7754 - learning_rate: 2.0000e-04\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.2629 - output1_accuracy: 0.8691 - output1_loss: 0.6699 - output2_accuracy: 0.9144 - output2_loss: 0.5821 - val_loss: 1.7669 - val_output1_accuracy: 0.7196 - val_output1_loss: 0.9680 - val_output2_accuracy: 0.8019 - val_output2_loss: 0.7880 - learning_rate: 2.0000e-04\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2557 - output1_accuracy: 0.8680 - output1_loss: 0.6675 - output2_accuracy: 0.9179 - output2_loss: 0.5774 - val_loss: 1.7286 - val_output1_accuracy: 0.7306 - val_output1_loss: 0.9449 - val_output2_accuracy: 0.8179 - val_output2_loss: 0.7730 - learning_rate: 2.0000e-04\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2494 - output1_accuracy: 0.8706 - output1_loss: 0.6615 - output2_accuracy: 0.9176 - output2_loss: 0.5771\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2494 - output1_accuracy: 0.8706 - output1_loss: 0.6615 - output2_accuracy: 0.9176 - output2_loss: 0.5771 - val_loss: 1.7558 - val_output1_accuracy: 0.7181 - val_output1_loss: 0.9665 - val_output2_accuracy: 0.8107 - val_output2_loss: 0.7784 - learning_rate: 2.0000e-04\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2426 - output1_accuracy: 0.8737 - output1_loss: 0.6613 - output2_accuracy: 0.9210 - output2_loss: 0.5705 - val_loss: 1.7284 - val_output1_accuracy: 0.7272 - val_output1_loss: 0.9459 - val_output2_accuracy: 0.8221 - val_output2_loss: 0.7718 - learning_rate: 4.0000e-05\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2447 - output1_accuracy: 0.8715 - output1_loss: 0.6616 - output2_accuracy: 0.9190 - output2_loss: 0.5724 - val_loss: 1.7038 - val_output1_accuracy: 0.7318 - val_output1_loss: 0.9309 - val_output2_accuracy: 0.8185 - val_output2_loss: 0.7621 - learning_rate: 4.0000e-05\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2428 - output1_accuracy: 0.8756 - output1_loss: 0.6568 - output2_accuracy: 0.9161 - output2_loss: 0.5752 - val_loss: 1.7365 - val_output1_accuracy: 0.7232 - val_output1_loss: 0.9543 - val_output2_accuracy: 0.8179 - val_output2_loss: 0.7714 - learning_rate: 4.0000e-05\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.2376 - output1_accuracy: 0.8765 - output1_loss: 0.6531 - output2_accuracy: 0.9189 - output2_loss: 0.5737 - val_loss: 1.7358 - val_output1_accuracy: 0.7246 - val_output1_loss: 0.9512 - val_output2_accuracy: 0.8165 - val_output2_loss: 0.7739 - learning_rate: 4.0000e-05\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2410 - output1_accuracy: 0.8747 - output1_loss: 0.6566 - output2_accuracy: 0.9189 - output2_loss: 0.5736 - val_loss: 1.7258 - val_output1_accuracy: 0.7356 - val_output1_loss: 0.9345 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.7807 - learning_rate: 4.0000e-05\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2487 - output1_accuracy: 0.8720 - output1_loss: 0.6612 - output2_accuracy: 0.9166 - output2_loss: 0.5768 - val_loss: 1.7286 - val_output1_accuracy: 0.7224 - val_output1_loss: 0.9549 - val_output2_accuracy: 0.8197 - val_output2_loss: 0.7630 - learning_rate: 4.0000e-05\n",
      "Epoch 32/250\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2357 - output1_accuracy: 0.8777 - output1_loss: 0.6525 - output2_accuracy: 0.9183 - output2_loss: 0.5725\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2357 - output1_accuracy: 0.8776 - output1_loss: 0.6525 - output2_accuracy: 0.9183 - output2_loss: 0.5725 - val_loss: 1.7525 - val_output1_accuracy: 0.7234 - val_output1_loss: 0.9545 - val_output2_accuracy: 0.8041 - val_output2_loss: 0.7873 - learning_rate: 4.0000e-05\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2308 - output1_accuracy: 0.8767 - output1_loss: 0.6526 - output2_accuracy: 0.9213 - output2_loss: 0.5676 - val_loss: 1.7604 - val_output1_accuracy: 0.7200 - val_output1_loss: 0.9675 - val_output2_accuracy: 0.8149 - val_output2_loss: 0.7822 - learning_rate: 8.0000e-06\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2337 - output1_accuracy: 0.8772 - output1_loss: 0.6552 - output2_accuracy: 0.9223 - output2_loss: 0.5678 - val_loss: 1.7266 - val_output1_accuracy: 0.7256 - val_output1_loss: 0.9563 - val_output2_accuracy: 0.8181 - val_output2_loss: 0.7596 - learning_rate: 8.0000e-06\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2404 - output1_accuracy: 0.8757 - output1_loss: 0.6568 - output2_accuracy: 0.9216 - output2_loss: 0.5729 - val_loss: 1.6982 - val_output1_accuracy: 0.7296 - val_output1_loss: 0.9338 - val_output2_accuracy: 0.8241 - val_output2_loss: 0.7537 - learning_rate: 8.0000e-06\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2296 - output1_accuracy: 0.8803 - output1_loss: 0.6485 - output2_accuracy: 0.9214 - output2_loss: 0.5704 - val_loss: 1.7459 - val_output1_accuracy: 0.7252 - val_output1_loss: 0.9530 - val_output2_accuracy: 0.8085 - val_output2_loss: 0.7822 - learning_rate: 8.0000e-06\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2368 - output1_accuracy: 0.8771 - output1_loss: 0.6557 - output2_accuracy: 0.9184 - output2_loss: 0.5705 - val_loss: 1.7236 - val_output1_accuracy: 0.7392 - val_output1_loss: 0.9393 - val_output2_accuracy: 0.8109 - val_output2_loss: 0.7736 - learning_rate: 8.0000e-06\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2293 - output1_accuracy: 0.8819 - output1_loss: 0.6461 - output2_accuracy: 0.9193 - output2_loss: 0.5725 - val_loss: 1.7229 - val_output1_accuracy: 0.7294 - val_output1_loss: 0.9415 - val_output2_accuracy: 0.8169 - val_output2_loss: 0.7707 - learning_rate: 8.0000e-06\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2342 - output1_accuracy: 0.8779 - output1_loss: 0.6535 - output2_accuracy: 0.9216 - output2_loss: 0.5700 - val_loss: 1.7099 - val_output1_accuracy: 0.7316 - val_output1_loss: 0.9401 - val_output2_accuracy: 0.8269 - val_output2_loss: 0.7591 - learning_rate: 8.0000e-06\n",
      "Epoch 40/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2324 - output1_accuracy: 0.8782 - output1_loss: 0.6490 - output2_accuracy: 0.9190 - output2_loss: 0.5727\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.2324 - output1_accuracy: 0.8782 - output1_loss: 0.6490 - output2_accuracy: 0.9190 - output2_loss: 0.5727 - val_loss: 1.7314 - val_output1_accuracy: 0.7328 - val_output1_loss: 0.9478 - val_output2_accuracy: 0.8175 - val_output2_loss: 0.7728 - learning_rate: 8.0000e-06\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2403 - output1_accuracy: 0.8789 - output1_loss: 0.6543 - output2_accuracy: 0.9180 - output2_loss: 0.5754 - val_loss: 1.7587 - val_output1_accuracy: 0.7264 - val_output1_loss: 0.9523 - val_output2_accuracy: 0.8133 - val_output2_loss: 0.7958 - learning_rate: 1.6000e-06\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.2283 - output1_accuracy: 0.8796 - output1_loss: 0.6497 - output2_accuracy: 0.9234 - output2_loss: 0.5679 - val_loss: 1.7260 - val_output1_accuracy: 0.7298 - val_output1_loss: 0.9406 - val_output2_accuracy: 0.8177 - val_output2_loss: 0.7747 - learning_rate: 1.6000e-06\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.2364 - output1_accuracy: 0.8751 - output1_loss: 0.6547 - output2_accuracy: 0.9212 - output2_loss: 0.5710 - val_loss: 1.7126 - val_output1_accuracy: 0.7400 - val_output1_loss: 0.9378 - val_output2_accuracy: 0.8191 - val_output2_loss: 0.7642 - learning_rate: 1.6000e-06\n",
      "Epoch 44/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.2350 - output1_accuracy: 0.8753 - output1_loss: 0.6539 - output2_accuracy: 0.9208 - output2_loss: 0.5705 - val_loss: 1.7426 - val_output1_accuracy: 0.7222 - val_output1_loss: 0.9536 - val_output2_accuracy: 0.8187 - val_output2_loss: 0.7783 - learning_rate: 1.6000e-06\n",
      "Epoch 45/250\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2302 - output1_accuracy: 0.8802 - output1_loss: 0.6504 - output2_accuracy: 0.9222 - output2_loss: 0.5691\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.2302 - output1_accuracy: 0.8802 - output1_loss: 0.6504 - output2_accuracy: 0.9222 - output2_loss: 0.5691 - val_loss: 1.7092 - val_output1_accuracy: 0.7324 - val_output1_loss: 0.9369 - val_output2_accuracy: 0.8231 - val_output2_loss: 0.7616 - learning_rate: 1.6000e-06\n",
      "Epoch 45: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.000001, verbose=1)\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7728849947452545\n",
      "standard deviation =  0.0034772096260280113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('77.2acc.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCNRR2():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    #inputs = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    #inputs = layers.RandomTranslation(height_factor=5/32, width_factor=5/32, fill_mode='nearest')(inputs)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    # Classifers\n",
    "    x1 = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    x2 = layers.Conv2D(192, (1,1), activation='relu')(x)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    #x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCNRR2',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCNRR2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCNRR2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,079,818</span> (4.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,079,818\u001b[0m (4.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,077,322</span> (4.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,077,322\u001b[0m (4.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> (9.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,496\u001b[0m (9.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 3.0003 - output1_accuracy: 0.3958 - output1_loss: 1.4703 - output2_accuracy: 0.4535 - output2_loss: 1.3992 - val_loss: 2.8194 - val_output1_accuracy: 0.3658 - val_output1_loss: 1.4871 - val_output2_accuracy: 0.5164 - val_output2_loss: 1.2903 - learning_rate: 0.0010\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3907 - output1_accuracy: 0.5291 - output1_loss: 1.2516 - output2_accuracy: 0.6290 - output2_loss: 1.1049 - val_loss: 2.5269 - val_output1_accuracy: 0.4954 - val_output1_loss: 1.3755 - val_output2_accuracy: 0.6222 - val_output2_loss: 1.1302 - learning_rate: 0.0010\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.2353 - output1_accuracy: 0.5688 - output1_loss: 1.1941 - output2_accuracy: 0.6793 - output2_loss: 1.0211 - val_loss: 2.7355 - val_output1_accuracy: 0.4581 - val_output1_loss: 1.4114 - val_output2_accuracy: 0.5469 - val_output2_loss: 1.3048 - learning_rate: 0.0010\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.1224 - output1_accuracy: 0.6036 - output1_loss: 1.1347 - output2_accuracy: 0.7069 - output2_loss: 0.9691 - val_loss: 2.2061 - val_output1_accuracy: 0.5803 - val_output1_loss: 1.1882 - val_output2_accuracy: 0.6895 - val_output2_loss: 1.0006 - learning_rate: 0.0010\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0571 - output1_accuracy: 0.6236 - output1_loss: 1.1031 - output2_accuracy: 0.7286 - output2_loss: 0.9364 - val_loss: 2.3532 - val_output1_accuracy: 0.5475 - val_output1_loss: 1.2457 - val_output2_accuracy: 0.6402 - val_output2_loss: 1.0895 - learning_rate: 0.0010\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0022 - output1_accuracy: 0.6468 - output1_loss: 1.0687 - output2_accuracy: 0.7373 - output2_loss: 0.9160 - val_loss: 2.3348 - val_output1_accuracy: 0.5469 - val_output1_loss: 1.2735 - val_output2_accuracy: 0.6739 - val_output2_loss: 1.0445 - learning_rate: 0.0010\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9631 - output1_accuracy: 0.6598 - output1_loss: 1.0472 - output2_accuracy: 0.7482 - output2_loss: 0.8990 - val_loss: 2.2593 - val_output1_accuracy: 0.5553 - val_output1_loss: 1.2594 - val_output2_accuracy: 0.7081 - val_output2_loss: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9308 - output1_accuracy: 0.6649 - output1_loss: 1.0308 - output2_accuracy: 0.7587 - output2_loss: 0.8836 - val_loss: 2.1601 - val_output1_accuracy: 0.5843 - val_output1_loss: 1.1722 - val_output2_accuracy: 0.7097 - val_output2_loss: 0.9727 - learning_rate: 0.0010\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8926 - output1_accuracy: 0.6807 - output1_loss: 1.0093 - output2_accuracy: 0.7654 - output2_loss: 0.8675 - val_loss: 2.3165 - val_output1_accuracy: 0.5325 - val_output1_loss: 1.2878 - val_output2_accuracy: 0.6823 - val_output2_loss: 1.0133 - learning_rate: 0.0010\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8717 - output1_accuracy: 0.6832 - output1_loss: 1.0073 - output2_accuracy: 0.7751 - output2_loss: 0.8489 - val_loss: 2.4826 - val_output1_accuracy: 0.4972 - val_output1_loss: 1.3793 - val_output2_accuracy: 0.6446 - val_output2_loss: 1.0880 - learning_rate: 0.0010\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8484 - output1_accuracy: 0.6958 - output1_loss: 0.9865 - output2_accuracy: 0.7784 - output2_loss: 0.8468 - val_loss: 2.0296 - val_output1_accuracy: 0.6384 - val_output1_loss: 1.0993 - val_output2_accuracy: 0.7384 - val_output2_loss: 0.9157 - learning_rate: 0.0010\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8125 - output1_accuracy: 0.7038 - output1_loss: 0.9734 - output2_accuracy: 0.7937 - output2_loss: 0.8242 - val_loss: 2.0965 - val_output1_accuracy: 0.6370 - val_output1_loss: 1.0941 - val_output2_accuracy: 0.7005 - val_output2_loss: 0.9880 - learning_rate: 0.0010\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8089 - output1_accuracy: 0.7043 - output1_loss: 0.9698 - output2_accuracy: 0.7849 - output2_loss: 0.8247 - val_loss: 2.2494 - val_output1_accuracy: 0.6102 - val_output1_loss: 1.1346 - val_output2_accuracy: 0.6599 - val_output2_loss: 1.1005 - learning_rate: 0.0010\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7956 - output1_accuracy: 0.7072 - output1_loss: 0.9609 - output2_accuracy: 0.7948 - output2_loss: 0.8204 - val_loss: 2.2194 - val_output1_accuracy: 0.5911 - val_output1_loss: 1.1957 - val_output2_accuracy: 0.6995 - val_output2_loss: 1.0098 - learning_rate: 0.0010\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7678 - output1_accuracy: 0.7236 - output1_loss: 0.9446 - output2_accuracy: 0.7990 - output2_loss: 0.8092 - val_loss: 1.9767 - val_output1_accuracy: 0.6546 - val_output1_loss: 1.0639 - val_output2_accuracy: 0.7510 - val_output2_loss: 0.8992 - learning_rate: 0.0010\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7486 - output1_accuracy: 0.7269 - output1_loss: 0.9349 - output2_accuracy: 0.8056 - output2_loss: 0.7998 - val_loss: 2.0529 - val_output1_accuracy: 0.6530 - val_output1_loss: 1.0680 - val_output2_accuracy: 0.7091 - val_output2_loss: 0.9713 - learning_rate: 0.0010\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7423 - output1_accuracy: 0.7261 - output1_loss: 0.9360 - output2_accuracy: 0.8054 - output2_loss: 0.7929 - val_loss: 2.0794 - val_output1_accuracy: 0.6222 - val_output1_loss: 1.1118 - val_output2_accuracy: 0.7214 - val_output2_loss: 0.9547 - learning_rate: 0.0010\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7337 - output1_accuracy: 0.7285 - output1_loss: 0.9268 - output2_accuracy: 0.8079 - output2_loss: 0.7936 - val_loss: 1.9567 - val_output1_accuracy: 0.6645 - val_output1_loss: 1.0369 - val_output2_accuracy: 0.7478 - val_output2_loss: 0.9061 - learning_rate: 0.0010\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7137 - output1_accuracy: 0.7379 - output1_loss: 0.9138 - output2_accuracy: 0.8122 - output2_loss: 0.7866 - val_loss: 2.3779 - val_output1_accuracy: 0.5357 - val_output1_loss: 1.3283 - val_output2_accuracy: 0.6797 - val_output2_loss: 1.0361 - learning_rate: 0.0010\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7112 - output1_accuracy: 0.7349 - output1_loss: 0.9198 - output2_accuracy: 0.8157 - output2_loss: 0.7784 - val_loss: 1.9679 - val_output1_accuracy: 0.6396 - val_output1_loss: 1.0833 - val_output2_accuracy: 0.7674 - val_output2_loss: 0.8716 - learning_rate: 0.0010\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6963 - output1_accuracy: 0.7374 - output1_loss: 0.9097 - output2_accuracy: 0.8227 - output2_loss: 0.7737 - val_loss: 1.8997 - val_output1_accuracy: 0.6817 - val_output1_loss: 1.0083 - val_output2_accuracy: 0.7658 - val_output2_loss: 0.8788 - learning_rate: 0.0010\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6805 - output1_accuracy: 0.7429 - output1_loss: 0.9038 - output2_accuracy: 0.8259 - output2_loss: 0.7639 - val_loss: 1.9941 - val_output1_accuracy: 0.6480 - val_output1_loss: 1.0884 - val_output2_accuracy: 0.7558 - val_output2_loss: 0.8932 - learning_rate: 0.0010\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6685 - output1_accuracy: 0.7457 - output1_loss: 0.8952 - output2_accuracy: 0.8261 - output2_loss: 0.7608 - val_loss: 2.0191 - val_output1_accuracy: 0.6494 - val_output1_loss: 1.0704 - val_output2_accuracy: 0.7280 - val_output2_loss: 0.9365 - learning_rate: 0.0010\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6623 - output1_accuracy: 0.7546 - output1_loss: 0.8856 - output2_accuracy: 0.8238 - output2_loss: 0.7642 - val_loss: 2.1331 - val_output1_accuracy: 0.6218 - val_output1_loss: 1.1399 - val_output2_accuracy: 0.7147 - val_output2_loss: 0.9802 - learning_rate: 0.0010\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.6589 - output1_accuracy: 0.7519 - output1_loss: 0.8868 - output2_accuracy: 0.8295 - output2_loss: 0.7597 - val_loss: 1.9842 - val_output1_accuracy: 0.6400 - val_output1_loss: 1.0785 - val_output2_accuracy: 0.7536 - val_output2_loss: 0.8937 - learning_rate: 0.0010\n",
      "Epoch 26/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6500 - output1_accuracy: 0.7555 - output1_loss: 0.8838 - output2_accuracy: 0.8330 - output2_loss: 0.7540\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6500 - output1_accuracy: 0.7555 - output1_loss: 0.8837 - output2_accuracy: 0.8330 - output2_loss: 0.7540 - val_loss: 1.9442 - val_output1_accuracy: 0.6689 - val_output1_loss: 1.0606 - val_output2_accuracy: 0.7682 - val_output2_loss: 0.8714 - learning_rate: 0.0010\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5947 - output1_accuracy: 0.7722 - output1_loss: 0.8506 - output2_accuracy: 0.8456 - output2_loss: 0.7318 - val_loss: 1.8018 - val_output1_accuracy: 0.7053 - val_output1_loss: 0.9712 - val_output2_accuracy: 0.8009 - val_output2_loss: 0.8183 - learning_rate: 2.0000e-04\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5757 - output1_accuracy: 0.7784 - output1_loss: 0.8449 - output2_accuracy: 0.8522 - output2_loss: 0.7184 - val_loss: 1.7731 - val_output1_accuracy: 0.7210 - val_output1_loss: 0.9548 - val_output2_accuracy: 0.8021 - val_output2_loss: 0.8061 - learning_rate: 2.0000e-04\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5673 - output1_accuracy: 0.7817 - output1_loss: 0.8360 - output2_accuracy: 0.8498 - output2_loss: 0.7191 - val_loss: 1.8248 - val_output1_accuracy: 0.6957 - val_output1_loss: 0.9881 - val_output2_accuracy: 0.7911 - val_output2_loss: 0.8243 - learning_rate: 2.0000e-04\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5590 - output1_accuracy: 0.7843 - output1_loss: 0.8328 - output2_accuracy: 0.8527 - output2_loss: 0.7138 - val_loss: 1.8022 - val_output1_accuracy: 0.6965 - val_output1_loss: 0.9800 - val_output2_accuracy: 0.8031 - val_output2_loss: 0.8099 - learning_rate: 2.0000e-04\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5520 - output1_accuracy: 0.7838 - output1_loss: 0.8331 - output2_accuracy: 0.8588 - output2_loss: 0.7066 - val_loss: 1.7788 - val_output1_accuracy: 0.7171 - val_output1_loss: 0.9662 - val_output2_accuracy: 0.8023 - val_output2_loss: 0.8003 - learning_rate: 2.0000e-04\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5488 - output1_accuracy: 0.7924 - output1_loss: 0.8255 - output2_accuracy: 0.8539 - output2_loss: 0.7110 - val_loss: 1.8287 - val_output1_accuracy: 0.7061 - val_output1_loss: 0.9849 - val_output2_accuracy: 0.7893 - val_output2_loss: 0.8314 - learning_rate: 2.0000e-04\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5398 - output1_accuracy: 0.7912 - output1_loss: 0.8250 - output2_accuracy: 0.8591 - output2_loss: 0.7024\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5398 - output1_accuracy: 0.7912 - output1_loss: 0.8250 - output2_accuracy: 0.8591 - output2_loss: 0.7024 - val_loss: 1.7807 - val_output1_accuracy: 0.7069 - val_output1_loss: 0.9744 - val_output2_accuracy: 0.8099 - val_output2_loss: 0.7940 - learning_rate: 2.0000e-04\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5298 - output1_accuracy: 0.7894 - output1_loss: 0.8216 - output2_accuracy: 0.8624 - output2_loss: 0.6960 - val_loss: 1.7499 - val_output1_accuracy: 0.7220 - val_output1_loss: 0.9431 - val_output2_accuracy: 0.8057 - val_output2_loss: 0.7944 - learning_rate: 4.0000e-05\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5212 - output1_accuracy: 0.7986 - output1_loss: 0.8118 - output2_accuracy: 0.8639 - output2_loss: 0.6970 - val_loss: 1.7619 - val_output1_accuracy: 0.7151 - val_output1_loss: 0.9628 - val_output2_accuracy: 0.8133 - val_output2_loss: 0.7868 - learning_rate: 4.0000e-05\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5218 - output1_accuracy: 0.7942 - output1_loss: 0.8180 - output2_accuracy: 0.8652 - output2_loss: 0.6914 - val_loss: 1.7642 - val_output1_accuracy: 0.7151 - val_output1_loss: 0.9540 - val_output2_accuracy: 0.8069 - val_output2_loss: 0.7979 - learning_rate: 4.0000e-05\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5203 - output1_accuracy: 0.7962 - output1_loss: 0.8110 - output2_accuracy: 0.8634 - output2_loss: 0.6969 - val_loss: 1.7522 - val_output1_accuracy: 0.7071 - val_output1_loss: 0.9714 - val_output2_accuracy: 0.8241 - val_output2_loss: 0.7684 - learning_rate: 4.0000e-05\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5221 - output1_accuracy: 0.7967 - output1_loss: 0.8149 - output2_accuracy: 0.8638 - output2_loss: 0.6949 - val_loss: 1.7642 - val_output1_accuracy: 0.7121 - val_output1_loss: 0.9556 - val_output2_accuracy: 0.8127 - val_output2_loss: 0.7962 - learning_rate: 4.0000e-05\n",
      "Epoch 39/250\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5196 - output1_accuracy: 0.7991 - output1_loss: 0.8120 - output2_accuracy: 0.8690 - output2_loss: 0.6953\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5196 - output1_accuracy: 0.7991 - output1_loss: 0.8120 - output2_accuracy: 0.8690 - output2_loss: 0.6953 - val_loss: 1.7833 - val_output1_accuracy: 0.7085 - val_output1_loss: 0.9767 - val_output2_accuracy: 0.8035 - val_output2_loss: 0.7943 - learning_rate: 4.0000e-05\n",
      "Epoch 40/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5199 - output1_accuracy: 0.7988 - output1_loss: 0.8103 - output2_accuracy: 0.8640 - output2_loss: 0.6973 - val_loss: 1.7522 - val_output1_accuracy: 0.7159 - val_output1_loss: 0.9543 - val_output2_accuracy: 0.8125 - val_output2_loss: 0.7855 - learning_rate: 8.0000e-06\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.5158 - output1_accuracy: 0.7969 - output1_loss: 0.8088 - output2_accuracy: 0.8620 - output2_loss: 0.6947 - val_loss: 1.7789 - val_output1_accuracy: 0.7095 - val_output1_loss: 0.9653 - val_output2_accuracy: 0.8023 - val_output2_loss: 0.8013 - learning_rate: 8.0000e-06\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5117 - output1_accuracy: 0.8028 - output1_loss: 0.8052 - output2_accuracy: 0.8663 - output2_loss: 0.6941 - val_loss: 1.7595 - val_output1_accuracy: 0.7139 - val_output1_loss: 0.9492 - val_output2_accuracy: 0.8083 - val_output2_loss: 0.7980 - learning_rate: 8.0000e-06\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5114 - output1_accuracy: 0.7977 - output1_loss: 0.8064 - output2_accuracy: 0.8648 - output2_loss: 0.6926 - val_loss: 1.7999 - val_output1_accuracy: 0.7043 - val_output1_loss: 0.9823 - val_output2_accuracy: 0.8073 - val_output2_loss: 0.8054 - learning_rate: 8.0000e-06\n",
      "Epoch 44/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5096 - output1_accuracy: 0.7997 - output1_loss: 0.8100 - output2_accuracy: 0.8671 - output2_loss: 0.6873\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5096 - output1_accuracy: 0.7997 - output1_loss: 0.8100 - output2_accuracy: 0.8671 - output2_loss: 0.6873 - val_loss: 1.7526 - val_output1_accuracy: 0.7244 - val_output1_loss: 0.9454 - val_output2_accuracy: 0.8041 - val_output2_loss: 0.7949 - learning_rate: 8.0000e-06\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "model = ACCNRR2()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.000001, verbose=1)\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7608000040054321\n",
      "standard deviation =  0.0014462036836579227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCNRR3():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # Classifers\n",
    "    x1 = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.Conv2D(192, (1,1), activation='relu')(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    x2 = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.Conv2D(192, (1,1), activation='relu')(x2)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    #x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCNRR3',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCNRR3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCNRR3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,412,554</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,412,554\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409,674</span> (5.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,409,674\u001b[0m (5.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - loss: 3.0550 - output1_accuracy: 0.3926 - output1_loss: 1.4776 - output2_accuracy: 0.4317 - output2_loss: 1.4364 - val_loss: 2.6912 - val_output1_accuracy: 0.3962 - val_output1_loss: 1.4266 - val_output2_accuracy: 0.5681 - val_output2_loss: 1.2173 - learning_rate: 0.0010\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.3946 - output1_accuracy: 0.5275 - output1_loss: 1.2529 - output2_accuracy: 0.6273 - output2_loss: 1.1048 - val_loss: 2.7027 - val_output1_accuracy: 0.5032 - val_output1_loss: 1.3021 - val_output2_accuracy: 0.5365 - val_output2_loss: 1.3793 - learning_rate: 0.0010\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2188 - output1_accuracy: 0.5798 - output1_loss: 1.1796 - output2_accuracy: 0.6786 - output2_loss: 1.0188 - val_loss: 2.3980 - val_output1_accuracy: 0.5397 - val_output1_loss: 1.2643 - val_output2_accuracy: 0.6118 - val_output2_loss: 1.1155 - learning_rate: 0.0010\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.1183 - output1_accuracy: 0.6077 - output1_loss: 1.1291 - output2_accuracy: 0.7036 - output2_loss: 0.9710 - val_loss: 2.3274 - val_output1_accuracy: 0.5575 - val_output1_loss: 1.2113 - val_output2_accuracy: 0.6468 - val_output2_loss: 1.0993 - learning_rate: 0.0010\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.0531 - output1_accuracy: 0.6269 - output1_loss: 1.1013 - output2_accuracy: 0.7257 - output2_loss: 0.9346 - val_loss: 2.2675 - val_output1_accuracy: 0.5695 - val_output1_loss: 1.1945 - val_output2_accuracy: 0.6556 - val_output2_loss: 1.0570 - learning_rate: 0.0010\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 2.0019 - output1_accuracy: 0.6448 - output1_loss: 1.0701 - output2_accuracy: 0.7411 - output2_loss: 0.9152 - val_loss: 2.3375 - val_output1_accuracy: 0.5222 - val_output1_loss: 1.3312 - val_output2_accuracy: 0.6983 - val_output2_loss: 0.9901 - learning_rate: 0.0010\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.9565 - output1_accuracy: 0.6612 - output1_loss: 1.0445 - output2_accuracy: 0.7498 - output2_loss: 0.8956 - val_loss: 2.2495 - val_output1_accuracy: 0.5619 - val_output1_loss: 1.2158 - val_output2_accuracy: 0.6951 - val_output2_loss: 1.0174 - learning_rate: 0.0010\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9177 - output1_accuracy: 0.6701 - output1_loss: 1.0306 - output2_accuracy: 0.7661 - output2_loss: 0.8709 - val_loss: 2.1809 - val_output1_accuracy: 0.5789 - val_output1_loss: 1.1913 - val_output2_accuracy: 0.7065 - val_output2_loss: 0.9742 - learning_rate: 0.0010\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 1.8997 - output1_accuracy: 0.6740 - output1_loss: 1.0178 - output2_accuracy: 0.7669 - output2_loss: 0.8663 - val_loss: 2.1757 - val_output1_accuracy: 0.5933 - val_output1_loss: 1.1667 - val_output2_accuracy: 0.6903 - val_output2_loss: 0.9931 - learning_rate: 0.0010\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8680 - output1_accuracy: 0.6805 - output1_loss: 1.0043 - output2_accuracy: 0.7766 - output2_loss: 0.8485 - val_loss: 2.8514 - val_output1_accuracy: 0.4587 - val_output1_loss: 1.6013 - val_output2_accuracy: 0.5791 - val_output2_loss: 1.2351 - learning_rate: 0.0010\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8448 - output1_accuracy: 0.6876 - output1_loss: 0.9900 - output2_accuracy: 0.7828 - output2_loss: 0.8400 - val_loss: 2.1746 - val_output1_accuracy: 0.5954 - val_output1_loss: 1.1805 - val_output2_accuracy: 0.7143 - val_output2_loss: 0.9797 - learning_rate: 0.0010\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8279 - output1_accuracy: 0.7005 - output1_loss: 0.9764 - output2_accuracy: 0.7822 - output2_loss: 0.8371 - val_loss: 2.0780 - val_output1_accuracy: 0.6168 - val_output1_loss: 1.1388 - val_output2_accuracy: 0.7388 - val_output2_loss: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.8042 - output1_accuracy: 0.7036 - output1_loss: 0.9683 - output2_accuracy: 0.7910 - output2_loss: 0.8216 - val_loss: 2.1473 - val_output1_accuracy: 0.6322 - val_output1_loss: 1.1120 - val_output2_accuracy: 0.6883 - val_output2_loss: 1.0209 - learning_rate: 0.0010\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7856 - output1_accuracy: 0.7123 - output1_loss: 0.9587 - output2_accuracy: 0.7971 - output2_loss: 0.8129 - val_loss: 2.0926 - val_output1_accuracy: 0.6242 - val_output1_loss: 1.1137 - val_output2_accuracy: 0.7125 - val_output2_loss: 0.9650 - learning_rate: 0.0010\n",
      "Epoch 15/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7688 - output1_accuracy: 0.7149 - output1_loss: 0.9549 - output2_accuracy: 0.8034 - output2_loss: 0.8000 - val_loss: 2.1162 - val_output1_accuracy: 0.6150 - val_output1_loss: 1.1484 - val_output2_accuracy: 0.7194 - val_output2_loss: 0.9542 - learning_rate: 0.0010\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7487 - output1_accuracy: 0.7237 - output1_loss: 0.9399 - output2_accuracy: 0.8056 - output2_loss: 0.7952 - val_loss: 1.9723 - val_output1_accuracy: 0.6567 - val_output1_loss: 1.0712 - val_output2_accuracy: 0.7600 - val_output2_loss: 0.8874 - learning_rate: 0.0010\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7391 - output1_accuracy: 0.7235 - output1_loss: 0.9323 - output2_accuracy: 0.8093 - output2_loss: 0.7933 - val_loss: 2.0008 - val_output1_accuracy: 0.6350 - val_output1_loss: 1.0895 - val_output2_accuracy: 0.7502 - val_output2_loss: 0.8987 - learning_rate: 0.0010\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7155 - output1_accuracy: 0.7359 - output1_loss: 0.9206 - output2_accuracy: 0.8156 - output2_loss: 0.7818 - val_loss: 1.9841 - val_output1_accuracy: 0.6573 - val_output1_loss: 1.0665 - val_output2_accuracy: 0.7502 - val_output2_loss: 0.9047 - learning_rate: 0.0010\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7049 - output1_accuracy: 0.7361 - output1_loss: 0.9196 - output2_accuracy: 0.8226 - output2_loss: 0.7723 - val_loss: 1.9011 - val_output1_accuracy: 0.6709 - val_output1_loss: 1.0298 - val_output2_accuracy: 0.7706 - val_output2_loss: 0.8581 - learning_rate: 0.0010\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6997 - output1_accuracy: 0.7386 - output1_loss: 0.9138 - output2_accuracy: 0.8213 - output2_loss: 0.7731 - val_loss: 1.9940 - val_output1_accuracy: 0.6577 - val_output1_loss: 1.0722 - val_output2_accuracy: 0.7512 - val_output2_loss: 0.9092 - learning_rate: 0.0010\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.6878 - output1_accuracy: 0.7446 - output1_loss: 0.9037 - output2_accuracy: 0.8195 - output2_loss: 0.7712 - val_loss: 2.0439 - val_output1_accuracy: 0.6244 - val_output1_loss: 1.1275 - val_output2_accuracy: 0.7490 - val_output2_loss: 0.9036 - learning_rate: 0.0010\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.6711 - output1_accuracy: 0.7533 - output1_loss: 0.8943 - output2_accuracy: 0.8259 - output2_loss: 0.7641 - val_loss: 2.0218 - val_output1_accuracy: 0.6540 - val_output1_loss: 1.0614 - val_output2_accuracy: 0.7294 - val_output2_loss: 0.9481 - learning_rate: 0.0010\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.6694 - output1_accuracy: 0.7475 - output1_loss: 0.8956 - output2_accuracy: 0.8298 - output2_loss: 0.7613 - val_loss: 2.0031 - val_output1_accuracy: 0.6623 - val_output1_loss: 1.0416 - val_output2_accuracy: 0.7276 - val_output2_loss: 0.9493 - learning_rate: 0.0010\n",
      "Epoch 24/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6579 - output1_accuracy: 0.7504 - output1_loss: 0.8895 - output2_accuracy: 0.8310 - output2_loss: 0.7560\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.6579 - output1_accuracy: 0.7504 - output1_loss: 0.8895 - output2_accuracy: 0.8310 - output2_loss: 0.7560 - val_loss: 2.3334 - val_output1_accuracy: 0.5771 - val_output1_loss: 1.2781 - val_output2_accuracy: 0.6861 - val_output2_loss: 1.0429 - learning_rate: 0.0010\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.6022 - output1_accuracy: 0.7680 - output1_loss: 0.8600 - output2_accuracy: 0.8442 - output2_loss: 0.7297 - val_loss: 1.8187 - val_output1_accuracy: 0.6975 - val_output1_loss: 0.9866 - val_output2_accuracy: 0.7913 - val_output2_loss: 0.8193 - learning_rate: 2.0000e-04\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5833 - output1_accuracy: 0.7753 - output1_loss: 0.8456 - output2_accuracy: 0.8473 - output2_loss: 0.7251 - val_loss: 1.8024 - val_output1_accuracy: 0.7083 - val_output1_loss: 0.9626 - val_output2_accuracy: 0.7893 - val_output2_loss: 0.8269 - learning_rate: 2.0000e-04\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5570 - output1_accuracy: 0.7825 - output1_loss: 0.8318 - output2_accuracy: 0.8538 - output2_loss: 0.7125 - val_loss: 1.8076 - val_output1_accuracy: 0.7077 - val_output1_loss: 0.9809 - val_output2_accuracy: 0.7937 - val_output2_loss: 0.8142 - learning_rate: 2.0000e-04\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5598 - output1_accuracy: 0.7865 - output1_loss: 0.8329 - output2_accuracy: 0.8526 - output2_loss: 0.7143 - val_loss: 1.8129 - val_output1_accuracy: 0.6961 - val_output1_loss: 0.9788 - val_output2_accuracy: 0.7901 - val_output2_loss: 0.8215 - learning_rate: 2.0000e-04\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5453 - output1_accuracy: 0.7881 - output1_loss: 0.8263 - output2_accuracy: 0.8571 - output2_loss: 0.7063 - val_loss: 1.8184 - val_output1_accuracy: 0.6893 - val_output1_loss: 0.9992 - val_output2_accuracy: 0.8005 - val_output2_loss: 0.8063 - learning_rate: 2.0000e-04\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5466 - output1_accuracy: 0.7880 - output1_loss: 0.8281 - output2_accuracy: 0.8581 - output2_loss: 0.7057 - val_loss: 1.8179 - val_output1_accuracy: 0.6969 - val_output1_loss: 0.9858 - val_output2_accuracy: 0.7913 - val_output2_loss: 0.8192 - learning_rate: 2.0000e-04\n",
      "Epoch 31/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5331 - output1_accuracy: 0.7906 - output1_loss: 0.8193 - output2_accuracy: 0.8607 - output2_loss: 0.7009 - val_loss: 1.7806 - val_output1_accuracy: 0.7119 - val_output1_loss: 0.9635 - val_output2_accuracy: 0.7997 - val_output2_loss: 0.8046 - learning_rate: 2.0000e-04\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5371 - output1_accuracy: 0.7903 - output1_loss: 0.8244 - output2_accuracy: 0.8644 - output2_loss: 0.7001 - val_loss: 1.8107 - val_output1_accuracy: 0.7049 - val_output1_loss: 0.9775 - val_output2_accuracy: 0.7965 - val_output2_loss: 0.8204 - learning_rate: 2.0000e-04\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5299 - output1_accuracy: 0.7963 - output1_loss: 0.8120 - output2_accuracy: 0.8590 - output2_loss: 0.7052 - val_loss: 1.8409 - val_output1_accuracy: 0.6871 - val_output1_loss: 1.0087 - val_output2_accuracy: 0.8025 - val_output2_loss: 0.8196 - learning_rate: 2.0000e-04\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5273 - output1_accuracy: 0.7937 - output1_loss: 0.8167 - output2_accuracy: 0.8610 - output2_loss: 0.6980 - val_loss: 1.8073 - val_output1_accuracy: 0.7037 - val_output1_loss: 0.9741 - val_output2_accuracy: 0.7955 - val_output2_loss: 0.8208 - learning_rate: 2.0000e-04\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5194 - output1_accuracy: 0.7968 - output1_loss: 0.8117 - output2_accuracy: 0.8658 - output2_loss: 0.6951 - val_loss: 1.8246 - val_output1_accuracy: 0.6981 - val_output1_loss: 0.9918 - val_output2_accuracy: 0.7985 - val_output2_loss: 0.8204 - learning_rate: 2.0000e-04\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5141 - output1_accuracy: 0.7945 - output1_loss: 0.8154 - output2_accuracy: 0.8694 - output2_loss: 0.6863\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5141 - output1_accuracy: 0.7945 - output1_loss: 0.8154 - output2_accuracy: 0.8694 - output2_loss: 0.6863 - val_loss: 1.7863 - val_output1_accuracy: 0.7051 - val_output1_loss: 0.9753 - val_output2_accuracy: 0.8047 - val_output2_loss: 0.7985 - learning_rate: 2.0000e-04\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5041 - output1_accuracy: 0.8010 - output1_loss: 0.8023 - output2_accuracy: 0.8652 - output2_loss: 0.6892 - val_loss: 1.7702 - val_output1_accuracy: 0.7157 - val_output1_loss: 0.9565 - val_output2_accuracy: 0.8009 - val_output2_loss: 0.8013 - learning_rate: 4.0000e-05\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.5119 - output1_accuracy: 0.7976 - output1_loss: 0.8101 - output2_accuracy: 0.8695 - output2_loss: 0.6894 - val_loss: 1.7831 - val_output1_accuracy: 0.7053 - val_output1_loss: 0.9687 - val_output2_accuracy: 0.7983 - val_output2_loss: 0.8019 - learning_rate: 4.0000e-05\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4985 - output1_accuracy: 0.8012 - output1_loss: 0.8025 - output2_accuracy: 0.8683 - output2_loss: 0.6835 - val_loss: 1.7904 - val_output1_accuracy: 0.7093 - val_output1_loss: 0.9592 - val_output2_accuracy: 0.7999 - val_output2_loss: 0.8187 - learning_rate: 4.0000e-05\n",
      "Epoch 40/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.5004 - output1_accuracy: 0.8003 - output1_loss: 0.8059 - output2_accuracy: 0.8735 - output2_loss: 0.6819 - val_loss: 1.7841 - val_output1_accuracy: 0.7101 - val_output1_loss: 0.9583 - val_output2_accuracy: 0.7935 - val_output2_loss: 0.8133 - learning_rate: 4.0000e-05\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4934 - output1_accuracy: 0.8074 - output1_loss: 0.7956 - output2_accuracy: 0.8690 - output2_loss: 0.6853 - val_loss: 1.7737 - val_output1_accuracy: 0.7121 - val_output1_loss: 0.9633 - val_output2_accuracy: 0.8083 - val_output2_loss: 0.7978 - learning_rate: 4.0000e-05\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4978 - output1_accuracy: 0.8048 - output1_loss: 0.7972 - output2_accuracy: 0.8687 - output2_loss: 0.6880 - val_loss: 1.7661 - val_output1_accuracy: 0.7131 - val_output1_loss: 0.9551 - val_output2_accuracy: 0.8131 - val_output2_loss: 0.7984 - learning_rate: 4.0000e-05\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4988 - output1_accuracy: 0.8073 - output1_loss: 0.7958 - output2_accuracy: 0.8675 - output2_loss: 0.6904 - val_loss: 1.7808 - val_output1_accuracy: 0.7192 - val_output1_loss: 0.9693 - val_output2_accuracy: 0.8043 - val_output2_loss: 0.7990 - learning_rate: 4.0000e-05\n",
      "Epoch 44/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4961 - output1_accuracy: 0.8031 - output1_loss: 0.8014 - output2_accuracy: 0.8728 - output2_loss: 0.6822 - val_loss: 1.7824 - val_output1_accuracy: 0.7097 - val_output1_loss: 0.9615 - val_output2_accuracy: 0.8021 - val_output2_loss: 0.8084 - learning_rate: 4.0000e-05\n",
      "Epoch 45/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4940 - output1_accuracy: 0.8056 - output1_loss: 0.7969 - output2_accuracy: 0.8715 - output2_loss: 0.6846 - val_loss: 1.7720 - val_output1_accuracy: 0.7051 - val_output1_loss: 0.9642 - val_output2_accuracy: 0.8073 - val_output2_loss: 0.7953 - learning_rate: 4.0000e-05\n",
      "Epoch 46/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4909 - output1_accuracy: 0.8060 - output1_loss: 0.7943 - output2_accuracy: 0.8705 - output2_loss: 0.6841 - val_loss: 1.7724 - val_output1_accuracy: 0.7133 - val_output1_loss: 0.9695 - val_output2_accuracy: 0.8117 - val_output2_loss: 0.7904 - learning_rate: 4.0000e-05\n",
      "Epoch 47/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 1.4882 - output1_accuracy: 0.8083 - output1_loss: 0.7932 - output2_accuracy: 0.8705 - output2_loss: 0.6825 - val_loss: 1.7624 - val_output1_accuracy: 0.7109 - val_output1_loss: 0.9539 - val_output2_accuracy: 0.8051 - val_output2_loss: 0.7960 - learning_rate: 4.0000e-05\n",
      "Epoch 48/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4870 - output1_accuracy: 0.8051 - output1_loss: 0.7960 - output2_accuracy: 0.8761 - output2_loss: 0.6785 - val_loss: 1.7864 - val_output1_accuracy: 0.7059 - val_output1_loss: 0.9749 - val_output2_accuracy: 0.8075 - val_output2_loss: 0.7989 - learning_rate: 4.0000e-05\n",
      "Epoch 49/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4935 - output1_accuracy: 0.8032 - output1_loss: 0.8010 - output2_accuracy: 0.8754 - output2_loss: 0.6799 - val_loss: 1.8064 - val_output1_accuracy: 0.7053 - val_output1_loss: 0.9875 - val_output2_accuracy: 0.8001 - val_output2_loss: 0.8065 - learning_rate: 4.0000e-05\n",
      "Epoch 50/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4908 - output1_accuracy: 0.8082 - output1_loss: 0.7999 - output2_accuracy: 0.8745 - output2_loss: 0.6784 - val_loss: 1.7616 - val_output1_accuracy: 0.7095 - val_output1_loss: 0.9569 - val_output2_accuracy: 0.8193 - val_output2_loss: 0.7921 - learning_rate: 4.0000e-05\n",
      "Epoch 51/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4947 - output1_accuracy: 0.8055 - output1_loss: 0.7999 - output2_accuracy: 0.8732 - output2_loss: 0.6823 - val_loss: 1.7708 - val_output1_accuracy: 0.7069 - val_output1_loss: 0.9689 - val_output2_accuracy: 0.8073 - val_output2_loss: 0.7895 - learning_rate: 4.0000e-05\n",
      "Epoch 52/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4834 - output1_accuracy: 0.8103 - output1_loss: 0.7921 - output2_accuracy: 0.8747 - output2_loss: 0.6788 - val_loss: 1.7637 - val_output1_accuracy: 0.7145 - val_output1_loss: 0.9623 - val_output2_accuracy: 0.8089 - val_output2_loss: 0.7889 - learning_rate: 4.0000e-05\n",
      "Epoch 53/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4841 - output1_accuracy: 0.8115 - output1_loss: 0.7914 - output2_accuracy: 0.8735 - output2_loss: 0.6802 - val_loss: 1.7640 - val_output1_accuracy: 0.7208 - val_output1_loss: 0.9480 - val_output2_accuracy: 0.8045 - val_output2_loss: 0.8034 - learning_rate: 4.0000e-05\n",
      "Epoch 54/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4894 - output1_accuracy: 0.8063 - output1_loss: 0.7945 - output2_accuracy: 0.8709 - output2_loss: 0.6824 - val_loss: 1.7943 - val_output1_accuracy: 0.7043 - val_output1_loss: 0.9804 - val_output2_accuracy: 0.8077 - val_output2_loss: 0.8014 - learning_rate: 4.0000e-05\n",
      "Epoch 55/250\n",
      "\u001b[1m699/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4855 - output1_accuracy: 0.8102 - output1_loss: 0.7915 - output2_accuracy: 0.8739 - output2_loss: 0.6815\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4855 - output1_accuracy: 0.8102 - output1_loss: 0.7915 - output2_accuracy: 0.8740 - output2_loss: 0.6814 - val_loss: 1.7769 - val_output1_accuracy: 0.7143 - val_output1_loss: 0.9603 - val_output2_accuracy: 0.8037 - val_output2_loss: 0.8040 - learning_rate: 4.0000e-05\n",
      "Epoch 56/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4748 - output1_accuracy: 0.8093 - output1_loss: 0.7932 - output2_accuracy: 0.8787 - output2_loss: 0.6690 - val_loss: 1.7462 - val_output1_accuracy: 0.7244 - val_output1_loss: 0.9480 - val_output2_accuracy: 0.8121 - val_output2_loss: 0.7856 - learning_rate: 8.0000e-06\n",
      "Epoch 57/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4808 - output1_accuracy: 0.8103 - output1_loss: 0.7925 - output2_accuracy: 0.8758 - output2_loss: 0.6758 - val_loss: 1.7785 - val_output1_accuracy: 0.7145 - val_output1_loss: 0.9680 - val_output2_accuracy: 0.8141 - val_output2_loss: 0.7980 - learning_rate: 8.0000e-06\n",
      "Epoch 58/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4828 - output1_accuracy: 0.8058 - output1_loss: 0.7955 - output2_accuracy: 0.8770 - output2_loss: 0.6748 - val_loss: 1.7625 - val_output1_accuracy: 0.7210 - val_output1_loss: 0.9573 - val_output2_accuracy: 0.8085 - val_output2_loss: 0.7927 - learning_rate: 8.0000e-06\n",
      "Epoch 59/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4799 - output1_accuracy: 0.8151 - output1_loss: 0.7871 - output2_accuracy: 0.8742 - output2_loss: 0.6803 - val_loss: 1.7976 - val_output1_accuracy: 0.7085 - val_output1_loss: 0.9726 - val_output2_accuracy: 0.7983 - val_output2_loss: 0.8124 - learning_rate: 8.0000e-06\n",
      "Epoch 60/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4898 - output1_accuracy: 0.8082 - output1_loss: 0.7953 - output2_accuracy: 0.8743 - output2_loss: 0.6820 - val_loss: 1.7777 - val_output1_accuracy: 0.7163 - val_output1_loss: 0.9680 - val_output2_accuracy: 0.8083 - val_output2_loss: 0.7972 - learning_rate: 8.0000e-06\n",
      "Epoch 61/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4774 - output1_accuracy: 0.8093 - output1_loss: 0.7890 - output2_accuracy: 0.8759 - output2_loss: 0.6758\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4774 - output1_accuracy: 0.8093 - output1_loss: 0.7890 - output2_accuracy: 0.8759 - output2_loss: 0.6758 - val_loss: 1.7950 - val_output1_accuracy: 0.7125 - val_output1_loss: 0.9739 - val_output2_accuracy: 0.7973 - val_output2_loss: 0.8086 - learning_rate: 8.0000e-06\n",
      "Epoch 62/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4792 - output1_accuracy: 0.8114 - output1_loss: 0.7896 - output2_accuracy: 0.8756 - output2_loss: 0.6771 - val_loss: 1.7773 - val_output1_accuracy: 0.7145 - val_output1_loss: 0.9656 - val_output2_accuracy: 0.8085 - val_output2_loss: 0.7992 - learning_rate: 1.6000e-06\n",
      "Epoch 63/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4792 - output1_accuracy: 0.8095 - output1_loss: 0.7903 - output2_accuracy: 0.8747 - output2_loss: 0.6764 - val_loss: 1.7728 - val_output1_accuracy: 0.7123 - val_output1_loss: 0.9524 - val_output2_accuracy: 0.8003 - val_output2_loss: 0.8079 - learning_rate: 1.6000e-06\n",
      "Epoch 64/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.4840 - output1_accuracy: 0.8076 - output1_loss: 0.7937 - output2_accuracy: 0.8727 - output2_loss: 0.6778 - val_loss: 1.7824 - val_output1_accuracy: 0.7091 - val_output1_loss: 0.9700 - val_output2_accuracy: 0.8143 - val_output2_loss: 0.7999 - learning_rate: 1.6000e-06\n",
      "Epoch 65/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4746 - output1_accuracy: 0.8142 - output1_loss: 0.7848 - output2_accuracy: 0.8721 - output2_loss: 0.6773 - val_loss: 1.8101 - val_output1_accuracy: 0.7037 - val_output1_loss: 0.9851 - val_output2_accuracy: 0.7977 - val_output2_loss: 0.8125 - learning_rate: 1.6000e-06\n",
      "Epoch 66/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4704 - output1_accuracy: 0.8127 - output1_loss: 0.7852 - output2_accuracy: 0.8800 - output2_loss: 0.6727\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.4704 - output1_accuracy: 0.8127 - output1_loss: 0.7852 - output2_accuracy: 0.8800 - output2_loss: 0.6727 - val_loss: 1.7786 - val_output1_accuracy: 0.7147 - val_output1_loss: 0.9701 - val_output2_accuracy: 0.8047 - val_output2_loss: 0.7960 - learning_rate: 1.6000e-06\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "model = ACCNRR3()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.1), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=1e-9, verbose=1)\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7647300004959107\n",
      "standard deviation =  0.0036044590901915708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACCNRR4():\n",
    "    # CIFAR-10\n",
    "    inputs = keras.Input(shape=(32,32,3))\n",
    "    inputs = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    # Feature Extractor\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(96, (3,3), activation='relu', strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(192, (3,3), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # Classifers\n",
    "    x1 = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.Conv2D(192, (1,1), activation='relu')(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "    x2 = layers.Conv2D(192, (3,3), activation='relu', strides=2)(x)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.Conv2D(192, (1,1), activation='relu')(x2)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.GlobalAveragePooling2D()(x2)\n",
    "    #x = layers.Flatten()(x)\n",
    "    output1 = layers.Dense(5, activation='softmax', name='output1', kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "    output2 = layers.Dense(5, activation='softmax', name='output2', kernel_regularizer=regularizers.l2(0.01))(x2)\n",
    "    # Model creation\n",
    "    model = keras.Model(\n",
    "        inputs,\n",
    "        outputs={'output1':output1, 'output2':output2}, name='ACCNRR4',\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ACCNRR4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ACCNRR4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_1CLONE │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ keras_tensor_1CL… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">331,968</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">965</span> │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_1CLONE │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │      \u001b[38;5;34m2,688\u001b[0m │ keras_tensor_1CL… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m83,040\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m384\u001b[0m │ conv2d_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m96\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │    \u001b[38;5;34m166,080\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m,    │        \u001b[38;5;34m768\u001b[0m │ conv2d_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m192\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_4[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │    \u001b[38;5;34m331,968\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_5[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_7[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │     \u001b[38;5;34m37,056\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_6[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ conv2d_8[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m965\u001b[0m │ global_average_p… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,412,554</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,412,554\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409,674</span> (5.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,409,674\u001b[0m (5.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - loss: 3.0740 - output1_accuracy: 0.3799 - output1_loss: 1.5243 - output2_accuracy: 0.4385 - output2_loss: 1.4133 - val_loss: 3.1164 - val_output1_accuracy: 0.3590 - val_output1_loss: 1.5732 - val_output2_accuracy: 0.4087 - val_output2_loss: 1.5015 - learning_rate: 0.0010\n",
      "Epoch 2/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.4760 - output1_accuracy: 0.5226 - output1_loss: 1.3433 - output2_accuracy: 0.6347 - output2_loss: 1.1008 - val_loss: 2.5771 - val_output1_accuracy: 0.5162 - val_output1_loss: 1.3523 - val_output2_accuracy: 0.5647 - val_output2_loss: 1.2064 - learning_rate: 0.0010\n",
      "Epoch 3/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 2.3311 - output1_accuracy: 0.5637 - output1_loss: 1.2911 - output2_accuracy: 0.6774 - output2_loss: 1.0228 - val_loss: 2.5407 - val_output1_accuracy: 0.5142 - val_output1_loss: 1.3686 - val_output2_accuracy: 0.5994 - val_output2_loss: 1.1563 - learning_rate: 0.0010\n",
      "Epoch 4/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.2281 - output1_accuracy: 0.6011 - output1_loss: 1.2496 - output2_accuracy: 0.7135 - output2_loss: 0.9629 - val_loss: 2.5560 - val_output1_accuracy: 0.4914 - val_output1_loss: 1.4040 - val_output2_accuracy: 0.6210 - val_output2_loss: 1.1373 - learning_rate: 0.0010\n",
      "Epoch 5/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.1689 - output1_accuracy: 0.6204 - output1_loss: 1.2219 - output2_accuracy: 0.7305 - output2_loss: 0.9322 - val_loss: 2.4938 - val_output1_accuracy: 0.4966 - val_output1_loss: 1.4147 - val_output2_accuracy: 0.6585 - val_output2_loss: 1.0641 - learning_rate: 0.0010\n",
      "Epoch 6/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 2.1316 - output1_accuracy: 0.6360 - output1_loss: 1.2080 - output2_accuracy: 0.7446 - output2_loss: 0.9090 - val_loss: 2.4048 - val_output1_accuracy: 0.5669 - val_output1_loss: 1.2979 - val_output2_accuracy: 0.6558 - val_output2_loss: 1.0931 - learning_rate: 0.0010\n",
      "Epoch 7/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0922 - output1_accuracy: 0.6449 - output1_loss: 1.1916 - output2_accuracy: 0.7539 - output2_loss: 0.8865 - val_loss: 2.3116 - val_output1_accuracy: 0.6094 - val_output1_loss: 1.2353 - val_output2_accuracy: 0.6741 - val_output2_loss: 1.0629 - learning_rate: 0.0010\n",
      "Epoch 8/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0706 - output1_accuracy: 0.6589 - output1_loss: 1.1757 - output2_accuracy: 0.7580 - output2_loss: 0.8813 - val_loss: 2.3583 - val_output1_accuracy: 0.5605 - val_output1_loss: 1.3371 - val_output2_accuracy: 0.6955 - val_output2_loss: 1.0075 - learning_rate: 0.0010\n",
      "Epoch 9/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0374 - output1_accuracy: 0.6713 - output1_loss: 1.1623 - output2_accuracy: 0.7711 - output2_loss: 0.8618 - val_loss: 2.3545 - val_output1_accuracy: 0.5631 - val_output1_loss: 1.3092 - val_output2_accuracy: 0.6875 - val_output2_loss: 1.0316 - learning_rate: 0.0010\n",
      "Epoch 10/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 2.0161 - output1_accuracy: 0.6800 - output1_loss: 1.1517 - output2_accuracy: 0.7737 - output2_loss: 0.8510 - val_loss: 2.1307 - val_output1_accuracy: 0.6464 - val_output1_loss: 1.2082 - val_output2_accuracy: 0.7418 - val_output2_loss: 0.9092 - learning_rate: 0.0010\n",
      "Epoch 11/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9971 - output1_accuracy: 0.6835 - output1_loss: 1.1457 - output2_accuracy: 0.7815 - output2_loss: 0.8387 - val_loss: 2.1802 - val_output1_accuracy: 0.6288 - val_output1_loss: 1.2362 - val_output2_accuracy: 0.7304 - val_output2_loss: 0.9315 - learning_rate: 0.0010\n",
      "Epoch 12/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9651 - output1_accuracy: 0.6961 - output1_loss: 1.1296 - output2_accuracy: 0.7914 - output2_loss: 0.8229 - val_loss: 2.2484 - val_output1_accuracy: 0.6036 - val_output1_loss: 1.2590 - val_output2_accuracy: 0.7194 - val_output2_loss: 0.9772 - learning_rate: 0.0010\n",
      "Epoch 13/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9574 - output1_accuracy: 0.6942 - output1_loss: 1.1276 - output2_accuracy: 0.7960 - output2_loss: 0.8174 - val_loss: 2.1938 - val_output1_accuracy: 0.5980 - val_output1_loss: 1.2538 - val_output2_accuracy: 0.7310 - val_output2_loss: 0.9275 - learning_rate: 0.0010\n",
      "Epoch 14/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9375 - output1_accuracy: 0.7087 - output1_loss: 1.1171 - output2_accuracy: 0.8019 - output2_loss: 0.8081 - val_loss: 2.2027 - val_output1_accuracy: 0.6204 - val_output1_loss: 1.2255 - val_output2_accuracy: 0.7198 - val_output2_loss: 0.9650 - learning_rate: 0.0010\n",
      "Epoch 15/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9219 - output1_accuracy: 0.7108 - output1_loss: 1.1113 - output2_accuracy: 0.8066 - output2_loss: 0.7985\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.9219 - output1_accuracy: 0.7108 - output1_loss: 1.1113 - output2_accuracy: 0.8066 - output2_loss: 0.7985 - val_loss: 2.2549 - val_output1_accuracy: 0.6380 - val_output1_loss: 1.1987 - val_output2_accuracy: 0.6819 - val_output2_loss: 1.0438 - learning_rate: 0.0010\n",
      "Epoch 16/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8677 - output1_accuracy: 0.7272 - output1_loss: 1.0901 - output2_accuracy: 0.8228 - output2_loss: 0.7653 - val_loss: 2.0187 - val_output1_accuracy: 0.6729 - val_output1_loss: 1.1500 - val_output2_accuracy: 0.7712 - val_output2_loss: 0.8566 - learning_rate: 2.0000e-04\n",
      "Epoch 17/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8348 - output1_accuracy: 0.7425 - output1_loss: 1.0706 - output2_accuracy: 0.8300 - output2_loss: 0.7519 - val_loss: 1.9664 - val_output1_accuracy: 0.6991 - val_output1_loss: 1.1329 - val_output2_accuracy: 0.7981 - val_output2_loss: 0.8212 - learning_rate: 2.0000e-04\n",
      "Epoch 18/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8288 - output1_accuracy: 0.7399 - output1_loss: 1.0730 - output2_accuracy: 0.8361 - output2_loss: 0.7436 - val_loss: 1.9936 - val_output1_accuracy: 0.6821 - val_output1_loss: 1.1399 - val_output2_accuracy: 0.7778 - val_output2_loss: 0.8414 - learning_rate: 2.0000e-04\n",
      "Epoch 19/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8259 - output1_accuracy: 0.7450 - output1_loss: 1.0673 - output2_accuracy: 0.8349 - output2_loss: 0.7463 - val_loss: 1.9607 - val_output1_accuracy: 0.6975 - val_output1_loss: 1.1330 - val_output2_accuracy: 0.7985 - val_output2_loss: 0.8152 - learning_rate: 2.0000e-04\n",
      "Epoch 20/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8098 - output1_accuracy: 0.7474 - output1_loss: 1.0628 - output2_accuracy: 0.8425 - output2_loss: 0.7346 - val_loss: 2.0204 - val_output1_accuracy: 0.6795 - val_output1_loss: 1.1497 - val_output2_accuracy: 0.7680 - val_output2_loss: 0.8584 - learning_rate: 2.0000e-04\n",
      "Epoch 21/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.8021 - output1_accuracy: 0.7497 - output1_loss: 1.0589 - output2_accuracy: 0.8464 - output2_loss: 0.7310 - val_loss: 1.9694 - val_output1_accuracy: 0.6883 - val_output1_loss: 1.1368 - val_output2_accuracy: 0.7887 - val_output2_loss: 0.8204 - learning_rate: 2.0000e-04\n",
      "Epoch 22/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7968 - output1_accuracy: 0.7522 - output1_loss: 1.0588 - output2_accuracy: 0.8437 - output2_loss: 0.7258 - val_loss: 1.9488 - val_output1_accuracy: 0.7037 - val_output1_loss: 1.1329 - val_output2_accuracy: 0.8083 - val_output2_loss: 0.8038 - learning_rate: 2.0000e-04\n",
      "Epoch 23/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7879 - output1_accuracy: 0.7569 - output1_loss: 1.0506 - output2_accuracy: 0.8482 - output2_loss: 0.7252 - val_loss: 1.9470 - val_output1_accuracy: 0.6931 - val_output1_loss: 1.1389 - val_output2_accuracy: 0.8125 - val_output2_loss: 0.7960 - learning_rate: 2.0000e-04\n",
      "Epoch 24/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7856 - output1_accuracy: 0.7626 - output1_loss: 1.0475 - output2_accuracy: 0.8470 - output2_loss: 0.7260 - val_loss: 1.9623 - val_output1_accuracy: 0.6905 - val_output1_loss: 1.1383 - val_output2_accuracy: 0.7933 - val_output2_loss: 0.8119 - learning_rate: 2.0000e-04\n",
      "Epoch 25/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7826 - output1_accuracy: 0.7578 - output1_loss: 1.0477 - output2_accuracy: 0.8478 - output2_loss: 0.7227 - val_loss: 1.9640 - val_output1_accuracy: 0.6913 - val_output1_loss: 1.1337 - val_output2_accuracy: 0.7969 - val_output2_loss: 0.8182 - learning_rate: 2.0000e-04\n",
      "Epoch 26/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7752 - output1_accuracy: 0.7571 - output1_loss: 1.0488 - output2_accuracy: 0.8540 - output2_loss: 0.7144 - val_loss: 1.9411 - val_output1_accuracy: 0.7015 - val_output1_loss: 1.1224 - val_output2_accuracy: 0.8015 - val_output2_loss: 0.8067 - learning_rate: 2.0000e-04\n",
      "Epoch 27/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7677 - output1_accuracy: 0.7614 - output1_loss: 1.0418 - output2_accuracy: 0.8543 - output2_loss: 0.7138 - val_loss: 1.9642 - val_output1_accuracy: 0.6853 - val_output1_loss: 1.1392 - val_output2_accuracy: 0.7977 - val_output2_loss: 0.8130 - learning_rate: 2.0000e-04\n",
      "Epoch 28/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7679 - output1_accuracy: 0.7659 - output1_loss: 1.0392 - output2_accuracy: 0.8524 - output2_loss: 0.7166 - val_loss: 1.9629 - val_output1_accuracy: 0.6969 - val_output1_loss: 1.1332 - val_output2_accuracy: 0.7971 - val_output2_loss: 0.8176 - learning_rate: 2.0000e-04\n",
      "Epoch 29/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7672 - output1_accuracy: 0.7633 - output1_loss: 1.0409 - output2_accuracy: 0.8535 - output2_loss: 0.7143 - val_loss: 1.9742 - val_output1_accuracy: 0.6821 - val_output1_loss: 1.1499 - val_output2_accuracy: 0.7981 - val_output2_loss: 0.8125 - learning_rate: 2.0000e-04\n",
      "Epoch 30/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7617 - output1_accuracy: 0.7639 - output1_loss: 1.0394 - output2_accuracy: 0.8535 - output2_loss: 0.7105 - val_loss: 1.9881 - val_output1_accuracy: 0.6805 - val_output1_loss: 1.1548 - val_output2_accuracy: 0.7977 - val_output2_loss: 0.8215 - learning_rate: 2.0000e-04\n",
      "Epoch 31/250\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7525 - output1_accuracy: 0.7693 - output1_loss: 1.0369 - output2_accuracy: 0.8601 - output2_loss: 0.7039\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7525 - output1_accuracy: 0.7693 - output1_loss: 1.0369 - output2_accuracy: 0.8601 - output2_loss: 0.7039 - val_loss: 1.9436 - val_output1_accuracy: 0.6991 - val_output1_loss: 1.1202 - val_output2_accuracy: 0.7993 - val_output2_loss: 0.8117 - learning_rate: 2.0000e-04\n",
      "Epoch 32/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7502 - output1_accuracy: 0.7682 - output1_loss: 1.0365 - output2_accuracy: 0.8608 - output2_loss: 0.7019 - val_loss: 1.9372 - val_output1_accuracy: 0.7023 - val_output1_loss: 1.1209 - val_output2_accuracy: 0.8011 - val_output2_loss: 0.8045 - learning_rate: 4.0000e-05\n",
      "Epoch 33/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7370 - output1_accuracy: 0.7742 - output1_loss: 1.0268 - output2_accuracy: 0.8638 - output2_loss: 0.6983 - val_loss: 1.9426 - val_output1_accuracy: 0.6993 - val_output1_loss: 1.1227 - val_output2_accuracy: 0.8039 - val_output2_loss: 0.8080 - learning_rate: 4.0000e-05\n",
      "Epoch 34/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7369 - output1_accuracy: 0.7740 - output1_loss: 1.0291 - output2_accuracy: 0.8675 - output2_loss: 0.6959 - val_loss: 1.9327 - val_output1_accuracy: 0.7091 - val_output1_loss: 1.1187 - val_output2_accuracy: 0.8009 - val_output2_loss: 0.8022 - learning_rate: 4.0000e-05\n",
      "Epoch 35/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7334 - output1_accuracy: 0.7767 - output1_loss: 1.0243 - output2_accuracy: 0.8638 - output2_loss: 0.6973 - val_loss: 1.9253 - val_output1_accuracy: 0.7101 - val_output1_loss: 1.1141 - val_output2_accuracy: 0.8061 - val_output2_loss: 0.7993 - learning_rate: 4.0000e-05\n",
      "Epoch 36/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7291 - output1_accuracy: 0.7779 - output1_loss: 1.0242 - output2_accuracy: 0.8658 - output2_loss: 0.6930 - val_loss: 1.9301 - val_output1_accuracy: 0.6951 - val_output1_loss: 1.1341 - val_output2_accuracy: 0.8137 - val_output2_loss: 0.7840 - learning_rate: 4.0000e-05\n",
      "Epoch 37/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7347 - output1_accuracy: 0.7747 - output1_loss: 1.0310 - output2_accuracy: 0.8664 - output2_loss: 0.6918 - val_loss: 1.9414 - val_output1_accuracy: 0.6957 - val_output1_loss: 1.1323 - val_output2_accuracy: 0.8027 - val_output2_loss: 0.7972 - learning_rate: 4.0000e-05\n",
      "Epoch 38/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 1.7349 - output1_accuracy: 0.7744 - output1_loss: 1.0263 - output2_accuracy: 0.8649 - output2_loss: 0.6966 - val_loss: 1.9264 - val_output1_accuracy: 0.6995 - val_output1_loss: 1.1244 - val_output2_accuracy: 0.8109 - val_output2_loss: 0.7902 - learning_rate: 4.0000e-05\n",
      "Epoch 39/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7356 - output1_accuracy: 0.7747 - output1_loss: 1.0258 - output2_accuracy: 0.8643 - output2_loss: 0.6979 - val_loss: 1.9260 - val_output1_accuracy: 0.7005 - val_output1_loss: 1.1145 - val_output2_accuracy: 0.8081 - val_output2_loss: 0.7996 - learning_rate: 4.0000e-05\n",
      "Epoch 40/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7244 - output1_accuracy: 0.7779 - output1_loss: 1.0248 - output2_accuracy: 0.8692 - output2_loss: 0.6877\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7244 - output1_accuracy: 0.7779 - output1_loss: 1.0248 - output2_accuracy: 0.8692 - output2_loss: 0.6877 - val_loss: 1.9467 - val_output1_accuracy: 0.6947 - val_output1_loss: 1.1282 - val_output2_accuracy: 0.8007 - val_output2_loss: 0.8066 - learning_rate: 4.0000e-05\n",
      "Epoch 41/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 1.7191 - output1_accuracy: 0.7806 - output1_loss: 1.0207 - output2_accuracy: 0.8703 - output2_loss: 0.6865 - val_loss: 1.9421 - val_output1_accuracy: 0.7063 - val_output1_loss: 1.1156 - val_output2_accuracy: 0.7939 - val_output2_loss: 0.8146 - learning_rate: 8.0000e-06\n",
      "Epoch 42/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 1.7188 - output1_accuracy: 0.7853 - output1_loss: 1.0203 - output2_accuracy: 0.8705 - output2_loss: 0.6866 - val_loss: 1.9283 - val_output1_accuracy: 0.6973 - val_output1_loss: 1.1215 - val_output2_accuracy: 0.8059 - val_output2_loss: 0.7948 - learning_rate: 8.0000e-06\n",
      "Epoch 43/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 1.7263 - output1_accuracy: 0.7800 - output1_loss: 1.0197 - output2_accuracy: 0.8630 - output2_loss: 0.6946 - val_loss: 1.9335 - val_output1_accuracy: 0.7055 - val_output1_loss: 1.1216 - val_output2_accuracy: 0.8069 - val_output2_loss: 0.7999 - learning_rate: 8.0000e-06\n",
      "Epoch 44/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7256 - output1_accuracy: 0.7776 - output1_loss: 1.0260 - output2_accuracy: 0.8698 - output2_loss: 0.6876 - val_loss: 1.9203 - val_output1_accuracy: 0.7045 - val_output1_loss: 1.1172 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.7912 - learning_rate: 8.0000e-06\n",
      "Epoch 45/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7285 - output1_accuracy: 0.7753 - output1_loss: 1.0270 - output2_accuracy: 0.8662 - output2_loss: 0.6896 - val_loss: 1.9321 - val_output1_accuracy: 0.7143 - val_output1_loss: 1.1118 - val_output2_accuracy: 0.7997 - val_output2_loss: 0.8084 - learning_rate: 8.0000e-06\n",
      "Epoch 46/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7179 - output1_accuracy: 0.7830 - output1_loss: 1.0189 - output2_accuracy: 0.8668 - output2_loss: 0.6871 - val_loss: 1.9596 - val_output1_accuracy: 0.6959 - val_output1_loss: 1.1309 - val_output2_accuracy: 0.7921 - val_output2_loss: 0.8168 - learning_rate: 8.0000e-06\n",
      "Epoch 47/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7282 - output1_accuracy: 0.7772 - output1_loss: 1.0274 - output2_accuracy: 0.8688 - output2_loss: 0.6889 - val_loss: 1.9205 - val_output1_accuracy: 0.7113 - val_output1_loss: 1.1053 - val_output2_accuracy: 0.8049 - val_output2_loss: 0.8033 - learning_rate: 8.0000e-06\n",
      "Epoch 48/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7205 - output1_accuracy: 0.7806 - output1_loss: 1.0205 - output2_accuracy: 0.8680 - output2_loss: 0.6881 - val_loss: 1.9257 - val_output1_accuracy: 0.6963 - val_output1_loss: 1.1184 - val_output2_accuracy: 0.8023 - val_output2_loss: 0.7954 - learning_rate: 8.0000e-06\n",
      "Epoch 49/250\n",
      "\u001b[1m702/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7312 - output1_accuracy: 0.7766 - output1_loss: 1.0289 - output2_accuracy: 0.8683 - output2_loss: 0.6904\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7312 - output1_accuracy: 0.7766 - output1_loss: 1.0289 - output2_accuracy: 0.8683 - output2_loss: 0.6904 - val_loss: 1.9468 - val_output1_accuracy: 0.6963 - val_output1_loss: 1.1333 - val_output2_accuracy: 0.8033 - val_output2_loss: 0.8015 - learning_rate: 8.0000e-06\n",
      "Epoch 50/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7191 - output1_accuracy: 0.7781 - output1_loss: 1.0201 - output2_accuracy: 0.8695 - output2_loss: 0.6871 - val_loss: 1.9486 - val_output1_accuracy: 0.6939 - val_output1_loss: 1.1270 - val_output2_accuracy: 0.8009 - val_output2_loss: 0.8097 - learning_rate: 1.6000e-06\n",
      "Epoch 51/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7166 - output1_accuracy: 0.7836 - output1_loss: 1.0179 - output2_accuracy: 0.8715 - output2_loss: 0.6867 - val_loss: 1.9216 - val_output1_accuracy: 0.7021 - val_output1_loss: 1.1182 - val_output2_accuracy: 0.8107 - val_output2_loss: 0.7915 - learning_rate: 1.6000e-06\n",
      "Epoch 52/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7275 - output1_accuracy: 0.7776 - output1_loss: 1.0251 - output2_accuracy: 0.8678 - output2_loss: 0.6905 - val_loss: 1.9348 - val_output1_accuracy: 0.7113 - val_output1_loss: 1.1193 - val_output2_accuracy: 0.8043 - val_output2_loss: 0.8036 - learning_rate: 1.6000e-06\n",
      "Epoch 53/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7220 - output1_accuracy: 0.7776 - output1_loss: 1.0248 - output2_accuracy: 0.8713 - output2_loss: 0.6852 - val_loss: 1.9203 - val_output1_accuracy: 0.7125 - val_output1_loss: 1.1103 - val_output2_accuracy: 0.8087 - val_output2_loss: 0.7981 - learning_rate: 1.6000e-06\n",
      "Epoch 54/250\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7184 - output1_accuracy: 0.7819 - output1_loss: 1.0179 - output2_accuracy: 0.8699 - output2_loss: 0.6886\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7184 - output1_accuracy: 0.7819 - output1_loss: 1.0179 - output2_accuracy: 0.8699 - output2_loss: 0.6886 - val_loss: 1.9273 - val_output1_accuracy: 0.7021 - val_output1_loss: 1.1185 - val_output2_accuracy: 0.8019 - val_output2_loss: 0.7969 - learning_rate: 1.6000e-06\n",
      "Epoch 55/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7188 - output1_accuracy: 0.7806 - output1_loss: 1.0208 - output2_accuracy: 0.8720 - output2_loss: 0.6860 - val_loss: 1.9273 - val_output1_accuracy: 0.7077 - val_output1_loss: 1.1187 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.7966 - learning_rate: 3.2000e-07\n",
      "Epoch 56/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7178 - output1_accuracy: 0.7814 - output1_loss: 1.0215 - output2_accuracy: 0.8684 - output2_loss: 0.6844 - val_loss: 1.9337 - val_output1_accuracy: 0.7041 - val_output1_loss: 1.1200 - val_output2_accuracy: 0.8063 - val_output2_loss: 0.8018 - learning_rate: 3.2000e-07\n",
      "Epoch 57/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7163 - output1_accuracy: 0.7825 - output1_loss: 1.0210 - output2_accuracy: 0.8723 - output2_loss: 0.6834 - val_loss: 1.9517 - val_output1_accuracy: 0.6879 - val_output1_loss: 1.1332 - val_output2_accuracy: 0.8027 - val_output2_loss: 0.8066 - learning_rate: 3.2000e-07\n",
      "Epoch 58/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7219 - output1_accuracy: 0.7769 - output1_loss: 1.0249 - output2_accuracy: 0.8703 - output2_loss: 0.6850 - val_loss: 1.9370 - val_output1_accuracy: 0.7085 - val_output1_loss: 1.1150 - val_output2_accuracy: 0.8083 - val_output2_loss: 0.8100 - learning_rate: 3.2000e-07\n",
      "Epoch 59/250\n",
      "\u001b[1m700/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7238 - output1_accuracy: 0.7809 - output1_loss: 1.0220 - output2_accuracy: 0.8680 - output2_loss: 0.6899\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7238 - output1_accuracy: 0.7809 - output1_loss: 1.0220 - output2_accuracy: 0.8680 - output2_loss: 0.6899 - val_loss: 1.9542 - val_output1_accuracy: 0.6907 - val_output1_loss: 1.1316 - val_output2_accuracy: 0.8031 - val_output2_loss: 0.8107 - learning_rate: 3.2000e-07\n",
      "Epoch 60/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7246 - output1_accuracy: 0.7783 - output1_loss: 1.0219 - output2_accuracy: 0.8646 - output2_loss: 0.6907 - val_loss: 1.9376 - val_output1_accuracy: 0.7069 - val_output1_loss: 1.1201 - val_output2_accuracy: 0.8005 - val_output2_loss: 0.8056 - learning_rate: 6.4000e-08\n",
      "Epoch 61/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7228 - output1_accuracy: 0.7785 - output1_loss: 1.0247 - output2_accuracy: 0.8695 - output2_loss: 0.6862 - val_loss: 1.9416 - val_output1_accuracy: 0.7015 - val_output1_loss: 1.1281 - val_output2_accuracy: 0.8043 - val_output2_loss: 0.8016 - learning_rate: 6.4000e-08\n",
      "Epoch 62/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7217 - output1_accuracy: 0.7794 - output1_loss: 1.0208 - output2_accuracy: 0.8669 - output2_loss: 0.6890 - val_loss: 1.9286 - val_output1_accuracy: 0.7061 - val_output1_loss: 1.1207 - val_output2_accuracy: 0.8079 - val_output2_loss: 0.7959 - learning_rate: 6.4000e-08\n",
      "Epoch 63/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 1.7201 - output1_accuracy: 0.7789 - output1_loss: 1.0215 - output2_accuracy: 0.8685 - output2_loss: 0.6866 - val_loss: 1.9296 - val_output1_accuracy: 0.6989 - val_output1_loss: 1.1226 - val_output2_accuracy: 0.8077 - val_output2_loss: 0.7950 - learning_rate: 6.4000e-08\n",
      "Epoch 64/250\n",
      "\u001b[1m701/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7168 - output1_accuracy: 0.7840 - output1_loss: 1.0178 - output2_accuracy: 0.8689 - output2_loss: 0.6870\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7168 - output1_accuracy: 0.7840 - output1_loss: 1.0178 - output2_accuracy: 0.8689 - output2_loss: 0.6870 - val_loss: 1.9338 - val_output1_accuracy: 0.7033 - val_output1_loss: 1.1210 - val_output2_accuracy: 0.8021 - val_output2_loss: 0.8009 - learning_rate: 6.4000e-08\n",
      "Epoch 65/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7192 - output1_accuracy: 0.7831 - output1_loss: 1.0184 - output2_accuracy: 0.8680 - output2_loss: 0.6889 - val_loss: 1.9377 - val_output1_accuracy: 0.6955 - val_output1_loss: 1.1294 - val_output2_accuracy: 0.8127 - val_output2_loss: 0.7963 - learning_rate: 1.2800e-08\n",
      "Epoch 66/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7224 - output1_accuracy: 0.7781 - output1_loss: 1.0263 - output2_accuracy: 0.8717 - output2_loss: 0.6842 - val_loss: 1.9257 - val_output1_accuracy: 0.7039 - val_output1_loss: 1.1132 - val_output2_accuracy: 0.8071 - val_output2_loss: 0.8006 - learning_rate: 1.2800e-08\n",
      "Epoch 67/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7185 - output1_accuracy: 0.7792 - output1_loss: 1.0196 - output2_accuracy: 0.8703 - output2_loss: 0.6870 - val_loss: 1.9214 - val_output1_accuracy: 0.7083 - val_output1_loss: 1.1170 - val_output2_accuracy: 0.8127 - val_output2_loss: 0.7925 - learning_rate: 1.2800e-08\n",
      "Epoch 68/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7176 - output1_accuracy: 0.7814 - output1_loss: 1.0193 - output2_accuracy: 0.8726 - output2_loss: 0.6864 - val_loss: 1.9238 - val_output1_accuracy: 0.7057 - val_output1_loss: 1.1179 - val_output2_accuracy: 0.8115 - val_output2_loss: 0.7940 - learning_rate: 1.2800e-08\n",
      "Epoch 69/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7264 - output1_accuracy: 0.7753 - output1_loss: 1.0241 - output2_accuracy: 0.8680 - output2_loss: 0.6903 - val_loss: 1.9199 - val_output1_accuracy: 0.7061 - val_output1_loss: 1.1150 - val_output2_accuracy: 0.8099 - val_output2_loss: 0.7930 - learning_rate: 1.2800e-08\n",
      "Epoch 70/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7256 - output1_accuracy: 0.7774 - output1_loss: 1.0235 - output2_accuracy: 0.8669 - output2_loss: 0.6902 - val_loss: 1.9389 - val_output1_accuracy: 0.7043 - val_output1_loss: 1.1243 - val_output2_accuracy: 0.8061 - val_output2_loss: 0.8027 - learning_rate: 1.2800e-08\n",
      "Epoch 71/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7248 - output1_accuracy: 0.7740 - output1_loss: 1.0267 - output2_accuracy: 0.8700 - output2_loss: 0.6861 - val_loss: 1.9537 - val_output1_accuracy: 0.6993 - val_output1_loss: 1.1256 - val_output2_accuracy: 0.7927 - val_output2_loss: 0.8162 - learning_rate: 1.2800e-08\n",
      "Epoch 72/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7212 - output1_accuracy: 0.7799 - output1_loss: 1.0237 - output2_accuracy: 0.8688 - output2_loss: 0.6856 - val_loss: 1.9231 - val_output1_accuracy: 0.7113 - val_output1_loss: 1.1154 - val_output2_accuracy: 0.8087 - val_output2_loss: 0.7958 - learning_rate: 1.2800e-08\n",
      "Epoch 73/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7211 - output1_accuracy: 0.7781 - output1_loss: 1.0215 - output2_accuracy: 0.8681 - output2_loss: 0.6876 - val_loss: 1.9252 - val_output1_accuracy: 0.7093 - val_output1_loss: 1.1104 - val_output2_accuracy: 0.8035 - val_output2_loss: 0.8028 - learning_rate: 1.2800e-08\n",
      "Epoch 74/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7291 - output1_accuracy: 0.7795 - output1_loss: 1.0222 - output2_accuracy: 0.8640 - output2_loss: 0.6950\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.7291 - output1_accuracy: 0.7795 - output1_loss: 1.0222 - output2_accuracy: 0.8640 - output2_loss: 0.6950 - val_loss: 1.9280 - val_output1_accuracy: 0.7107 - val_output1_loss: 1.1114 - val_output2_accuracy: 0.8027 - val_output2_loss: 0.8047 - learning_rate: 1.2800e-08\n",
      "Epoch 75/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7219 - output1_accuracy: 0.7816 - output1_loss: 1.0218 - output2_accuracy: 0.8679 - output2_loss: 0.6882 - val_loss: 1.9228 - val_output1_accuracy: 0.7041 - val_output1_loss: 1.1272 - val_output2_accuracy: 0.8167 - val_output2_loss: 0.7837 - learning_rate: 2.5600e-09\n",
      "Epoch 76/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7252 - output1_accuracy: 0.7740 - output1_loss: 1.0260 - output2_accuracy: 0.8699 - output2_loss: 0.6873 - val_loss: 1.9332 - val_output1_accuracy: 0.7005 - val_output1_loss: 1.1203 - val_output2_accuracy: 0.8093 - val_output2_loss: 0.8009 - learning_rate: 2.5600e-09\n",
      "Epoch 77/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7113 - output1_accuracy: 0.7868 - output1_loss: 1.0161 - output2_accuracy: 0.8705 - output2_loss: 0.6832 - val_loss: 1.9509 - val_output1_accuracy: 0.6899 - val_output1_loss: 1.1362 - val_output2_accuracy: 0.8031 - val_output2_loss: 0.8028 - learning_rate: 2.5600e-09\n",
      "Epoch 78/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7218 - output1_accuracy: 0.7839 - output1_loss: 1.0155 - output2_accuracy: 0.8654 - output2_loss: 0.6944 - val_loss: 1.9283 - val_output1_accuracy: 0.7069 - val_output1_loss: 1.1156 - val_output2_accuracy: 0.8085 - val_output2_loss: 0.8007 - learning_rate: 2.5600e-09\n",
      "Epoch 79/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7168 - output1_accuracy: 0.7788 - output1_loss: 1.0197 - output2_accuracy: 0.8727 - output2_loss: 0.6852\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1e-09.\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7168 - output1_accuracy: 0.7788 - output1_loss: 1.0197 - output2_accuracy: 0.8727 - output2_loss: 0.6852 - val_loss: 1.9258 - val_output1_accuracy: 0.7041 - val_output1_loss: 1.1186 - val_output2_accuracy: 0.8049 - val_output2_loss: 0.7953 - learning_rate: 2.5600e-09\n",
      "Epoch 80/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7230 - output1_accuracy: 0.7802 - output1_loss: 1.0214 - output2_accuracy: 0.8686 - output2_loss: 0.6897 - val_loss: 1.9224 - val_output1_accuracy: 0.7081 - val_output1_loss: 1.1113 - val_output2_accuracy: 0.8071 - val_output2_loss: 0.7992 - learning_rate: 1.0000e-09\n",
      "Epoch 81/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7227 - output1_accuracy: 0.7822 - output1_loss: 1.0191 - output2_accuracy: 0.8679 - output2_loss: 0.6916 - val_loss: 1.9353 - val_output1_accuracy: 0.7065 - val_output1_loss: 1.1233 - val_output2_accuracy: 0.8015 - val_output2_loss: 0.8000 - learning_rate: 1.0000e-09\n",
      "Epoch 82/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7161 - output1_accuracy: 0.7785 - output1_loss: 1.0190 - output2_accuracy: 0.8707 - output2_loss: 0.6852 - val_loss: 1.9374 - val_output1_accuracy: 0.7065 - val_output1_loss: 1.1249 - val_output2_accuracy: 0.8021 - val_output2_loss: 0.8006 - learning_rate: 1.0000e-09\n",
      "Epoch 83/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7222 - output1_accuracy: 0.7766 - output1_loss: 1.0211 - output2_accuracy: 0.8669 - output2_loss: 0.6891 - val_loss: 1.9274 - val_output1_accuracy: 0.6947 - val_output1_loss: 1.1277 - val_output2_accuracy: 0.8069 - val_output2_loss: 0.7878 - learning_rate: 1.0000e-09\n",
      "Epoch 84/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7277 - output1_accuracy: 0.7788 - output1_loss: 1.0215 - output2_accuracy: 0.8652 - output2_loss: 0.6943 - val_loss: 1.9602 - val_output1_accuracy: 0.6971 - val_output1_loss: 1.1323 - val_output2_accuracy: 0.7957 - val_output2_loss: 0.8160 - learning_rate: 1.0000e-09\n",
      "Epoch 85/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7215 - output1_accuracy: 0.7838 - output1_loss: 1.0175 - output2_accuracy: 0.8672 - output2_loss: 0.6920 - val_loss: 1.9262 - val_output1_accuracy: 0.7057 - val_output1_loss: 1.1201 - val_output2_accuracy: 0.8109 - val_output2_loss: 0.7941 - learning_rate: 1.0000e-09\n",
      "Epoch 86/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7218 - output1_accuracy: 0.7836 - output1_loss: 1.0196 - output2_accuracy: 0.8660 - output2_loss: 0.6903 - val_loss: 1.9472 - val_output1_accuracy: 0.6993 - val_output1_loss: 1.1285 - val_output2_accuracy: 0.8049 - val_output2_loss: 0.8068 - learning_rate: 1.0000e-09\n",
      "Epoch 87/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 1.7170 - output1_accuracy: 0.7826 - output1_loss: 1.0179 - output2_accuracy: 0.8676 - output2_loss: 0.6872 - val_loss: 1.9373 - val_output1_accuracy: 0.6947 - val_output1_loss: 1.1280 - val_output2_accuracy: 0.8033 - val_output2_loss: 0.7974 - learning_rate: 1.0000e-09\n",
      "Epoch 88/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7209 - output1_accuracy: 0.7794 - output1_loss: 1.0240 - output2_accuracy: 0.8706 - output2_loss: 0.6850 - val_loss: 1.9286 - val_output1_accuracy: 0.7073 - val_output1_loss: 1.1148 - val_output2_accuracy: 0.7991 - val_output2_loss: 0.8018 - learning_rate: 1.0000e-09\n",
      "Epoch 89/250\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 1.7237 - output1_accuracy: 0.7846 - output1_loss: 1.0203 - output2_accuracy: 0.8666 - output2_loss: 0.6914 - val_loss: 1.9370 - val_output1_accuracy: 0.6945 - val_output1_loss: 1.1281 - val_output2_accuracy: 0.8091 - val_output2_loss: 0.7969 - learning_rate: 1.0000e-09\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() # garbage collection\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',  # Track the validation loss\n",
    "                               patience=20,         # Number of epochs to wait after the last improvement\n",
    "                               mode='min',         # Stop when the value stops decreasing (minimization)\n",
    "                               restore_best_weights=True,  # Restore the best weights when stopping\n",
    "                               verbose=1)\n",
    "model = ACCNRR4()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.2), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'output1': keras.losses.CategoricalCrossentropy(label_smoothing=0.2), 'output2': keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=1e-9, verbose=1)\n",
    "history = model.fit(\n",
    "    traingen,            \n",
    "    epochs=250,          \n",
    "    steps_per_epoch=len(cifar10_x_train)//batchsize, # necessary since generator loops infinitely\n",
    "    validation_data=valgen,\n",
    "    validation_steps=len(cifar10_x_val)//batchsize,  # necessary since generator loops infinitely\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =  0.7578449964523315\n",
      "standard deviation =  0.003335145901600307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,testgen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
